{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "import os\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "biology.html contains Learning Objectives\n",
      "extracted 100 lectures and 100 questions groups\n",
      "QUESTIONS 0\n",
      "Identify and describe the properties of life ### Describe the levels of organization among living things ### List examples of different sub disciplines in biology\n",
      "LECTURE 0\n",
      "Watch a video about Evolution by Natural Selection. Biology is the science that studies life. What exactly is life? This may sound like a silly question with an obvious answer, but it is not easy to define life. For example, a branch of biology called virology studies viruses, which exhibit some of the characteristics of living entities but lack others. It turns out that although viruses can attack living organisms, cause diseases, and even reproduce, they do not meet the criteria that biologists use to define life. From its earliest beginnings, biology has wrestled with four questions: What are the shared properties that make something “alive”? How do those various living things function? When faced with the remarkable diversity of life, how do we organize the different kinds of organisms so that we can better understand them? And, finally—what biologists ultimately seek to understand—how did this diversity arise and how is it continuing? As new organisms are discovered every day, bio\n",
      "on) Figure 1.7 by Brian0918 © Public Domain Figure 1.8 “molecule”: modification of work by Jane Whitney; “organelles”: modification of work by Louisa Howard; “cells”: modification of work by Bruce Wetzel, Harry Schaefer, National Cancer Institute; “tissue ”: modification of work by “Kilbad” © Public Domain “organs”: modification of work by Mariana Ruiz Villareal, Joaquim Alves Gaspar; “organisms”: modification of work by Peter Dutton; “ecosystem”: modification of work by “gigi4791″ © CC BY (Attribution) “biosphere”: modification of work by NASA © Public Domain Figure 1.10 EscherichiaColi NIAID : modification of work by Rocky Mountain Laboratories, NIAID, NIH © Public Domain Extremophiles modification of work by Steve Jurvetson © CC BY (Attribution) Sunflower modification of work by Michael Arrighi Lion modification of work by Frank Vassen  © CC BY (Attribution) Figure 1.12 by Mario Modesto © Public Domain Figure 1.13 by U.S. Army CID Command Public Affairs 2 1.2 The Process of Science \n",
      "\n",
      "QUESTIONS 1\n",
      "Identify the shared characteristics of the natural sciences ### Understand the process of scientific inquiry ### Compare inductive reasoning with deductive reasoning ### Describe the goals of basic science and applied science\n",
      "LECTURE 1\n",
      "Watch a video about the Scientific Method. Figure 1.14 Formerly called blue-green algae, the (a) cyanobacteria seen through a light microscope are some of Earth’s oldest life forms. These (b) stromatolites along the shores of Lake Thetis in Western Australia are ancient structures formed by the layering of cyanobacteria in shallow waters. Like geology, physics, and chemistry, biology is a science that gathers knowledge about the natural world. Specifically, biology is the study of life. The discoveries of biology are made by a community of researchers who work individually and together using agreed-on methods. In this sense, biology, like all sciences is a social enterprise like politics or the arts. The methods of science include careful observation, record keeping, logical and mathematical reasoning, experimentation, and submitting conclusions to the scrutiny of others. Science also requires considerable imagination and creativity; a well-designed experiment is commonly described as \n",
      "r) that are the fundamental molecular components of all organisms. In this chapter, we will discuss these important building blocks and learn how the unique properties of the atoms of different elements affect their interactions with other atoms to form the molecules of life. These interactions determine what atoms combine and the ultimate shape of the molecules and macromolecules, that shape will determine their function. Food provides an organism with nutrients—the matter it needs to survive. Many of these critical nutrients come in the form of biological macromolecules, or large molecules necessary for life. These macromolecules are built from different combinations of smaller organic molecules. What specific types of biological macromolecules do living things require? How are these molecules formed? What functions do they serve? In this chapter, we will explore these questions. Media Attribution Figure 2.1 by Bengt Nyman © CC BY (Attribution) 3 2.1 The Building Blocks of Molecules \n",
      "\n",
      "QUESTIONS 2\n",
      "Describe matter and elements ### Describe the interrelationship between protons, neutrons, and electrons, and the ways in which electrons can be donated or shared between atoms\n",
      "LECTURE 2\n",
      "Watch a video about electrons and how the electrons in chemical bonds influence the shape and function of molecules. At its most fundamental level, life is made up of matter . Matter occupies space and has mass. All matter is composed of elements , substances that cannot be broken down or transformed chemically into other substances. Each element is made of atoms, each with a constant number of protons and unique properties. A total of 118 elements have been defined; however, only 92 occur naturally, and fewer than 30 are found in living cells. The remaining 26 elements are unstable and, therefore, do not exist for very long or are theoretical and have yet to be detected. Each element is designated by its chemical symbol (such as H, N, O, C, and Na), and possesses unique properties. These unique properties allow elements to combine and to bond with each other in specific ways. Atoms An atom is the smallest component of an element that retains all of the chemical properties of that elem\n",
      "up of protons and (except in the case of a hydrogen atom) neutrons octet rule: states that the outermost shell of an element with a low atomic number can hold eight electrons periodic table of elements: an organizational chart of elements, indicating the atomic number and mass number of each element; also provides key information about the properties of elements polar covalent bond: a type of covalent bond in which electrons are pulled toward one atom and away from another, resulting in slightly positive and slightly negative charged regions of the molecule proton: a positively charged particle that resides in the nucleus of an atom; has a mass of 1 and a charge of +1 radioactive isotope: an isotope that spontaneously emits particles or energy to form a more stable element van der Waals interaction : a weak attraction or interaction between molecules caused by slightly positively charged or slightly negatively charged atoms Media Attribution Figure 2.4 by Bill Faulkner/NPS 4 2.2 Water \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "buildingblocks.html contains Learning Objectives\n",
      "extracted 13 lectures and 13 questions groups\n",
      "QUESTIONS 0\n",
      "Differentiate between sources that suit your purpose and those that don’t. ### Determine if an electronic source is trustworthy. ### Format a simple MLA or APA style bibliographic entry. ### Explain the importance of citation as an academic practice.\n",
      "LECTURE 0\n",
      "How do you gather background material on your topic? How can you tell a useful source from one that might lead you astray or provide inaccurate information, especially on the internet, where anyone can publish anything? And once you’ve located a trustworthy source, how do you credit it in your own bibliographical list of sources? Is citation even a big deal anymore, anyhow? 1 1.1 Finding Sources With today’s easy access to the internet and its limitless resources, finding appropriate sources seems like the easiest part of your work as a writer. Simply think up a topic, plug it into a search engine like Google, and search up the results. Pick the first likely-looking source and your job is done. Right? In fact, it’s not so simple. The internet is a little bit like the Wild West: there are very few rules. If you pick up a book and open it to a particular chapter, the book publisher almost certainly assigned it an editor, whose job it is to go over the author’s work and make sure it is ac\n",
      "s how “citation helps others” find the same work if needed (Brooks 9). Students often wonder why it is necessary to get a citation exactly right, down to questions of punctuation, capitalization, and which lines to indent. The truth? It probably isn’t. However, what is important is training yourself in the ability to apply a model to your own sources and getting good enough that you can copy it exactly. Your instructors have probably seen thousands of pages of student citations: after a while, it is extremely easy for them to pick out the mistakes. The table below gives a sample structure for APA and MLA entries. Table 1.2 Sample entries for a chapter in an edited book Citation Style Sample Entry APA LastName, First Initial(s). (Date). Title of chapter. In Editor’s Name &amp; OtherEditor’s Name (Eds.), Title of book (xx–xx). Location: Publisher. MLA LastName, FirstName. “Title of Chapter.” Title of Book , edited by Editor’s Name(s), Publisher, Year, pp. xx–xx. II Chapter 2: Prewriting \n",
      "\n",
      "QUESTIONS 1\n",
      "Understand the purpose of prewriting. ### Identify your own writing practices as linear or associative. ### Practise the three suggested prewriting options—outline, mind map, and freewriting—in different writing situations.\n",
      "LECTURE 1\n",
      "Many of us write haphazardly, using strategies we may have evolved as beginning learners. There is something incredibly frustrating in sitting and looking at a blank page, waiting for inspiration to strike. Wondering what to write about and how to start are normal parts of the writing process, and they happen to everyone—even people who make their living as writers. How can you get past the blank page? Prewriting can help. The following strategies—outlines, mind maps, and freewriting—may or may not work for you. Even if they don’t, however, they can help spark ideas for what will—and free you from the dreaded blank page. 3 2.1 Outlines Some writers swear by outlines; others loathe them. When assigned an outline in school, I would simply write the assignment, then extract the outline afterward. To this day, I’m an associative rather than a linear writer, whether I’m crafting an assignment description or revising a poem. If this also describes you, try the two techniques later in this ch\n",
      "d, your mind map should look sort of like a giant, blobby Starship Enterprise from Star Trek . 5 2.3 Freewriting Freewriting is a form of brainstorming. Whether you have been given a topic by your instructor to write on, and your mind is blank, or you have been told to pick your own topic, and your mind is also blank, you can use this technique. Freewriting involves writing for a certain amount of time—say, ten minutes—without taking your pen off the page. This means that you write down anything that comes to mind, even if that is “This is a really stupid exercise. I don’t know why I’m doing it. Wow, am I bored.” The goal is to continue writing for the specified time. There is only one rule: do not stop writing, even for a minute, during the specified time period. Your job is not to think about what you are writing, but to write. Afterwards, you’ll have a chance to go over what you wrote and pick out your favourite parts. III Chapter 3: Paragraph Structure 6 3.1 Descriptive Paragraphs \n",
      "\n",
      "QUESTIONS 2\n",
      "Understand and utilize the descriptive language associated with the five senses. ### Conceptualize the difference between showing the reader and telling the reader. ### Identify the different types of descriptive paragraphs: person, place, object, and event. ### Describe a person, a place, an object, or an event adequately and concisely. ### Master the organizational schemes associated with descriptive paragraphs. ### Indicate in writing the significance of a person, place, object, and event.\n",
      "LECTURE 2\n",
      "A descriptive paragraph provides a vibrant experience for the reader through vivid language and descriptions of something. Unlike narrative paragraphs, which must include personal thoughts, feelings, and growth, descriptive paragraphs do not need to be personal in nature. Instead, descriptive paragraphs must focus on vividly and objectively describing something to the reader. In order to provide this vivid detail, the writer must use language that appeals to the reader’s five senses: sight, smell, sound, taste, and touch. To appeal to these senses, the writer must use descriptive language, usually in the form of adjectives, that describes the sensations felt by the senses. For instance, examine the differences between the descriptions below: Sentence 1 : The tree was tall and green. Sentence 2 : The soft and damp pink flowers of the dogwood tree smelled sweet in the cool spring air as the wind whistled through its yellow-green leaves. How do these descriptions compare? If these two sen\n",
      "are important to them because they came to the graduation. The central park in their hometown is important to them because they graduated there. Their diploma is important to them because it symbolizes their graduation. Their graduation itself is important because it was the first time they saw their grandparents in ten years, at the central park in their hometown, and when they received their diploma. Hence, while in the other descriptive paragraphs, you must never let the event overshadow the significance of the person, place, or object being described, in an event descriptive paragraph, you should focus on how the people, place, and objects surrounding the event make it important. In this way, an event descriptive paragraph is a lot like the person, place, and object paragraphs. Thus, think of the objects, people, and place of an event as the characteristics that make the event important to you whenever you are constructing an event descriptive paragraph. 7 3.2 Narrative Paragraphs \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "clinicalskills.html contains Learning Objectives\n",
      "extracted 10 lectures and 10 questions groups\n",
      "QUESTIONS 0\n",
      "Define infection prevention and control practices, and list the principles and practices of infection control and prevention ### Explain how to perform hand hygiene using soap and water and alcohol-based hand rubs ### Describe how and when to use additional precautions and personal protective equipment ### Explain the difference between the three types of additional precautions: contact, airborne, and droplet ### Define blood or body fluid exposure and the steps to take if exposed ### Describe when surgical asepsis and sterile technique are used ### Explain the principles of sterile technique ### Describe how to perform various procedures such as surgical hand scrub, applying sterile gloves, and preparing a sterile field\n",
      "LECTURE 0\n",
      "2 1.2 Infection Prevention and Control Practices Infection prevention and control (IPAC) practices are evidence-based procedures and practices that can prevent and reduce disease transmission, and eliminate sources of potential infections (PIDAC, 2012). When used consistently,  IPAC practices will prevent the transfer of health care associated infections (HAIs) in all health care settings. HAIs, also known as nosocomial infections , are infections that occur in any health care setting as a result of  contact with a pathogen that was not present at the time the person infected was admitted (World Health Organization[WHO], 2009a). Two types of techniques are used to prevent infection in the hospital setting. The first, medical asepsis , or clean technique , has been used in the past to describe measures for reducing and preventing the spread of organisms (Perry, Potter &amp; Ostendorf, 2014). The second, sterile technique , also known as sterile asepsis , is a strict technique to elimina\n",
      "us and for comparison with the previous assessment. Focused assessments are done in response to a specific problem recognized by the assessor as needing further assessment of a body system. Emergency assessments are done in emergency situations. A routine physical assessment reveals information to supplement a patient’s database. The assessment is documented according to agency policy, and unusual findings are reported to appropriate members of the health care team. Ongoing, objective, and comprehensive assessments promote continuity in health care. The ability to think critically and interpret patient behaviours and physiologic changes is essential. The skills of physical assessment are powerful tools for detecting both subtle and obvious changes in a patient’s health. The assessment skills outlined in this chapter are meant to provide a framework to develop assessment competencies applicable and salient to everyday practice as recommended by Anderson, Nix, Norman, and McPike (2014). \n",
      "\n",
      "QUESTIONS 1\n",
      "Describe the purposes of physical assessment ### Describe the different types of assessment and when they should be used to inform care ### Discuss techniques to promote a patient’s physical and psychological comfort during an examination ### Make environmental preparations before an assessment ### Identify data to collect from the nursing history before an examination ### Incorporate health promotion and health teaching into an assessment ### Use physical assessment techniques and skills during routine nursing care ### Document assessment findings according to agency policy ### Communicate abnormal findings to appropriate members of the health care team\n",
      "LECTURE 1\n",
      "10 2.2 Pain Assessment “Pain is whatever the experiencing person says it is, existing whenever the experiencing person says it does” (McCaffery, 1968, cited in Rosdahl &amp; Kowalski, 2007, p. 704). Pain is a subjective experience, and self-report of pain is the most reliable indicator of a patient’s experience. Determining pain is an important component of a physical assessment, and pain is sometimes referred to as the “fifth vital sign.” Figure 2.1 Example of a pain scale Pain assessment is an ongoing process rather than a single event (see Figure 2.1). A more comprehensive and focused assessment should be performed when someone’s pain changes notably from previous findings, because sudden changes may indicate an underlying pathological process (Jarvis, Browne, MacDonald-Jenkins, &amp; Luctkar-Flude, 2014). Always assess pain at the beginning of a physical health assessment to determine the patient’s comfort level and potential need for pain comfort measures. At any other time you th\n",
      " . Toronto, ON: Elsevier-Saunders. Perry, A., Potter, P., &amp; Ostendorf, W. (2014). Clinical skills and nursing techniques (8th ed.). St Louis, MO: Elsevier-Mosby. Rosdahl, C. B., &amp; Kowalski, M. T. (2007). Textbook of basic nursing . Philadelphia, PA: Lippincott Williams &amp; Wilkins. Stephen, T. C., Skillen, D. L., Day, R. A., &amp; Jensen, S. (2012). Canadian Jensen’s nursing health assessment: A best practice approach . Philadelphia, PA: Wolters Kluwer-Lippincott. Wilson, S. F., &amp; Giddens, J. F. (2013) Health assessment for nursing practice ( 5th ed.) St Louis, MO: Mosby. III Chapter 3. Safe Patient Handling, Positioning, and Transfers 17 3.1 Introduction In health care, all patient-handling activities, such as positioning, transfers, and ambulation, are considered high risk for injury to patients and health care providers. This chapter reviews the essential guidelines for proper body mechanics and safe transfer techniques to minimize and eliminate injury in health care. \n",
      "\n",
      "QUESTIONS 2\n",
      "Describe body mechanics and principles of body mechanics ### Define musculoskeletal injury (MSI), factors that contribute to an MSI, and ways to prevent an MSI ### Describe how to complete a mobility assessment prior to positioning, transferring, or ambulating a patient ### Describe various techniques for positioning a patient in bed and types of positions ### Describe how to transfer a patient using assistive devices ### Describe how to transfer a patient from a stretcher to a bed and from a wheelchair to a bed ### Discuss how to prevent accidental falls in the acute and community setting\n",
      "LECTURE 2\n",
      "18 3.2 Body Mechanics Body mechanics involves the coordinated effort of muscles, bones, and the nervous system to maintain balance, posture, and alignment during moving, transferring, and positioning patients. Proper body mechanics allows individuals to carry out activities without excessive use of energy, and helps prevent injuries for patients and health care providers (Perry, Potter, &amp; Ostendorf, 2014). Musculoskeletal Injuries A musculoskeletal injury (MSI) is an injury or disorder of the muscles, tendons, ligaments, joints or nerves, blood vessels, or related soft tissue including a sprain, strain, or inflammation related to a work injury. MSIs are the most common health hazard for health care providers (WorkSafeBC, 2013). Table 3.1 lists risk factors that contribute to an MSI. Table 3.1 Factors That Contribute to an MSI Factor Special Information Ergonomic risk factors Repetitive or sustained awkward postures, repetition, or forceful exertion Individual risk factors Poor work\n",
      "rs Compensation Board (WCB). (2001).Understanding the risks of musculoskeletal injury (MSI). An educational guide for workers on sprains, strains and other MSIs. Retrieved on Oct 10, 2015, from WorkSafeBC. (2006). Transfer assist devices for safer handling of patients. Retrieved on April 2, 2015, from WorkSafeBC. (2010). Patient handling. Retrieved on Oct 10, 2015, from WorkSafeBC. (2013). Preventing musculoskeletal injury (MSI). Retrieved on April 2, 2015, from IV Chapter 4. Wound Care 26 4.1 Introduction Wound healing is a complex physiological process. It occurs after an injury in the cells and tissues of our bodies to restore function of the tissue. The healing process is affected by the severity of the wound, location, extent of injury, and other external and internal factors that will either inhibit or promote wound healing. A health care provider must understand how to assess a wound, assess external and internal factors, and determine treatment to optimize the healing process. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "geography.html contains Learning Objectives\n",
      "extracted 8 lectures and 8 questions groups\n",
      "QUESTIONS 0\n",
      "Discuss and describe the trajectory of urban development in British Columbia. ### Analyze how cities fit into the concept of a relational sense of place. ### Develop a comprehensive/systems thinking understanding of cities, their people and the environment.\n",
      "LECTURE 0\n",
      "1 Introduction This chapter focuses on understanding the role and processes of urbanization in the context of BC. In particular, it emphasizes recent understandings of urban sustainability and urban systems thinking. The primary goal, on finishing this chapter, is to have an understanding of the relationality and territoriality of cities; that is, understanding how cities exist in what geographer Doreen Massey calls a “ g lobal sense of place .” This will connect with the second goal of the chapter, which is to understand how cities are related to other places, and how cities are at the same time unique places. The concept of a global sense of place has three characteristics: Places have multiple identities and meanings. The meaning is dependent on the people who are experiencing a place. Places are more than physical locations; they are made up of processes. Places are not static, they are ongoing and ever changing because of relationships to other places. A global sense of place mean\n",
      "mo and Ley, David. 1994. Neighbourhood Organizations and the Welfare State . Toronto: University of Toronto Press. Hulchanski, David and Shapcott, M. 2004. Finding room: Options for a Canadian Rental Housing Strategy . Toronto: CUCS Press. Liscombe, Rhodri W. 2011. “A study in Modern(ist) urbanism: planning Vancouver, 1945–1965.” Urban History 38 (1): 124-149. Massey, D. (1991). A global sense of place. Marxism today , 35 (6), 24-29. Rosol, Marit &amp; Temenos, Cristina. (In Press). The Greenest City Experience: Exploring Social Action and Social Sustainability in Vancouver, Canada. Mössner, S., Freytag, T., Krueger, R. (eds) Adventures in Urban Sustainable Development: Theoretical interventions and notes from the field. MIT Press. Resources Federation of Canadian Municipalities Interactive demographic map of BC cities Residential School Primer Dockside Green Case Study from Terrain.org Is This The World’s Greenest Neighbourhood (The Atlantic) II 2. Socio-Economics in British Columbia \n",
      "\n",
      "QUESTIONS 1\n",
      "Discuss the measurement of socio-economic development and well-being through the use of statistical tools. ### Construct British Columbia (BC) as a desirable place to live and work. ### Assess what is understood by quality of life and BC’s (Vancouver) rank. ### Debate the “hidden” social issues behind quality of life. ### Appraise the cost of real estate as a frame for socio-economic well-being.\n",
      "LECTURE 1\n",
      "9 Introduction This chapter will focus on the notion of quality-of-life measures, livable cities and some social issues. In Geography, economic development analysis often focuses on a core-periphery global divide based on advanced technological economies versus less-developed countries (LDCs) or what is sometimes referred to as the Global South or the Third World. Economic development is measured based on a country’s gross domestic product (GDP) , gross national income (GNI) and purchasing power parity (PPP) . Gross domestic product (GDP) is usually used as an estimate of the total value of all materials, foodstuffs, goods and services that a country produces in one year. As GDP is a measure of commodities, the figure for each country is divided by the total population of the country in order to get the per capita GDP. Gross national income (GNI) is a measure of the income that flows into a country from production no matter where in the world companies from that country may be operatin\n",
      "s in Canada: Past, Present and Future”. Growing Home: Housing and Homelessness in Canada. Calgary, Alberta: University of Calgary. Knox, P.L. 1975. Social well-being: a spatial perspective . Oxford: The Clarendon Press. Mitchell, D. 2003 The Right to the City: social justice and the fight for public space . New York: Guilford Press Smith, D.M. 1973. The geography of social well-being in the United States: an introduction to territoral social indicators . New York: McGraw-Hill. Statistics Canada 2006 Takahashi, L.M., 1996. A decade of understanding homelessness in the USA: from characterization to representation. Prog Hum Geogr 20, 291–310. doi:10.1177/030913259602000301 Resources OECD Better Life Index Canadians best-off in housing, third overall in new OECD quality of life survey (Financial post) Greater Victoria Report on Housing and Supports 2012/13 Williams Lake Social Development Homeless Hub: Victoria Community Snapshot: Williams Lake III 3. Aboriginal Issues in British Columbia \n",
      "\n",
      "QUESTIONS 2\n",
      "Create a comprehensive historical summary of the Aboriginal titles and treaties. ### Identify the geographical locations of the BC treaty negotiations. ### Explain the difference between comprehensive and specific claims. ### Critically evaluate the role of the residential schools in Canadian nation building.\n",
      "LECTURE 2\n",
      "18 Introduction Archeological evidence shows that humans have inhabited the area now known as British Columbia (BC) for at least 10,000 to 12,000 years. The two most widely recognized routes for the migration of humans into the region are along the coast and through an interior ice-free corridor. The term Aboriginal refers to the ancestors of these inhabitants and includes the distinct subgroups of Inuit, Métis and First Nations peoples. Pre-contact Aboriginal communities were located throughout BC in three cultural regions identified as the northwest coast, southern Interior, and northern Interior. These three cultural regions had dramatically different ecosystems to which indigenous people adapted. The southern Interior was the most climatically dry, the northern Interior the coldest, and the northwest coast the wettest and richest in terms of animal and plant resources. Although the pre-contact Aboriginal population may have numbered over 300,000, by 1881 European settlement had red\n",
      "[WWW Document]. URL (accessed 8.27.14). Government of Canada, S.C., 2013. British Columbia – Focus on Geography Series – 2011 National Household Survey (NHS) [WWW Document]. URL (accessed 7.22.14). Hirsch, M. (2003). Trading across time and space: Culture along the North American “Grease Trails” from a European perspective. Canadian Studies International Interdisciplinary Conference: Across Time &amp; Space Visions of Canada from Abroad. University College of the Cariboo, Kamloops, Sept 12-14, 2003. Access: Indian Residential School Resources Date Accessed 11 June 2014 Rice, Brian and Snyder, Anna. (ND)  Reconciliation in the Context of a Settler Society: Healing the Legacy of Colonialism in Canada. Accessed: on 11 June 2014. Resources First People’s Language Map Indigenous Foundations Indian Residential School Resources BC Stats: External Links BC Government: Aboriginal Peoples of BC NHS Focus on Geography Series: BC First Peoples’ Cultural Council IV 4. Resources in British Columbia \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "geology.html contains Learning Objectives\n",
      "extracted 19 lectures and 19 questions groups\n",
      "QUESTIONS 0\n",
      "Explain what geology is, how it incorporates the other sciences, and how it is different from the other sciences ### Discuss why we study Earth and what type of work geologists do ### Define some of the properties of a mineral and explain the differences between minerals and rocks ### Describe the nature of Earth’s interior and some of the processes that take place deep beneath our feet ### Explain how those processes are related to plate tectonics and describe a few of the features that are characteristic of plate boundaries ### Use the notation for geological time, gain an appreciation for the vastness of geological time, and describe how very slow geological processes can have enormous impacts over time\n",
      "LECTURE 0\n",
      "1 1.1 What Is Geology? In its broadest sense, geology is the study of Earth — its interior and its exterior surface, the rocks and other materials that are around us, the processes that have resulted in the formation of those materials, the water that flows over the surface and lies underground, the changes that have taken place over the vastness of geological time, and the changes that we can anticipate will take place in the near future. Geology is a science, meaning that we use deductive reasoning and scientific methods (see Box 1.1) to understand geological problems. It is, arguably, the most integrated of all of the sciences because it involves the understanding and application of all of the other sciences: physics, chemistry, biology, mathematics, astronomy, and others. But unlike most of the other sciences, geology has an extra dimension, that of time — deep time — billions of years of it. Geologists study the evidence that they see around them, but in most cases, they are obser\n",
      "engaged in fundamental research about Earth and in teaching. 1.4 Minerals and Rocks Minerals are naturally occurring, specific combinations of elements that have particular three-dimensional structures. Rocks are made up of mixtures of minerals and can form though igneous, sedimentary, or metamorphic processes. 1.5 Fundamentals of Plate Tectonics Convection currents move through Earth’s mantle because the mantle is being heated from below by the hot core. Those convection currents cause the movement of tectonic plates (which are composed of the crust and the uppermost rigid mantle). Plates are formed at divergent boundaries and consumed (subducted) at convergent boundaries. Many important geological processes take place at plate boundaries. 1.6 Geological Time Earth is approximately 4,570,000,000 years old; that is, 4.57 billion years or 4.57 Ga or 4,570 Ma. It’s such a huge amount of time that even extremely slow geological processes can have an enormous impact. II Chapter 2 Minerals \n",
      "\n",
      "QUESTIONS 1\n",
      "Describe the nature of atoms and their constituents, particularly the behaviour of electrons and the formation of ions ### Apply your understanding of atoms to explain bonding within minerals ### Describe mineral lattices and explain how they influence mineral properties ### Categorize minerals into groups based on their compositions ### Describe a silica tetrahedron and the ways in which tetrahedra combine to make silicate minerals ### Differentiate between ferromagnesian and other silicate minerals ### Explain some of the mechanisms of mineral formation ### Describe some of the important properties for identifying minerals\n",
      "LECTURE 1\n",
      "Minerals are all around us: the graphite in your pencil, the salt on your table, the plaster on your walls, and the trace amounts of gold in your computer. Minerals can be found in a wide variety of consumer products including paper, medicine, processed foods, cosmetics, and many more. And of course, everything made of metal is also derived from minerals. As defined in Chapter 1, a mineral is a naturally occurring combination of specific elements arranged in a particular repeating three-dimensional structure (Figure 2.1). “Naturally occurring” implies that minerals are not artificially made, although many naturally occurring minerals (e.g., diamond) are also made in laboratories. That doesn’t disqualify them from being minerals. “Specific elements” means that most minerals have a specific chemical formula or composition. The mineral pyrite, for example, is FeS 2 (two atoms of sulphur for each atom of iron), and any significant departure from that would make it a different mineral. But \n",
      "have important implications for mineral properties. 2.3 Mineral Groups Minerals are grouped according to the anion part of their formula, with some common types being oxides, sulphides, sulphates, halides, carbonates, phosphates, silicates, and native minerals. 2.4 Silicate Minerals Silicate minerals are, by far, the most important minerals in Earth’s crust. They all include silica tetrahedra (four oxygens surrounding a single silicon atom) arranged in different structures (chains, sheets, etc.). Some silicate minerals include iron or magnesium and are called ferromagnesian silicates. 2.5 Formation of Minerals Most minerals in the crust form from the cooling and crystallization of magma. Some form from hot water solutions, during metamorphism or weathering, or through organic processes. 2.6 Mineral Properties Some of the important properties for mineral identification include hardness, cleavage/fracture, density, lustre, colour, and streak colour. III Chapter 3 Intrusive Igneous Rocks \n",
      "\n",
      "QUESTIONS 2\n",
      "Explain the relationships between plate tectonics, the formation of magma, and volcanism ### Describe the range of magma compositions formed in differing tectonic environments, and discuss the relationship between magma composition (and gas content) and eruption style ### Explain the geological and eruption-style differences between different types of volcanoes, especially shield volcanoes, composite volcanoes, and cinder cones ### Understand the types of hazards posed to people and to infrastructure by the different types of volcanic eruptions ### Describe the behaviours that we can expect to observe when a volcano is ready to erupt, and the techniques that we can use to monitor those behaviours and predict eruptions ### Summarize the types of volcanoes that have erupted in British Columbia over the past 2.6 Ma, and the characteristics of some of those eruptions\n",
      "LECTURE 2\n",
      "A volcano is any location where magma comes to the surface, or has done so within the past several million years. This can include eruptions on the ocean floor (or even under the water of lake), where they are called subaqueous eruptions , or on land, where they are called subaerial eruptions . Not all volcanic eruptions produce the volcanic mountains with which we are familiar; in fact most of Earth’s volcanism takes place along the spreading ridges on the sea floor and does not produce volcanic mountains at all — not even sea-floor mountains. Canada has a great deal of volcanic rock, but most of it is old, some of it billions of years old. Only in B.C. and the Yukon are there volcanoes that have been active within the past 2.6 Ma (Pleistocene or younger), and the vast majority of these are in B.C. We’ll look at those in some detail toward the end of this chapter, but a few of them are shown on Figures 4.1 and 4.2. The study of volcanoes is critical to our understanding of the geologi\n",
      "ively, especially composite volcanoes. Pyroclastic density currents, some as hot as 1000˚C can move at hundreds of km/h and will kill anything in the way. Lahars, volcano-related mudflows, can be large enough to destroy entire towns.  Lava flows will destroy anything in their paths, but tend to move slowly enough so that people can get to safety. 4.5 Monitoring Volcanoes and Predicting Eruptions We have the understanding and technology to predict volcanic eruptions with some success, and to ensure that people are not harmed. The prediction techniques include monitoring seismicity in volcanic regions, detecting volcanic gases, and measuring deformation of the flanks of a volcano. 4.6 Volcanoes in British Columbia There are examples of all of the important types of volcanoes in British Columbia, including subduction volcanism north of Vancouver, mantle-plume volcanism along the Nazco trend, and rift-related volcanism in the Wells Gray and Stikine regions. V Chapter 5 Weathering and Soil \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "graphicdesign.html contains Learning Objectives\n",
      "extracted 7 lectures and 7 questions groups\n",
      "QUESTIONS 0\n",
      "Morris ### Werkbund ### Bauhaus ### Dada ### International Typographic Style (ITS) ### Late Modern ### Post Modern ### Evaluate the influence of past design styles on one another ### Explain the influence of culture on major modern graphic design styles ### Identify the cross-cultural influences of visual culture that impacted graphic design style ### Identify the technological influences that affected and advanced graphic design\n",
      "LECTURE 0\n",
      "Industrial Revolution Overview The Craftsman Before the Industrial Revolution (1760-1840 in Britain) most aspects of design and all aspects of production were commonly united in the person of the craftsman. The tailor, mason, cobbler, potter, brewer, and any other kind of craftsman integrated their personal design aesthetic into each stage of product development. In print, this meant that the printer designed the fonts, the page size, and the layout of the book or broadsheet; the printer chose (even at times made) the paper and ran the press and bindery. Unity of design was implicit. Typography in this pre-industrial era was predominantly used for books and broadsheets. The visual flavour of the fonts was based on the historic styles of western cultural tradition — roman, black letter, italic, and grotesque fonts were the mainstay of the industry. Typography was naturally small scale — needed only for sheets and pages — and was only large when it was chiseled into buildings and monumen\n",
      " and unique design approaches that complement and speak to the new urban landscape. References Ball, H. (1996). Dada Manifesto. Flight out of time: A Dada diary . Retrieved from Bergdoll, B., &amp; Dickerman, L. (2009). Bauhaus 1919-1933: Workshops for modernity . New York City, NY: The Museum of Modern Art. Meggs, P. B., &amp; Purvis, A. W. (2011). Meggs’ history of graphic design (5th ed.). Hoboken, NJ: Wiley. Schjeldahl, P. (2009, November 16). Bauhaus rules. New Yorker. Retrieved from Schneider, S. (2011, September 20). Josef Müller-Brockmann: Principal of The Swiss School . Retrieved from Tzara, T. (1992). Dada Manifesto 1918. In Motherwell, R., Schwitters, K., et al. (Eds). The Dada Painters and Poets (81 ) . Boston, MA: GK Hall &amp; Co. Whitford, F. (1995). Bauhaus . London, England: Thames and Hudson. Suggested Reading Meggs, P. B. (1998). A history of graphic design (3rd ed). New York City, NY: John Wiley &amp; Sons. II Chapter 2. Design Process 10 2.1 Introduction Alex Hass \n",
      "\n",
      "QUESTIONS 1\n",
      "Explain the role of communication design in print and media ### Describe how the creative process relates to strategic problem solving ### Contrast how the creative process relates to the design process ### Define critical phases of the design process ### Discover how project research helps to define a communication problem ### Give examples of brainstorming techniques that generate multiple concepts based on a common message ### Learn about metaphors and other rhetorical devices to generate concepts ### Explore how concepts translate into messages within a visual form\n",
      "LECTURE 1\n",
      "Communication Design and The Design Process The practice of graphic or communication design is founded on crafting visual communications between clients and their audience. The communication must carry a specific message to a specific audience on behalf of the client, and do so effectively — usually within the container of a concept that creates context and builds interest for the project in the viewer. See an illustrated model of the design process here: A Model of the Creative Process Overview of the Design Process The process of developing effective design is complex. It begins with research and the definition of project goals. Defining goals allows you to home in on precisely what to communicate and who the audience is. You can then appropriately craft the message you are trying to communicate to them. Additional information regarding how to deliver your message and why it’s necessary are also clarified in the research stage. Often the preferred medium becomes clear (i.e., web, soc\n",
      "etitor analysis – A graphic design perspective. Ezine Articles . Retrieved from Frey, C. (2008). How to generate breakthrough ideas using a concept tree . Retrieved from Gianatasio, D. (2013, July 2). Happy 25th birthday to Nike’s ‘Just Do It,’ the last great advertising slogan. Adweek. Retrieved from Grossnickle, T., Feldmann, D., White, A., &amp; Parkevich, N. (2010). Millennial donors: A study of millennial giving and engagement habits . Achieve and Johnson Grossnickle Associates. Retrieved from Harris, R. A. (2013). A handbook of rhetorical devices . VirtualSalt . Retrieved from Tanyel, F., Stuart, E. W., &amp; Griffin, J. (2013). Have “Millennials” embraced digital advertising as they have embraced digital media? Journal of Promotion Management , 19 (5), 652–673. Suggested Reading Dubberly Design Office. (2009, March 20). A model of the creative process . Retrieved from III Chapter 3. Design Elements, Design Principles, and Compositional Organization 17 3.1 Introduction Alex Hass \n",
      "\n",
      "QUESTIONS 2\n",
      "Utilize basic design principles relating to visual composition ### Define design terminology pertaining to form ### Describe organizational systems and core principles for layout grids ### Differentiate between typographic categories ### Establish a visual hierarchy within a layout ### Express ideas using the principles of composition and form\n",
      "LECTURE 2\n",
      "Communication design is essentially the crafting of a message meant for a specific section of the public. This written message is infused with meaningful and relevant visual components. The composition of these components should amplify, clarify, and enhance the message for the viewer. To assist in making sound design choices, a designer applies principles of composition and principles of organization to the design elements selected for a project. Understanding how to utilize the fundamentals of design elements, principles, and composition is necessary to be able to confidently move through the stages of the design development process and build a project from the initial design brief to the final published design work. Definitions from various design sources about what comprises a design element are consistent for the most part, but defining design principles is not as consistent and varies from one text to the next. Marvin Bartel’s (2012) definitions of these categories are both simpl\n",
      "anuary 31). Counterpart and counterpoint in typographic hierarchy . Vanseo Design . Retrieved from Bringhurst, R. (2004). The elements of typographic style (3rd ed.). Point Roberts, WA: Hartley and Marks Publishers. Lupton, E., &amp; Phillips, J. C. (2014). Graphic design: The new basics (2nd ed.). New York City, NY: Princeton Architectural Press. Moholy-Nagy, L. (1947). The new vision and abstract of an artist. (1st ed.). New York City, NY: Wittenborn. Porter, J. (2010, March 12). Visual hierarchy. 52 Weeks of UX , week 10. Retrieved from Suggested Readings Bradley, S. (2011, January 31). Counterpart and counterpoint in typographic hierarchy . Vanseo Design . Retrieved from Elam, K. (2007). Typographic systems . New York City, NY: Princeton Architectural Press. Designhistory.org (2011). The Sans Serif Retrieved from Taylor, K. (n.d.). The metaphysics of color . Philosophy talk . Retrieved from IV Chapter 4. Colour Management in the Graphic Technologies 22 4.1 Introduction Alan Martin \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "h5ppsychology.html contains Learning Objectives\n",
      "extracted 88 lectures and 88 questions groups\n",
      "QUESTIONS 0\n",
      "Understand the etymology of the word “psychology” ### Define psychology ### Understand the merits of an education in psychology\n",
      "LECTURE 0\n",
      "In Greek mythology, Psyche was a mortal woman whose beauty was so great that it rivaled that of the goddess Aphrodite. Aphrodite became so jealous of Psyche that she sent her son, Eros, to make Psyche fall in love with the ugliest man in the world. However, Eros accidentally pricked himself with the tip of his arrow and fell madly in love with Psyche himself. He took Psyche to his palace and showered her with gifts, yet she could never see his face. While visiting Psyche, her sisters roused suspicion in Psyche about her mysterious lover, and eventually, Psyche betrayed Eros’ wishes to remain unseen to her. Because of this betrayal, Eros abandoned Psyche. When Psyche appealed to Aphrodite to reunite her with Eros, Aphrodite gave her a series of impossible tasks to complete. Psyche managed to complete all of these trials; ultimately, her perseverance paid off as she was reunited with Eros and was ultimately transformed into a goddess herself (Ashliman, 2001; Greek Myths &amp; Greek Mytho\n",
      "t, and our experiences in determining who we are and how we will behave. They learn about basic principles that guide how we think and behave, and they come to recognize the tremendous diversity that exists across individuals and across cultural boundaries (American Psychological Association, 2011). Watch a brief video that describes some of the questions a student should consider before deciding to major in psychology: Why Major in Psychology? A YouTube element has been excluded from this version of the text. You can view it online here: Summary Psychology derives from the roots psyche (meaning soul) and –ology (meaning scientific study of). Thus, psychology is defined as the scientific study of mind and behavior. Students of psychology develop critical thinking skills, become familiar with the scientific method, and recognize the complexity of behavior. Personal Application Question “ iDelcare – Why Major in Psychology? ” by humbiomovies . CC BY 3.0 Licence . 2 History of Psychology \n",
      "\n",
      "QUESTIONS 1\n",
      "Understand the importance of Wundt and James in the development of psychology ### Appreciate Freud’s influence on psychology ### Understand the basic tenets of Gestalt psychology ### Appreciate the important role that behaviorism played in psychology’s history ### Understand basic tenets of humanism ### Understand how the cognitive revolution shifted psychology’s focus back to the mind\n",
      "LECTURE 1\n",
      "Psychology is a relatively young science with its experimental roots in the 19th century, compared, for example, to human physiology, which dates much earlier. As mentioned, anyone interested in exploring issues related to the mind generally did so in a philosophical context prior to the 19th century. Two men, working in the 19th century, are generally credited as being the founders of psychology as a science and academic discipline that was distinct from philosophy. Their names were Wilhelm Wundt and William James. This section will provide an overview of the shifts in paradigms that have influenced psychology from Wundt and James through today. Wundt and Structuralism Wilhelm Wundt (1832–1920) was a German scientist who was the first person to be referred to as a psychologist. His famous book entitled Principles of Physiological Psychology was published in 1873. Wundt viewed psychology as a scientific study of conscious experience, and he believed that the goal of psychology was to i\n",
      " shift back to its roots of focus on mental processes. The emergence of neuroscience and computer science aided this transition. Ultimately, the cognitive revolution took hold, and people came to realize that cognition was crucial to a true appreciation and understanding of behavior. Personal Application Questions Glossary Image Descriptions Maslow’s Heirarchy of Needs Image Description: A pyramid shape divided into five horizontal sections that are labelled. From top to bottom, the triangle’s sections are labeled as follows: Self-actualization corresponds to “Inner fulfillment”; Esteem corresponds to “Self-worth, accomplishment, confidence”; Social corresponds to “Family, friendship, intimacy, belonging”; Security corresponds to “Safety, employment, assets”; Physiological corresponds to “Food, water, shelter, warmth.” [Return to Maslow’s Heirarchy of Needs image] “ Carl Rogers on Person-Centered Therapy Video ” by PsychotherapyNet . Standard YouTube License. 3 Contemporary Psychology \n",
      "\n",
      "QUESTIONS 2\n",
      "Appreciate the diversity of interests and foci within psychology ### Understand basic interests and applications in each of the described areas of psychology ### Demonstrate familiarity with some of the major concepts or important figures in each of the described areas of psychology\n",
      "LECTURE 2\n",
      "Contemporary psychology is a diverse field that is influenced by all of the historical perspectives described in the preceding section. Reflective of the discipline’s diversity is the diversity seen within the American Psychological Association (APA) . The APA is a professional organization representing psychologists in the United States. The APA is the largest organization of psychologists in the world, and its mission is to advance and disseminate psychological knowledge for the betterment of people. There are 56 divisions within the APA, representing a wide variety of specialties that range from Societies for the Psychology of Religion and Spirituality to Exercise and Sport Psychology to Behavioral Neuroscience and Comparative Psychology. Reflecting the diversity of the field of psychology itself, members, affiliate members, and associate members span the spectrum from students to doctoral-level psychologists, and come from a variety of places including educational settings, crimina\n",
      "e description: A diagram describing what a low and high score in each of the traits in the five factor model looks like: Five Factor Model Trait Low score High score O – Opennes (imagination, feelings, actions, ideas) Practical, conventional, prefers routine Curious, wide range of interests, independent C – Conscientiousness (competence, self-discipline, thoughtfulness, goal driven) Impulsive, careless, disorganized Hardworking, dependable, organized E – Extroversion (sociability, assertiveness, emotional expression) Quiet, reserved, withdrawn Outgoing, warm, seek adventure A – Agreeableness (cooperative, trustworthy, good-natured) Critical, uncooperative, suspicious Helpful, trusting, empathetic N – Neuroticism (tendency toward unstable emotions) Calm, even-tempered, secure Anxious, unhappy, prone to negative emotions [Return to Five Factor Model image] “ 1.2 – Lesson 1 – introduction to cognitive psychology ” by Abbey SocialScience . Standard YouTube License. 4 Careers in Psychology \n",
      "\n",
      "found too many blacklisted strings\n",
      "d understanding of behavior. Personal Application Questions Glossary Image Descriptions Maslow’s Heirarchy of Needs Image Description: A pyramid shape divided into five horizontal sections that are labelled. From top to bottom, the triangle’s sections are labeled as follows: Self-actualization corre\n",
      "y and in our personal lives. Personal Application Questions Glossary Image Descriptions Scientific Method image description: A diagram showing the cycle of the scientific method: Theory. Use the theory to form a hypothesis. Hypothesis. Design a study to test the hypothesis. Research. Perform the res\n",
      "population at a single time. Personal Application Questions Glossary 8 Analyzing Findings \n",
      " are being treated humanely. Personal Application Questions Glossary 10 References American Academy of Pediatrics, American Academy of Child &amp; Adolescent Psychiatry, American Psychological Association, American Medical Association, American Academy of Family Physicians, American Psychiatric Asso\n",
      " genes and our environments. Personal Application Questions Glossary “ In the Expert’s Chair with Dr. David Buss ” by PsychologyLive . Standard YouTube License. 12 Cells of the Nervous System \n",
      "ng under relaxed conditions. Personal Application Questions Glossary 14 The Brain and Spinal Cord \n",
      "nd structure simultaneously. Personal Application Questions “ Clive Wearing Living Without Memory. ” by Mike Forte . Standard YouTube License. 15 The Endocrine System \n",
      "am vary gradually over time. Personal Application Questions Glossary 16 References Arnst, C. (2003, November). Commentary: Getting rational about health-care rationing. Bloomberg Businessweek Magazine . Retrieved from Berridge, K. C., &amp; Robinson, T. E. (1998). What is the role of dopamine in rew\n",
      " physiological consequences. Personal Application Questions Glossary “ Reprogramming Our Circadian Rhythms for the Modern World ” by Big Think . Standard YouTube License. “ 6 Tips To Beat Jet Lag ” by Greg and Mitch . Standard YouTube License. 18 Sleep and Why We Sleep \n",
      "he mind that helps a person during consciousness. Review Questions Personal Application Question 20 Sleep Problems and Disorders \n",
      "th cataplexy and hallucination. Critical Thinking Questions One of the recommendations that therapists will make to people who suffer from insomnia is to spend less waking time in bed. Why do you think spending waking time in bed might interfere with the ability to fall asleep later? Answers will va\n",
      "influenced by bias, prejudice, and other factors. Review Questions Critical Thinking Question The central tenet of Gestalt psychology is that the whole is different from the sum of its parts. What does this mean in the context of perception? This means that perception cannot be understood completely\n",
      "earning by observing others. Personal Application Questions Glossary 32 Classical Conditioning \n",
      " or variable period of time. Personal Application Questions Think of a behavior that you have that you would like to change. How could you use behavior modification, specifically positive reinforcement, to change your behavior? What is your positive reinforcer? “ Operant conditioning ” by jenningh .\n",
      "recognition, and relearning. Personal Application Questions Glossary “ Endless Memory, Part 1 ” by CBS News . Standard YouTube License. 44 Parts of the Brain Involved with Memory \n",
      "ory) is not always accurate. Personal Application Questions Glossary “ A Mouse. A Laser Beam. A Manipulated Memory ” by TED. CC BY-NC-ND 4.0 . “ How does your memory work? | Head Squeeze ” by BBC Earth Lab . Standard YouTube License. 45 Problems with Memory \n",
      "recall of older information. Personal Application Questions Glossary “ Scott Bolzan – My Life Was Deleted ” by Kevin Spidel . Standard YouTube License. 46 Ways to Enhance Memory \n",
      "u to study more effectively. Personal Application Questions “ Feats of Memory Anyone Can Do ” by TED. CC BY-NC-ND 4.0 . 47 References Abel, M., &amp; Bäuml, K.-H. T. (2013). Sleep can reduce proactive interference. Memory, 22 (4), 332–339. doi:10.1080/09658211.2013.785570. Retrieved from Anderson, N\n",
      "rsus nurture on development. Personal Application Questions Glossary 49 Lifespan Theories \n",
      "n our cognitive development. Personal Application Questions Glossary “ Piaget – Stage 1 – Sensorimotor stage : Object Permanence ” by Geert Stienissen . Standard YouTube License. “ A typical child on Piaget’s conservation tasks ” by munakatay . Standard YouTube License. “ Piaget’s Mountains Task ” b\n",
      " remain important as we age. Personal Application Questions Glossary “ Reflexes in newborn babies ” by Bernadette Bos . Standard YouTube License. “ The “False Belief” Test: Theory of Mind ” by 007IceWeasel . Standard YouTube License. “ Harlow’s Studies on Dependency in Monkeys ” by Michael Baker . S\n",
      "ble, supportive environment. Personal Application Questions Glossary “ Randy Pausch Last Lecture: Achieving Your Childhood Dreams ” by Carnegie Mellon University . Standard YouTube License. 52 References Ainsworth, M. D. S., &amp; Bell, S. M. (1970). Attachment, exploration, and separation: Illustra\n",
      ", and cultural perspectives. Personal Application Questions Glossary “ Video Lecture: Explain the Major Perspectives on Personality ” by wkeenecsu . Standard YouTube License. 59 Freud and the Psychodynamic Perspective \n",
      "es leads to a healthy adult. Personal Application Questions Glossary “ Freudian Defense Mechanisms ” by Brad Wray . Standard YouTube License. 60 Neo-Freudians: Adler, Erikson, Jung, and Horney \n",
      "rmation from their patients. Personal Application Questions Glossary 61 Learning Approaches \n",
      "y external locus of control. Personal Application Questions Glossary Media Attribitions “ Don’t eat the marshmallow! | Joachim de Posada ” by TED . Standard YouTube License. 62 Humanistic Approaches \n",
      "best person they can become. Personal Application Questions Glossary 63 Biological Approaches \n",
      "personalities are expressed. Personal Application Questions Glossary 64 Trait Theorists \n",
      "its occur along a continuum. Personal Application Questions Glossary 65 Cultural Understandings of Personality \n",
      "both elements of both views. Personal Application Questions Glossary 66 Personality Assessment \n",
      "l forms of projective tests. Personal Application Questions Glossary 67 References Adler, A. (1930). Individual psychology. In C. Murchison (Ed.), Psychologies of 1930 (pp. 395–405). Worcester, MA: Clark University Press. Adler, A. (1937). A school girl’s exaggeration of her own importance. Internat\n",
      "hat bolster our self-esteem. Personal Application Questions Glossary 69 Self-presentation \n",
      "ary to our typical behavior. Personal Application Questions Glossary 70 Attitudes and Persuasion \n",
      "fame, and positive emotions. Personal Application Questions Glossary 71 Conformity, Compliance, and Obedience \n",
      "efforts cannot be evaluated. Personal Application Questions Glossary “ conformity ” by freescoring . Standard YouTube License. 72 Prejudice and Discrimination \n",
      "egoat for their frustration. Personal Application Questions Glossary “ What Would You Do? Bike Theft (White Guy, Black Guy, Pretty Girl) ” by VladCantSleep . Standard YouTube License. 73 Aggression \n",
      "d of any one person helping. Personal Application Questions Glossary 74 Prosocial Behavior \n",
      " maintaining a relationship. Personal Application Questions Glossary “ Good Deeds Do NOT exist | Friends | 77Math ” by Emy Ahmad . Standard YouTube License. 75 References Adams, H. E., Wright, L. W., Jr., &amp; Lohr, B.A. (1996). Is homophobia associated with homosexual arousal? Journal of Abnormal \n",
      "efore they become a problem. Personal Application Questions Glossary 79 Human Factors Psychology and Workplace Design \n",
      " in Human Factors Psychology Area Description I-O Questions Attention Includes vigilance and monitoring, recognizing signals in noise, mental resources, and divided attention How is attention maintained? What about tasks maintains attention? How to design systems to support attention? Cognitive engi\n",
      "unds, or private (self) pay. Personal Application Questions Glossary 100 Types of Treatment \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "haircolourforhairstylistslevel2.html contains Learning Objectives\n",
      "extracted 7 lectures and 7 questions groups\n",
      "QUESTIONS 0\n",
      "Interpret basic colour theory and how it applies to formulating hair colour ### Interpret how hair behaves, and analyze the factors to consider when colouring hair ### Distinguish between non-oxidative and oxidative colouring products and how they work\n",
      "LECTURE 0\n",
      "To become a great hair colourist, you must understand the basics of colour theory and trichology. Once you have a solid understanding how colour works and how hair behaves, you will gain the confidence to get more creative with your formulating and placement. This chapter serves as an important recap of colour theory and colour-relevant trichology, along with the basics of non-oxidative and oxidative colouring products. These principles are fundamental to your success as a hair colourist and this section aims to prepare you for what is to follow throughout this manual. 1 1.1 Colour Theory Colour has three main characteristics: Hue , level , and intensity . Hue You will have learned in Hairstylist Foundations that the three primary (or “pure”) colours are red, yellow, and blue. Every colour (or hue) that exists is the result of mixing two or three primary colours in varying proportions. When all three are mixed in varying, yet fairly equal amounts, these primary colours create our natur\n",
      " colour products have a mixture of small and large colour molecules, with the larger sitting near the surface of the cuticle layer and the smaller sitting within the cuticle and cortex layers. Oxidant colour molecures. Non-Oxidative Colours Non-oxidative semi and temporary colouring products generally have an acid pH and therefore do not swell the hair strand as much, which makes them a gentler option. Semi and temporary colours are deposit only and cannot lift hair colour to a lighter level. These products contain large colour molecules which sit on the surface of the cuticle layer. Non-oxidant colour molecules Once you have a solid understanding of how and why colour works the way it does, you will be better equipped to apply that knowledge to your colour consultations and colour formulations. In Chapter 2: The Consultation , we will review these principles in more depth. All images in this chapter are by A. Magtiza and are under a CC BY 4.0 Licence . II Chapter 2 - The Consultation \n",
      "\n",
      "QUESTIONS 1\n",
      "Identify the appropriate use and content of a client record ### Perform all stages of a thorough client consultation ### Perform a thorough colour assessment\n",
      "LECTURE 1\n",
      "Every successful client interaction begins with a comprehensive consultation. As a stylist, learning to communicate with the client to ensure that you are both on the same page is key. This includes learning to recognize, inform, and educate the client on their particular hair limitations, all within a professional manner. Remember, there is no such thing as a one-formula-fits-all colour service! 4 2.1 Client Records Why keep client records? A client record helps the stylist communicate with the client by tracking changes in lifestyle and hair health, as well as keeping record of previous hair services, including colour formulations, haircut preferences, and retail products. Most salons will keep an electronic record using their POS (point of sale) system, although some may choose to keep a paper file on each client. An electronic record system can save valuable salon space and is usually tied into each client’s booking profile, making it easy to access at the click of a button. Many o\n",
      "t poorly. A strand test is conducted by applying your chosen formula(s) to a strand of hair, usually in a concealed area of the head. If you are dealing with multiple hair conditions and formulas, you should do a strand test in each area of concern. Apply and process your test formula according to manufacturers guidelines to ensure you will get an accurate result. Then, assess the results and work together with the client to decide on a course of action. Congratulations! Your consultation is complete and you have gathered all the information necessary to perform a successful colour service! In Chapter 3: Product Selection and Formulation , you will learn how to apply this information to determine your choice of colouring product and to formulate your colour, In addition, we will review the various tools used for a variety of colour techniques and services. All images in this chapter are by A. Magtiza and are under a CC BY 4.0 Licence . III Chapter 3 - Product Selection and Formulation \n",
      "\n",
      "QUESTIONS 2\n",
      "Compare and contrast oxidative and non-oxidative coloring products ### Select an appropriate colouring product based on hair analysis and consultation ### Utilize the colour wheel to neutralize or enhance existing tone ### Select the ideal tools and supplies to perform various application techniques\n",
      "LECTURE 2\n",
      "In this chapter, you will learn about the different product options for lightening and darkening hair while focusing on the hair texture considerations that should be factored into your product selection. You will also review the various tools and supplies used for different colouring techniques. 7 3.1 Colouring Products Now comes time to choose a colouring product to use. But first, recap the necessary steps that got you to this point! Assess hair and scalp Porosity , elasticity and texture Existing level and tone Percentage of grey Perform a thorough client consultation Determine target level and tone Discuss maintenance, commitment, and budget Next, you must: Select an appropriate colouring product based on: Lift or deposit Grey coverage Hair assessment Lasting ability Application technique Consider existing tone/ underlying pigment Enhance or neutralize Select appropriate tools and supplies for selected application technique Depositing, or Going Darker Let’s first compare options f\n",
      " processing progress Keeps product moist without insulating Hard to work with Not efficient/ must rip as you work Difficult to remove individual sections NO No-stick Film Balayage Ombré Backcombing techniques Bleach Colour Cost effective Non-slip Transparent to see placement and processing progress Keeps product moist without insulating Pre-ripped sheets Easy to use Difficult to remove individual sections NO Thermal Strips Highlighting Lowlighting Weaves Slices Bleach Colour Heavy direct-dye product Lightweight Sturdy Non-slip Insulating Can apply product close to scalp Pre-ripped Easy and efficient to use Easy to remove Must open to view processing progress YES Meche Balayage Ombré Backcombing techniques Bleach Colour Heavy direct-dye product Non-slip Transparent to see placement and processing progress Keeps product moist without insulating Pre-ripped Easy and efficient to use Easy to remove May slip Not ideal for small sections YES IV Chapter 4 - Lightening Virgin Hair and Regrowth \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "humanresourcesinfoodservices.html contains Learning Objectives\n",
      "extracted 5 lectures and 5 questions groups\n",
      "QUESTIONS 0\n",
      "Describe current human resources department principles and practices ### Describe the various functions of human resources management ### Describe current human resources management issues ### Describe the human resources planning process\n",
      "LECTURE 0\n",
      "Human resources management (HRM) is often perceived as an extra cost for businesses; however, the opposite can be true. Regardless of the type of business you are running, in order to successfully attract and retain good workers, you need to have a good understanding of effective human resources practices and implement those practices in your business. A well-planned HRM program that is tailored to your organization and staff can actually improve your business’s bottom line. Increasingly, employers in the hospitality sector are recognizing the importance of, and challenges associated with, attracting and retaining good workers and are placing human resources issues at the top of their priority list. Business success can never be achieved by just one person; it takes a team – and the right team – for you and your business. So how do you find, attract, and keep the right people to work for you and your business? You do this by putting employees first. Some of the overall benefits of good\n",
      "following six questions before hiring can help with the process. Your answers will increase your success rate, save you valuable time and resources, and provide you with employees who can quickly fit well into your company. How many new employees do I need? How much should I budget for a new employee? What dollar amount do you need to allow for salary, training, and benefits? What type of employee do I need? Do you require full-time, part-time, long-term, or seasonal employees? What skills do they need? What level/length of previous experience is important for the employees to have? Should they have supervisory experience? What do I need my new employee to do? What specific duties will employees be responsible for? Are there any responsibilities outside the role? When do I need the employee to start? Where can I find my ideal candidate? What resources to find candidates have you used or do you know of? Who can you ask to learn about new resources? II Employee Recruitment and Selection \n",
      "\n",
      "QUESTIONS 1\n",
      "Describe the employee recruitment process ### Write job descriptions ### Describe internal and external recruitment methods ### Describe how to prepare for and conduct an interview ### Evaluate and select candidates ### Know and apply the human rights legislation\n",
      "LECTURE 1\n",
      "Figure 1. The typical stages of employee recruitment and selection. 3 Job Analysis: A Crucial First Step The job analysis is a crucial first step. It’s the foundation of the recruitment and selection process. Job analysis is the process of collecting information about the specifics of each job in the organization. A job analysis answers the question “What does the job involve?” It is a list of behaviours and skills required to do the job. But how do you really know what the job involves? There are many ways to gather this job information depending on the size and scope of your operation. Methods can include: Surveys completed by current employees Managers interviewing employees who are currently doing the job General observation It is important that all key stakeholders participate in the job analysis process to ensure the information is accurate and for employee buy-in. No one knows the job better than the person who does it, and both manager and employee perspectives are important so\n",
      " for your jurisdiction.) Specifically the BC Human Rights Code sets out the following list of protected grounds that you cannot ask about or discriminate against: Race Colour Ancestry Religion Place of origin Age Sex Sexual orientation Marital status Family status Physical or mental disability Political belief Criminal or summary conviction offence that is unrelated to the employment or to the intended employment of that person Interview questions should avoid these protected grounds and focus strictly on determining the applicant’s ability to perform the essential duties of the available position. For more information on complying with human rights legislation, the following resources are available: Websites BC Human Rights Tribunal Canadian Human Rights Commission Videos Canadian Human Rights Act video What Is Discrimination? video Duty to Accommodate video Harassment video Fact sheets Human Rights in British Columbia [PDF] Human Rights in Employment [PDF] III Performance Management \n",
      "\n",
      "QUESTIONS 2\n",
      "Describe the components of an orientation program ### Describe the components of a training program ### Describe employment development programs ### Identify the basics of an employee performance planning and review program ### Describe the role of discipline in performance management ### Describe termination procedures and legal issues\n",
      "LECTURE 2\n",
      "12 Orientation Orientation is an event that is structured and organized to focus on all the information a new employee needs to get started in a new job. Orientation is the best time to influence and shape perceptions and attitudes in new employees. According to the Merriam-Webster Dictionary , the word orient means “to acquaint with an existing situation or environment” (Encyclopedia Britannica Company, n.d.). Therefore one of the main objectives of an orientation program is to integrate employees into their new work environment. The goals of orientation are to: Familiarize new hires with your organization’s history, current undertakings, and future plans Inform them about relevant policies and procedures Outline desired workplace philosophy and behaviours when people are most receptive Why orientation? Orientation is well worth the time. With the focus on integrating into the organization, orientation allows a new employee to feel comfortable in the environment and with the new job. \n",
      "ailable information. When you meet with the employee for the final termination meeting, hold it in a private location where the employee will not have to walk past co-workers afterwards. Have a witness or backup present in case the conversation gets heated. Explain how the employee has continued to perform below expectations. Refer to warnings given earlier. Announce the termination. Collect all property of the company, such as keys and uniforms. Ensure that the employee’s hours of work are sent to the payroll department, and final cheques and vacation pay are paid out according to the provincial regulations. Inform the employee of any information they need to know, such as when the final paycheque will be ready if not already available, where to hand in keys and uniform, and if and when there will be an exit interview. In all termination cases, aim to preserve the dignity of the employee and to have them leave with the feeling of being treated fairly and with respect. IV Compensation \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "indigenousperspectivesbusiness.html contains Learning Objectives\n",
      "extracted 23 lectures and 23 questions groups\n",
      "QUESTIONS 0\n",
      "Describe the effects of the Royal Proclamation, 1763. ### Identify which government is responsible for relationships with Indigenous peoples.\n",
      "LECTURE 0\n",
      "British America and New France were both initially established as trading posts, then as colonies of their mother countries in the late 1500s through the early 1700s with the assistance of Indigenous persons in modern-day northeastern United States and eastern Canada. In the 1750s, the French and Indian War was a theatre of the Seven Years’ War fought between Great Britain and France. British colonialists led by James Wolfe triumphed over New France led by Montcalm in the Battle of the Plains of Abraham (Eccles, 2021). However, that victory was not achieved without help from the Iroquois Confederacy, also known as the Five Nations: the Mohawk, Onondaga, Oneida, Cayuga, and Seneca (Bleiweis, 2013). A problem arose in the aftermath of the French and Indian War. Colonials in British America, in search of new land, were travelling west into the continent. On their way, they purchased or stole lands from Indigenous persons, and asked their government to protect their newfound property. This\n",
      "ady fragile bond of the Union, refused to enforce the judgment (Paul, 2018). The cost was an immense human tragedy. This series of events led to the heartbreaking Trail of Tears, in which 12,000 people were forcibly marched 1,300 kilometres. Four thousand of those people never made it. Not only was this tragic event permitted in order to avoid a conflict between the national government and the Southern states, but the American Civil War occurred anyway not three decades later (National Park Service, 2020). In Canada, Great Britain continued to assert its role in governing Canada until the British North America Act, 1867 (the first of Canada’s two constitutions). After, the Government of Canada assumed responsibility for its relationship with First Peoples. To this day, the federal government remains responsible for the Crown’s relationship with Indigenous Peoples, although the provinces have been active partners in guiding the actions of the federal government. 2 The Numbered Treaties \n",
      "\n",
      "QUESTIONS 1\n",
      "Consider why the Government of Canada set out to negotiate the Numbered Treaties. ### Analyze the effects of the Numbered Treaties on Aboriginal Title in British Columbia.\n",
      "LECTURE 1\n",
      "The first order of business for the Canadian government was twofold: secure land for settlement and the construction of the Canadian Pacific Railway to unite the provinces. The Royal Proclamation made it illegal for individuals or businesses to make agreements with Indigenous communities, and the land was explicitly reserved for all Indigenous Peoples. To do this, the government had to purchase lands and so engaged in the process of negotiating the “Numbered Treaties” (Black, 2014). Map of the Numbered Treaties negotiated in the late 1800s to early 1900s. [Numbered Treaties Map image description] The Numbered Treaties remain controversial to this day. The Government of Canada views them as treaties for the legal purchase of land, with modest “reserves” set aside for Indigenous groups (Filice, 2016). Affected groups viewed the treaties as a “right-of-way” or a sharing agreement, or did not understand the language that would have made clear the intent of the Canadian government. Further,\n",
      "h Columbia. Image Descriptions A map of Canada showing the lands covered by each of the eleven Numbered Treaties that were established between 1871 and 1921. It includes most of northern and western Ontario, all of Manitoba, Saskatchewan, and Alberta, northeastern British Columbia, most of Northwest Territories, southeastern Yukon, and a small bit of northwestern Nunavut. [Return to Numbered Treaties Map] “ Numbered Treaties Map ” by Themightyquill is licensed under a CC BY-SA 2.5 Licence . Adapted from Canada Location Map by Yug , which is licensed under a CC BY-SA 2.5 Licence . See also Indigenous and Northern Affairs Canada, 2010. Douglas had also negotiated treaties on Vancouver Island before becoming governor of British Columbia (see Douglas Treaties ). These are similar in nature to the Numbered Treaties, but as they were not negotiated by the Government of Canada, they are not considered part of that series of treaties. 3 The Indian Act, Residential Schools, and the White Paper \n",
      "\n",
      "QUESTIONS 2\n",
      "Explain the justification for the White Paper. ### Identify why the Indian Act was enacted. ### Consider why Indigenous people opposed the White Paper.\n",
      "LECTURE 2\n",
      "Government-funded residential schools opened in the 1880s and operated until 1996. In this system, Indigenous children across Canada were removed from their parents and taught in Christian-run schools. Residential schools operated in various forms before the Indian Act (1876) came into effect. This is because education provisions in treaties were negotiated so that Indigenous youth could “learn the skills of the newcomer society and help them make a successful transition to a world dominated by the strangers” (Miller, 2020). After the passage of the Indian Act, the goals of government-mandated Indigenous education changed. They became about not just learning the tools to succeed in a modern world, but also the assimilation of Indigenous people into Euro-Canadian culture. To achieve this goal, Indigenous youth were separated from their parents, transported to remote locations, given a “white man’s name,” and forbidden to speak their native language. They also attended Anglican or Cathol\n",
      " commissioner would be appointed to resolve land claims and terminate existing treaties. These recommendations were dramatic. The Indian Act is legislation that has numerous flaws, including imposing Canadian law unilaterally on Indigenous groups. Still, it at the very least acknowledged the special status of Indigenous Peoples due to their living on the continent first. The White Paper sought to remove that privilege as a means to equalize the status of all Canadians. The White Paper never became law due to the backlash against it. One of the lasting effects of the White Paper was the formation of Indigenous political groups, including the Union of British Columbia Indian Chiefs (Indigenous Foundations, 2009b). Note that “Indian” is the term used in foundational Canadian documents and is a legal term that remains in use to this day. This is no longer an acceptable form of address outside the strict legal usage. 5 The Constitution Act, 1982, and Court Cases from the 1970s to the 2010s \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ingredients.html contains Learning Objectives\n",
      "extracted 12 lectures and 12 questions groups\n",
      "QUESTIONS 0\n",
      "Identify and describe sugar and other sweeteners used in the food service industry ### Describe the production of sugar and other sweeteners ### Describe the function of sweeteners in baking\n",
      "LECTURE 0\n",
      "We often think of baked goods as being sweet, and sweeteners play an important role in the world of food and baking in particular. Sweetness is one of the key elements of taste (which is explored in more detail in the open textbook Nutrition and Labelling for the Canadian Baker ) but sugars play many other important roles in baking, including contributing to texture, colour, and the chemical processes needed for fermentation. Sweetness is only one of the considerations, and this group of ingredients and how they affect different aspects of the baking process is a key to understanding baking science. 13 Sugar Chemistry Chemically, sugar consists of carbon (C), oxygen (O), and hydrogen (H) atoms, and is classified as a carbohydrate . There are three main groups of sugars, classified according to the way the atoms are arranged together in the molecular structure. These groups are the following: Monosaccharides or simple sugars. Dextrose ( glucose ) is the major monosaccharide. Others are \n",
      "t work in a recipe in the same way. More information on sugar substitutes and their relative sweetness can be found online. 24 Key Takeaways Key Takeaways Sugar comes from a variety of sources. Our primary sugar, sucrose, comes from two sources: sugar cane and sugar beet, but both these sugars are chemically identical. As a food item, sugars are classed as carbohydrates, being formed from carbon, oxygen, and hydrogen atoms. There are three types of sugar, two of which are most important in their applications for the baker: monosaccharides (simple sugars) and disaccharides (complex sugars). Simple sugars comprise glucose (also known as dextrose), levulose, and galactose. Complex sugars comprise sucrose (our regular sugar), maltose, and lactose. Glucose is the same as dextrose, and fructose is the same as levulose. Relative sweetness varies among the different sugar types, from low as in lactose, to high as in levulose. Sugar has a wide range of applications in baking. III Fats and Oils \n",
      "\n",
      "QUESTIONS 1\n",
      "Identify and describe fats and oils used in the food service industry ### Describe the refining and production of fats and oils ### Describe the function of fats and oils in baking\n",
      "LECTURE 1\n",
      "Fats and oils are important in the baking process and to our diet. This section reviews the common terms used with fats and oils and provides basic information on their relevance in baking and food production. Fats and oils are fundamentally and chemically similar, but oil is liquid, while fat is solid, at room temperature. However, any oil, when sufficiently chilled, will solidify. Conversely, any edible fat will liquefy when sufficiently heated. The various needs of food manufacturers and dietary changes by consumers have determined the evolution of fat manufacturing. To a large extent, vegetable oils have displaced animal fats in food production. Note that the fats and oils discussed here are different from essential oils. The oils we discuss in this section are fixed oils. Stain a piece of paper towel with a fixed oil, such as canola or melted lard, and the stain will remain. Stain a piece of paper with an essential oil, such as the oil from a lemon, and it will disappear. 25 Under\n",
      "so easier to mix and to handle. This characteristic is known as lubrication . Moistening Ability Whether in dough or in a cake batter, fat retards drying out. For this purpose, a 100% fat shortening will be superior to either butter or margarine. Nutrition As one of the three major food categories, fats provide a very concentrated source of energy. They contain many of the fatty acids essential for health. 29 Key Takeaways Key Takeaways Fats and oils are manufactured and selected by the baker on the basis of certain functions or special characteristics. Fats and oils used in baking are made from animal and vegetable sources, with the trend toward vegetable sources. Fats and oils form one of the three major food groups and are concentrated energy sources. The major categories of fat used by the baker are: Butter Margarine Regular shortenings Hydrogenated shortenings The functions of fat in baking are: Shortening Lubrication Lamination Creaming Moistening Deep-frying IV Leavening Agents \n",
      "\n",
      "QUESTIONS 2\n",
      "Identify and describe leavening agents used in the food service industry ### Describe the production of leavening agents ### Describe the function of leavening agents in baking\n",
      "LECTURE 2\n",
      "The word leavening in the baking trade is used to describe the source of gas that makes a dough or batter expand in the presence of moisture and heat. Leavening agents are available in different forms, from yeast (the organic leavener) to chemical, mechanical, and physical leaveners. Bakers choose the appropriate type of leavening based on the product they are making. 30 Yeast Yeast is a microscopic unicellular fungus that multiplies by budding, and under suitable conditions, causes fermentation. Cultivated yeast is widely used in the baking and distilling industries. History tells us that the early Chaldeans, Egyptians, Greeks, and Romans made leavened bread from fermented doughs. This kind of fermentation, however, was not always reliable and easy to control. It was Louis Pasteur, a French scientist who lived in the 19th century, who laid the foundation for the modern commercial production of yeast as we know it today through his research and discoveries regarding the cause and preve\n",
      "is the agent responsible for leavening most breads. It is made under carefully controlled factory conditions, using just one of many strains of yeast. It is available in two basic forms: Compressed or “fresh” yeast, with a moisture content of about 70% and a shelf life of a few weeks Instant active dry yeast, vacuum packed with a moisture content of about 4% and a shelf life of up to a year if unopened. Once opened, it is good for several weeks if properly handled. The conversion ratios for the many brands of dry yeast are shown on the packages. They are about 1:3, dry to compressed. The functions of yeast are twofold: To create carbon dioxide to make the bread rise To mellow or improve the gluten When handling yeast, avoid warm temperatures. Don’t combine yeast with salt. Keep yeast in a cool place, near the freezing temperature. Keep it well wrapped, but allow space for breathing. Chemical leaveners include baking powder, baking soda, cream of tartar, and ammonium bicarbonate V Eggs \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "introconsumerbehaviour.html contains Learning Objectives\n",
      "extracted 8 lectures and 8 questions groups\n",
      "QUESTIONS 0\n",
      "Explain the role of sensory stimuli and sensory receptors. ### Distinguish between “sensation” and “perception.” ### Identify and explain the key elements in the perceptual process. ### Describe how marketers develop positioning strategies.\n",
      "LECTURE 0\n",
      "1 Key Terms and Concepts Absolute threshold: A term that refers to the smallest (minimal) level of a stimuli (e.g. sound; sight, taste) that can still be detected at least half of the time.Attention: Following “exposure” in the perceptual process, Attention describes the dedicated effort and focus we give to incoming sensory information (e.g. sights, sounds). Differential threshold (“JND”): The differential threshold—also known as the JND or just noticeable difference—refers to the minimum difference in intensity that can be detected between two objects (e.g. the size of two bags of potato chips or the subtle difference in two logo designs). Exposure: This term refers to the vast amount of stimuli that surround us and that we come into contact with on a regular basis. In marketing this refers to the massive amount of commercial advertisements, commercials, products, branding, packaging, etc. Guerilla Marketing: A type of experiential advertising that is highly engaging, unanticipated, \n",
      "are adapted from Launch! Advertising and Promotion in Real Time [PDF] by Saylor Academy which is licensed under CC BY-NC-SA 3.0 . The section under “Perceptual Mapping and Positioning Dimensions” is adapted from Principles of Marketing by University of Minnesota which is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. The section on “Repositioning” is adapted from Repositioning created by Lumen Learning which is licensed under CC BY . References American Red Cross Launches Gifts that Save the Day Holiday Campaign . (2009, November 18). Direct Marketing. Berner, R. (2007). Chanel’s American in Paris . BusinessWeek, 70–71. Kelley, L. and Jugenheimer, D.W. (2015). Advertising Account Planning: Planning and Managing an IMC Campaign (3rd ed.). Routledge. Figuring Out The Delicate Art Of Positioning Your Startup . (2014, August 25). Fast Company. Positioning templates . (n.d.). EquiBrand Consulting. 5 Chapter Reflections II Learning Theories \n",
      "\n",
      "QUESTIONS 1\n",
      "Define behaviour learning and summarize the key learning strategies associated with it. ### Define observational learning and summarize the key learning strategies associated with it. ### Give examples of behavioural and observational learning taking place in marketing contexts. ### Discuss the role of memory and nostalgia in the learning process and their application in marketing.\n",
      "LECTURE 1\n",
      "6 Key Terms and Concepts Associative learning: An aspect of behavioural learning theory involving the repetitive pairing of stimuli over time in order to form a strong connection (association) between two items. Behavioural learning theories: Learning theories that focus on how people respond to external events or stimuli. Classical conditioning (Pavlovian conditioning): A type of behavioural learning theory developed by Ivan Pavlov that explains how our responses (behaviour) to one situation can inform our response (behaviour) to a new situation. Cognitive biases: Described as errors in memory or judgement and often an inaccurate perception of something. Cognitive learning theories: Learning theories that focus on how people learn from mental processes and by observing others. Encoding: Describes the process of converting our experiences into memories. Family branding: A branding structure in which the brand focus is on the company name which appears on all the products (services) off\n",
      "3–218. Questions and Answers on Monosodium Glutamate (MSG) . (2012, November 19). U.S. Food and Drug Administration. Rassin, E., Merckelbach, H., &amp; Spaan, V. (2001). When dreams become a royal road to confusion: Realistic dreams, dissociation, and fantasy proneness. Journal of Nervous and Mental Disease, 189 (7), 478–481. Stangor, C., &amp; McMillan, D. (1992). Memory for expectancy-congruent and expectancy-incongruent information: A review of the social and social developmental literatures. Psychological Bulletin, 111 (1), 42–61. Trope, Y., &amp; Thompson, E. (1997). Looking for truth in all the wrong places? Asymmetric search of individuating information about stereotyped group members. Journal of Personality and Social Psychology, 73 , 229–241. Winograd, E., Peluso, J. P., &amp; Glover, T. A. (1998). Individual differences in susceptibility to memory illusions. Applied Cognitive Psychology, 12 (Spec. Issue), S5–S27. 11 Chapter Reflections III Consumer Motivation and Involvement \n",
      "\n",
      "QUESTIONS 2\n",
      "Define motivation and describe various types of needs and goals. ### Summarize how marketers can use motivational concepts to develop marketing strategies. ### Explain and identify the key differences between different involvement levels. ### Discuss methods marketers may use to increase consumer involvement.\n",
      "LECTURE 2\n",
      "12 Key Terms and Concepts Cognitive dissonance (post-purchase dissonance): Also known as “consumer remorse” or “consumer guilt,” this is an unsettling feeling consumers may experience post-purchase if they feel their actions are not aligned with their needs. Consumer involvement: A consumer’s involvement level reflects how personally important or interested they are in purchasing/consuming an item. Customization: A marketing strategy used to increase involvement and engagement levels with consumers, customization involves the personalization of products for large groups of homogenous (similar) consumers. Drives/Drive theory: Drives represent the “tension” we feel when our body is out of balance, for example, due to hunger. Hunger is therefore a “drive state”: drives represent physiological characteristics, or, things that we feel, and are motivated to resolve because they are essential to our survival. Expectancy theory: This theory works very differently from Drive theory because it e\n",
      "nciples of Marketing which is licensed under CC BY-NC-SA 3.0. References About Us . (n.d.). Body Form. Retrieved February 2, 2019, from Kalamut, A. (2010, August 18). Old Spice Video “Case Study” . YouTube [Video]. Bernazzani, S. (n.d.). Customer Loyalty: The Ultimate Guide [Blog post]. Bodyform Channel. (2012, October 16). Bodyform Responds: The Truth . YouTube [Video]. Consumer-Goods’ Brands That Demonstrate Commitment to Sustainability Outperform Those That Don’t. (2015, October 12). Nielsen [Press Release]. Curtin, M. (2018, March 30). 73 Per Cent of Millennials are Willing to Spend More Money on This 1 Type of Product . Inc. Izaguirre, X. (2012, October 17). How are brands using audience involvement to increase reach and engagement? EConsultancy. Rihanna Designs Help Lift Puma Sportswear Sales . (2017, October 24). Reuters. Tarver, E. (2018, October 20). Why the “Share a Coke” Campaign Is So Successful . Investopedia. 16 Chapter Reflections IV Personality, Lifestyle, and The Self \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "introductiontopsychology.html contains Learning Objectives\n",
      "extracted 55 lectures and 55 questions groups\n",
      "QUESTIONS 0\n",
      "Explain why using our intuition about everyday behaviour is insufficient for a complete understanding of the causes of behaviour. ### Describe the difference between values and facts and explain how the scientific method is used to differentiate between the two.\n",
      "LECTURE 0\n",
      "Despite the differences in their interests, areas of study, and approaches, all psychologists have one thing in common: they rely on scientific methods. Research psychologists use scientific methods to create new knowledge about the causes of behaviour , whereas psychologist-practitioners , such as clinical, counselling, industrial-organizational, and school psychologists, use existing research to enhance the everyday life of others . The science of psychology is important for both researchers and practitioners. In a sense all humans are scientists. We all have an interest in asking and answering questions about our world. We want to know why things happen, when and if they are likely to happen again, and how to reproduce or change them. Such knowledge enables us to predict our own behaviour and that of others. We may even collect data (i.e., any information collected through formal observation or measurement ) to aid us in this undertaking. It has been argued that people are “everyday\n",
      " What it means for us . Retrieved May 2, 2014 from  Seedat, S., Scott, K. M., Angermeyer, M. C., Berglund, P., Bromet, E. J., Brugha, T. S., &amp; Kessler, R. C. (2009). Cross-national associations between gender and mental disorders in the World Health Organization World Mental Health Surveys. Archives of General Psychiatry, 66 (7), 785–795. Wells, G. L., &amp; Hasel, L. E. (2008). Eyewitness identification: Issues in common knowledge and generalization. In E. Borgida &amp; S. T. Fiske (Eds.), Beyond common sense: Psychological science in the courtroom (pp. 159–176). Malden, NJ: Blackwell. Williams, N., Simpson, A. N., Simpson, K., &amp; Nahas, Z. (2009). Relapse rates with long-term antidepressant drug therapy: A meta-analysis. Human Psychopharmacology: Clinical and Experimental, 24 (5), 401–408. Wilson, E. O. (1998). Consilience: The unity of knowledge . New York, NY: Vintage Books. Source: Huffington Post, 2014. 3 1.2 The Evolution of Psychology: History, Approaches, and Questions \n",
      "\n",
      "QUESTIONS 1\n",
      "Explain how psychology changed from a philosophical to a scientific discipline. ### List some of the most important questions that concern psychologists. ### Outline the basic schools of psychology and how each school has contributed to psychology.\n",
      "LECTURE 1\n",
      "In this section we will review the history of psychology with a focus on the important questions that psychologists ask and the major approaches (or schools) of psychological inquiry. The schools of psychology that we will review are summarized in Table 1.3, “The Most Important Approaches (Schools) of Psychology,” while Table 1.4, “History of Psychology,” presents a timeline of some of the most important psychologists, beginning with the early Greek philosophers and extending to the present day. Table 1.3 and Table 1.4 both represent a selection of the most important schools and people; to mention all the approaches and all the psychologists who have contributed to the field is not possible in one chapter. The approaches that psychologists have used to assess the issues that interest them have changed dramatically over the history of psychology. Perhaps most importantly, the field has moved steadily from speculation about behaviour toward a more objective and scientific approach as the\n",
      " . Cambridge, MA: MIT Press. Watson, R. I. (1967). Psychology: A prescriptive science. American Psychologist , 22 , 435–443. Long Descriptions Figure 2.1 Long Description – Major Psychological Perspectives Timeline. Physiological Perspective Year Person Biological – Physiological Psychology 1874 Wundt 1898 Titchener Phsychodynamic – Interpretation of Dreams 1990 Freud Behaviouristic – Stimulus and Response 1927 Pavlov 1938 Skinner Humanistic – Self Actualization 1942 Rogers 1954 Maslow Cognitive – Information Processing 1967 Neisser Evolutionary – Adaptation 1999 Buss [Return to Figure 2.1] Figure 2.2 long description: There are three elements of psychology: Why? How? and What? “Why” deals with things like evolution, environment, and culture. “How” deals with things like cognition, behaviour, and subconscious. “What” deals with sensations, emotions, thoughts, perceptions, and actions. [Return to Figure 2.2] Research study design principles. 6 2.1 Biological Psychology Jennifer Walinga \n",
      "\n",
      "QUESTIONS 2\n",
      "Understand the core premises of biological psychology and the early thinkers. ### Critically evaluate empirical support for various biological psychology theories. ### Explore applications and implications of key concepts from this perspective.\n",
      "LECTURE 2\n",
      "Biological psychologists are interested in measuring biological, physiological, or genetic variables in an attempt to relate them to psychological or behavioural variables . Because all behaviour is controlled by the central nervous system, biological psychologists seek to understand how the brain functions in order to understand behaviour. Key areas of focus include sensation and perception; motivated behaviour (such as hunger, thirst, and sex); control of movement; learning and memory; sleep and biological rhythms; and emotion. As technical sophistication leads to advancements in research methods, more advanced topics such as language, reasoning, decision making, and consciousness are now being studied. Biological psychology has its roots in early structuralist and functionalist psychological studies, and as with all of the major perspectives, it has relevance today. In section 1.2, we discuss the history and development of functionalism and structuralism. In this chapter, we extend \n",
      "d identity . Stamford, CT: JAI Press. Kolb, B., Gibb, K., &amp; Robinson, T. E. (2003). Brain plasticity and behavior. Current Directions in Psychological Science , 12 , 1–5. Schmitz, T.W., Cheng, F.H. &amp; De Rosa, E. (2010). Failing to ignore: paradoxical neural effects of perceptual load on early attentional selection in normal aging. Journal of Neuroscience , 30 (44), 14750 –14758. Totsika, V., &amp; Wulf, G. (2003). The influence of external and internal foci of attention on transfer to novel situations and skills. Research Quarterly Exercise and Sport , 74 , 220–225. Wulf, G., Höß, M., &amp; Prinz, W. (1998). Instructions for motor learning: Differential effects of internal versus external focus of attention. Journal of Motor Behavior, 30 , 169–179. A system for taking information in one form and transforming it into another. The generation or growth of new brain cells, specifically when neurons are created from neural stem cells. 7 2.2 Psychodynamic Psychology Jennifer Walinga \n",
      "\n",
      "found too many blacklisted strings\n",
      "Evolution of Psychology: History, Approaches, and Questions \n",
      "rvisor brought him an additional project, he felt ____ (fill in the blank). Contempt most closely combines which two emotions? anger and fear fear and surprise disgust and anger surprise and disgust Debbie just came back from vacation. She was feeling peaceful and content. How well would each of the\n",
      "2005). The emergence of Nicaraguan Sign Language: Questions of development, acquisition, and evolution. In S. T. Parker, J. Langer, &amp; C. Milbrath (Eds.), Biology and knowledge revisited: From neurogenesis to psychogenesis (pp. 287–306). Mahwah, NJ: Lawrence Erlbaum Associates. Seyfarth, R. M., &\n",
      "tions of the law (e.g., traffic tickets) 11 Total ______ You can calculate your score on this scale by adding the total points across each of the events that you have experienced over the past year. Then use Table 11.3, “Interpretation of Holmes and Rahe Stress Scale” to determine your likelihood of\n",
      ", including the social groups to which we belong. Questions these psychologists ask include why we are often helpful to other people but at other times are unfriendly or aggressive; why we sometimes conform to the behaviours of others but at other times are able to assert our independence; and what \n",
      "Evolution of Psychology: History, Approaches, and Questions , “Halifax, New Brunswick” was corrected to “Halifax, Nova Scotia.” Copyright information was edited to conform to the revised BCcampus style guide The “About the Book” page was renamed “About BCcampus Open Education” and the content of the\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "introductiontosociology2ndedition.html contains Learning Objectives\n",
      "extracted 20 lectures and 20 questions groups\n",
      "QUESTIONS 0\n",
      "1.1. What Is Sociology? Explain the concepts central to sociology. ### Describe the different levels of analysis in sociology: micro-level sociology,  macro-level sociology, and global-level sociology. ### Define the sociological imagination. ### 1.2. The History of Sociology Explain why sociology emerged when it did. ### Describe the central ideas of the founders of sociology. ### 1.3. Theoretical Perspectives Explain what sociological theories and paradigms are and how they are used. ### Describe sociology as a multi-perspectival social science divided into positivist, interpretive and critical paradigms. ### Define the similarities and differences between quantitative sociology, structural functionalism, historical materialism, feminism, and symbolic interactionism. ### 1.4. Why Study Sociology? Explain why it is worthwhile to study sociology. ### Identify ways sociology is applied in the real world.\n",
      "LECTURE 0\n",
      "Introduction to Sociology Concerts, sporting matches and games, and political rallies can have very large crowds. When you attend one of these events you may know only the people you came with, yet you may experience a feeling of connection to the group. You are one of the crowd. You cheer and applaud when everyone else does. You boo and yell alongside them. You move out of the way when someone needs to get by, and you say “excuse me” when you need to leave. You know how to behave in this kind of crowd. It can be a very different experience if you are travelling in a foreign country and you find yourself in a crowd moving down the street. You may have trouble figuring out what is happening. Is the crowd just the usual morning rush, or is it a political protest of some kind? Perhaps there was some sort of accident or disaster. Is it safe in this crowd, or should you try to extract yourself? How can you find out what is going on? Although you are in it, you may not feel like you are part\n",
      "es: A painting of men, women, and children looking upset and weary and surrounded by their belongings next to the ocean. Return to Figure 1.16 Figure 1.18 Long Description: Sociologists are placed into quadrants based on whether they privilege structure over agency or see society governed by normative vs. conflictual means. Normative Conflictual Structure Comte’s Positivism and Durkheim’s Structural Functionalism Foucault’s Poststructuralism Agency Weber’s Interpretive Sociology and Mead’s Symbolic Interactionism Martineau’s Feminism and Marx’s Critical Sociology [Return to Figure 1.18] 2 Chapter 2. Sociological Research Figure 2.1. Ottawa map showing the sites of the October 22, 2014 attack on Parliament Hill by Michael Zehaf-Bibeau. One was the National War Memorial and the other the Centre Block parliament building. What social factors led to the process of radicalization and political violence? How do sociologists study these questions? (Courtesy of User:Veggies/Wikimedia Commons) \n",
      "\n",
      "QUESTIONS 1\n",
      "2.1. Approaches to Sociological Research Define and describe the scientific method. ### Explain how the scientific method is used in sociological research. ### Understand the difference between positivist and interpretive approaches to the scientific method in sociology. ### Define what reliability and validity mean in a research study.\n",
      "LECTURE 1\n",
      "2.2. Research Methods Differentiate between four kinds of research methods: surveys, experiments, field research, and secondary data or textual analysis. Understand why certain topics are better suited to different research approaches. 2.3. Ethical Concerns Understand why ethical standards exist. Demonstrate awareness of the Canadian Sociological Association’s Code of Ethics. Define value neutrality, and outline some of the issues of value neutrality in sociology. Introduction to Sociological Research In an unfortunate comment following the Boston Marathon bombing in April 2013, the then Prime Minister Stephen Harper said “this is not a time to commit sociology.” He implied that the “utter condemnation of this kind of violence” precluded drawing on sociological research into the causes of political violence  (Cohen, 2013). In his [Harper’s] position, there is a disjunction between taking a strong political and moral stance on violence on one hand and working towards a deeper, evidence-\n",
      "estion. Research existing sources Formulate a hypothesis. Design and conduct a study Draw conclusions. Report results. [Return to Figure 2.5] Figure 2.17 Long Description: A sociology for women would offer a knowledge of the social organization and determinations of the properties and events of our directly experienced world. [Return to Figure 2.17] Figure 2.18 Long description: Different Research Methods: Textual analysis uses qualitative data and is highly reliable. Participant observation uses qualitative data and is a unique observation. Experiments and survey research use quantitative data and are highly reliable. Journalism uses quantitative data and is a unique observation. [Return to Figure 2.18] 3 Chapter 3. Culture Figure 3.1. Graffiti’s mix of colourful drawings, words, and symbols is a vibrant expression of culture—or, depending on one’s viewpoint, a disturbing expression of the creator’s lack of respect for a community’s shared space. (Photo courtesy of aikijuanma/Flickr) \n",
      "\n",
      "QUESTIONS 2\n",
      "3.1. What Is Culture? Differentiate between culture and society. ### Distinguish between biological and cultural explanations of human behaviour. ### Compare and contrast cultural universalism, cultural relativism, ethnocentrism, and androcentrism. ### Examine the policy of multiculturalism as a solution to the problem of diversity. ### 3.2. Elements of Culture Understand the basic elements of culture: values, beliefs, and norms. ### Explain the significance of symbols and language to a culture. ### Describe the Sapir-Whorf hypothesis. ### Distinguish material and nonmaterial culture. ### 3.3. Culture as Innovation: Pop Culture, Subculture, and Global Culture Distinguish two modes of culture: innovation and restriction. ### Discuss the distinction between high culture, pop culture, and postmodern culture. ### Differentiate between subculture and counterculture. ### Understand the role of globalization in cultural change and local lived experience. ### 3.4. Culture as Restriction: Rationalization and Commodification Describe culture \n",
      "LECTURE 2\n",
      "Introduction to Culture Figure 3.2. Fast food nation. (Photo courtesy of Jon Bunting/Flickr) Are there rules for eating at McDonald’s? Generally, we do not think about rules in a fast food restaurant because they are designed to be casual, quick, and convenient. But if you look around one on a typical weekday, you will see people acting as if they were trained for the role of fast food customer. They stand in line, pick their items from overhead menus before they order, swipe debit cards to pay, and stand to one side to collect trays of food. After a quick meal, customers wad up their paper wrappers and toss them into garbage cans. This is a food system that has become highly rationalized in Max Weber’s terms. Customers’ movement through this fast food routine is orderly and predictable, even if no rules are posted and no officials direct the process. If you want more insight into these unwritten rules, think about what would happen if you behaved according to some other standards. (Yo\n",
      "City by Michael Gil ( used under CC-BY 2.0 license ( Figure 3.13. Canadian nurses voting 1917 by William Rider-Rider ( is in public domain Long Descriptions Figure 3.25 Long description: A young woman leans against an old-style blue bike. She wears bright clothes, large glasses, knee high socks and an owl backpack.” [Return to Figure 3.25] Figure 3.27 Long description: Betty the Beatnik with a collection of fashion choices including black, long sleeve shirts and turtlenecks, black pants, and long black dresses. [Return to Figure 3.27] Figure 3.32 Long description: One man in an ill-fitting suit holds a sign ductaped together that says, “cobble, together, assorted software, to do music, movies and websites.’; The other man is dressed casually and holds a simple sign that says, “I come with iLife.” [Return to Figure 3.32] 4 Chapter 4. Society and Modern Life Figure 4.1. Effigy of a Shaman from Haida Tribe, late 19th century. (Image courtesy of Wellcome Library, London/Wikimedia Commons) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "introtourism.html contains Learning Objectives\n",
      "extracted 14 lectures and 14 questions groups\n",
      "QUESTIONS 0\n",
      "Specify the commonly understood definitions of tourism and tourist ### Classify tourism into distinct industry groups using North American Industry Classification Standards (NAICS) ### Define hospitality ### Gain knowledge about the origins of the tourism industry ### Provide an overview of the economic, social, and environmental impacts of tourism worldwide ### Understand the history of tourism development in Canada and British Columbia ### Analyze the value of tourism in Canada and British Columbia ### Identify key industry associations and understand their mandates\n",
      "LECTURE 0\n",
      "What Is Tourism? Before engaging in a study of tourism , let’s have a closer look at what this term means. Definition of Tourism There are a number of ways tourism can be defined, and for this reason, the United Nations World Tourism Organization (UNWTO) embarked on a project from 2005 to 2007 to create a common glossary of terms for tourism. It defines tourism as follows: Tourism is a social, cultural and economic phenomenon which entails the movement of people to countries or places outside their usual environment for personal or business/professional purposes. These people are called visitors (which may be either tourists or excursionists; residents or non-residents) and tourism has to do with their activities, some of which imply tourism expenditure (United Nations World Tourism Organization, 2008). Using this definition, we can see that tourism is the movement of people for a number of purposes (whether business or pleasure). Definition of Tourist Building on the definition of tou\n",
      " tourism: Basic glossary . Retrieved from  United Nations World Tourism Organization. (2012, May 7). International tourism receipts surpass US$ 1 trillion in 2011. Retrieved from  United Nations World Tourism Organization. (2014a). UNWTO world tourism barometer, 12 [PDF] (1). Retrieved from  United Nations World Tourism Organization. (2014b). Who we are. Retrieved from Figure 1.1 Selkirk College and Nelson by LinkBC is used under a CC-BY 2.0 license. Figure 1.2 Capilano University’s Team by LinkBC is used under a CC-BY 2.0 license. Figure 1.3 Vancouver Island University by LinkBC is used under a CC-BY 2.0 license. Figure 1.4 Canadian Pacific 4-4-0 A-2-m No 136 by Peter Broster is used under a CC-BY 2.0 license. Figure 1.5 Vancouver Island University by LinkBC is used under a CC-BY 2.0 license. Figure 1.6 Switzerland vs. Canada by s.yume is used under a CC-BY 2.0 license. Figure 1.7 CTC’s Boardroom by LinkBC is used under a CC-BY 2.0 license. 2 Chapter 2. Transportation Morgan Westcott \n",
      "\n",
      "QUESTIONS 1\n",
      "Understand the role of transportation in the tourism industry ### Recognize milestones in the development of the air industry and explain how profitability is measured in this sector ### Report on the historic importance of rail travel and challenges to rail operations today ### Describe water-based transportation segments including cruise travel and passenger ferries ### Recognize the importance of transportation infrastructure in tourism destinations ### Specify elements of sightseeing transportation, and explain current issues regarding rental vehicles and taxis ### Identify and relate industry trends and issues including fuel costs, environmental impacts, and changing weather\n",
      "LECTURE 1\n",
      "Overview The transportation sector is vital to the success of our industry. Put simply, if we can’t move people from place to place — whether by air, sea, or land — we don’t have an industry. This chapter takes a broad approach, covering each segment of the transportation sector globally, nationally, and at home in British Columbia. Let’s start our review by taking a look at the airline industry. Air According to the International Air Transport Association (IATA), in 2014, airlines transported 3.3 billion people across a network of almost 50,000 routes generating 58 million jobs and $2.4 trillion in business activity (International Air Transport Association, 2014a). Spotlight On: International Air Transport Association The International Air Transport Association (IATA) is the trade association for the world’s airlines, representing around 240 airlines or 84% of total air traffic. It supports many areas of aviation activity and helps formulate industry policy on critical aviation issues\n",
      "June). Vancouver Tourism master plan. [PDF] Retrieved from  WestJet. (2014). About WestJet . Retrieved from  YCharts. (2014, September). Apple Profit Margin (Quarterly). Retrieved from  Figure 2.1 Sky Jet by Jez is used under a CC-BY-NC-ND 2.0 license. Figure 2.2 Airbus 380-800 by Ponte112 is used under a CC-BY-NC-SA 2.0 license. Figure 2.3 airplane 036 by MamaMia05 is used under a CC-BY 2.0 license. Figure 2.4 C.P.R. Mount Stephen House, Field, BC, 1909 by Musee McCord Museum has No known copyright restrictions . Figure 2.5 Sunset Cruise by Evan Leeson is used under a CC-BY-NC-SA 2.0 license. Figure 2.6 Uniworld River Cruises River Beatrice in Passau Germany by Gary Bembridge is used under a CC-BY 2.0 license. Figure 2.7 BC Ferry by David Lewis is used under a CC-BY-NC-ND 2.0 license. Figure 2.8 Lincoln Town Car by Nathan is used under a CC-BY-NC-ND 2.0 license. Figure 2.9 Baltimore Airport by Lee Ruk is used under a CC-BY-SA 2.0 license. 3 Chapter 3. Accommodation Rebecca Wilson-Mah \n",
      "\n",
      "QUESTIONS 2\n",
      "Explain the contribution the accommodations sector makes to Canada’s economy ### Identify how a hotel category is determined, and describe different hotel categories in Canada ### Explain the meaning and structure of independent ownership, franchise agreements, and management contracts ### Summarize current accommodation trends ### Discuss the structure of hotel operations\n",
      "LECTURE 2\n",
      "Overview In essence, hospitality is made up of two services: the provision of overnight accommodation for people travelling away from home, and options for people dining outside their home. We refer to the accommodation and food and beverage services sectors together as the hospitality industry. This chapter explores the accommodation sector, and the Chapter 4 details the food and beverage sector. Figure 3.1 The view from a balcony at the Westin Bayshore hotel in downtown Vancouver In Canada, approximately 25% to 35% of visitor spending is attributed to accommodation, making it a substantial portion of travel expenditures. Hotels There were 8,090 hotel properties with a total of 440,123 rooms in Canada in 2014. Direct spending on overnight stays was $16.7 billion, and the year’s average occupancy rate was forecast at 64%. Across the country the sector employed 287,000 people (Hotel Association of Canada, 2014). According to go2HR, “with a projected rate of annual employment growth of 1\n",
      "e. Figure 3.6 The Empress by 3dpete is used under a CC BY ND 2.0 license. Figure 3.7 Coast Bastion Hotel (Nanaimo) by Raul Pacheco-Vega is used under a CC BY-NC-ND 2.0 license. Figure 3.8 Delta Sun Peaks Hotel by jhopkins is used under a CC BY 2.0 license. Figure 3.9 Hotel Georgia, Rosewood Hotel Vancouver by Rishad Daroowala is used under a CC BY-ND 2.0 license. Figure 3.10 Night Neighbours by James Wheeler is used under a CC BY-NC-SA 2.0 license. Figure 3.11 Vicky Lee at Delta Burnaby Hotel by LinkBC is used under a CC BY 2.0 license. Figure 3.12 Scott and Tina Visit the Pan Pacific Vancouver by Pan Pacific Hotel is used under a CC BY 2.0 license. Figure 3.13 Cafe Pacifica Restaurant 2013 Winter Menus by Pan Pacific is used under a CC BY 2.0 license. Figure 3.14 Airbnb by Gustavo da Cunha Pimenta is used under a CC BY-SA 2.0 license. Figure 3.15 Waiting at baggage claim by hjl is used under a CC BY-NC 2.0 license. 4 Chapter 4. Food and Beverage Services Peter Briscoe and Griff Tripp \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "introtourism2e.html contains Learning Objectives\n",
      "extracted 14 lectures and 14 questions groups\n",
      "QUESTIONS 0\n",
      "Specify the commonly understood definitions and differentiations of travel, tourism, and hospitality ### Classify tourism into distinct industry groups using North American Industry Classification Standards (NAICS) ### Define tourist and excursionist ### Gain knowledge about the origins of the tourism industry ### Provide an overview of the economic, social, and environmental impacts of tourism worldwide ### Understand the history of tourism development in Canada and British Columbia ### Analyze the value of tourism in Canada and British Columbia ### Identify key industry associations and understand their mandates\n",
      "LECTURE 0\n",
      "1 1.1 What is Tourism? Before engaging in a study of tourism , let’s have a closer look at what this term means. Definition of Tourism There are a number of ways tourism can be defined, and for this reason, the United Nations World Tourism Organization (UNWTO) embarked on a project from 2005 to 2007 to create a common glossary of terms for tourism. It defines tourism as follows: Tourism is a social, cultural and economic phenomenon which entails the movement of people to countries or places outside their usual environment for personal or business/professional purposes. These people are called visitors (which may be either tourists or excursionists; residents or non-residents) and tourism has to do with their activities, some of which imply tourism expenditure (United Nations World Tourism Organization, 2008). Using this definition, we can see that tourism is not just the movement of people for a number of purposes (whether business or pleasure), but the overall agglomeration of activit\n",
      "mendations on tourism statistics. [PDF] Retrieved from  United Nations World Tourism Organization. (2008). Understanding tourism: Basic glossary . Retrieved from  United Nations World Tourism Organization. (2012, May 7). International tourism receipts surpass US$ 1 trillion in 2011. Retrieved from  United Nations World Tourism Organization. (2014a). UNWTO world tourism barometer, 12 [PDF] (1). Retrieved from  United Nations World Tourism Organization. (2014b). Who we are. Retrieved from United Nations World Tourism Organization. (2019). International Tourism Highlights, 2019 Edition . UNWTO. United Nations World Tourism Organization. (2020a). Glossary of Tourism Terms . Retrieved from United Nations World Tourism Organization. (2020b). International Tourist Numbers Could Fall 60-80% in 2020, UNWTO Reports . Retrieved from Vancouver Airport Authority. (2020). Facts and Stats . Retrieved from II Chapter 2. Transportation Original author: Morgan Westcott Revisions made by: Moira McDonald \n",
      "\n",
      "QUESTIONS 1\n",
      "Understand the role of transportation in the tourism industry ### Recognize milestones in the development of the air industry and explain how profitability is measured in this sector ### Report on the historic importance of rail travel and challenges to rail operations today ### Describe water-based transportation segments including cruise travel and passenger ferries ### Recognize the importance of transportation infrastructure in tourism destinations ### Specify elements of sightseeing transportation, and explain current issues regarding rental vehicles and taxis ### Identify and relate industry trends and issues including fuel costs, environmental impacts, and changing weather\n",
      "LECTURE 1\n",
      "7 2.1 Air The transportation sector is vital to the success of our industry. Put simply, if we cannot move people from place to place — whether by air, sea, or land — we do not have an industry. This chapter takes a broad approach, covering each segment of the transportation sector globally, nationally, and at home in British Columbia. Let’s start our review by taking a look at the airline industry. According to the International Air Transport Association (IATA) , in 2018, airlines transported more people than ever, 4.1 billion people across a network of 25,000 origin to destination (O-D) passenger journeys generating over 58 million jobs and $2.7 trillion in business activity (International Air Transport Association, 2019). Spotlight On: International Air Transport Association The International Air Transport Association (IATA) is the trade association for the world’s airlines, representing around 240 airlines or 84% of total air traffic. It supports many areas of aviation activity and\n",
      "ld’s most beautiful rerry Rides.” Travel + Leisure . Retrieved from  Owram, Kristine. (2014, July 5). Unfriendly skies await proposed low-cost airlines Canada jetlines, jet naked. The Financial Post . Retrieved from  Proctor, Benn. (2014, June 3). Opinion: Time to reform Vancouver’s antiquated taxi industry . The Vancouver Sun. Retrieved from PWC. (2012). Transportation &amp; Logistics 2030, volume 5: Winning the talent race. [PDF] Retrieved from Rocky Mountaineer. (2014). Canadian train travel, trips, rail journeys, vacations, holidays. Rocky Mountaineer . Retrieved from  Science Daily. (2013, June 17). Planes, trains, or automobiles: Travel choices for a smaller carbon footprint. Retrieved from  Tourism Vancouver. (2013, June). Vancouver Tourism master plan. [PDF] Retrieved from  WestJet. (2014). About WestJet . Retrieved from  YCharts. (2014, September). Apple Profit Margin (Quarterly). Retrieved from  III Chapter 3. Accommodation Original author &amp; revisions: Rebecca Wilson-Mah \n",
      "\n",
      "QUESTIONS 2\n",
      "Explain the contribution the accommodations sector makes to Canada’s economy ### Identify how a hotel category is determined, and describe different hotel categories in Canada ### Explain the meaning and structure of independent ownership, franchise agreements, and management contracts ### Summarize current accommodation trends ### Discuss the structure of hotel operations\n",
      "LECTURE 2\n",
      "13 3.1 Hotels In essence, hospitality is made up of two services: the provision of overnight accommodation for people travelling away from home, and options for people dining outside their home. We refer to the accommodation and food and beverage services sectors together as the hospitality industry. This chapter explores the accommodation sector, and Chapter 4 details the food and beverage sector. Figure 3.1 The view from a balcony at the Westin Bayshore hotel in downtown Vancouver. In Canada, approximately 25% to 35% of visitor spending is attributed to accommodation, making it a substantial portion of travel expenditures. There were 8,289 hotels, motels and resorts with a total of 460,688 rooms across Canada in 2019. Direct spending on overnight stays was $21.9 billion, and the year’s average occupancy rate was 65%.  Across the country the sector employed 309,800 people directly or indirectly on a full-time or part-time basis (Hotel Association of Canada, 2019). In 2018, Tourism HR \n",
      "w.hotel-online.com/News/PR2005_4th/Oct05_FranchiseCost.html SilverBirch Hotels. (2020). About us . Retrieved from www.silverbirchhotels.com/about/ Tourism HR Canada. (2018). Tourism Shortages: Jobs to Fill. Retrieved from Travel Click. (n.d.). Find your market mix – OTAs vs. direct .  Retrieved from Wedgewood Hotel &amp; Spa. (2020). Wedgewood Hotel &amp; Spa, Meet the Team . Retrieved from www.wedgewoodhotel.com Western Investor. (2012). Investors burnt in hotel condos, fractionals . Retrieved from westerninvestor.com/index.php/news/ab/692-investors-burnt-in-hotel-condos-fractionals Zervas, G., Preserpio, D., &amp; Byers, J.W., (2015). The rise of the sharing economy: Estimating the impact of Airbnb on the hotel industry . Boston U. School of Management Research Paper No. 2013-16. Available at SSRN: ssrn.com/abstract=2366898 or dx.doi.org/10.2139/ssrn.2366898 IV Chapter 4. Food and Beverage Services Original authors: Peter Briscoe and Griff Tripp Revisions made by: David MacGillivray \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "meatcutting.html contains Learning Objectives\n",
      "extracted 3 lectures and 3 questions groups\n",
      "QUESTIONS 0\n",
      "Describe the composition and characteristics of meat ### Describe the chemical changes associated with slaughter ### Describe the aging, blooming, and tenderness factors of meat ### Describe diseases associated with meat ### Describe the nutritional value of meat ### Describe the handling and storage of meat and meat products\n",
      "LECTURE 0\n",
      "Introduction Meat science and the research and studies conducted both independently and in conjunction with many industry stakeholders over the last 40 years have provided a greater understanding of the relationship between animal-handling techniques prior to harvesting (slaughter) and the quality of the meat produced. As well, improved practices during and after the harvesting of animals, especially in large processing plants, have contributed to progress in the meat industry. These include improvements to refrigeration and storage, aging of meats (mainly beef and lamb carcasses), and transportation. Additionally, the slaughter process itself has changed over time, and now beef and veal animals are usually stunned with a captive bolt gun (with a retractable bolt penetrating the brain), rendering the animals unconscious prior to bleeding. All of these developments have improved the end product, which ultimately ends up at local meat stores and restaurants. However, even today a small a\n",
      "e already cleaned and sanitized. Ensure surfaces are dry with no residue of any sanitizer on them (remember that most sanitizers are toxic while wet). Maintain separate cutting and processing boards for different species, especially fish, chicken, and pork. Clean and sanitize boards immediately after use and elevate to air dry as quickly as possible. Have separate cutting boards for cooked meat slicing. Thoroughly clean and sanitize meat slicers and tenderizers between uses for different species and between cooked and raw products. These slicing tools and machines pose a very real risk for cross-contamination and are always subject to scrutiny by health inspectors. If possible, process different species and cooked and raw products on different days. This helps minimize risk of cross-contamination in processing areas, tools, and machines that are used for a variety of products. II Inspection and Grading of Meats and Poultry 12 Introduction to Inspection and Grading of Meats and Poultry \n",
      "\n",
      "QUESTIONS 1\n",
      "Identify meat inspection levels and agencies ### Define the meat inspection process ### Describe grading regulations for meat\n",
      "LECTURE 1\n",
      "Introduction Meat inspection for the domestic animal market is mandatory for beef, pork, lamb, bison, and poultry and is overseen by the Canadian Food Inspection Agency (CFIA). There are two levels of inspection in Canada: federal and provincial. Federally inspected meats can be sold and transported throughout Canada and also exported or sold internationally. Provincially inspected meats can be sold under the following two categories: Intraprovincially, which means the meat can be sold only within the province where the harvesting plant is located Interprovincially, which means the meat can be sold in a province or territory other than the one in which the harvesting plant is located Meat grading measures the characteristics of carcasses and classifies them into groups of similar quality, yield, and value, which in turn assists in marketing and merchandizing the products. Grading standards and regulations are set for each species separately through government consultation with each ind\n",
      "vides the same amount of protein as most other livestock. Studies at the Agriculture and Agri-Food Canada Research Station in Lacombe, Alberta, have shown that elk is generally more tender than beef. Currently there are two federally inspected plants in Alberta that accept elk and deer for processing. Wild deer species in B.C., Alberta, and other parts of Canada are not used for farm and meat production. However, some of Canada’s deer species are susceptible to chronic wasting disease (CWD) , which is a progressive, fatal disease of the nervous system. It is known as a transmissible spongiform encephalopathy (TSE). Other TSEs include scrapie in sheep, bovine spongiform encephalopathy (BSE) in cattle, and Creutzfeldt-Jakob disease (CJD) in humans. In Canada, CWD is a serious concern for deer and elk farmers and is a reportable disease under the Health of Animals Act. All cases must be reported to the CFIA. III Cutting and Processing Meats 16 Introduction to Cutting and Processing Meats \n",
      "\n",
      "QUESTIONS 2\n",
      "Describe the muscle and bone structure of meat ### Identify suitable cuts of meat for various cooking methods ### Identify primal cuts of beef, lamb, pork, and veal ### Identify secondary cuts of beef, lamb, pork, and veal ### Describe variety meats and offal ### Describe cuts of game\n",
      "LECTURE 2\n",
      "Introduction You will remember from the first chapter of this book that meat is muscle made up of fibres. These muscle fibres are held together by connective tissue such as collagen and elastin. The amount of connective tissue contained in the muscle (or meat) has to be acknowledged before choosing the appropriate way to prepare the product. A highly exercised muscle, such as a shank or shoulder area, will develop much more connective tissue and more coarse muscle fibres. This means they require a moist heat cooking method. If cooked with liquid, collagen breaks down at 80°C (176°F) into gelatin. This gelatin provides not only body to the cooking liquid but also, more importantly, moisture to the cooked meat and rich flavour. A lightly exercised muscle will contain less connective tissue and more fine muscle fibres, allowing it to be prepared using dry heat cooking methods. Beef tenderloin is a perfect example of this type of meat. Generally, four-legged animals use their shoulder and \n",
      "roject to standardize BCcampus-published books. Added additional publication information and sample citation Updated copyright information Renamed “About the book” to “About BCcampus Open Education” and updated the content Added a Versioning History page Updated the book cover 5 List of Links by Part for Print Users Front Matter Adoption of an Open Textbook: BCcampus: BCcampus Open Education: British Columbia Ministry of Advanced Education, Skills &amp; Training: Creative Commons licence: Hewlett Foundation: Meat Science and Nutrition Certified Organics Association of BC (COABC): Cyst: Grandin Livestock Handling Systems, Inc.: Inspection and Grading of Meats and Poultry Alberta Pork:  BC Pork:  Canadian Pork Council:  Canadian Pork International: Reportable Diseases:  Western Hog Exchange Grading Grids:  Cutting and Processing Meat Canadian Beef Merchandising Guide: CFIA:  CFIA Beef Cuts Manual:  CFIA Meat Cuts Manual:  CFIA Veal Cuts Manual: Lamb Primal Cuts Poster:  Veal Cut Chart:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "modernpastryandplateddesserts.html contains Learning Objectives\n",
      "extracted 4 lectures and 4 questions groups\n",
      "QUESTIONS 0\n",
      "Describe the process of coagulation ### Describe the process of gelatinization ### Describe the process of crystallization ### Describe the use of hydrocolloids ### Describe the process of spherification ### Describe molecular gastronomy techniques used in the pastry shop ### Describe the use of low temperature and sous-vide cooking in the pastry shop\n",
      "LECTURE 0\n",
      "Today we understand more than we once did about how ingredients of food scientifically interact with one another and how to change them to make them different using methods such as jellifying, powdering, foaming—methods common to what is known as molecular gastronomy . As a result, modern pastry chefs are making amendments to time-honoured recipes to suit the modern palate. They are not cutting corners to make a less professional or delicious product. They are using new technology and knowledge that was not available 100 years ago, and they want to explore the creative side of pastry. This creativity sometimes comes with an expectation of total freedom in the kitchen; an expectation that one will be able to create without following any rules or requiring traditional recipe formats. While it’s good to foster a creative mindset, it’s also important to acknowledge that creativity in baking must also adhere to certain scientific and professional guidelines in order to make well-executed, c\n",
      "ture within the plant tissue to rapidly expand and rupture the structures within the food. When the surrounding pressure is restored to a normal level, the labyrinth of air-filled spaces collapses. As a result, light tends to pass through the food rather than being scattered and diffused, which is why vacuum-compressed plant foods appear translucent. Causing the porous structure of a plant food to collapse also imparts a somewhat dense, toothsome texture that can give a familiar ingredient, such as watermelon, an entirely new appeal. Figure 5. Infusions When adding liquids, the vacuum-seal process creates a rapid infusion—especially with more porous foods (such as adding spices to cream or herbs to melon). This can add flavour and texture in a shorter time than traditional infusions. Sous Vide Cooking © Derek is licensed under a CC BY-ND (Attribution NoDerivatives) license WD-50 (7th Course) © Peter Dillon is licensed under a CC BY (Attribution) license 6 Activities II Plated Desserts \n",
      "\n",
      "QUESTIONS 1\n",
      "Describe how to design a plated dessert ### Learn factors that will contribute to a successful plated dessert ### Apply design principles\n",
      "LECTURE 1\n",
      "What makes a worthy plated dessert? Many will argue presentation, complexity, or the type of plate it is served on are important factors. Texture is also critical in making a dish successful. Mushy apples would ruin an otherwise perfect apple pie, and how helpful is the granulated sugar garnish on the crust? But most will still agree that the most important factor in creating an exceptional plated dessert is flavour. Whether it is a simple slice of pie served in a casual restaurant, or an intricate, multicomponent dessert crafted for a fine dining establishment, flavour is what makes a dessert memorable. Dessert plating styles are constantly changing and evolving thanks to today’s creative pastry chefs and cooks. Past trends included towering architectural assemblies that were impressive and beautiful to look at but were difficult to eat, or making complex designs on the rims of plates with squirts of sauce or dustings of cocoa or icing sugar (which often ended up on the diners’ sleeve\n",
      "ence in a variety of ways. Imagine if food didn’t have the following attributes, which in many cases provide our first impressions, lasting memories, and overall like or dislike of a certain dish or dining experience: Temperature: both real and perceived (such as mint as a cooling sensation or spice as heat) Colour: use a wide palette Shape: create visual interest Texture: some of each creates contrast Mouth feel: dry, fat, rich Smells: avoid overpowering or distracting Sound: noisy, difficult foods may spoil a mood or setting And always try to remember a few guidelines as you go along: Think outside the box; try new things. Too much of anything is never a good idea. Great dishes hit on multiple senses in a variety of ways. Look to classic combinations for inspiration, then make logical leaps. If flavours work together in one context, they will do so in another. A great example of this is the recent trend of bringing savoury pantry items into desserts. III Dessert Garnishes and Sauces \n",
      "\n",
      "QUESTIONS 2\n",
      "Describe the effect of garnishes on presentation ### Describe the additional effects garnishes can have on a plated dessert ### Prepare garnishes from a variety of mediums ### Describe the contributing roles of sauces in a plated dessert ### Prepare dessert sauces\n",
      "LECTURE 2\n",
      "Many, if not most, dessert presentations can be improved with one or more items added to enhance them. But before you add anything, take a moment to consider whether serving the dessert alone would be effective. A simple, ungarnished plating is usually all that’s needed for a home-style dessert, and at the opposite extreme, an elegant pastry or gateaux that is beautiful on its own may not need any additional elements. 8 Garnishes A garnish, simply put, can be just an add-on whose main purpose is decoration. However, carefully selected garnishes have other functions too. This “decorative” item can add important flavour, texture, and functional elements to the plating of the dessert, and can enhance the enjoyment of the dish. Garnishes can solve the problem of serving a frozen component (ice cream or sorbet, for example) as part of a plated dessert. If a scoop of ice cream is placed directly onto the plate, it will start melting immediately, marring the presentation. If that scoop is pla\n",
      "ny patterns. Or just a spoon is needed to drizzle random patterns of sauce onto a plate. Another technique for saucing is applying a small amount of sauce and streaking it with a brush, an offset spatula, or the back of a spoon. Sauces are a great way to highlight flavours. Choose ones that will create balance on the plate, not just for colour, but with all the components. A tart berry sauce will complement a rich cheesecake or chocolate dessert because sourness (acid) will cut through fat, making it taste lighter than it is. A sweet sauce served with a sweet dessert will have the overall effect of hiding flavours in both. Hold back on sweetness in order to intensify other flavours. Many modern presentations may have a minimal amount of sauce. Sometimes this is done just for aesthetic reasons and not for how it will complement the dessert. Think of the dish and the balance of the components. This is the most important factor: flavour first, presentation second. IV Dessert Presentation \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nursingpharmacology.html contains Learning Objectives\n",
      "extracted 10 lectures and 10 questions groups\n",
      "QUESTIONS 0\n",
      "Identify and describe the processes of pharmacokinetics ### Apply principles of evidence-based practice to identify pertinent information related to drugs ### Consider pharmacodynamic differences across the lifespan ### Differentiate among prescription drugs, over-the-counter drugs, herbals, and dietary supplements\n",
      "LECTURE 0\n",
      "Safe medication administration is a vital component of the nursing role. Each day it is common for nurses to make clinical judgments regarding the safety, appropriateness, and effectiveness of the medications administered to their clients. Examples of decisions that a nurse might make during client care include: Is my client’s heart rate within the correct range to receive this beta-blocker medication? Does my client have adequate renal function prior to administering this dose of antibiotic? Is this pain medication effective in controlling my client’s discomfort? In order to make safe medication administration decisions, the nurse must have a strong understanding of pharmacology . Symptom management, physical recovery, and individual well-being can be strongly connected to the use of medications in a client’s treatment plan. Before a nurse reviews a medication order, checks a medication administration record, or administers a medication, it is important to have a foundational understa\n",
      "th new-onset atrial fibrillation. She has been prescribed amiodarone for her irregular heartbeat and is set to receive her first dose with her morning breakfast tray. When you arrive in the room, you notice that she has grapefruit juice on her breakfast meal tray. Is this a concern? Why? What is the nurse’s next action? A nurse is caring for a 55-year-old male who recently was admitted to the medical-surgical unit for a total knee replacement. He is prescribed oxycodone/acetaminophen 5/325 mg (Percocet) every 4 hours for moderate pain. The client complains of pain in the knee, rating it at a “6.”  Use your online resources to help you answer the following questions: When does the nurse anticipate the medication will peak in action? When does the nurse anticipate another dose will be needed due to the half-life of this drug? Note: Answers to the light bulb moments can be found in the “ Answer Key ” sections at the end of the book. II Safety and Ethics 2.1 Safety and Ethics Introduction \n",
      "\n",
      "QUESTIONS 1\n",
      "Identify drug administration guidelines for registered nurses in Canada ### Identify nursing responsibilities to prevent and respond to medication errors ### Identify nursing responsibilities associated with controlled substances ### Identify ethical responsibilities as they relate to medication errors ### Explain client-centered care and cultural safety during medication administration ### Outline nursing actions within the scope of nursing practice as they relate to the administration of medication ### Identify nursing responsibilities associated with safe client medication administration and education\n",
      "LECTURE 1\n",
      "Medication administration is an essential task that nurses perform while providing client care. However, safe medication administration is more than just a nursing task; it is a process involving several members of the health care team, as well as legal, ethical, social, and cultural issues. The primary focus of effective medication administration by all health professionals is client safety. Although many measures have been put into place over the past few decades to promote improved client safety, medication errors and adverse effects continue to be a common event. The World Health Organization (WHO) estimates, “Unsafe medication practices and medication errors are a leading cause of injury and avoidable harm in health care systems across the world. Globally, the cost associated with medication errors has been estimated at $42 billion USD annually.” This chapter will examine the safety and ethical foundations of medication administration by nurses, as well as the practice standards a\n",
      "l., 2014 Doyle, Glynda and Jodie McCutcheon. Clinical Procedures for Safer Patient Care . Victoria, BC: BCcampus, 2021. Doyle, Glynda and Jodie McCutcheon. Clinical Procedures for Safer Patient Care . Victoria, BC: BCcampus, 2021. BCCNM (2021). Medication: Practice Standard for Registered Nurses - Applying the principles to practice. Institute of Medicine. (2007). Preventing medication errors. The National Academies Press. U.S. Department of Health &amp; Human Services, Centers for Medicare &amp; Medicaid Services. (2014). Memo: requirements for hospital medication administration, particularly intravenous (IV) medications and post-operative care of patients receiving IV opioids . BCCNM. (2021). Practice Standards - Documentation. Doyle, Glynda and Jodie McCutcheon. Clinical Procedures for Safer Patient Care . Victoria, BC: BCcampus, 2021. 2.7 Clinical Reasoning and Decision-Making Learning Activities Interactive Activity III Antimicrobials 3.1 Infection and Antimicrobials Introduction \n",
      "\n",
      "QUESTIONS 2\n",
      "Identify the classifications and actions of antimicrobial medications ### Provide examples of when, how, and to whom antimicrobial drugs may be administered ### Identify the side effects and special considerations associated with antimicrobial therapy ### Explain considerations and implications of using antimicrobial medications across the lifespan ### Consider evidence-based concepts when using the nursing process, clinical reasoning and decision-making\n",
      "LECTURE 2\n",
      "Have you ever been prescribed an antibiotic for an infection and asked, “Why do I have to finish taking all these pills when I already feel better”? Or, perhaps you wondered why the healthcare provider chose a certain medication over another or why the pharmacist told you to avoid certain foods when taking a certain antibiotic. You may have had these questions in your own healthcare experiences. It is important to remember that if you have these questions, many of your patients will as well. Learning about the various types of antimicrobials and how they work will help you provide better health education to your patients. Did you know that the use of antimicrobial agents dates back to ancient times? Although the discovery of antimicrobials and their subsequent widespread use is commonly associated with modern medicine, there is evidence that humans have been exposed to antimicrobial compounds for millennia. Chemical analyses of the skeletal remains from between 350 and 550 AD of people\n",
      "t by a particular antibiotic. Sensitivity Analysis: A test performed in addition to a culture to select an effective antibiotic to treat a microorganism. Superinfection: A secondary infection in a patient having a preexisting infection.  C-diff and yeast infections resulting from antibiotic therapy are examples of superinfections. Synergistic Interaction: Concurrent drug administration producing a synergistic interaction that is better than the efficacy of either drug alone.  An example of synergistic drug combinations is trimethoprim and sulfamethoxazole (Bactrim). Time Dependent: Time dependency occurs when greater therapeutic effects are seen with lower blood levels over a longer period of time. Vancomycin-Resistant S. Aureus (VRSA): An infection caused by Vancomycin-resistant Staphylococcus aureus that is difficult to treat because it exhibits resistance to nearly all available antibiotics. IV Autonomic Nervous System Regulation 4.1 Autonomic Nervous System Regulation Introduction \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nutrition.html contains Learning Objectives\n",
      "extracted 3 lectures and 3 questions groups\n",
      "QUESTIONS 0\n",
      "Describe the basic nutritional elements and properties of food ### Describe the nutritional requirements of a healthy diet ### Understand the nutrition facts tables (NFT)\n",
      "LECTURE 0\n",
      "Most Canadians have been introduced at one point or another to Canada’s Food Guide for a balanced diet. The latest version, adapted in 2007, includes changes and improvements based on recent studies and focuses on eating more wholesome foods. The four food groups are: Vegetables and fruit Grain products Milk and alternatives Meat and alternatives Depending on a person’s gender and age, Canada’s food guide recommends the number of servings in each food group that a person should consume (Tables 1a-1d). It also contains information about what is considered a serving of different types of food. Table 1a: Recommended servings of each food group for children, girls and boys Food 2-3 years old 4-8 years old 9-13 years old Vegetables and Fruit 4 servings 5 servings 6 servings Grain Products 3 servings 4 servings 6 servings Milk and Alternatives 2 servings 2 servings 3-4 servings Meat and Alternatives 1 serving 1 serving 1-2 servings Table 1b: Recommended servings of each food group for teens,\n",
      "regarding the use of this process for fruit and vegetable-based juices. On this basis, mandatory labelling requirements are not necessary in this case” (Health Canada, Food and Nutrition, 2015). Long Descriptions Figure 2 long description: A sample bilingual Nutrition Facts table. This one contains nutrition information per 125 mL (87 g) serving of an unknown product. It lists the amount of each of thirteen nutrients present per serving, then describes what percent of the daily suggested value this amount is. The product has 80 calories per serving. The thirteen nutrients are as follows: Fat: 0.5 g. 1% DV Saturated fat: 0 g. 0% DV Trans fat: 0 g. 0% DV Cholesterol: 0 mg. No DV Sodium. 0 mg. 0% DV Carbohydrate: 18 g. 6% DV Fibre: 2 g. 8% DV Sugars: 2 g. No DV Protein: 3 g. No DV Vitamin A: 2% DV Vitamin C: 10% DV Calcium: 0% DV Iron: 2% DV [Return to Figure 2] 12 Learning Activities II Labelling and Packaging Requirements 13 Introduction to Understanding Labelling Rules and Regulations \n",
      "\n",
      "QUESTIONS 1\n",
      "Describe product labelling procedures and regulations ### Describe nutritional information required on labels and packages ### Describe types of packaging, uses, and regulations\n",
      "LECTURE 1\n",
      "Food labels are often not well understood by consumers. The Canadian government has, however, made efforts to create labels that provide necessary information for consumers. It is important for consumers to become knowledgeable about how to read and interpret food labels in order to make informed choices about healthy and safe products. Health Canada is responsible for constructing policies to meet the standards set by the Food and Drug Act (FDA). Other governing bodies, such as the Canadian Food Inspection Agency (CFIA), have responsibilities for administering food-labelling policies as well as managing the Consumer Packaging and Labelling Act. Beyond this, food producers such as bakers play an important role in the food industry by producing great tasting products that are high in nutritional value and meet customers’ needs. Food producers, including bakers, who produce food sold locally, nationally, or internationally must meet governmental labelling requirements. Mandatory food lab\n",
      "ost Canadians are not getting enough of this nutrient. Remove vitamin A and vitamin C because most Canadians get enough of these nutrients in their diets. Then there is a diagram showing the differences between the current and the proposed Nutrition Facts table. In the proposed table, arrows point to the increased serving size information; the increased size of the information about calories, with a thick underline; how the nutrients that provide calories—fats, carbohydrates, and protein—are listed below calories; the added % Daily Value for sugars; how vitamins A and C are removed and potassium is added; how sodium is moved down close to potassium; how the amounts of potassium, calcium and iron are shown; and the quick rule of thumb about % Daily Value added at the bottom in a footnote. [Return to Figure 3] 16 Learning Activity III Special Diets, Allergies, Intolerances, Emergent Issues, and Trends 17 Introduction to Special Diets, Allergies, Intolerances, Emergent Issues, and Trends \n",
      "\n",
      "QUESTIONS 2\n",
      "Describe food allergies and intolerances ### Describe a variety of special diets ### Identify ingredients appropriate for special diets, allergies, and intolerances ### Discuss emergent issues and trends\n",
      "LECTURE 2\n",
      "Bakers prepare food for a wide audience, and that means addressing nutritional and dietary concerns has to be a top priority. The majority of issues facing bakers are related to allergies and intolerances to particular ingredients, such as gluten and lactose. Bakers and pastry chefs must also be aware of other dietary restrictions, such as the variety of vegetarian diets ranging from ovo-lacto vegetarians who eat eggs and dairy to vegans who do not consume any animal products, including honey. Religion-based diets, such as kosher and halal, are also important to consider when producing baked goods that contain meat and dairy products, as is the ever-changing landscape of personal preferences and fad diets. 18 Food Allergies and Intolerances This section focuses on food allergies and intolerances, which are areas of great concern in the food service industry. Bakers must pay close attention to how they accommodate food allergies and intolerances in their products, and may need to offer \n",
      "015 Organics Ban:  Foods Usually Exempt from Carrying a Nutrition Facts Table: “Gluten Free” Claims in the Marketplace: Gluten-free is the fastest-growing market segment addressing food intolerances:  GM foods approved by Health Canada: Growing Resistance: Canadian Farmers and the Politics of Genetically Modified Wheat:  Health Canada website: Highwood Crossing:  High-sodium restaurant meals: Information for Canadians with a soy allergy: List of ingredients and allergens – Manner of declaring:  List of Permitted Additives: Locust bean gum: Mesquite flour:  Milk allergies: Novel foods: Robin Hood’s basic white bread recipe: “Safety for Patients With Celiac Disease of Baked Goods Made of Wheat Flour Hydrolyzed During Food Processing” (2011) [PDF]: Sugar substitutes: Tax Reductions for Celiac Disease:  Teff:  The Secrets of Sugar: Type 2 diabetes:  Understanding GMO: Vancouver city bylaw ban on food scraps: Voluntary labelling standard:  When to use food allergen precautionary labelling: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "patterndevelopment.html contains Learning Objectives\n",
      "extracted 5 lectures and 5 questions groups\n",
      "QUESTIONS 0\n",
      "Understand the layout and pattern-development processes. ### Layout Terms Elevation view – looking at the front or side of something, to have elevation (height), 2D. ### Element Line – a line representing an edge or bend. ### Perimeter – the distance around an object. ### Plan view – looking down at something, a “birds eye view,” “floor plan,” 2D. ### Profile – a view showing half of a plan view. ### Sector – a special profile which is inside of an object, a section view. ### Step-off – a length equal to of a circumference. ### Stretch-out – a shape which has been “stretched out,” to take a perimeter and make it straight. ### True length – a dimension or line that is not distorted by the view.\n",
      "LECTURE 0\n",
      "I Geometric Construction Introduction As a sheet metal worker, we work with different lines, angles and shapes. We work with geometry. Be it in the field or in a shop, geometry is a tool we use in many different ways. From creating 2D patterns of 3D objects, to making sure roof panels are installed square, to locating duct runs and penetrations, geometry is used everyday by a sheet metal worker. This is the foundation for which all layout is done. Craftspeople who excel at this stage are able to quickly transform any complex ideas into reality. \n",
      "I Geometric Construction Introduction As a sheet metal worker, we work with different lines, angles and shapes. We work with geometry. Be it in the field or in a shop, geometry is a tool we use in many different ways. From creating 2D patterns of 3D objects, to making sure roof panels are installed square, to locating duct runs and penetrations, geometry is used everyday by a sheet metal worker. This is the foundation for which all layout is done. Craftspeople who excel at this stage are able to quickly transform any complex ideas into reality. \n",
      "\n",
      "QUESTIONS 1\n",
      "Understand the process of geometric construction and its uses ### Learn geometric terms ### Geometric Terms Acute Angle/Triangle – an angle/triangle with an angle smaller than 90° ### Bisect – to divide in half ### Horizontal – a line/plane level with the horizon. Flat, level ### Obtuse Angle/Triangle – an angle/triangle with an angle larger than 90° ### Parallel – a line/plane that is equal distance from another\n",
      "LECTURE 1\n",
      "Parts of a Circle Radius – the distance from centre to any point of the circumference or half the diameter Diameter – the distance across a circle at centre, twice the radius Circumference – the distance around a circle, perimeter of a circle Arc – a portion of a circumference Chord – a straight line from 2 points on a circumference Segment – the area of a circle bound by an arc and a chord Sector – the area of a circle bound by 2 radii and an arc Quadrant – a sector which equals one quarter of the area of a circle Tangent – a line which touches only 1 point of a circumference Point of Tangency – 90° to the centre of the circle Perpendicular – a line/plane which is 90° to another Right Angle/Triangle – an angle/triangle which has a 90° angle Vertical – a line/plane straight up and down, vertically level (plumb) Vertex – the point at which an angle is formed Circle Facts: There are 360° in a circle. Circumference (or perimeter) = Pi × diameter or 2 × Pi × radius. Area = Pi × radius 2 . \n",
      "Use this radius to draw a complete circle. Set your compass to the required side length and swing it along the circumference however many times needed to complete the polygon. 13 Video: Geometric Construction Watch the following video: Geometric Construction (30 minutes) II Parallel Line Pattern Development Introduction When wanting to build a project, we need to first imagine it. The process of pattern development gives us the ability to take that visual representation and actually create the object. It allows us to turn two-dimensional metal into three-dimensional objects, which is the basis for everything we fabricate. Consider a globe and a map. The map is a 2D representation of a 3D object. What should the map look like? Is it truly flat? Well, maybe some would argue, but a map is not a true representation of the Earth until we remove some of it. The actual shape of the map will have numerous “cut outs” which would allow it to form a sphere. This is a form of pattern development. \n",
      "\n",
      "QUESTIONS 2\n",
      "Understand the parallel line pattern development processes. ### Understand the “language” of layout.\n",
      "LECTURE 2\n",
      "Layout Terms Allowance – the material needed for a specific component. “We must allow this much extra.” Usually a seam for connection. Auxiliary Line – an extra element line added, different from the standard divisions. Elbow Rule – the number of pieces of a round elbow times 2 then minus 2 (# of pcs × 2 − 2) gives us the number of gores in the elbow. Element Line – a line representing an edge or bend. Elevation View – looking at the front or side of something, to have elevation (height), 2D. Gore – a part of a round elbow which allows us to calculate the miter angle. Miter – an intersection of 2 pieces, an irregular cut on the end of something. Pattern – the shape of the object, still in 2D form. Plan view – looking down at something, a “birds eye view,” “floor plan,” (2D). Profile – a half of a plan view, drawn on the outside of an object. Sector – a special profile which is inside of an object, a section view. Stretch-out -a shape which has been “stretched out,” to take a perimeter \n",
      "allel Line Pattern Development, we required parallel element line or bends. Some objects are of a conical shape and parallel line will not work on them. Rather, we will look at using Radial Line Pattern Development . In radial line, we develop patterns for shapes that have a taper, all element lines (bends) must radiate back to a common point, a radius point. We need two things for this process to work: A radius point that is on centre (right cone). A radius point that is within a reasonable distance. So, when we find ourselves determining if radial line will work, we look at those two things. If the cone is a scalene or oblique cone, it will not work. If a radius point is 40 feet away, it is not worth the effort with this process, another should be chosen, but if it will fit in our bench space, then it will work. Being one of the simplest forms of layout, it allows us to create these patterns with accuracy and speed. If we can use radial line, it is an effective and efficient choice. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "physicalgeology2ed.html contains Learning Objectives\n",
      "extracted 18 lectures and 18 questions groups\n",
      "QUESTIONS 0\n",
      "Explain what geology is, how it incorporates the other sciences, and how it is different from the other sciences. ### Discuss why we study Earth and what type of work geologists do. ### Define some of the properties of a mineral and explain the differences between minerals and rocks. ### Describe the nature of Earth’s interior and some of the processes that take place deep beneath our feet. ### Explain how those processes are related to plate tectonics and describe a few of the features that are characteristic of plate boundaries. ### Use the notation for geological time, gain an appreciation for the vastness of geological time, and describe how very slow geological processes can have enormous impacts over time.\n",
      "LECTURE 0\n",
      "1 1.1 What is Geology? In its broadest sense, geology is the study of Earth—its interior and its exterior surface, the minerals, rocks and other materials that are around us, the processes that have resulted in the formation of those materials, the water that flows over the surface and through the ground, the changes that have taken place over the vastness of geological time, and the changes that we can anticipate will take place in the near future. Geology is a science, meaning that we use deductive reasoning and scientific methods to understand geological problems. It is, arguably, the most integrated of all of the sciences because it involves the understanding and application of all of the other sciences: physics, chemistry, biology, mathematics, astronomy, and others. But unlike most of the other sciences, geology has an extra dimension, that of time—deep time—billions of years of it. Geologists study the evidence that they see around them, but in most cases, they are observing the\n",
      "gists are also engaged in fundamental research about Earth and in teaching. 1.4 Minerals and Rocks Minerals are naturally occurring, specific combinations of elements that have particular three-dimensional structures. Rocks are made up of mixtures of minerals and can form though igneous, sedimentary, or metamorphic processes. 1.5 Fundamentals of Plate Tectonics The Earth’s mantle is convecting because it is being heated from below by the hot core. Those convection currents contribute to the movement of tectonic plates (which are composed of the crust and the uppermost rigid mantle). Plates are formed at divergent boundaries and consumed (subducted) at convergent boundaries. Many important geological processes take place at plate boundaries. 1.6 Geological Time Earth is approximately 4,570,000,000 years old; that is, 4.57 billion years or 4.57 Ga or 4,570 Ma. It’s such a huge amount of time that even extremely slow geological processes can have an enormous impact. II Chapter 2 Minerals \n",
      "\n",
      "QUESTIONS 1\n",
      "Describe the nature of atoms and their constituents, particularly the behaviour of electrons and the formation of ions. ### Apply your understanding of atoms to explain bonding within minerals. ### Describe mineral lattices and explain how they influence mineral properties. ### Categorize minerals into groups based on their compositions. ### Describe a silica tetrahedron and the ways in which tetrahedra combine to make silicate minerals. ### Differentiate between ferromagnesian and other silicate minerals. ### Explain some of the mechanisms of mineral formation. ### Describe some of the important techniques for identifying minerals.\n",
      "LECTURE 1\n",
      "Minerals are all around us: the graphite in your pencil, the salt on your table, the plaster on your walls, and the trace amounts of gold in your computer. Minerals can be found in a wide variety of consumer products including paper, medicine, processed foods, cosmetics, electronic devices, and many more. And of course, everything made of metal is also derived from minerals. As defined in Chapter 1, a mineral is a naturally occurring combination of specific elements arranged in a particular repeating three-dimensional structure (Figure 1.4.1). “ Naturally occurring ” implies that minerals are not artificially made.  Many minerals (e.g., diamond) can be made in laboratories, but if they can also occur naturally, they still qualify as minerals. “ Specific elements ” means that most minerals have a specific chemical formula or composition. The mineral pyrite, for example, is FeS 2 (two atoms of sulfur for each atom of iron), and any significant departure from that would make it a differen\n",
      "ing to the anion part of their formula, with some common types being oxides, sulphides, sulphates, halides, carbonates, phosphates, silicates, and native minerals. 2.4 Silicate Minerals Silicate minerals are, by far, the most important minerals in Earth’s crust. They all include silica tetrahedra (four oxygens surrounding a single silicon atom) arranged in different structures (chains, sheets, etc.). Some silicate minerals include iron or magnesium and are called ferromagnesian silicates. 2.5 Formation of Minerals Most minerals in the crust form from the cooling and crystallization of magma. Some form from hot water solutions, during metamorphism or weathering, or through organic processes. 2.6 Mineral Properties Some of the important properties for mineral identification include hardness, cleavage/fracture, density, lustre, colour, and streak colour.  It’s critical to be able to recognize these properties in order to be able to identify minerals. III Chapter 3 Intrusive Igneous Rocks \n",
      "\n",
      "QUESTIONS 2\n",
      "Explain the relationships between plate tectonics, the formation of magma, and volcanism. ### Describe the range of magma compositions formed in differing tectonic environments, and discuss the relationship between magma composition and eruption style. ### Explain the geological and eruption-style differences between different types of volcanoes, especially shield volcanoes, composite volcanoes, and cinder cones. ### Understand the types of hazards posed to people and to infrastructure by the different types of volcanic eruptions. ### Describe the symptoms that we can expect to observe when a volcano is ready to erupt, and the techniques that we can use to monitor those volcanic symptoms and predict eruptions. ### Summarize the types of volcanoes that have erupted in British Columbia since 2.6 Ma, and the characteristics of some of those eruptions.\n",
      "LECTURE 2\n",
      "A volcano is any location where magma comes to the surface, or has done so within the past several million years. This can include eruptions on the ocean floor (or even under the water of a lake), where they are called subaqueous eruptions , or on land, where they are called subaerial eruptions . Not all volcanic eruptions produce the volcanic mountains with which we are familiar; in fact most of Earth’s volcanism takes place along the spreading ridges on the sea floor and does not produce volcanic mountains at all—not even sea-floor mountains. Canada has a great deal of volcanic rock, but most of it is old, some of it billions of years old. Only in B.C. and the Yukon are there volcanoes that have been active since 2.6 Ma (Pleistocene or younger), and the vast majority of these are in B.C. We’ll look at those in some detail toward the end of this chapter, but a few of them are shown on Figures 4.0.1 and 4.0.2. The study of volcanoes is critical to our understanding of the geological ev\n",
      "olcano-related mudflows, can be large enough to destroy entire towns.  Lava flows will destroy anything in their paths, but tend to move slowly enough so that people can get to safety.  But the indirect effects of volcanism have been more deadly in the past, mostly because volcanic ash and gases can lead to short-term significant climate cooling. 4.5 Monitoring Volcanoes and Predicting Eruptions We have the understanding and technology to predict volcanic eruptions with some success, and to ensure that people are not harmed. The prediction techniques include monitoring seismicity in volcanic regions, detecting volcanic gases, and measuring deformation of the flanks of a volcano. 4.6 Volcanoes in British Columbia There are examples of all of the important types of volcanoes in British Columbia, including subduction volcanism north of Vancouver, mantle-plume volcanism along the Nazco trend, and rift-related volcanism in the Wells Gray and Stikine regions. V Chapter 5 Weathering and Soil \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "plantidentification.html contains Learning Objectives\n",
      "extracted 32 lectures and 32 questions groups\n",
      "QUESTIONS 0\n",
      "Describe the scientific system of plant classification and naming.\n",
      "LECTURE 0\n",
      "A working knowledge of taxonomy is useful for classifying, naming, and identifying unknown plants. Theophrastus (370-285 BC), a Greek philosopher, first used taxonomy to describe and group plants according to their morphology (shape), growth, and reproductive traits. In the 18th century, a scientist named Carl Linnaeus applied binomials (two-term names) and classified known plants into a hierarchical system of classification. Classification and Naming The most effective classification systems are hierarchical and comprised of a nested series of categories or ranks. A good analogy is a computer filing system. Certain kinds of information reside at each level (drive, library, directory or folder, sub-directory, document, etc.), with file names (or labels) that signify the sort of information found there. Every level in the hierarchy is more inclusive than the one below it and the more of the filing system that is investigated, the more related information is uncovered. Similarly, the cat\n",
      "other words, the taxa “family” may include numerous plant genera, and within a genus (singular of genera) there may be any number of species, whereas within a given species, a subspecies may describe only a few populations or individuals. Within taxa – family, genus, species, etc., there are identifiable characteristics common to each group. For example, plants in the cypress family typically have broad, flattened, scale leaves, while plants in the pine family exhibit needle-like leaves. Once organized into a sensible system that recognizes similarities or relatedness, the grouping becomes easier to understand and remember. That is, once characteristics for a given group are known, they can be used to match unknown plants with known taxons. Plant Classification Hierarchy of Taxons Family Genus (plural = genera) Species Subspecies or Variety Forma Other Classification terms Hybrid Cultivar Common Names Plant Groups Review Identify the hierarchy of plant taxons. 3 Introduction to Taxons \n",
      "\n",
      "QUESTIONS 1\n",
      "Identify characteristics of taxons.\n",
      "LECTURE 1\n",
      "The plant family taxon is a grouping of plants consisting of one or more related genera that are more like each other than to other genera, and that includes the entire surviving lineage of the ancestral population. Family names always end with the suffix -aceae, except in a few notable cases where use of traditional names is also acceptable. Newer family names are based on the “type-genus” concept which means that for every family there is a genus that best represents the characteristics of the family. For example, Brassica (the cabbage genus) is the base for the family Brassicaceae, as is Rosa (the rose genus) for the family Rosaceae. Older family names are still used since many are somewhat descriptive and may be more familiar than their newer counterparts. For example, Cruciferae (from the Latin crucifer, a cross) refers to the four-petal arrangement of flowers characteristic of the mustard family. The revised family names for some familiar plant groups are listed in Table 3.1. Tab\n",
      "in established and reclassified family names can be expected. Table 3.2:  Reclassified family names Family Name Reclassified Name Common Name Aceraceae Sapindaceae Soapberry Asclepiadaceae Apocynaceae Dogbane Taxodiaceae Cupressaceae Cypress Taxonomic Example The list of ten Pacific Northwest native conifers can be grouped into three families.  Within each family, there are a different number of genera, as represented by the common names. Within each genus, unless a monospecific (single) genus as with Taxus and Pseudotsuga, there are a number of different species. Pinaceae – pine family Douglas fir ( Pseudotsuga , 1 species) hemlock ( Tsuga , 2 species) larch ( Larix , 3 species) true fir ( Abies , 3 species) spruce ( Picea , 4 species) pine ( Pinus , 7 species) Cupressaceae – cypress family arborvitae ( Thuja , 1 species) yellow cedar ( Cupressus , 1 species) juniper ( Juniperus , 3 species) Taxaceae – yew family yew ( Taxus , 1 species) Review 4 Introduction to Binomial Nomenclature \n",
      "\n",
      "QUESTIONS 2\n",
      "Employ correct naming and plant identification terminology.\n",
      "LECTURE 2\n",
      "For an orderly system of classification, botanists give each group of plants a name that is recognized by people who know binomial nomenclature, regardless of where they are or the language they speak. This way every plant species will have a unique botanical name based on the binomial system of nomenclature. For example, one of the best-known trees of the Pacific Northwest, the Douglas fir, recognizes botanist Archibald Menzies in its scientific name Pseudotsuga menziesii . While the common name recognizes fellow botanist David Douglas, Archibard Menzies is credited with the first botanical description of the plant. A plant name or binomial is made up of two names: a genus name and a (usually) descriptive specific epithet (species name), both commonly of Latin or Greek origin. For example, of the many species within the group known as pines (genus = Pinus ) there is only one named Pinus contorta (contorta = twisted). This species is characterized by often having contorted or twisted y\n",
      "l completely different plants. For example, the common name “cedar” is a name given to a variety of plants with aromatic wood (recalling the “cedar” of antiquity, Cedrus spp.) or to plants that are reminiscent of other plants called “cedars,” for example. In the Pacific Northwest, cedar refers to Thuja (western red cedar) and to Cupressus (yellow cedar). Similarly, a single species may have numerous common names, particularly if known from a variety of locations. For example, yellow cedar is also known as Nootka cypress and Alaska cedar. Clearly, there is potential for much confusion with common names. In text, common names are written out in lower case, except where they include proper names; e.g., Douglas fir, Japanese painted fern, etc. Common names are not botanical names. While botanical names are often, at least initially, difficult to remember and pronounce, they are universally recognized and considerably more accurate than common names. 5 Conventions for Binomial Nomenclature \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "postconfederation.html contains Learning Objectives\n",
      "extracted 12 lectures and 12 questions groups\n",
      "QUESTIONS 0\n",
      "Describe the political and economic background to Confederation. ### Identify the principal features of the Aboriginal and non-Aboriginal people in the northern half of North America. ### Explain the residual uncertainty about, and the hostility toward, the Canadian project.\n",
      "LECTURE 0\n",
      "Figure 1.1 Canada provinces evolution 2 by Golbez is used under a CC-BY-SA-3.0 license. 3 1.2 Historical Demography of Canada, 1608-1921 Lisa Dillon, Département de démographie, Université de Montréal Sustained settlement of Canada by Europeans began in the St. Lawrence Valley, where the colony named “le Canada” stretched over 500 km from Quebec City to present-day Montreal. Hubert Charbonneau, Bertrand Desjardins, Jacques Légaré and Hubert Denis, “The Population of the St. Lawrence Valley, 1608-1760,” in Michael Haines and Richard Steckel, eds., A Population History of North America (Cambridge: Cambridge University Press, 2000): 99. From its founding in 1608 by Samuel de Champlain, the colony grew modestly until 1663, when the King of France, Louis XIV, and Jean-Baptiste Colbert, his minister of finance, instituted measures for the colony to grow through natural increase . Male immigrants dominated the colony in its early years, creating a severe sex ratio imbalance. However, between \n",
      "erecting a national sensibility in the years immediately after Confederation. Maritimers may have had common interests but they also had a century of intercolonial competition and rivalry under their belts. British Columbians referred to “Canadians” contemptuously and regarded the BNA colonies on the other side of the continent as at least as foreign as Americans. Regional and provincial accents were strong, even among the English-speaking populations. This chapter examines the new federal union’s growth in the years from 1867 to about 1900. During these years, it became clear that there was no singular vision of “Canada” to which everyone could subscribe. The conflicts that arose between several of these competing views were very often vocal and sometimes lethal. Keeping in mind that the previous Canadian constitution — the Act of Union of 1841 — lasted a mere 26 years before being tossed out, one can understand how the three decades after Confederation were understood to be pivotal. \n",
      "\n",
      "QUESTIONS 1\n",
      "Describe the territorial growth of Canada from 1867 to circa 1914. ### Account for Canada’s struggle to attract certain colonies into the fold. ### Explain the rise of secessionist movements in the 19th century. ### Outline the relationship between Canada and First Nations during this period. ### Detail the institutions that were created and utilized for the purpose of expanding the Dominion of Canada.\n",
      "LECTURE 1\n",
      "9 2.2 Nova Scotia's Second Thoughts Nova Scotia was, of course, one of the original parties to the federal union. From the outset, however, there were political and economic leaders in the colony who had qualms. Nova Scotia would have been the leading third in the proposed Maritime Union with New Brunswick and Prince Edward Island. Halifax was easily the largest city and one of the most industrially advanced. Even if it didn’t become the political capital of the “United Maritimes,” it would emerge almost certainly as the economic capital of this new configuration. The 1864 Maritime Union plan was put aside to make way for Confederation, and many Nova Scotians continued to think that was a mistake. Buyer’s Remorse The most prominent and highly appealing opponent of Confederation was Joseph Howe. A journalist and writer, his political speeches and editorials were of an exceptional calibre. His initial opposition to Confederation stemmed from a belief in a broader British imperial federat\n",
      "): D86-106. The proportion of Canadians living on the land was still greater than that of urbanites, but, as of 1901, the number of Canadians earning an income from wages pulled ahead of those earning farm incomes. And those wage-earning workers were doing so increasingly in industries and factories that did not much resemble what existed in the 1860s. Figure 3.7 As late as 1910, the boundary between rural life and industrial employment was not a great one. The countryside forms a backdrop to a shoe factory in Aurora, Ontario, ca. 1910. Postcards like this one were a way of framing modernization and material progress. Industrialization marked a significant departure from the pre-Confederation economy, and it brought in its wake social and economic changes that could hardly have been predicted. It was, however, part of a conscious strategy for nation-building and making economic policy. The most obvious expression of that strategic (and, yes, hopeful) thinking was the National Policy . \n",
      "\n",
      "QUESTIONS 2\n",
      "Develop an understanding of the causes and contours of the Second Industrial Revolution. ### Explain the rise of a working class and describe its main features. ### Assess the main features and goals of the National Policy and its individual components. ### Discuss the ways in which age and gender shaped the historic experience of industrialization. ### Connect the phenomena of industrialization with urbanization in the pre-1914 period. ### Describe the strategies explored by working people to improve their conditions. ### Account for the rise of the first-wave of feminism.\n",
      "LECTURE 2\n",
      "Figure 3.1 Coal Mining, Alberta – picking coal before same leaves on conveyor – Atlas Mine (Online MIKAN no.3351151) by Library and Archives Canada is in the public domain . Figure 3.2 Habitant series – weaving loom (Online MIKAN no.3349488) by Library and Archives Canada is in the public domain . Figure 3.3 The loading pier at Bell Island by Verne Equinox is in the public domain . Figure 3.4 A horse-drawn winter tram by Tim Pierce is in the public domain . Figure 3.5 Drawing of a horse-powered thresher by Bogdan is in the public domain . Figure 3.6 Artist rendering of the Sydney Nova Scotia by Verne Equinox is in the public domain . Figure 3.7 Shoe factory, Aurora, Ontario, Canada by Special Collections Toronto Public Library is used under a CC BY SA 2.0 license. This image is available from Toronto Public Library under the identifier PC-ON 65 . 23 3.2 Industrialization, Labour, and Historians Robert Sweeny, Dept. of History, Memorial University of Newfoundland Figure 3.8 Postcards li\n",
      ", from time to time, play a considerable and active role in many facets of Canadian life. Political history is about much more than constitutional history, but the constitution and the division of powers found therein are the ground rules for the Dominion’s governmental processes. As well, the British North America Act functioned in the first three decades of Confederation as a kind of strategic plan. It is highly unusual for a constitution to include provision for a railway; in the BNA Act it stands out like a contractual obligation, and this was a facet that was reinforced in BC’s Terms of Union in 1871. Likewise the BNA Act , and the debates that brought it together, made it clear that Canada was to be a mutual defence pact between a small group of colonies that were highly anxious about American appetites. Measuring the performance of 19th century governments in particular thus means that we have to look at the tasks they were given and how they interpreted their responsibilities. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "postconfederation2e.html contains Learning Objectives\n",
      "extracted 12 lectures and 12 questions groups\n",
      "QUESTIONS 0\n",
      "Describe the political and economic background to Confederation. ### Identify the principal features of the Indigenous and non-Indigenous people in the northern half of North America. ### Explain the residual uncertainty about, and the hostility toward, the Canadian project.\n",
      "LECTURE 0\n",
      "Long Descriptions Figure 1.1 long description: A series of historical maps of Canada between 1867 and 2003. In order, the maps are labelled: July 1, 1867: Dominion of Canada formed. July 15, 1870: Rupert’s Land and North-Western Territory join, become Northwest Territories; Manitoba formed. July 20, 1871: British Columbia joins. July 1, 1873: Prince Edward Island joins. July 26, 1874: Ontario provisionally expanded north and west. April 12, 1876: District of Keewatin formed. September 1, 1880: British Arctic Islands join as part of North-West Territories. July 1, 1881: Manitoba expanded. May 7, 1886: Border of District of Keewatin adjusted. August 12, 1889: Ontario’s expansion finalized. October 2, 1895: District of Keewatin enlarged. June 13, 1898: Yukon Territory formed, Quebec enlarged. May 23, 1901: Yukon Territory adjusted. September 1, 1905: Alberta and Saskatchewan formed, District of Keewatin dissolved. May 15, 1912: Manitoba, Ontario, and Quebec enlarged; North-West Territorie\n",
      "erecting a national sensibility in the years immediately after Confederation. Maritimers may have had common interests but they also had a century of intercolonial competition and rivalry under their belts. British Columbians referred to “Canadians” contemptuously and regarded the BNA colonies on the other side of the continent as at least as foreign as Americans. Regional and provincial accents were strong, even among the English-speaking populations. This chapter examines the new federal union’s growth in the years from 1867 to about 1900. During these years, it became clear that there was no singular vision of “Canada” to which everyone could subscribe. The conflicts that arose between several of these competing views were very often vocal and sometimes lethal. Keeping in mind that the previous Canadian constitution — the Act of Union of 1841 — lasted a mere 26 years before being tossed out, one can understand how the three decades after Confederation were understood to be pivotal. \n",
      "\n",
      "QUESTIONS 1\n",
      "Describe the territorial growth of Canada from 1867 to circa 1914. ### Account for Canada’s struggle to attract certain colonies into the fold. ### Explain the rise of secessionist movements in the 19th century. ### Outline the relationship between Canada and First Nations during this period. ### Detail the institutions that were created and utilized for the purpose of expanding the Dominion of Canada.\n",
      "LECTURE 1\n",
      "9 2.2 Nova Scotia’s Second Thoughts Nova Scotia was, of course, one of the original parties to the federal union. From the outset, however, there were political and economic leaders in the colony who had qualms. Nova Scotia would have been the leading third in the proposed Maritime Union with New Brunswick and Prince Edward Island. Halifax was easily the largest city and one of the most industrially advanced. Even if it didn’t become the political capital of the “United Maritimes,” it would emerge almost certainly as the economic capital of this new configuration. The 1864 Maritime Union plan was put aside to make way for Confederation, and many Nova Scotians continued to think that was a mistake. Buyer’s Remorse The most prominent and highly appealing opponent of Confederation was Joseph Howe. A journalist and writer, his political speeches and editorials were of an exceptional calibre. His initial opposition to Confederation stemmed from a belief in a broader British imperial federat\n",
      " (715,122). The proportion of Canadians living on the land was still greater than that of urbanites, but, as of 1901, the number of Canadians earning an income from wages pulled ahead of those earning farm incomes. And those wage-earning workers were doing so increasingly in industries and factories that did not much resemble what existed in the 1860s. Figure 3.7 As late as 1910, the boundary between rural life and industrial employment was not a great one. The countryside forms a backdrop to a shoe factory in Aurora, Ontario, ca. 1910. Postcards like this one were a way of framing modernization and material progress. Industrialization marked a significant departure from the pre-Confederation economy, and it brought in its wake social and economic changes that could hardly have been predicted. It was, however, part of a conscious strategy for nation-building and making economic policy. The most obvious expression of that strategic (and, yes, hopeful) thinking was the National Policy . \n",
      "\n",
      "QUESTIONS 2\n",
      "Develop an understanding of the causes and contours of the Second Industrial Revolution. ### Explain the rise of a working class and describe its main features. ### Assess the main features and goals of the National Policy and its individual components. ### Discuss the ways in which age and gender shaped the historic experience of industrialization. ### Connect the phenomena of industrialization with urbanization in the pre-1914 period. ### Describe the strategies explored by working people to improve their conditions. ### Account for the rise of the first-wave of feminism.\n",
      "LECTURE 2\n",
      "Coal Mining, Alberta © Library and Archives Canada (MIKAN no. 3351151) is licensed under a Public Domain license Weaving Loom (Habitant Series) © Library and Archives Canada (MIKAN no. 3349488) is licensed under a Public Domain license The loading pier at Bell Island, Conception Bay, Newfounland © C.W. Vernon is licensed under a Public Domain license Horse-drawn winter tram in Montreal © Montreal Street Railway Company is licensed under a Public Domain license Batteuse, 1881 is licensed under a Public Domain license SydneyCokeOvenGeneralViewCa1900 Shoe Factory in Aurora, Ontario © Warwick Bros &amp; Rutter, Toronto Public Library (PC-ON 65) is licensed under a Public Domain license Margaret R. Conrad and James K. Hiller, Atlantic Canada: A Concise History (Don Mills: Oxford University Press, 2006), 131-2. British coal miners who moved to Vancouver Island in the late 19th century repeatedly indicated that they saw West Coast mine work as a stepping stone to independence on their own lan\n",
      ", from time to time, play a considerable and active role in many facets of Canadian life. Political history is about much more than constitutional history, but the constitution and the division of powers found therein are the ground rules for the Dominion’s governmental processes. As well, the British North America Act functioned in the first three decades of Confederation as a kind of strategic plan. It is highly unusual for a constitution to include provision for a railway; in the BNA Act it stands out like a contractual obligation, and this was a facet that was reinforced in BC’s Terms of Union in 1871. Likewise the BNA Act , and the debates that brought it together, made it clear that Canada was to be a mutual defence pact between a small group of colonies that were highly anxious about American appetites. Measuring the performance of 19th century governments in particular thus means that we have to look at the tasks they were given and how they interpreted their responsibilities. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "preconfederation.html contains Learning Objectives\n",
      "extracted 14 lectures and 14 questions groups\n",
      "QUESTIONS 0\n",
      "Describe some of the principal concerns of historians as they undertake historical research. ### Explain the difference between primary and secondary sources. ### Demonstrate an ability to interrogate sources. ### Identify the dominant themes and debates in the telling of Canadian history.\n",
      "LECTURE 0\n",
      "2 1.2 The Writing of History The telling of every country’s national story is unique, and there are conflicts in that telling. Who gets to speak? Who does not? What alternative stories are there to be told? And how did it all turn out this way? Historical writing is never without purpose. As early as the 18th century, historical accounts of New France were being produced that promoted the role of the Catholic Church and the seigneurs (the major landowners) as the custodians of the Canadien culture. These accounts were intended to buttress the position of the Church and seigneurs in the years to come as the authentic voice of Canadien ambitions. In the mid- and late-19th century, nationalist histories covering the whole of the Canadian timeline began to appear. They told the tale of the new nation, the Dominion of Canada, as something that embodied a recognizable vision of the modern state and thus provided historical legitimacy. Titles like Colony to Nation (1946) tell the tale: Canada\n",
      " An Introduction for Students created by Kathryn Walbert for LEARN NC. It is used under a CC-BY-NC-SA 3.0 unported license. II Chapter 2. Aboriginal Canada before Contact 6 2.1 Introduction When does the history of Canada begin?  If we think of Canada as a political entity, then we will offer up one kind of answer (although, in all likelihood, we won’t agree at the outset on the answer). If we think of Canada as a space roughly defined by our current borders and as a stage on which humans perform, then the answer is necessarily going to take us as deeply into the past as we can go. Having taken on the question of how do we know what it is we think we know? in Chapter 1 , this chapter tackles the challenge of pushing back the frontier of history. Generations of students learned that the moment of contact between Europeans and Aboriginal peoples in the “Americas” marks the end of pre-history in this hemisphere and the beginning of the historical period. But that perspective has changed. \n",
      "\n",
      "QUESTIONS 1\n",
      "Explain the various interpretations, scientific and religious, of the origins of indigenous peoples in the New World. ### Describe the political, cultural, and social differences between the major eras of the pre-contact peoples of Canada. ### Describe the political, cultural, and social differences between the groups of the major regions of Canada. ### Identify the great empires and confederacies of the pre-contact Americas. ### Locate the many different peoples of what is now Canada and its borderlands. ### Describe the different language groups, the different economic orders of the northlands, and their interconnectedness. ### Argue critically against notions of “pan-Indianism” and speak to the advantages enjoyed by Aboriginal societies in the absence of European contact.\n",
      "LECTURE 1\n",
      "7 2.2 History without Archives The idea that the Americas have no history before the arrival of Europeans derives mainly from the apparent absence of a written record. European, Middle Eastern, and Asian civilizations evolved highly bureaucratic and centralized administrative functions based on the ability to write things down. The influential Canadian economic historian, Harold Innis , described the impact of writing on the building of empires in his 1951 book, The Bias of Communication. He argued that there are two kinds of communications: time-biased and space-biased. Time-biased media seek to transcend time. They are heavy and durable, such as clay and stone. They have a long lifespan but they do not encourage the extension of empires. Think here of ancient Egypt or Sumeria as examples. Innis associated these media with the customary, the sacred, and the moral: they’re heavy on gods and proclamations, light on detailed instructions. Time-biased media facilitate the development of s\n",
      " two significant challenges, however: distance and time. The long journey between Europe and the colonies meant that communication was difficult and slow. Distance and time played a key role in shaping colonial administration as well as patterns and methods of imperial control. The direct impact of European exploration on the northern half of North America was slight until the early 17th century, with colonization and some measure of agricultural settlement occurring only very slowly. The earlier successes modelled by the Spanish and Portuguese from the Carolinas south to Tierra del Fuego had a profound effect on European attitudes and ambitions for the lands to the north. This chapter surveys early European interest in what was called the “Americas” through the first stages of establishing colonies. It explores the various economic and political models that emerged, and the impact of this phase of transatlantic plunder on the emergence of western Europe as a centre of imperial power. \n",
      "\n",
      "QUESTIONS 2\n",
      "Type your learning objectives here. Account for the European incursion into the western Atlantic. ### Describe the factors that made European exploration and expansion possible. ### Identify the ideas and attitudes that provide the intellectual context for the “age of exploration.” ### Account for the presence of the French in North America. ### Explain the evident failure of Cartier’s expeditions.\n",
      "LECTURE 2\n",
      "Figure 3.1 Wikinger by Rdnk is in the public domain . 13 3.2 Beginnings of Globalism In Chapter 2 we considered the very deep history of human occupation in the Americas. Here, we do the same for the Europeans. Northwestern Europe to 1491 The earliest human-made or anthropogenic tools discovered in France have been dated to more than 1.5 million BPE, but that does not mean that there has been continuous human occupation of the region. The area’s multiple climate zones and various entry points made it a crossroads for human traffic over millennia. Neanderthal populations appear around 300,000 BPE but are thought to have gone extinct around 30,000 BPE. Modern humans (in this case, Cro-Magnons) became the dominant hominid species. They enjoyed a long run, but glaciation scoured humans and other fauna from much of northwestern Europe until about 15,000 years ago. It was only then — about the same time humans were appearing in the Americas, if not some years later — that humans returned to \n",
      " experiments in the English-speaking enclaves on the Atlantic seaboard. New France was distinct in its geography as well; rather than growing outward from a well-entrenched core, its people and its diplomacy rushed into and across the centre of the continent. At its peak in 1712, New France extended from Newfoundland to the Rocky Mountains and from Hudson Bay to the Gulf of Mexico. The extent to which New France was settled by French colonists, however, was limited to a few concentrated pockets. It is best to think of New France as an enormous zone of influence, one that was divided into five colonies, each with its own administration: Canada, Acadia, Hudson Bay, Newfoundland (Plaisance), and Louisiana. This chapter describes the establishment and growth of the colony, its economy, and its peoples. While it is easy to find ways in which New France was an extension and product of France itself, it is also important to observe the ways in which it was distinct from the “mother country.” \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "preconfederation2e.html contains Learning Objectives\n",
      "extracted 14 lectures and 14 questions groups\n",
      "QUESTIONS 0\n",
      "Describe some of the principal concerns of historians as they undertake historical research. ### Explain the difference between primary and secondary sources. ### Demonstrate an ability to interrogate sources. ### Identify the dominant themes and debates in the telling of Canadian history.\n",
      "LECTURE 0\n",
      "1.2 The Writing of History The telling of every country’s national story is unique, and there are conflicts in that telling. Who gets to speak? Who does not? What alternative stories are there to be told? And how did it all turn out this way? Historical writing is never without purpose. As early as the 18th century, historical accounts of New France were being produced that promoted the role of the Catholic Church and the seigneurs (the major landowners) as the custodians of the Canadien culture. These accounts were intended to buttress the position of the Church and seigneurs in the years to come as the authentic voice of Canadien ambitions. In the mid- and late-19th century, nationalist histories covering the whole of the Canadian timeline began to appear. They told the tale of the new nation, the Dominion of Canada, as something that embodied a recognizable vision of the modern state and thus provided historical legitimacy. Titles like Colony to Nation (1946) tell the tale: Canada h\n",
      " An Introduction for Students , created by Kathryn Walbert for LEARN NC. It is used under a CC BY-NC-SA 3.0 Unported licence. II Chapter 2. Indigenous Canada before Contact 2.1 Introduction When does the history of Canada begin?  If we think of Canada as a political entity, then we will offer up one kind of answer (although, in all likelihood, we won’t agree at the outset on the answer). If we think of Canada as a space roughly defined by our current borders and as a stage on which humans perform, then the answer is necessarily going to take us as deeply into the past as we can go. Having taken on the question of how do we know what it is we think we know? in Chapter 1 , this chapter tackles the challenge of pushing back the frontier of history. Generations of students learned that the moment of contact between Europeans and Indigenous peoples in the “Americas” marks the end of pre-history in this hemisphere and the beginning of the historical period. But that perspective has changed. \n",
      "\n",
      "QUESTIONS 1\n",
      "Explain the various interpretations, scientific and religious, of the origins of Indigenous peoples in the New World. ### Describe the political, cultural, and social differences between the major eras of the pre-contact peoples of Canada. ### Describe the political, cultural, and social differences between the groups of the major regions of Canada. ### Identify the great empires and confederacies of the pre-contact Americas. ### Locate the many different peoples of what is now Canada and its borderlands. ### Describe the different language groups, the different economic orders of the northlands, and their interconnectedness. ### Argue critically against notions of “pan-Indianism” and speak to the advantages enjoyed by Indigenous societies in the absence of European contact.\n",
      "LECTURE 1\n",
      "2.2 History without Archives The idea that the Americas have no history before the arrival of Europeans derives mainly from the apparent absence of a written record. European, Middle Eastern, and Asian civilizations evolved highly bureaucratic and centralized administrative functions based on the ability to write things down. The influential Canadian economic historian, Harold Innis , described the impact of writing on the building of empires in his 1951 book, The Bias of Communication. He argued that there are two kinds of communications: time-biased and space-biased. Time-biased media seek to transcend time. They are heavy and durable, such as clay and stone. They have a long lifespan but they do not encourage the extension of empires. Think here of ancient Egypt or Sumeria as examples. Innis associated these media with the customary, the sacred, and the moral: they’re heavy on gods and proclamations, light on detailed instructions. Time-biased media facilitate the development of soc\n",
      " two significant challenges, however: distance and time. The long journey between Europe and the colonies meant that communication was difficult and slow. Distance and time played a key role in shaping colonial administration as well as patterns and methods of imperial control. The direct impact of European exploration on the northern half of North America was slight until the early 17th century, with colonization and some measure of agricultural settlement occurring only very slowly. The earlier successes modelled by the Spanish and Portuguese from the Carolinas south to Tierra del Fuego had a profound effect on European attitudes and ambitions for the lands to the north. This chapter surveys early European interest in what was called the “Americas” through the first stages of establishing colonies. It explores the various economic and political models that emerged, and the impact of this phase of transatlantic plunder on the emergence of western Europe as a centre of imperial power. \n",
      "\n",
      "QUESTIONS 2\n",
      "Type your learning objectives here. Account for the European incursion into the western Atlantic. ### Describe the factors that made European exploration and expansion possible. ### Identify the ideas and attitudes that provide the intellectual context for the “age of exploration.” ### Account for the presence of the French in North America. ### Explain the evident failure of Cartier’s expeditions.\n",
      "LECTURE 2\n",
      "St. Brendan © unknown adapted by Chet Van Duzer is licensed under a Public Domain license 3.2 Beginnings of Globalism In Chapter 2 we considered the very deep history of human occupation in the Americas. Here, we do the same for the Europeans. Northwestern Europe to 1491 The earliest human-made or anthropogenic tools discovered in France have been dated to more than 1.5 million BP, but that does not mean that there has been continuous human occupation of the region. The area’s multiple climate zones and various entry points made it a crossroads for human traffic over millennia. Neanderthal populations appear around 300,000 BP but are thought to have gone extinct around 30,000 BP. Modern humans (in this case, Cro-Magnons) became the dominant hominid species. They enjoyed a long run, but glaciation scoured humans and other fauna from much of northwestern Europe until about 15,000 years ago. It was only then — about the same time humans were appearing in the Americas, if not some years la\n",
      " however, was limited to a few concentrated pockets. It is best to think of New France as an enormous zone of influence, one that was divided into five colonies, each with its own administration: Canada, Acadia, Hudson Bay, Newfoundland (Plaisance), and Louisiana. This chapter describes the establishment and growth of the colony, its economy, and its peoples. While it is easy to find ways in which New France was an extension and product of France itself, it is also important to observe the ways in which it was distinct from the “mother country.” Historians on Video Allan Greer is a professor of history at McGill University in Montreal. Here, he talks about New France and why (and what) we should learn about its history … and how its history impacts our present. Here is a link to the transcript of a video titled What should a student of pre-Confederation history know about New France? [PDF] . A video element has been excluded from this version of the text. You can watch it online here: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "psyclanguage.html contains Learning Objectives\n",
      "extracted 9 lectures and 9 questions groups\n",
      "QUESTIONS 0\n",
      "Understand the defining characteristics of human language ### Explore the concept of language families and their typology ### Describe the research techniques employed by psycholinguists\n",
      "LECTURE 0\n",
      "Language is the most human of all qualities. No human population has been found that doesn’t have language and uses it not just for communication but as an instrument of cultural identity and transmission. Psycholinguistics is a discipline with roots in psychology and linguistics. It combines the theories from both to develop a scientific understanding of language. Given the centrality of language to human culture, its analysis and investigation goes back thousands of years. The earliest formalization of a language was conducted almost 4000 years ago in Babylonia. As Sumerian was considered a language of prestige, word lists of the language were created to help people learn it as a foreign language. A similar position was help by Sanskrit in India. Around 1200 BCE, the oral transmission of the Vedas became standardized in as people started to notice that the language was changing over time (Staal, 1986). Strict rules were developed to preserve the oral scriptures which have survived to\n",
      "as a common human attribute Psycholinguists use a variety of research methods to explore language 6 References Dinesh Ramoo Chomsky, N. (1959). Review of “Verbal behavior” by B. F. Skinner. Language , 35, 26–58. Freud, S. (1901/1975). The psychopathology of everyday life (Trans. A. Tyson). Harmondsworth, UK: Penguin. Meringer, R., &amp; Mayer, K. (1895). Versprechen und Verlesen: Eine Pyschologisch-Linguistische Studie . Stuttgart: Gössen. Osgood, C. E., &amp; Sebeok, T. A. (Eds.). (1954/1965). Psycholinguistics: A survey of theory and research problems . Bloomington: Indiana University Press. Bod R. (2014). A new history of the humanities: The search for principles and patterns from antiquity to the present . Oxford University Press. Shallice, T. (1988). From neuropsychology to mental structure . Cambridge: Cambridge University Press. Staal, J. F. (1986). The fidelity of oral tradition and the origins of science . North-Holland Publishing Company. II Chapter 2: The Sounds of Language \n",
      "\n",
      "QUESTIONS 1\n",
      "Understand how sounds can be categorised based on how they are produced. ### Explore how we produce the different sounds in our language ### Describe the role of syllables and syllable structure in language ### Explore the presence of phonological rules in various languages\n",
      "LECTURE 1\n",
      "This chapter is an introduction to various articulatory building blocks that make up human language: sounds and syllables. We will explore how we define the specific sounds of language and how we can describe them. You may encounter a lot of technical terminology and it may appear difficult at first to understand these terms. However, you will find it worthwhile as you will gain valuable insight into how you speak. You will also find it easier to understand the rest of this book as the classification of sounds forms the basis for a lot of what we will be discussing later. 7 2.1 Describing Sounds Dinesh Ramoo The sounds we produce can be described in terms of their physical properties and in terms of how they are articulated. The acoustic details of speech sounds are studied as phonetics . The description of sounds in terms of how they are produced is known as phonology . Think about how to produce the ‘t’ at the beginning of the word ‘tin.’ If you are native speaker of English, you wil\n",
      "the acoustic analysis of sounds Phonemes can be broadly divided into consonants and vowels Vowels are produced with an unobstructed airflow through the vocal tract while consonants are produced with some kind of stricture to the airflow Consonants are classified using place and manner of articulation. They are also classified according to voicing and aspiration in some languages Vowels are classified using tongue height, backness and roundness Syllables are the smallest units of articulation The most basic syllable structure found in all languages is the CV syllable Syllables consist of a mandatory nucleus or peak and optional onsets and codas Phonological rules are rules of phonology that are applied by native speakers without conscious awareness 14 References Dinesh Ramoo Goldsmith, J. A. (1995). The handbook of phonological theory . Oxford: Blackwell. Ladefoged, P. &amp; Maddieson, I. (1996). The sounds of the world’s languages . Oxford: Blackwell III Chapter 3: The Parts of Speech \n",
      "\n",
      "QUESTIONS 2\n",
      "Understand the definition of morphemes ### Explore the typology of morphology across the world’s languages ### Define syntax and syntactic categories\n",
      "LECTURE 2\n",
      "This chapter is an introduction to words and their meaning. We will explore meaningful units of language and their typology across different languages. This includes inflectional, isolating, agglutinative and polysynthetic morphologies. We will also look at inflectional versus derivational morpheme translations as well as unusual nonconcatenative morphology in Semitic languages. We will also look at syntax and the parts-of-speech that make up sentences or utterances. We will end this chapter with a look at word order and how they differ across languages. 15 3.1 Words and Their Meaning Dinesh Ramoo It may seem a superficial question to ask “what is a word?” However, this question has stymied some of the greatest minds on history. Ferdinand de Saussure once said that a word is like a coin. It has two sides in that it has form (the sounds that make up a word) and meaning (the concept associated with it). In this sense, we could say that a word links form with meaning. Words also have some\n",
      "t-object-verb is the most common word order in the world’s languages. English has a subject-verb-object word order as do a third of the world’s languages. 20 References Dinesh Ramoo Anderson, C. (2018). Essentials of linguistics . Canada: McMaster University Chomsky, N. (1957). Syntactic structures . The Hague: Mouton. Chomsky, N. (1965). Aspects of the theory of syntax . Cambridge, MA: MIT Press. Chomsky, N. (1981). Lectures on government and binding . Dordrecht: Foris. Chomsky, N. (1995). Bare phrase structure. In G. Webelhuth (Ed.), Government and binding theory and the minimalist programme (pp. 383–400). Oxford: Blackwell. Smyth, H. W. (1920). “Part II: Inflection”. A Greek grammar for colleges . Cambridge: American Book Company. Tomlin, R. S. (1986). Basic word order: Functional principles . London: Croom Helm. Wehr, H. (1994) A dictionary of modern written Arabic: (Arabic-English). 4th edition , Ithaca, NY: Spoken Language Services. IV Chapter 4: The Biological Basis of Language \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "researchmethods.html contains Learning Objectives\n",
      "extracted 41 lectures and 41 questions groups\n",
      "QUESTIONS 0\n",
      "Define science. ### Describe the three fundamental features of science. ### Explain why psychology is a science. ### Define pseudoscience and give some examples.\n",
      "LECTURE 0\n",
      "What Is Science? Some people are surprised to learn that psychology is a science . They generally agree that astronomy, biology, and chemistry are sciences but wonder what psychology has in common with these other fields. Before answering this question, however, it is worth reflecting on what astronomy, biology, and chemistry have in common with each other . It is clearly not their subject matter. Astronomers study celestial bodies, biologists study living organisms, and chemists study matter and its properties. It is also not the equipment and techniques that they use. Few biologists would know what to do with a radio telescope, for example, and few chemists would know how to track a moose population in the wild. For these and other reasons, philosophers and scientists who have thought deeply about this question have concluded that what the sciences have in common is a general approach to understanding the natural world. Psychology is a science because it takes this same general appro\n",
      "t psychology (9th ed.). Boston, MA: Allyn &amp; Bacon. Klein, R. A., Ratliff, K. A., Vianello, M., Adams, R. B., Bahník, S., Bernstein, M. J., . . . Nosek, B. A. (2013). Investigating variation in replicability: A “many labs” replication project. Social Psychology, 45 (3), 142-152. doi: 10.1027/1864-9335/a000178 Schnall, S., Benton, J., &amp; Harvey, S. (2008). With a clean conscience: Cleanliness reduces the severity of moral judgments. Psychological Science, 19 (12), 1219-1222. doi: 10.1111/j.1467-9280.2008.02227.x Johnson, D. J., Cheung, F., &amp; Donnellan, M. B. (2013). Does cleanliness influence moral judgments? A direct replication of Schnall, Benton, and Harvey (2008). Social Psychology, 45 (3), 209-215. doi: 10.1027/1864-9335/a000186 Hines, T. M. (1998). Comprehensive review of biorhythm theory. Psychological Reports, 83 , 19–64. Popper, K. R. (2002). Conjectures and refutations: The growth of scientific knowledge . New York, NY: Routledge. 2 Scientific Research in Psychology \n",
      "\n",
      "QUESTIONS 1\n",
      "Describe a general model of scientific research in psychology and give specific examples that fit the model. ### Explain who conducts scientific research in psychology and why they do it. ### Distinguish between basic research and applied research.\n",
      "LECTURE 1\n",
      "A Model of Scientific Research in Psychology Figure 1.1 presents a more specific model of scientific research in psychology. The researcher (who more often than not is really a small group of researchers) formulates a research question, conducts a study designed to answer the question, analyzes the resulting data, draws conclusions about the answer to the question, and publishes the results so that they become part of the research literature. Because the research literature is one of the primary sources of new research questions, this process can be thought of as a cycle. New research leads to new questions, which lead to new research, and so on. Figure 1.1 also indicates that research questions can originate outside of this cycle either with informal observations or with practical problems that need to be solved. But even in these cases, the researcher would start by checking the research literature to see if the question had already been answered and to refine it based on what previo\n",
      "ublished and become part of the research literature. Scientific research in psychology is conducted mainly by people with doctoral degrees in psychology and related fields, most of whom are college and university faculty members. They do so for professional and for personal reasons, as well as to contribute to scientific knowledge about human behaviour. Basic research is conducted to learn about human behaviour for its own sake, and applied research is conducted to solve some practical problem. Both are valuable, and the distinction between the two is not always clear-cut. “ Understanding driver distraction ” by American Psychological Association . Standard YouTube Licence. “ Not all scientific studies are created equal – David H. Schwartz ” by TED-Ed . Standard YouTube Licence. Collet, C., Guillot, A., &amp; Petit, C. (2010). Phoning while driving I: A review of epidemiological, psychological, behavioural and physiological studies. Ergonomics, 53 , 589–601. 3 Science and Common Sense \n",
      "\n",
      "QUESTIONS 2\n",
      "Explain the limitations of common sense when it comes to achieving a detailed and accurate understanding of human behaviour. ### Give several examples of common sense or folk psychology that are incorrect. ### Define skepticism and its role in scientific psychology.\n",
      "LECTURE 2\n",
      "Can We Rely on Common Sense? Some people wonder whether the scientific approach to psychology is necessary. Can we not reach the same conclusions based on common sense or intuition? Certainly we all have intuitive beliefs about people’s behaviour, thoughts, and feelings—and these beliefs are collectively referred to as folk psychology . Although much of our folk psychology is probably reasonably accurate, it is clear that much of it is not. For example, most people believe that anger can be relieved by “letting it out”—perhaps by punching something or screaming loudly. Scientific research, however, has shown that this approach tends to leave people feeling more angry, not less (Bushman, 2002) . Likewise, most people believe that no one would confess to a crime that he or she had not committed, unless perhaps that person was being physically tortured. But again, extensive empirical research has shown that false confessions are surprisingly common and occur for a variety of reasons (Kass\n",
      "nnel Vision: Confirmation Bias” © ESC European Skeptics Congress is licensed under a CC BY (Attribution) license Bushman, B. J. (2002). Does venting anger feed or extinguish the flame? Catharsis, rumination, distraction, anger, and aggressive responding. Personality and Social Psychology Bulletin, 28 , 724–731. Kassin, S. M., &amp; Gudjonsson, G. H. (2004). The psychology of confession evidence: A review of the literature and issues. Psychological Science in the Public Interest, 5 , 33–67. Lilienfeld, S. O., Lynn, S. J., Ruscio, J., &amp; Beyerstein, B. L. (2010). 50 great myths of popular psychology . Malden, MA: Wiley-Blackwell. Gilovich, T. (1991). How we know what isn’t so: The fallibility of human reason in everyday life . New York, NY: Free Press. Mann, T., Tomiyama, A. J., Westling, E., Lew, A., Samuels, B., &amp; Chatman, J. (2007). Medicare’s search for effective obesity treatments: Diets are not the answer. American Psychologist, 62 , 220–233. 4 Science and Clinical Practice \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "socialpsychology.html contains Learning Objectives\n",
      "extracted 45 lectures and 45 questions groups\n",
      "QUESTIONS 0\n",
      "History and Principles Define social psychology . ### Review the history of the field of social psychology and the topics that social psychologists study. ### Summarize the principles of evolutionary psychology. ### Describe and provide examples of the person-situation interaction. ### Review the concepts of (a) social norms and (b) cultures.\n",
      "LECTURE 0\n",
      "2. Affect, Behavior, and Cognition Define and differentiate affect , behavior , and cognition as considered by social psychologists. Summarize the principles of social cognition. 3. Conducting Research in Social Psychology Explain why social psychologists rely on empirical methods to study social behavior. Provide examples of how social psychologists measure the variables they are interested in. Review the three types of research designs, and evaluate the strengths and limitations of each type. Consider the role of validity in research, and describe how research programs should be evaluated. The Story of Raoul Wallenberg Born into a prominent and wealthy family in Sweden, Raoul Wallenberg grew up especially close to his mother and grandfather (his father had earlier died from cancer). Early in life he demonstrated a flair for languages and became fluent in English, French, German, and Russian. Raoul pursued a college education in the United States, where he distinguished himself academ\n",
      " how juries work together to make important group decisions, and what makes some people more likely to recycle and engage in other environmentally friendly behaviors than others. And social psychologists also study more unusual events, such as how someone might choose to risk their life to save that of a complete stranger. The goal of this book is to help you learn to think about social behaviors in the same way that social psychologists do. We believe you will find this approach useful because it will allow you to think about human behavior more critically and more objectively and to gain insight into your own relationships with other people. Social psychologists study everyday behavior scientifically, and their research creates a useful body of knowledge about our everyday social interactions. “ Raoul Wallenberg. Raoul Wallenberg sculpture, Great Cumberland Place, London ” by Mira 66 is licensed under CC BY-NC-SA 2.0 licence . 1 1.1 Defining Social Psychology: History and Principles \n",
      "\n",
      "QUESTIONS 1\n",
      "Define social psychology . ### Review the history of the field of social psychology and the topics that social psychologists study. ### Summarize the principles of evolutionary psychology. ### Describe and provide examples of the person-situation interaction. ### Review the concepts of (a) social norms and (b) cultures.\n",
      "LECTURE 1\n",
      "The field of social psychology is growing rapidly and is having an increasingly important influence on how we think about human behavior. Newspapers, magazines, websites, and other media frequently report the findings of social psychologists, and the results of social psychological research are influencing decisions in a wide variety of areas. Let’s begin with a short history of the field of social psychology and then turn to a review of the basic principles of the science of social psychology. The History of Social Psychology The science of social psychology began when scientists first started to systematically and formally measure the thoughts, feelings, and behaviors of human beings (Kruglanski &amp; Stroebe, 2011). The earliest social psychology experiments on group behavior were conducted before 1900 (Triplett, 1898), and the first social psychology textbooks were published in 1908 (McDougall, 1908/2003; Ross, 1908/1974). During the 1940s and 1950s, the social psychologists Kurt L\n",
      "ical evidence. Journal of Happiness Studies, 5 (3), 223–239. Williams, K. D., Cheung, C. K. T., &amp; Choi, W. (2000). Cyberostracism: Effects of being ignored over the Internet. Journal of Personality &amp; Social Psychology, 79 (5), 748–762. Workman, L., &amp; Reader, W. (2008). Evolutionary psychology: An introduction (2nd ed.). . New York, NY: Cambridge University Press. “ Happy family (1) ” by cscott2006 is licensed under a CC BY-SA 2.0 licence. “ Formosan macaque ” by KaurJmeb is licensed under a CC BY-SA 2.0 licence. “ Old couple in a busy street ” by Geir Halvorsen is licensed under a CC BY-NC-SA 2.0 licence. “ Piggy Back ” by Tricia J is licensed under a CC BY-NC-ND 2.0 licence. “ Elderly Care 2 ” by Mark-Adkins is licensed under a CC BY-NC-SA 2.0 licence. “ Family playing a board game (3) ” by Bill Branson is licensed under a CC0 1.0 licence. “ West Wittering Wonderful As Always ” by Gareth Williams is licensed under a CC BY 2.0 licence. 2 1.2 Affect, Behavior, and Cognition \n",
      "\n",
      "QUESTIONS 2\n",
      "Explain why social psychologists rely on empirical methods to study social behavior. ### Provide examples of how social psychologists measure the variables they are interested in. ### Review the three types of research designs, and evaluate the strengths and limitations of each type. ### Consider the role of validity in research, and describe how research programs should be evaluated.\n",
      "LECTURE 2\n",
      "Social psychologists are not the only people interested in understanding and predicting social behavior or the only people who study it. Social behavior is also considered by religious leaders, philosophers, politicians, novelists, and others, and it is a common topic on TV shows. But the social psychological approach to understanding social behavior goes beyond the mere observation of human actions. Social psychologists believe that a true understanding of the causes of social behavior can only be obtained through a systematic scientific approach, and that is why they conduct scientific research. Social psychologists believe that the study of social behavior should be empirical —that is, based on the collection and systematic analysis of observable data . The Importance of Scientific Research Because social psychology concerns the relationships among people, and because we can frequently find answers to questions about human behavior by using our own common sense or intuition, many pe\n",
      "othesis. The goal of correlational research is to search for and test hypotheses about the relationships between two or more variables. In these studies, a statistic known as the Pearson correlation coefficient is used to summarize the association, or correlation, between the variables. Because scientists are interested in determining the causal relationships among variables, they frequently use experimental research designs. In experiments, the variables of interest are called the independent variable and the dependent variable. The most common method of creating equivalence among the experimental conditions, and thus increasing internal validity, is through random assignment to conditions. External validity refers to the extent to which relationships can be expected to hold up when they are tested again in different ways and for different people. Meta-analyses can be used to assess the observed relationships among variables across many studies. II Chapter 2. Social Cognition Chapter \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "strategicmanagement.html contains Learning Objectives\n",
      "extracted 52 lectures and 52 questions groups\n",
      "QUESTIONS 0\n",
      "What are strategic management and strategy? ### Why does strategic management matter? ### How do strategic choices affect  firm performance?\n",
      "LECTURE 0\n",
      "Strategic Management: A Prickly Problem for Blackberry® How did the once-dominant smartphone maker BlackBerry get crushed by Apple, Samsung, and other competitors in the mobile marketplace? Formerly known as Research In Motion, BlackBerry once was the unquestioned leader in smartphones, at a time when email was the Internet’s killer app and its devices provided an excellent way to stay on top of it. BlackBerry was fully committed to hard keyboards, while Apple sought to be rid of them. At first glance, it’s obvious that BlackBerry was too wedded to its keyboard-based devices, while new designs and technologies cut into its business. Looking deeper, one could pin some blame on the Canadian firm’s dual-CEO leadership structure, as well as its inordinate focus on corporate customers. Its bid to recapture market share [in 2013] with the touch-screen Z10 and hard-keyboard Q10 fell far short. BlackBerry investors over the previous five years had seen more than 90 percent of shareholder value\n",
      "e rolled into town, followed by Android devices, BlackBerry was struggling to compete, and simply didn’t innovate quickly enough to keep its loyal following. The BlackBerry brand already has been pressed to near extinction by competitors, including the Apple iPhone and Google Android OS smartphones, led by Samsung products. Apple’s iPhone had about half of BlackBerry’s market share in 2008, and Google Android was in its infancy. By the end of 2011, BlackBerry had less than 9 percent market share, Apple had almost 24 percent, and Android OS phones dominated with more than 50 percent. The Z10 was hardly the start of the downfall of the BlackBerry brand, but it may be part of the final chapter (Lazarus, 2013; Martin, 2013). References Lazarus, A. (2013, September 24). How Did Blackberry Do Everything Wrong? Daily Finance. Retrieved from Martin, C. (2013, August 13). Blackberry Up For Sale: 5 Reasons It Went Wrong . Tech Advisor. Retrieved from 1 Defining Strategic Management and Strategy \n",
      "\n",
      "QUESTIONS 1\n",
      "Learn what strategic management is. ### Understand the key question addressed by strategic management. ### Understand why it is valuable to consider different definitions of strategy. ### Learn what is meant by each of the 5 P’s of strategy.\n",
      "LECTURE 1\n",
      "What Is Strategic Management? Boiled down to its simplest, strategy is basically about making choices… For you, which career interests you, who to marry/partner, whether to have children, or car and house ownership, and even whether investing in post-secondary education is to your advantage or not.  For corporations, which product/service to sell, the right balance of labour (people) and capital (machines) to use in producing the product/service and where to physically locate among the hundreds if not thousands of strategic choices. Choices. Studying strategic management is the combination of learning about various models which can assist us on how and why to make these strategic choices, coupled with lots of case studies on the results actual companies and people achieved – case studies. In our first case study, issues such as those currently faced by BlackBerry and Apple are the focus of strategic management because they help answer the key question —“Why do some firms outperform oth\n",
      "rategic plan of small steps . New York Times . Retrieved from  -plan-of-small-steps.html Mintzberg, H. (1987). The strategy concept I: Five P’s for strategy. California Management Review , 30 (1), 11–24. Porter, M. E. (1996, November–December). What is strategy? Harvard Business Review , 61–79. Slater, J. (2013, April 5). Charles Bronfman opens up about Seagram’s demise: ‘It is a disaster’ . The Globe and Mail. Retrieved from Twain, M. (1876). Tom Sawyer Whitewashing the Fence . In Tom Sawyer (Chapter 2). Retrieved from Reuters.  (2011, March 2). Pizza Maker Charged with Using Mice Against Competition .  Retrieved from:  Smith College Hood © Clara S. is licensed under a CC BY (Attribution) license BostonPizzaLondon © Raysonho @ Open Grid Scheduler / Grid Engine is licensed under a CC0 (Creative Commons Zero) license Hannibal’s Famous Crossing of the Alps © Wikipedia Clearance © Lindsey Turner is licensed under a CC BY (Attribution) license 2 Intended, Emergent, and Realized Strategies \n",
      "\n",
      "QUESTIONS 2\n",
      "Learn what is meant by intended and emergent strategies and the differences between them. ### Understand realized strategies and how they are influenced by intended, deliberate, and emergent strategies.\n",
      "LECTURE 2\n",
      "A few years ago, a consultant posed a question to thousands of executives: “Is your industry facing overcapacity and fierce price competition?” All but one said “yes.” The only “no” came from the manager of a unique operation—the Panama Canal! And even there, they are building a second one connecting the Atlantic to Pacific oceans scheduled to open in 2015. This manager was fortunate to be in charge of a venture whose services are desperately needed by shipping companies and that offers the only simple route linking the Atlantic and Pacific Oceans. The canal’s current success will be challenged with this second goes into operation. With the current increase in globalization, the additional boat transportation make both canals appear to be guaranteed to have many customers for as long as anyone can see into the future. When an organization’s environment is stable and predictable, strategic planning can provide enough of a strategy for the organization to gain and maintain success. The e\n",
      "tility rate, by province and territory . Retrieved from Wells, K. (2002). Floating off the page: The best stories from the Wall Street Journal’s middle column . New York: Simon &amp; Shuster. Quote from page 97. Image descriptions Figure 1.6: A Model of Intended, Deliberate, and Realized Strategy You start with an intended strategy. The nonrealized strategy are any parts of the intended strategy that you abandon. The deliberate strategy is what you put into action, and the realized strategy is often a combination of your deliberate strategy and any emergent strategies that develop. [Return to Figure 1.6] Women applying make-up © Mark J Sebastian is licensed under a CC BY-SA (Attribution ShareAlike) license Andre_Ellington_2011 is licensed under a CC BY-SA (Attribution ShareAlike) license As seen on TV © Radiant chains is licensed under a Public Domain license Facebook Press Conference © Robert Scoble is licensed under a CC BY (Attribution) license 3 The History of Strategic Management \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "studentsuccess.html contains Learning Objectives\n",
      "extracted 15 lectures and 15 questions groups\n",
      "QUESTIONS 0\n",
      "Describe the challenges and advantages of adult learning and life-long learning. ### Describe student responsibilities in a college/university environment. ### Evaluate the spiritual, physical, intellectual, and emotional dimensions of self in relation to returning to school. ### Assess the impact of returning to school on family, friends, and co-workers. ### Investigate personal wellness (support networks, nutrition, fitness, stress, and habits) and recognize its impact on learning. ### Create a learning action plan.\n",
      "LECTURE 0\n",
      "2 1.1 Adult Learning Challenges and Fears Learning as an adult is much different than learning as a youth in school. It has many challenges. Many of you will be taking courses at the same time as working, raising children, managing a household, or being involved in many community activities. Success in college will require balancing your obligations; time management will be crucial.  It is important to be on top of your schedule and responsibilities and to ensure you are setting realistic goals for completion. Many adults are very nervous when they first start in college. You may be asking yourself many questions. Will I be able to succeed? Will people think I’m stupid? I’ve been out of school so long- will I be able to learn and remember things? Don’t worry. You are not alone! Many students experience these feelings of anxiety and fear. You need to know that you are already a big step ahead of many people, because you have already made a commitment to move forward. It may have been ne\n",
      " type of learning and the preference of the learner, it is good to note that individual learners have different strengths and abilities. Utilizing these to the fullest makes for better learning. Along with preferences and strengths, learners have different challenges. These can come in the form of learning challenges or challenging circumstances. Learning challenges can include learning disabilities of varying degrees, or if not diagnosed disabilities, learning struggles that have impeded ability to learn in the past. Challenging circumstances that affect learning can include temporary or long-term circumstances that impact ability to learn such as losing a loved one, medical conditions, or dysfunctional living conditions. These often have a negative impact on learners’ abilities to be successful at school. Identifying and recognizing all these factors impacting learning will help you to examine different strategies and supports to help you to maximize your learning at post-secondary. \n",
      "\n",
      "QUESTIONS 1\n",
      "Identify own learning preferences and strengths. ### Recognize how personal learning preferences affect perception and processing information. ### Recognize learning differences and challenges and their impact on learners. ### Examine different applicable strategies.\n",
      "LECTURE 1\n",
      "10 2.1 Learning Preferences and Strengths What Are Your Learning Preferences? Knowing how to utilize your learning preferences helps you become a more efficient learner. Different people have different learning preferences. There are many models which are used to describe these preferences. Learning styles is one that accounts for learner differences, which can be useful in understanding the different ways we learn. It can also be useful to know your strengths and use them to enhance learning. Style refers to a student’s specific learning preferences and actions. One student may learn more effectively from listening to the instructor, while another prefers to take notes. Another learns more effectively from reading the textbook, while another student benefits most from charts, graphs, and images the instructor presents during a lecture. It’s important to note that people don’t necessarily have a single style. Students can use different styles in different situations, but they often ten\n",
      "f smart. The Multiple Intelligences model describes 9 different types of smart. Because your learning style preference may not match your instructor’s teaching style, you need to be flexible and work to develop new learning strategies essential for student success. Using a variety of modalities to learn will strengthen learning, understanding, and memory. IV Chapter 3 Support and Resources Student Services © Gordon Shier is licensed under a CC BY (Attribution) license 14 Introduction Let’s face it: being a student can be stressful! However, there are numerous supports available to students to aid along the way. Some are personal supporters who have been part of your network all along, and some are built in systems at colleges and universities. All too often, students don’t realize the number of supports available to them until things reach crisis conditions. In this chapter, you will identify supports that you may need  so that you can utilize them throughout your educational journey. \n",
      "\n",
      "QUESTIONS 2\n",
      "Identify and access personal support systems to address barriers to education. ### Familiarize themselves with post-secondary student support services. ### Familiarize themselves with course supports available within post-secondary institutions.\n",
      "LECTURE 2\n",
      "15 3.1 Personal Support Systems Personal Support Network No one can do it alone. We aren’t meant to. We are designed to be in relationships, and it is these relationships which will give us the courage and strength to forge ahead in our lives. Support can come in many ways. Personal supports come in the personal relationships in our lives through family, friends, and connections. Spending quality time with good friends contributes to personal wellness. As well as personal supports, your support network should also include your community. Community is the group of people you associate with. It could be a group of people in the place you live (your neighbourhood) or at work, or a group of people you associate with through an activity. It could be a sports team, a club, a volunteer group, a church, or a parents’ group. It could be an exercise group, or a pottery club,  or a music group. We all cherish a sense of belonging. Having a community of support for various aspects of our lives is \n",
      "receivers are fluid (e.g. a group conversation where different people become the senders at different times). Any time the message is misinterpreted, there is a breakdown in the communication process, and this serves as the impetus of conflict. Good communication skills may be the most important skills for success in life! No one is a perfect communicator; even the most skilled communicators can have issues with clarity and struggle in different scenarios. Even areas that are strengths for people in one context may not be in another. Being aware of and strengthening communication skills will be an asset in many areas of your life. It is important that you remember that making small changes in your communication skills can make a big difference in your work, home and school. In this chapter you will learn about styles of communication, barriers to communication, and several aspects of good communication skills. As you learn about them, try to apply them in your real life circumstances. \n",
      "\n",
      "found too many blacklisted strings\n",
      " the time, money, and opportunities in the world? Questions like these help us define our own values. Author’s story I am very fortunate to live in the Rocky Mountains. It is absolutely gorgeous, and I never take it for granted: the stunning views, the fresh air, the smells of nature, the sounds of \n",
      "er a CC BY (Attribution) license 21 4.2 Effective Questions A questioning mind contributes to student success. Part of learning is being an active learner. Learning which only involves being fed information is merely surface learning. To really understand, a learner has to be actively engaged in the\n",
      "ake it easier to prepare for the test. Anticipate Questions What kind of questions would you include if you were the instructor? What areas did the instructor personally show the most interest in? Brainstorm possible questions with your study group. Look for possible questions in your notes. Review \n",
      "ved, so their body language will be easy to read. Questions and Discussion As a presenter, it’s a good idea to allow a little time at the end of your presentation to invite questions from the audience and to facilitate a little discussion about the topic. If possible and applicable you can include a\n",
      "pter 4 Communication Skills Section 4.2 Effective Questions Bloom’s Taxonomy Printable Worksheet [PDF] Chapter 5 Study Skills Section 5.2 Critical Reading Skills SQ3R printable worksheet [PDF] Chapter 6 Test Taking 6.3 Techniques During a Test Mr Bean-The Exam video Funny school video of kid taking \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "technicalwritingh5p.html contains Learning Objectives\n",
      "extracted 4 lectures and 4 questions groups\n",
      "QUESTIONS 0\n",
      "This chapter will help you Understand what technical writing is, why its important, and what it looks like ### Apply a “ problem-solving” approach to communications tasks, starting by learning how to fully define the problem before looking for solutions ### Recognize the main conventions and characteristics of technical writing, and how they differ from other forms, such as academic and journalistic writing ### Understand the importance of defining the “ rhetorical situation ” in which you are communicating ### Apply what you have learned so far by examining “ case studies ” that demonstrate the costs of poor communication ### Appreciate the complexity and iterative nature of a writing process in determining what writing process works best for you.\n",
      "LECTURE 0\n",
      "This book has been enhanced with H5P content. What does that mean for you as a reader? Throughout the book, you will find embedded interactive activities that will help you practice your new learning and test your skills. These will provide you with immediate feedback and you can complete them as many times as you like. You are encouraged to check your answers as you proceed by clicking the Check button after each question to check your answer and receive feedback. Click the Retry or Show Solutions buttons for any questions that you cannot solve. Click Finish at the end of the questions to see your overall results. Note: If you see a speech bubble with an I in it, this will provide you with more information. This first one is simply a demonstration. When you hear the term “technical communication,” what comes to mind? Perhaps you think of scientific reports, specifications, instructions, software documentation, or technical manuals. And you would be correct. However, technical communic\n",
      "r point. You may cycle back between drafting a reflection a number of times before moving on. Peer/tutor review. Now you can get feedback from others. This may require you to return to the drafting and reflecting stages. Revision. Here you are further developing and clarifying ideas and the structure of the text. This may require you to return to the drafting and reflecting stages. If the work requires additional research or idea generation, return to the planning stage. Editing and proofreading. Here the focus is on surface-level features of the text. [Return to Figure 1.5.2] Figure 1.5.1 The Engineering design process by Tufts University. Every attempt has been made to locate the copyright owner. For noncommercial, educational use only. Figure 1.5.2 Writing Process Diagram is from M.J. Curry and A. Hewings “Approaches to teaching writing,” in Teaching Academic Writing: A Toolkit for Higher Education. New York: Routledge, 2003. Used with permission. II 2. Professional Style Chapter 2 \n",
      "\n",
      "QUESTIONS 1\n",
      "5.1 Research Terminology : understand basic terms related to conducting and disseminating various kinds of research.\n",
      "LECTURE 1\n",
      "5.2 Finding and Evaluating Research Sources : review various kinds of sources and how to determine their reliability, authority, and relevance as research sources in professional context. 5.3 Defining the Scope of Your Project : understand how to use various methods to refine the scope of your project and determine a focused research question for a problem-based project. 5.4 Human Research Ethics : understand the requirements and protocols for conducting primary research using human subjects (e.g.: surveys, interviews, focus groups, etc.) 5.5 Stakeholder Engagement and Consultation : Understand what stakeholders are, how to map the stakeholders related to your project, and the general types of engagement strategies commonly used in public engagement plans. Most projects you work on—whether you are developing innovative new products, planning or implementing ideas, proposing ideas, or recommending solutions—will require research. Research can save you time by determining what other simi\n",
      " Figure 5.5.3 Spectrum of public engagement by Suzan Last is licensed under a CC BY 4.0 licence . C. Driscoll and M. Starik, “The primordial stakeholder: Advancing the conceptual consideration of stakeholder status for the natural environment,” Journal of Business Ethics , vol. 49, no. 1, 2004, pp. 55-73. Available: Canadian Wind Energy Association, Best Practices for Indigenous and Public Engagement, Oct. 2017. Available: EPA, “Public Participation Guide: View and Print Version,” United States Environmental Protection Agency [Online]. Available: [Accessed Feb. 24, 2019]. University of Victoria Campus Planning and Sustainability, “Engagement plan for: The University of Victoria Grand Promenade landscape plan and design guidelines,” Campus Greenway [Online]. Available: University of Victoria Campus Planning and Sustainability, \"The Grand Promenade Design Charrette: Summary Report 11.2018,\" Campus Greenway [Online]. Available: VI 6. Citing and Documenting Sources in IEEE Style Chapter 6 \n",
      "\n",
      "QUESTIONS 2\n",
      "7.1 Correspondence: Text Messages, E-mails, Letters, and Memos ### 7.2 Proposals ### 7.3 Progress Reports ### 7.4 Technical Descriptions and Definitions ### 7.5 Long Reports: Feasibility and Recommendation Reports ### 7.6 Lab Reports ### 7.7 Instructions\n",
      "LECTURE 2\n",
      "Just as the literary genre of poetry contains many forms — such as sonnets, haiku, epics, limericks, etc., — each with its own set of rules and conventions, technical writing also contains many forms, and each form has some conventions that must be observed.  This chapter discusses several of the most common document forms, and reviews the general requirements for content, formatting, and style. 7.1 Correspondence: Text Messages, Emails, Memos, and Letters Netiquette Text messaging, emailing, and posting on social media in a professional context requires that you be familiar with “netiquette,” or proper etiquette for using the internet. We have all heard the news stories about people who have been fired and companies that have been boycotted for making offensive or inappropriate social media posts . People have even gone to prison for illegal use of private messaging .  The digital world may seem like a free-for-all, “wild wild west” with no clear rules or regulations; however, this is\n",
      " See special notices for a complete discussion of the proper use of these special notices as well as their format and placement within instructions. Revision Checklist for Written Instructions As you reread and revise your instructions, check that they do the following: Clearly describe the exact procedure to be explained Provide an overview of content Indicate audience requirements Use various types of lists wherever appropriate; in particular, use numbered lists for sequential steps Use headings and subheadings to divide the main sections and subsections in a logical, coherent order Use special notices as appropriate Use graphics to illustrate key actions and objects Provide additional supplementary explanation of the steps as necessary Create a section listing equipment and supplies if necessary. Text Attribution This chapter was adapted from Online Technical Writing by David McMurrey, which is under a CC BY 4.0 International License . VIII 8. Oral and Visual Presentation Chapter 8 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "workinggroupguide.html contains Learning Objectives\n",
      "extracted 3 lectures and 3 questions groups\n",
      "QUESTIONS 0\n",
      "Compare different community frameworks for establishing an open working group. ### Develop best practices for forming an open working group. ### Discover strategies for determining the purposes and goals of the open working group. ### Identify ways of establishing an inventory of open education and open educational resources at your institution. ### Identify funding sources for open working groups and projects. ### Identify resources and supports for open education at your institution. ### Learn how project management might assist a working group with its tasks.\n",
      "LECTURE 0\n",
      "2 Frameworks and Approaches to Community What is an open working group? Open working groups are a great way to conduct advocacy and build momentum for open education in an institution. They bring together the people on campus that are interested in or already engaged in open educational practices (OEP). These groups are oriented towards particular tasks for a certain length of time. Some may revolve around a project like developing a Zed Cred or an Open Educational Resource (OER) strategy, and others may include cross-functional members in charge of distributing OER grants. The term “working group” is often used to distinguish a group from something more formal, such as a committee or steering group. Many institutions purposefully choose the term “working group” to signify ideological driven action, with members working in partnership towards a common goal. You may choose to name your group something even less formal—perhaps, “[School Name]’s Open Champions,” or more formal like, “Open\n",
      "onclusion Now that you have completed this section, go through the checklist below to guide you through the process of establishing a new open working group or use it to revisit how your current open working group is set up. Checklist: Establish an Open Working Group Establish a framework/approach for your open working group. Consider the fit for your institution. What sort of group can be the most effective? Formal or informal? Determine who are the open advocates or supporters at your institution and ways of engaging them in the open working group. List the relevant stakeholders and how you will engage them. Establish the open working group’s goals and purpose. Find ways that open education links with your institution’s strategic plan or vision. Identify potential funding options for open education at your institution. Find resources and support for open education. II Run a Working Group network-1246209_1920 (1) is licensed under a CC0 (Creative Commons Zero) license 10 Introduction \n",
      "\n",
      "QUESTIONS 1\n",
      "Determine collaboration points and opportunities. ### Identify roles at your institution that can help support open education. ### Explore processes and aspects of the working group that can be open. ### Identify examples of workshops and events that showcase and support open education. ### Create an inventory of open resources at your institution.\n",
      "LECTURE 1\n",
      "11 Key Considerations Regardless of where your open working group may fall on the spectrum of formal to informal, there are certain things to consider doing and places you can look for support. Keep a record Kick off your committee by establishing a shared digital place where agendas, minutes, best practices, and other documents can reside. Avoid documents becoming orphaned in individual emails. Inventory the different ways to communicate with your community at your institution and establish when, how, and what you will communicate out from your group. One approach that has been taken by a number of open working groups is to consider an open way to document and keep a record. At the University of British Columbia, the UBC Wiki (MediaWiki) is used for sharing all agendas, activities, and members in the open. You may want to look at the Open Ed Tech Collaborative apps available via Sandstorm for collaborative editing tools that will allow you to share and edit documents. Find administrat\n",
      "t you can engage with on open education at your institution. List specific ways that policies at your institution support or don’t support open education. Consider some of the following documents: the strategic plan and vision tenure promotion documents collective agreements Develop a plan for openly licensing and sharing the resources that you create within the open working group. How will you license, share, and make these resources accessible? Work together to design an open education workshop. List individuals and roles that you would like to celebrate and highlight at your institution. Make a list of resources that your institution currently has that support open education. Then go through the examples of open resources at different institutions. Look for gaps. What resources can your group develop or adapt to support open at your institution? III Sustain a Working Group 9451877268_b347e9347b_o © University of Exeter is licensed under a CC BY (Attribution) license 18 Introduction \n",
      "\n",
      "QUESTIONS 2\n",
      "Build strategies for developing a sustainable open working group. ### Identify ways of evaluating and communicating open working group activities. ### Assess tools and frameworks for evaluating open educational practices.\n",
      "LECTURE 2\n",
      "19 Sustain Sustainability in relation to OER is closely linked to the business model or approach that an individual, group or institution adopts to release, manage and support OER. It is not just about sustaining existing OER but about embedding processes and transforming practices to support ongoing OER production and release. The sustainability of your open working group is very much related to the sustainability of open education and the open educational resources (OER) that are used, created, and adapted at your institution. Sustaining OER is often done at the open working group level, and the practice of sustaining OER can strengthen the open working group. Koohang and Harman argue that because communities of practice (CoPs) are “characteristically decentralized,” they can improve the scalability of open projects. This is because the decentralized nature of CoPs allows for “members [with] different skills and experiences” to work together towards the “common goal” of sustaining OE\n",
      " Chicago Manual of Style Online . Chicago style is most often used to cite and style works in the humanities. MLA Style Manual . MLA (Modern Language Association of America) style is most frequently used to cite and style works in the literary and humanities fields. Canadian Press Stylebook . The Canadian Press style is the standard style guide for those working in media and communications. Templates and organization Providing templates for the content creators can help everyone develop a more cohesive resource. It can also make the writing process easier by creating a structure that writers can fill out during the session. In the Open Case Study Sprint at UBC, the sprint team collaboratively developed a MediaWiki template for the case study writing . If you are using platforms such as Pressbooks, you can create information boxes to structure common elements like learning objectives, chapter summaries, etc. This can guide the participants as they develop the resource. Figure 5: Sample \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "workinginfoodserviceindustry.html contains Learning Objectives\n",
      "extracted 6 lectures and 6 questions groups\n",
      "QUESTIONS 0\n",
      "Describe personal attributes and professionalism in the workplace ### Describe roles and responsibilities in the workplace\n",
      "LECTURE 0\n",
      "Working in the hospitality industry takes a certain kind of individual. The industry itself can be very rewarding and a lot of fun, but it also requires people who like to work with other people, enjoy a fast-paced environment, and enjoy a lot of variety in their routine, as things often change from day to day and week to week. Not all jobs in the industry require the same skills, so it is important for those who are interested in a career, either in the front or back of the house, to understand their own skills and interests, and then use that information to find the right “fit” when it comes to a job. If you don’t enjoy talking to new people and being outgoing, then likely a career in the front of the house isn’t for you. However, if you are creative, enjoy working with your hands, and find working as a team rewarding, then you might be the perfect candidate for a position in the kitchen. 2 Industry Expectations The hospitality and food service industry has a longstanding tradition o\n",
      "and sees that work is finished on time) Shows initiative (works hard without being told to) Does not give up easily (tries and tries again) Shows honesty (can be trusted; accepts the blame for own mistakes) Is dependable (always finishes the job) Does not waste materials (plans and works carefully so no goods are damaged or wasted; takes good care of tools and equipment) Obeys safety rules (prevents accidents by following all safety instructions) Follows instructions (pays attention to directions and follows them carefully) Is willing to learn (shows interest in improving job performance; follows suggestions) Works accurately (takes care to do things right; does not make careless mistakes, keeps good records) Gets along well with others (supervisors, co-workers, and customers; works cooperatively and is thoughtful and respectful of others) Shows loyalty (speaks well of the employer and its products; does not give out confidential information) II Food Service Occupations 5 Introduction \n",
      "\n",
      "QUESTIONS 1\n",
      "Describe food service occupations\n",
      "LECTURE 1\n",
      "There are many careers in the food service industry for talented and well-trained individuals. Opportunities in this industry have been steadily increasing for the last several decades and the demand for skilled people, at times, has exceeded the number of suitable applicants. Currently, there is expected to be higher demand for jobs than there are available people to work, and shortages in the tourism and hospitality industry could be as high as 15,000 people by 2020 (go2HR, 2012). Occupations in the industry generally fall into three categories: front of house; back of house, and administrative. Front of house occupations include those responsible for serving the food and the customers, such as waiters, hosts/hostesses, and bussers. Back of house occupations include those responsible for preparing the food, including cooks, chefs , and dishwashers. Administrative occupations are those which help grow the business or keep it running, including human resource and finance staff, and gen\n",
      " can progress from prep cook/kitchen helper, to cold kitchen (garde manger), to cook, to certified Professional Cook 3, to sous chef, to chef, to owner. Hotel: One can progress from prep cook/kitchen helper, to third cook, to second cook, to first cook, to certified Professional Cook 3, to chef de partie, to sous chef, to executive sous chef, to executive chef, to food and beverage manager/director. Institutional and Camps: One can progress from prep cook/kitchen helper, to cook, to certified Professional Cook 3, to supervisor/sous chef, to kitchen manager/chef, to regional chef. Catering: One can progress from prep cook/kitchen helper, to cook, to certified Professional Cook 3, to team leader, to sous chef, to chef, to owner. [Return to Figure 3] Kitchen Career Ladder © go2HR. Used with permission Cook Certifications in BC © go2HR. Used with permission Professional Cook career options. © go2HR. Used with permission III Employment Standards for B.C. Food Service Workers 9 Introduction \n",
      "\n",
      "QUESTIONS 2\n",
      "Describe the B.C. Employment Standards Act ### Describe the B.C. Human Rights Code\n",
      "LECTURE 2\n",
      "This section offers a general introduction to the BC Employment Standards Act . The Employment Standards Branch also has posters and a Guide to the Employment Standards Act available free of charge for employers to display in the workplace. This Act, like all provincial legislation, is subject to periodic review by government. It is your responsibility as an employee or employer to keep up to date with your rights and responsibilities. If you require specific advice about a dispute related to employment standards, you should contact the Employment Standards Branch. 10 About the Employment Standards Act The Employment Standards Act sets the minimum standards for wages and conditions of employment that apply in most workplaces in British Columbia. For those employees who are covered by a union collective agreement, the agreement supersedes the Act. However, most employees in the restaurant and food service industry are not unionized, and therefore you must know about these minimum standa\n",
      "ng areas or provide ramps or elevators between areas. Space tables and seating far enough apart to allow persons with limited mobility or wheelchairs to pass. If the seating is largely fixed (e.g., banquettes), provide some tables with chairs that can be easily removed to accommodate wheelchairs. Provide accessible washrooms with lever-style door handles and faucets. Check the level of sinks, light switches, pay telephones, towel dispensers, elevator controls. and other items to ensure that they can be reached by a person in a wheelchair. Advice on how to make your facility accessible and barrier-free is available from municipal engineering departments. If your restaurant is undergoing construction or renovations, you may also have to meet accessibility provisions of the British Columbia Building Code. The municipal engineering department can provide information about these requirements. Full Service © go2HR. Used with permission IV Workplace Communication and Teamwork 14 Introduction \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "writingforsuccess.html contains Learning Objectives\n",
      "extracted 46 lectures and 46 questions groups\n",
      "QUESTIONS 0\n",
      "Understand the expectations for reading and writing assignments in post-secondary (university, college, institute) courses ### Understand and apply general strategies to complete post-secondary-level reading assignments efficiently and effectively ### Recognize specific types of writing assignments frequently included in post-secondary courses ### Understand and apply general strategies for managing post-secondary-level writing assignments ### Determine specific reading and writing strategies that work best for you individually\n",
      "LECTURE 0\n",
      "In a post-secondary environment, academic expectations change from what you may have experienced in high school. The quantity of work you are expected to do is increased. When instructors expect you to read pages upon pages or study hours and hours for one particular course, managing your workload can be challenging. This chapter includes strategies for studying efficiently and managing your time. The quality of the work you do also changes. It is not enough to understand course material and summarize it on an exam. You will also be expected to seriously engage with new ideas by reflecting on them, analyzing them, critiquing them, making connections, drawing conclusions, or finding new ways of thinking about a given subject. Educationally, you are moving into deeper waters. A good introductory writing course will help you swim. Table 1.1 : High School versus Post-Secondary Assignments summarizes some of the other major differences between high school and university assignments. Table 1\n",
      "a class. You might need to contact administrators with questions about your tuition or financial aid. Later, you might ask instructors to write recommendations on your behalf. Treat these documents as professional communications. Address the recipient politely; state your question, problem, or request clearly; and use a formal, respectful tone. Doing so helps you make a positive impression and get a quicker response. Key Takeaways Post-secondary-level reading and writing assignments differ from high school assignments, not only in quantity but also in quality. Managing reading assignments successfully requires you to plan and manage your time, set a purpose for reading, practise effective comprehension strategies, and use active reading strategies to deepen your understanding of the text. Post-secondary writing assignments place greater emphasis on learning to think critically about a particular discipline and less emphasis on personal and creative writing. 1.2 Developing Study Skills \n",
      "\n",
      "QUESTIONS 1\n",
      "Use strategies for managing time effectively ### Understand and apply strategies for taking notes efficiently ### Determine the specific time management, study, and note taking strategies that work best for you individually\n",
      "LECTURE 1\n",
      "By now you have a general idea of what to expect from your courses. You have probably received course syllabi, started on your first few assignments, and begun applying the strategies you learned about in Section 1.1 Post – Secondary Reading and Writing . At the beginning of the semester, your workload is relatively light. This is the perfect time to brush up on your study skills and establish good habits. When the demands on your time and energy become more intense, you will have a system in place for handling them. This section covers specific strategies for managing your time effectively. You will also learn about different note-taking systems that you can use to organize and record information efficiently. As you work through this section, remember that every student is different. The strategies presented here are tried-and-true techniques that work well for many people. However, you may need to adapt them to develop a system that works well for you personally. If your friend swear\n",
      "hniques. (Remember that the Cornell system can be combined with other note-taking formats.) It can take some trial and error to find a note-taking system that works for you. If you find that you are struggling to keep up with lectures, consider whether you need to switch to a different format or be more careful about distinguishing key concepts from unimportant details. If you find that you are having trouble taking notes effectively, set up an appointment with your school’s academic resource centre. Key Takeaways Understanding your individual learning style and preferences can help you identify the study and time management strategies that will work best for you. To manage your time effectively, it is important to look both at the short term (daily and weekly schedules) and the long term (major semester deadlines). To manage your time effectively, be consistent about maintaining your schedule. If your schedule is not working for you, make adjustments. 1.3 Becoming a Successful Writer \n",
      "\n",
      "QUESTIONS 2\n",
      "Identify strategies for successful writing ### Demonstrate comprehensive writing skills ### Identify writing strategies for use in future classes\n",
      "LECTURE 2\n",
      "In the preceding sections, you learned what you can expect from your courses and identified strategies you can use to manage your work and to succeed. This section covers more about how to handle the demands placed on you as a writer at the post-secondary world. The general techniques you will learn will help ensure your success on any writing task, whether you complete an exam in an hour or an in-depth research project over several weeks. Putting It All Together: Strategies for Success Writing well is difficult. Even people who write for a living sometimes struggle to get their thoughts on the page. Even people who generally enjoy writing have days when they would rather be doing anything else. For people who do not like writing or do not think of themselves as good writers, writing assignments can be stressful or even intimidating. And of course, you cannot get through post-secondary courses without having to write—sometimes a lot, and often at a higher level than you are used to. No\n",
      " clarify the requirements with your instructor. Think carefully about the purpose of the writing, the intended audience, the topics you will need to address, and any specific requirements of the writing form. Complete each step of the writing process . With practice, using this process will come automatically to you. Use the resources available to you . Remember that most schools have specific services to help students with their writing. Key Takeaways Following the steps of the writing process helps students complete any writing assignment more successfully. To manage writing assignments, it is best to work backward from the due date, allotting appropriate time to complete each step of the writing process. Setting concrete long- and short-term goals helps students stay focused and motivated. A variety of resources are available to help students with writing and with other aspects of post-secondary life. 2 Chapter 2. Working with Words: Which Word Is Right? 2.1 Commonly Confused Words \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "writingforsuccessh5p.html contains Learning Objectives\n",
      "extracted 55 lectures and 55 questions groups\n",
      "QUESTIONS 0\n",
      "Understand the expectations for reading and writing assignments in post-secondary (university, college, institute) courses ### Understand and apply general strategies to complete post-secondary-level reading assignments efficiently and effectively ### Recognize specific types of writing assignments frequently included in post-secondary courses ### Understand and apply general strategies for managing post-secondary-level writing assignments ### Determine specific reading and writing strategies that work best for you individually\n",
      "LECTURE 0\n",
      "In a post-secondary environment, academic expectations change from what you may have experienced in high school. The quantity of work you are expected to do is increased. When instructors expect you to read pages upon pages or study hours and hours for one particular course, managing your workload can be challenging. This chapter includes strategies for studying efficiently and managing your time. The quality of the work you do also changes. It is not enough to understand course material and summarize it on an exam. You will also be expected to seriously engage with new ideas by reflecting on them, analyzing them, critiquing them, making connections, drawing conclusions, or finding new ways of thinking about a given subject. Educationally, you are moving into deeper waters. A good introductory writing course will help you swim. This chapter covers the types of reading and writing assignments you will encounter as a post-secondary student. You will also learn a variety of strategies for\n",
      "class. You might need to contact administrators with questions about your tuition or financial aid. Later, you might ask instructors to write recommendations on your behalf. Treat these documents as professional communications. Address the recipient politely; state your question, problem, or request clearly; and use a formal, respectful tone. Doing so helps you make a positive impression and get a quicker response. Key Takeaways Post-secondary-level reading and writing assignments differ from high school assignments, not only in quantity but also in quality. Managing reading assignments successfully requires you to plan and manage your time, set a purpose for reading, practise effective comprehension strategies, and use active reading strategies to deepen your understanding of the text. Post-secondary writing assignments place greater emphasis on learning to think critically about a particular discipline and less emphasis on personal and creative writing. 2 1.2 Developing Study Skills \n",
      "\n",
      "QUESTIONS 1\n",
      "Use strategies for managing time effectively ### Understand and apply strategies for taking notes efficiently ### Determine the specific time management, study, and note taking strategies that work best for you individually\n",
      "LECTURE 1\n",
      "By now you have a general idea of what to expect from your courses. You have probably received course syllabi, started on your first few assignments, and begun applying the strategies you learned about in Section 1.1 Post-Secondary Reading and Writing . At the beginning of the semester, your workload is relatively light. This is the perfect time to brush up on your study skills and establish good habits. When the demands on your time and energy become more intense, you will have a system in place for handling them. This section covers specific strategies for managing your time effectively. You will also learn about different note-taking systems that you can use to organize and record information efficiently. As you work through this section, remember that every student is different. The strategies presented here are tried-and-true techniques that work well for many people. However, you may need to adapt them to develop a system that works well for you personally. If your friend swears \n",
      "k Often, at school or in the workplace, a speaker will provide you with pre-generated notes summarizing electronic presentation slides. You may be tempted not to take notes at all because much of the content is already summarized for you. However, it is a good idea to jot down at least a few notes. Doing so keeps you focused during the presentation, allows you to record details you might otherwise forget, and gives you the opportunity to jot down questions or reflections to personalize the content. Key Takeaways Understanding your individual learning style and preferences can help you identify the study and time management strategies that will work best for you. To manage your time effectively, it is important to look both at the short term (daily and weekly schedules) and the long term (major semester deadlines). To manage your time effectively, be consistent about maintaining your schedule. If your schedule is not working for you, make adjustments. 3 1.3 Becoming a Successful Writer \n",
      "\n",
      "QUESTIONS 2\n",
      "Identify strategies for successful writing ### Demonstrate comprehensive writing skills ### Identify writing strategies for use in future classes\n",
      "LECTURE 2\n",
      "In the preceding sections, you learned what you can expect from your courses and identified strategies you can use to manage your work and to succeed. This section covers more about how to handle the demands placed on you as a writer at the post-secondary world. The general techniques you will learn will help ensure your success on any writing task, whether you complete an exam in an hour or an in-depth research project over several weeks. Putting It All Together: Strategies for Success Writing well is difficult. Even people who write for a living sometimes struggle to get their thoughts on the page. Even people who generally enjoy writing have days when they would rather be doing anything else. For people who do not like writing or do not think of themselves as good writers, writing assignments can be stressful or even intimidating. And of course, you cannot get through post-secondary courses without having to write—sometimes a lot, and often at a higher level than you are used to. No\n",
      "equirements with your instructor. Think carefully about the purpose of the writing, the intended audience, the topics you will need to address, and any specific requirements of the writing form. Complete each step of the writing process . With practice, using this process will come automatically to you. Use the resources available to you . Remember that most schools have specific services to help students with their writing. Key Takeaways Following the steps of the writing process helps students complete any writing assignment more successfully. To manage writing assignments, it is best to work backward from the due date, allotting appropriate time to complete each step of the writing process. Setting concrete long- and short-term goals helps students stay focused and motivated. A variety of resources are available to help students with writing and with other aspects of post-secondary life. Flashcards II Chapter 2: Working with Words: Which Word Is Right? 4 2.1 Commonly Confused Words \n",
      "\n",
      "found too many blacklisted strings\n",
      "f they could make a reality show about us. Asking Questions Who? What? Where? When? Why? How? In everyday situations, you pose these kinds of questions to get information. Who will be my partner for the project? When is the next meeting? Why is my car making that odd noise? You seek the answers to t\n",
      "t; it creates a dominant impression. Supplemental Exercises On a separate sheet of paper, choose one of the examples of a proper thesis statement from this chapter (one that interests you) and form three supporting points for that statement. After you have formed your three points, write a topic sen\n",
      "raphs. 30 6.4 The Writing Process: End-of-Chapter Exercises \n",
      "\n",
      "IND; IND Coordinating conjunctions: FANBOYS: IND, ____ IND for and nor but or yet so Conjunctive adverbs and other transitional expressions: IND. _____, IND or IND; _____,IND accordingly after all after a while also anyhow as a result at any rate at the same time besides consequently for example for\n"
     ]
    }
   ],
   "source": [
    "directory = \"downloaded\"\n",
    "i = 0\n",
    "for filename in os.listdir(directory):\n",
    "    filename2 = filename.replace(\".html\",\"\")\n",
    "    f = os.path.join(directory, filename)\n",
    "    # checking if it is a file\n",
    "    if os.path.isfile(f):\n",
    "        with open(f, \"r\") as read_file:\n",
    "            content = read_file.read()\n",
    "\n",
    "        if not content.__contains__(\"Learning Objectives\"):\n",
    "            print(filename + \" has nothing\")\n",
    "            #move it to the \"no objectives\" folder\n",
    "            os.rename(f, f\"downloaded/no objectives/{filename}\")\n",
    "            continue\n",
    "\n",
    "        # if filename2 != \"writingforsuccess\":\n",
    "        #     continue\n",
    "\n",
    "        print(\"\\n\\n\\n\\n\\n\\n\\n\\n\\n\" + filename + \" contains Learning Objectives\")\n",
    "\n",
    "        soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "        # Remove all exercises            \n",
    "        for el in soup.find_all(\"div\", {\"class\": \"textbox--exercises\"}):\n",
    "            el.decompose()\n",
    "        for el in soup.find_all(\"div\", {\"class\": \"review-questions\"}):\n",
    "            el.decompose()\n",
    "        for el in soup.find_all(\"div\", {\"class\": \"critical-thinking\"}):\n",
    "            el.decompose()\n",
    "        for el in soup.find_all(\"div\", {\"class\": \"exercise\"}):\n",
    "            el.decompose()\n",
    "        for el in soup.find_all(\"div\", {\"title\": \"Mid-Chapter Questions\"}):\n",
    "            el.decompose()\n",
    "        for el in soup.find_all(\"div\", {\"title\": \"End of Chapter Questions\"}):\n",
    "            el.decompose()\n",
    "\n",
    "        # If an element contains \"attributions\", remove it and the next element\n",
    "        for el in soup.find_all(\"h2\", text=re.compile(\"Attributions\")):\n",
    "            el.decompose()\n",
    "            if el.next_sibling:\n",
    "                el.next_sibling.decompose()\n",
    "        for el in soup.find_all(\"h3\", text=re.compile(\"Attributions\")):\n",
    "            el.decompose()\n",
    "            if el.next_sibling:\n",
    "                el.next_sibling.decompose()\n",
    "        for el in soup.find_all(\"h3\", text=re.compile(\"Exercises and Critical Thinking\")):\n",
    "            el.decompose()\n",
    "            if el.next_sibling:\n",
    "                el.next_sibling.decompose()\n",
    "        \n",
    "        for el in soup.find_all(\"h3\", text=re.compile(\"Supplemental Exercises\")):\n",
    "            el.parent.decompose()\n",
    "\n",
    "        # If an h3 contains \"Section Quiz\", remove it and its parent\n",
    "        for el in soup.find_all(\"h3\", text=re.compile(\"Section Quiz\")):\n",
    "            el.parent.decompose()\n",
    "\n",
    "        for el in soup.find_all(\"h3\", text=re.compile(\"Self-practice\")):\n",
    "            el.parent.decompose()\n",
    "        for el in soup.find_all(\"h3\", text=re.compile(\"Self-Practice\")):\n",
    "            el.parent.decompose()\n",
    "\n",
    "\n",
    "        for el in soup.find_all(\"strong\", text=re.compile(\"H5P\")):\n",
    "            # print(\"el.name: \" + el.name + \" el.parent.name: \" + el.parent.name + \" el.parent.parent.name: \" + el.parent.parent.name)\n",
    "            if el.parent is not None:\n",
    "                if el.parent.name != \"div\":\n",
    "                    el.parent.parent.decompose()\n",
    "                else:\n",
    "                    el.parent.decompose()\n",
    "            else:\n",
    "                el.decompose()\n",
    "            \n",
    "        for el in soup.find_all(\"strong\", text=re.compile(\"Practice Exercise\")):\n",
    "            # print(\"el.name: \" + el.name + \" el.parent.name: \" + el.parent.name + \" el.parent.parent.name: \" + el.parent.parent.name)\n",
    "            if el.parent is not None:\n",
    "                if el.parent.name != \"div\":\n",
    "                    el.parent.parent.decompose()\n",
    "                else:\n",
    "                    el.parent.decompose()\n",
    "            else:\n",
    "                el.decompose()  \n",
    "\n",
    "        for el in soup.find_all(\"strong\", text=re.compile(\"Practice EXERCISE\")):\n",
    "            # print(\"el.name: \" + el.name + \" el.parent.name: \" + el.parent.name + \" el.parent.parent.name: \" + el.parent.parent.name)\n",
    "            if el.parent is not None:\n",
    "                if el.parent.name != \"div\":\n",
    "                    el.parent.parent.decompose()\n",
    "                else:\n",
    "                    el.parent.decompose()\n",
    "            else:\n",
    "                el.decompose()  \n",
    "                 \n",
    "\n",
    "\n",
    "\n",
    "        if filename2 == \"biology\":\n",
    "            for el in soup.find_all(\"ol\"):\n",
    "                el.decompose()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        content = soup.prettify()\n",
    "        \n",
    "        #remove all \\n\n",
    "        content = re.sub('\\n', '', str(content))\n",
    "\n",
    "        #remove all &nbsp;\n",
    "        content = re.sub('&nbsp;', '', str(content))\n",
    "\n",
    "        #remove all the special characters like &#8220;\n",
    "        content = re.sub(r'&#\\d+;', '', str(content))\n",
    "\n",
    "        #add space after list elements\n",
    "        content = re.sub('</li>', '</li>\\n', str(content))\n",
    "        \n",
    "        #remove all the html tags\n",
    "        content = re.sub('<[^<]+?>', '', str(content))\n",
    "\n",
    "        #trim each line\n",
    "        content = re.sub(r'^\\s+', '', str(content), flags=re.MULTILINE)            \n",
    "\n",
    "        #remove all the duplicate spaces\n",
    "        content = re.sub(r'(\\s+)', lambda x:x.group(0), content, flags=re.DOTALL)\n",
    "\n",
    "        #remove all the broken content\n",
    "        content = re.sub(r'An interactive H5P element has been excluded from this version of the text. You can view it online here:', '', str(content))\n",
    "\n",
    "        #remove all the links\n",
    "        content = re.sub(r'https?://\\S+', '', str(content))\n",
    "\n",
    "\n",
    "        sections = content.split(\"Learning Objectives\")\n",
    "        lectures=[]\n",
    "        question_groups=[]\n",
    "        for (sectionidx,section) in enumerate(sections[1:]):\n",
    "            #the first few lines are the learning objectives. as soon as a line has one of the following, it is part of the lecture:\n",
    "            # more than 200 characters\n",
    "            # a © symbol \n",
    "            # it contains the text \"Media Attributions\"\n",
    "            # it contains \"Figure \\d\"\n",
    "            temp = section.split(\"\\n\")\n",
    "            question_group = \"\"\n",
    "            lecture = \"\"\n",
    "            processing_lec = False\n",
    "            #in the first line, remove everything that comes before the first colon\n",
    "            temp[0] = re.sub(r'^.*?:', '', temp[0])\n",
    "            for t in temp:\n",
    "                # print(\"processing: \" + t[:200])\n",
    "                if len(t) > 200 or t.__contains__(\"©\") or t.__contains__(\"Media Attributions\") or re.search(r'Figure \\d', t):\n",
    "                    processing_lec = True\n",
    "                if processing_lec:\n",
    "                    lecture += t\n",
    "                else:\n",
    "                    question_group += t+\"\\n\"\n",
    "            \n",
    "            #trim the question group\n",
    "            question_group = re.sub(r'^\\s+', '', question_group, flags=re.MULTILINE)\n",
    "            question_group = re.sub(r'\\s+$', '', question_group, flags=re.MULTILINE)\n",
    "            #remove duplicate spaces from the lecture\n",
    "            lecture = re.sub(r'([ ]+)', ' ', lecture, flags=re.DOTALL)\n",
    "            #remove duplicate spaces from the question group\n",
    "            question_group = re.sub(r'([ ]+)', ' ', question_group, flags=re.DOTALL)\n",
    "            if len(question_group) > 0:\n",
    "                lectures.append(lecture)\n",
    "                question_groups.append(question_group)\n",
    "\n",
    "            # print(\"question: \" + question)\n",
    "            # print(\"lecture: \" + lecture[:500])\n",
    "            # break\n",
    "\n",
    "\n",
    "\n",
    "        print(\"extracted \" + str(len(lectures)) + \" lectures and \" + str(len(question_groups)) + \" questions groups\")\n",
    "        for i in range(min(3, len(lectures))):\n",
    "            print(\"QUESTIONS \" + str(i))\n",
    "            print(re.sub(r'\\n', ' ### ', question_groups[i][:1000], flags=re.MULTILINE))\n",
    "            print(\"LECTURE \" + str(i))\n",
    "            print(re.sub(r'\\n', '', lectures[i][:1000], flags=re.MULTILINE))\n",
    "            print(re.sub(r'\\n', '', lectures[i][-1000:], flags=re.MULTILINE))\n",
    "            print(\"\")\n",
    "\n",
    "\n",
    "\n",
    "        #this is used to find problems\n",
    "        if filename2 != \"biology\":\n",
    "            blacklist = [\"____\", \"Exercises\",\"Questions\",\"Guided Practice\", \"Explore More\", \"Review Questions\", \"Which of the following\", \"Test Yourself\", \"Self-practice\"]\n",
    "            strings = []\n",
    "            for lecture in lectures:\n",
    "                if any(lecture.__contains__(word) for word in blacklist):\n",
    "                    \n",
    "                    occ = [lecture.find(end) for end in blacklist]\n",
    "                    idx = np.argmin([999999999 if o == -1 else o for o in occ])\n",
    "                    loc = occ[idx]\n",
    "                    strings.append(lecture[loc-50:loc+250])\n",
    "\n",
    "            if len(strings) > 4:\n",
    "                print(\"found too many blacklisted strings\")\n",
    "                for s in strings:\n",
    "                    print(s)\n",
    "\n",
    "\n",
    "\n",
    "        if len(lectures) == 1:\n",
    "            print(\"only one set of objectives\")\n",
    "            os.rename(f, f\"downloaded/no objectives/{filename}\")\n",
    "            continue\n",
    "        else:\n",
    "            filename2 = filename.replace(\".html\",\"\")\n",
    "            location = f\"processed_learning_objectives/{filename2}.pq\"\n",
    "            # create a dataframe that contains all the questions and lectures separately\n",
    "            df = pd.DataFrame(columns=[\"lecture\", \"question_group\"])\n",
    "            for (lecture, question_group) in zip(lectures, question_groups):\n",
    "                # df = df.append({\"lecture\": lecture, \"question_group\": question_group}, ignore_index=True)\n",
    "                df = pd.concat([df, pd.DataFrame({\"lecture\": [lecture], \"question_group\": [question_group]})], ignore_index=True)\n",
    "                \n",
    "\n",
    "            # print(df)\n",
    "            df.to_parquet(location, index=False)\n",
    "            # break\n",
    "            continue\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              lecture  \\\n",
      "0   Watch a video about Evolution by Natural Selec...   \n",
      "1   Watch a video about the Scientific Method. Fig...   \n",
      "2   Watch a video about electrons and how the elec...   \n",
      "3   Watch a video about why we need oxygen and how...   \n",
      "4   Watch a video about proteins and protein enzym...   \n",
      "5   Watch a video about eukaryotic cells Watch a v...   \n",
      "6   Cells fall into one of two broad categories: p...   \n",
      "7   Watch a video about oxygen in the atmosphere. ...   \n",
      "8   A cell’s plasma membrane defines the boundary ...   \n",
      "9   Plasma membranes must allow certain substances...   \n",
      "10  Active transport mechanisms require the use of...   \n",
      "11  Watch a video about heterotrophs. Scientists u...   \n",
      "12  Energy production within a cell involves many ...   \n",
      "13  The Citric Acid Cycle In eukaryotic cells, the...   \n",
      "14  In aerobic respiration, the final electron acc...   \n",
      "15  You have learned about the catabolism of gluco...   \n",
      "16  All living organisms on earth consist of one o...   \n",
      "17  How can light be used to make food? It is easy...   \n",
      "18  After the energy from the sun is converted and...   \n",
      "19  The continuity of life from one cell to anothe...   \n",
      "20  The cell cycle is an ordered series of events ...   \n",
      "21  Cancer is a collective name for many different...   \n",
      "22  Prokaryotes such as bacteria propagate by bina...   \n",
      "23   Sexual reproduction was an early evolutionary...   \n",
      "24  Sexual reproduction requires fertilization, a ...   \n",
      "25  Inherited disorders can arise when chromosomes...   \n",
      "26  Figure 8.2 Johann Gregor Mendel set the framew...   \n",
      "27  The seven characteristics that Mendel evaluate...   \n",
      "28  Mendel studied traits with only one mode of in...   \n",
      "29  In the 1950s, Francis Crick and James Watson w...   \n",
      "30  When a cell divides, it is important that each...   \n",
      "31  In both prokaryotes and eukaryotes, the second...   \n",
      "32  The synthesis of proteins is one of a cell’s m...   \n",
      "33  For a cell to function properly, necessary pro...   \n",
      "34  Biotechnology is the use of artificial methods...   \n",
      "35  It is easy to see how biotechnology can be use...   \n",
      "36  The study of nucleic acids began with the disc...   \n",
      "37  Homeostasis refers to the relatively stable st...   \n",
      "38  All living organisms need nutrients to survive...   \n",
      "39  Animals are complex multicellular organisms th...   \n",
      "40  The endocrine system produces hormones that fu...   \n",
      "41  The muscular and skeletal systems provide supp...   \n",
      "42  As you read this, your nervous system is perfo...   \n",
      "43  Figure 12.2 (a) The tobacco mosaic virus, seen...   \n",
      "44  The vertebrate, including human, immune system...   \n",
      "45  The adaptive, or acquired, immune response tak...   \n",
      "46  A functioning immune system is essential for s...   \n",
      "47  Some animals produce offspring through asexual...   \n",
      "48  The process by which an organism develops from...   \n",
      "49  As in all animals, the adaptations for reprodu...   \n",
      "50  Animals vary in form and function. From a spon...   \n",
      "51  Multicellular, complex animals have four prima...   \n",
      "52  Animal organs and organ systems constantly adj...   \n",
      "53  Animals obtain their nutrition from the consum...   \n",
      "54  Given the diversity of animal life on our plan...   \n",
      "55  Obtaining nutrition and energy from food is a ...   \n",
      "56  The brain is the control center for the sensat...   \n",
      "57  Nervous systems throughout the animal kingdom ...   \n",
      "58  All functions performed by the nervous system—...   \n",
      "59  The central nervous system (CNS) is made up of...   \n",
      "60  The peripheral nervous system (PNS) is the con...   \n",
      "61  A nervous system that functions correctly is a...   \n",
      "62  Senses provide information about the body and ...   \n",
      "63  Somatosensation is a mixed sensory category an...   \n",
      "64  Taste, also called gustation , and smell, also...   \n",
      "65  Audition , or hearing, is important to humans ...   \n",
      "66  Vision is the ability to detect light patterns...   \n",
      "67  Maintaining homeostasis within the body requir...   \n",
      "68  Hormones mediate changes in target cells by bi...   \n",
      "69  Hormones have a wide range of effects and modu...   \n",
      "70  Hormone production and release are primarily c...   \n",
      "71  Both the endocrine and nervous systems use che...   \n",
      "72  A skeletal system is necessary to support the ...   \n",
      "73  Bone , or osseous tissue , is a connective tis...   \n",
      "74  The point at which two or more bones meet is c...   \n",
      "75  Muscle cells are specialized for contraction. ...   \n",
      "76  The primary function of the respiratory system...   \n",
      "77  The structure of the lung maximizes its surfac...   \n",
      "78  Mammalian lungs are located in the thoracic ca...   \n",
      "79  Once the oxygen diffuses across the alveoli, i...   \n",
      "80  In all animals, except a few simple types, the...   \n",
      "81  Hemoglobin is responsible for distributing oxy...   \n",
      "82  The heart is a complex muscle that pumps blood...   \n",
      "83  Blood pressure (BP) is the pressure exerted by...   \n",
      "84  Osmosis is the diffusion of water across a mem...   \n",
      "85  Although the kidneys are the major osmoregulat...   \n",
      "86  Microorganisms and invertebrate animals use mo...   \n",
      "87  Of the four major macromolecules in biological...   \n",
      "88  Describe how hormones like epinephrine, norepi...   \n",
      "89  The immune system comprises both innate and ad...   \n",
      "90  The adaptive, or acquired, immune response tak...   \n",
      "91  An antibody , also known as an immunoglobulin ...   \n",
      "92  A functioning immune system is essential for s...   \n",
      "93  Animals produce offspring through asexual and/...   \n",
      "94  Sexual reproduction starts with the combinatio...   \n",
      "95  As animals became more complex, specific organ...   \n",
      "96  The human male and female reproductive cycles ...   \n",
      "97  Pregnancy begins with the fertilization of an ...   \n",
      "98  The process in which an organism develops from...   \n",
      "99  Gastrulation leads to the formation of the thr...   \n",
      "\n",
      "                                       question_group  \n",
      "0   Identify and describe the properties of life\\n...  \n",
      "1   Identify the shared characteristics of the nat...  \n",
      "2   Describe matter and elements\\nDescribe the int...  \n",
      "3   Describe the properties of water that are crit...  \n",
      "4   Describe the ways in which carbon is critical ...  \n",
      "5   Describe the roles of cells in organisms\\nComp...  \n",
      "6   Name examples of prokaryotic and eukaryotic or...  \n",
      "7   Describe the structure of eukaryotic plant and...  \n",
      "8   Understand the fluid mosaic model of membranes...  \n",
      "9   Explain why and how passive transport occurs\\n...  \n",
      "10  Understand how electrochemical gradients affec...  \n",
      "11  Explain what metabolic pathways are\\nState the...  \n",
      "12  Explain how ATP is used by the cell as an ener...  \n",
      "13  Describe the location of the citric acid cycle...  \n",
      "14  Discuss the fundamental difference between ana...  \n",
      "15  Discuss the way in which carbohydrate metaboli...  \n",
      "16  Summarize the process of photosynthesis\\nExpla...  \n",
      "17  Explain how plants absorb energy from sunlight...  \n",
      "18  Describe the Calvin cycle\\nDefine carbon fixat...  \n",
      "19  Describe the prokaryotic and eukaryotic genome...  \n",
      "20  Describe the three stages of interphase\\nDiscu...  \n",
      "21  Explain how cancer is caused by uncontrolled c...  \n",
      "22  Describe the process of binary fission in prok...  \n",
      "23  Explain that variation among offspring is a po...  \n",
      "24  Describe the behavior of chromosomes during me...  \n",
      "25  Explain how nondisjunction leads to disorders ...  \n",
      "26  Explain the scientific reasons for the success...  \n",
      "27  Explain the relationship between genotypes and...  \n",
      "28  Identify non-Mendelian inheritance patterns su...  \n",
      "29  Describe the structure of DNA\\nDescribe how eu...  \n",
      "30  Explain the process of DNA replication\\nExplai...  \n",
      "31  Explain the central dogma\\nExplain the main st...  \n",
      "32  Describe the different steps in protein synthe...  \n",
      "33  Discuss why every cell does not express all of...  \n",
      "34  Explain the basic techniques used to manipulat...  \n",
      "35  Describe uses of biotechnology in medicine\\nDe...  \n",
      "36  Define genomics and proteomics\\nDefine whole g...  \n",
      "37  Explain the concept of homeostasis\\nDescribe t...  \n",
      "38  Explain the processes of digestion and absorpt...  \n",
      "39  Describe the passage of air from the outside e...  \n",
      "40  List the different types of hormones and expla...  \n",
      "41  Discuss the axial and appendicular parts of th...  \n",
      "42  Describe the form and function of a neuron\\nDe...  \n",
      "43  Describe how viruses were first discovered and...  \n",
      "44  Describe the body’s innate physical and chemic...  \n",
      "45  Explain adaptive immunity\\nDescribe cell-media...  \n",
      "46     Describe hypersensitivity\\nDefine autoimmunity  \n",
      "47  Describe advantages and disadvantages of asexu...  \n",
      "48  Explain how the embryo forms from the zygote\\n...  \n",
      "49  Describe human male and female reproductive an...  \n",
      "50  Describe the various types of body plans that ...  \n",
      "51  Describe epithelial tissues\\nDiscuss the diffe...  \n",
      "52  Define homeostasis\\nDescribe the factors affec...  \n",
      "53  Explain the processes of digestion and absorpt...  \n",
      "54  Explain why an animal’s diet should be balance...  \n",
      "55  Describe the process of digestion\\nDetail the ...  \n",
      "56  Discuss the role of neural regulation in diges...  \n",
      "57  List and describe the functions of the structu...  \n",
      "58  Describe the basis of the resting membrane pot...  \n",
      "59  Identify the spinal cord, cerebral lobes, and ...  \n",
      "60  Describe the organization and functions of the...  \n",
      "61  Describe the symptoms, potential causes, and t...  \n",
      "62  Identify the general and special senses in hum...  \n",
      "63  Describe four important mechanoreceptors in hu...  \n",
      "64  Explain in what way smell and taste stimuli di...  \n",
      "65  Describe the relationship of amplitude and fre...  \n",
      "66  Explain how electromagnetic waves differs from...  \n",
      "67  List the different types of hormones\\nExplain ...  \n",
      "68  Explain how hormones work\\nDiscuss the role of...  \n",
      "69  Explain how hormones regulate the excretory sy...  \n",
      "70  Explain how hormone production is regulated\\nD...  \n",
      "71  Describe the role of different glands in the e...  \n",
      "72  Discuss the different types of skeletal system...  \n",
      "73  Classify the different types of bones in the s...  \n",
      "74  Classify the different types of joints on the ...  \n",
      "75  Classify the different types of muscle tissue\\...  \n",
      "76  Describe the passage of air from the outside e...  \n",
      "77  Name and describe lung volumes and capacities\\...  \n",
      "78  Describe how the structures of the lungs and t...  \n",
      "79  Describe how oxygen is bound to hemoglobin and...  \n",
      "80  Describe an open and closed circulatory system...  \n",
      "81  List the basic components of the blood\\nCompar...  \n",
      "82  Describe the structure of the heart and explai...  \n",
      "83  Describe the system of blood flow through the ...  \n",
      "84  Define osmosis and explain its role within mol...  \n",
      "85  Explain how the kidneys serve as the main osmo...  \n",
      "86  Explain how vacuoles, present in microorganism...  \n",
      "87  Compare and contrast the way in which aquatic ...  \n",
      "88  Explain how hormonal cues help the kidneys syn...  \n",
      "89  Describe physical and chemical immune barriers...  \n",
      "90  Explain adaptive immunity\\nCompare and contras...  \n",
      "91  Explain cross-reactivity\\nDescribe the structu...  \n",
      "92     Describe hypersensitivity\\nDefine autoimmunity  \n",
      "93  Describe advantages and disadvantages of asexu...  \n",
      "94  Discuss internal and external methods of ferti...  \n",
      "95  Describe human male and female reproductive an...  \n",
      "96  Describe the roles of male and female reproduc...  \n",
      "97  Explain fetal development during the three tri...  \n",
      "98  Discuss how fertilization occurs\\nExplain how ...  \n",
      "99  Describe the process of organogenesis\\nIdentif...  \n"
     ]
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None): \n",
    "    print(pd.read_parquet(\"./processed_learning_objectives/biology.pq\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Timothe\\AppData\\Local\\Temp/ipykernel_44424/2000946465.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged_df = merged_df.append(df, ignore_index=True)\n",
      "C:\\Users\\Timothe\\AppData\\Local\\Temp/ipykernel_44424/2000946465.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged_df = merged_df.append(df, ignore_index=True)\n",
      "C:\\Users\\Timothe\\AppData\\Local\\Temp/ipykernel_44424/2000946465.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged_df = merged_df.append(df, ignore_index=True)\n",
      "C:\\Users\\Timothe\\AppData\\Local\\Temp/ipykernel_44424/2000946465.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged_df = merged_df.append(df, ignore_index=True)\n",
      "C:\\Users\\Timothe\\AppData\\Local\\Temp/ipykernel_44424/2000946465.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged_df = merged_df.append(df, ignore_index=True)\n",
      "C:\\Users\\Timothe\\AppData\\Local\\Temp/ipykernel_44424/2000946465.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged_df = merged_df.append(df, ignore_index=True)\n",
      "C:\\Users\\Timothe\\AppData\\Local\\Temp/ipykernel_44424/2000946465.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged_df = merged_df.append(df, ignore_index=True)\n",
      "C:\\Users\\Timothe\\AppData\\Local\\Temp/ipykernel_44424/2000946465.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged_df = merged_df.append(df, ignore_index=True)\n",
      "C:\\Users\\Timothe\\AppData\\Local\\Temp/ipykernel_44424/2000946465.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged_df = merged_df.append(df, ignore_index=True)\n",
      "C:\\Users\\Timothe\\AppData\\Local\\Temp/ipykernel_44424/2000946465.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged_df = merged_df.append(df, ignore_index=True)\n",
      "C:\\Users\\Timothe\\AppData\\Local\\Temp/ipykernel_44424/2000946465.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged_df = merged_df.append(df, ignore_index=True)\n",
      "C:\\Users\\Timothe\\AppData\\Local\\Temp/ipykernel_44424/2000946465.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged_df = merged_df.append(df, ignore_index=True)\n",
      "C:\\Users\\Timothe\\AppData\\Local\\Temp/ipykernel_44424/2000946465.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged_df = merged_df.append(df, ignore_index=True)\n",
      "C:\\Users\\Timothe\\AppData\\Local\\Temp/ipykernel_44424/2000946465.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged_df = merged_df.append(df, ignore_index=True)\n",
      "C:\\Users\\Timothe\\AppData\\Local\\Temp/ipykernel_44424/2000946465.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged_df = merged_df.append(df, ignore_index=True)\n",
      "C:\\Users\\Timothe\\AppData\\Local\\Temp/ipykernel_44424/2000946465.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged_df = merged_df.append(df, ignore_index=True)\n",
      "C:\\Users\\Timothe\\AppData\\Local\\Temp/ipykernel_44424/2000946465.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged_df = merged_df.append(df, ignore_index=True)\n",
      "C:\\Users\\Timothe\\AppData\\Local\\Temp/ipykernel_44424/2000946465.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged_df = merged_df.append(df, ignore_index=True)\n",
      "C:\\Users\\Timothe\\AppData\\Local\\Temp/ipykernel_44424/2000946465.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged_df = merged_df.append(df, ignore_index=True)\n",
      "C:\\Users\\Timothe\\AppData\\Local\\Temp/ipykernel_44424/2000946465.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged_df = merged_df.append(df, ignore_index=True)\n",
      "C:\\Users\\Timothe\\AppData\\Local\\Temp/ipykernel_44424/2000946465.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged_df = merged_df.append(df, ignore_index=True)\n",
      "C:\\Users\\Timothe\\AppData\\Local\\Temp/ipykernel_44424/2000946465.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged_df = merged_df.append(df, ignore_index=True)\n",
      "C:\\Users\\Timothe\\AppData\\Local\\Temp/ipykernel_44424/2000946465.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged_df = merged_df.append(df, ignore_index=True)\n",
      "C:\\Users\\Timothe\\AppData\\Local\\Temp/ipykernel_44424/2000946465.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged_df = merged_df.append(df, ignore_index=True)\n",
      "C:\\Users\\Timothe\\AppData\\Local\\Temp/ipykernel_44424/2000946465.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged_df = merged_df.append(df, ignore_index=True)\n",
      "C:\\Users\\Timothe\\AppData\\Local\\Temp/ipykernel_44424/2000946465.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged_df = merged_df.append(df, ignore_index=True)\n",
      "C:\\Users\\Timothe\\AppData\\Local\\Temp/ipykernel_44424/2000946465.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged_df = merged_df.append(df, ignore_index=True)\n",
      "C:\\Users\\Timothe\\AppData\\Local\\Temp/ipykernel_44424/2000946465.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged_df = merged_df.append(df, ignore_index=True)\n",
      "C:\\Users\\Timothe\\AppData\\Local\\Temp/ipykernel_44424/2000946465.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged_df = merged_df.append(df, ignore_index=True)\n",
      "C:\\Users\\Timothe\\AppData\\Local\\Temp/ipykernel_44424/2000946465.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged_df = merged_df.append(df, ignore_index=True)\n",
      "C:\\Users\\Timothe\\AppData\\Local\\Temp/ipykernel_44424/2000946465.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged_df = merged_df.append(df, ignore_index=True)\n",
      "C:\\Users\\Timothe\\AppData\\Local\\Temp/ipykernel_44424/2000946465.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged_df = merged_df.append(df, ignore_index=True)\n",
      "C:\\Users\\Timothe\\AppData\\Local\\Temp/ipykernel_44424/2000946465.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged_df = merged_df.append(df, ignore_index=True)\n",
      "C:\\Users\\Timothe\\AppData\\Local\\Temp/ipykernel_44424/2000946465.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged_df = merged_df.append(df, ignore_index=True)\n",
      "C:\\Users\\Timothe\\AppData\\Local\\Temp/ipykernel_44424/2000946465.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged_df = merged_df.append(df, ignore_index=True)\n",
      "C:\\Users\\Timothe\\AppData\\Local\\Temp/ipykernel_44424/2000946465.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged_df = merged_df.append(df, ignore_index=True)\n",
      "C:\\Users\\Timothe\\AppData\\Local\\Temp/ipykernel_44424/2000946465.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged_df = merged_df.append(df, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "merged_df = pd.DataFrame(columns=[\"lecture\", \"question_group\"])\n",
    "\n",
    "#go through all the parquet files and merge them\n",
    "for filename in os.listdir(\"processed_learning_objectives\"):\n",
    "    if filename.endswith(\".pq\"):\n",
    "        df = pd.read_parquet(\"processed_learning_objectives/\" + filename)\n",
    "        merged_df = merged_df.append(df, ignore_index=True)\n",
    "\n",
    "merged_df.to_parquet(\"merged.pq\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Citric Acid Cycle In eukaryotic cells, the pyruvate molecules produced at the end of glycolysis are transported into mitochondria , which are sites of cellular respiration. If oxygen is available, aerobic respiration will go forward. In mitochondria, pyruvate will be transformed into a two-carbon acetyl group (by removing a molecule of carbon dioxide) that will be picked up by a carrier compound called coenzyme A (CoA), which is made from vitamin B 5 . The resulting compound is called acetyl CoA. ( Figure 4.17 ). Acetyl CoA can be used in a variety of ways by the cell, but its major function is to deliver the acetyl group derived from pyruvate to the next pathway in glucose catabolism. Figure 4.17 Pyruvate is converted into acetyl-CoA before entering the citric acid cycle. Like the conversion of pyruvate to acetyl CoA, the citric acid cycle in eukaryotic cells takes place in the matrix of the mitochondria . Unlike glycolysis, the citric acid cycle is a closed loop: The last part of the pathway regenerates the compound used in the first step. The eight steps of the cycle are a series of chemical reactions that produces two carbon dioxide molecules, one ATP molecule (or an equivalent), and reduced forms (NADH and FADH 2 ) of NAD + and FAD + , important coenzymes in the cell. Part of this is considered an aerobic pathway (oxygen-requiring) because the NADH and FADH 2 produced must transfer their electrons to the next pathway in the system, which will use oxygen. If oxygen is not present, this transfer does not occur. Two carbon atoms come into the citric acid cycle from each acetyl group. Two carbon dioxide molecules are released on each turn of the cycle; however, these do not contain the same carbon atoms contributed by the acetyl group on that turn of the pathway. The two acetyl-carbon atoms will eventually be released on later turns of the cycle; in this way, all six carbon atoms from the original glucose molecule will be eventually released as carbon dioxide. It takes two turns of the cycle to process the equivalent of one glucose molecule. Each turn of the cycle forms three high-energy NADH molecules and one high-energy FADH 2 molecule. These high-energy carriers will connect with the last portion of aerobic respiration to produce ATP molecules. One ATP (or an equivalent) is also made in each cycle. Several of the intermediate compounds in the citric acid cycle can be used in synthesizing non-essential amino acids; therefore, the cycle is both anabolic and catabolic. Figure 4.18 In eukaryotes, oxidative phosphorylation takes place in mitochondria. In prokaryotes, this process takes place in the plasma membrane. (Credit: modification of work by Mariana Ruiz Villareal) Oxidative Phosphorylation You have just read about two pathways in glucose catabolism—glycolysis and the citric acid cycle—that generate ATP. Most of the ATP generated during the aerobic catabolism of glucose, however, is not generated directly from these pathways. Rather, it derives from a process that begins with passing electrons through a series of chemical reactions to a final electron acceptor, oxygen. These reactions take place in specialized protein complexes located in the inner membrane of the mitochondria of eukaryotic organisms and on the inner part of the cell membrane of prokaryotic organisms. The energy of the electrons is harvested and used to generate a electrochemical gradient across the inner mitochondrial membrane. The potential energy of this gradient is used to generate ATP . The entirety of this process is called oxidative phosphorylation. The electron transport chain ( Figure 4.19 a ) is the last component of aerobic respiration and is the only part of metabolism that uses atmospheric oxygen. Oxygen continuously diffuses into plants for this purpose. In animals, oxygen enters the body through the respiratory system. Electron transport is a series of chemical reactions that resembles a bucket brigade in that electrons are passed rapidly from one component to the next, to the endpoint of the chain where oxygen is the final electron acceptor and water is produced. There are four complexes composed of proteins, labeled I through IV in Figure 4.19 c , and the aggregation of these four complexes, together with associated mobile, accessory electron carriers, is called the electron transport chain. The electron transport chain is present in multiple copies in the inner mitochondrial membrane of eukaryotes and in the plasma membrane of prokaryotes. In each transfer of an electron through the electron transport chain, the electron loses energy, but with some transfers, the energy is stored as potential energy by using it to pump hydrogen ions across the inner mitochondrial membrane into the intermembrane space, creating an electrochemical gradient. Figure 4.19 (a) The electron transport chain is a set of molecules that supports a series of oxidation-reduction reactions. (b) ATP synthase is a complex, molecular machine that uses an H+ gradient to regenerate ATP from ADP. (c) Chemiosmosis relies on the potential energy provided by the H+ gradient across the membrane. Cyanide inhibits cytochrome c oxidase, a component of the electron transport chain. If cyanide poisoning occurs, would you expect the pH of the intermembrane space to increase or decrease? What affect would cyanide have on ATP synthesis? Electrons from NADH and FADH 2 are passed to protein complexes in the electron transport chain. As they are passed from one complex to another (there are a total of four), the electrons lose energy, and some of that energy is used to pump hydrogen ions from the mitochondrial matrix into the intermembrane space. In the fourth protein complex, the electrons are accepted by oxygen, the terminal acceptor. The oxygen with its extra electrons then combines with two hydrogen ions, further enhancing the electrochemical gradient, to form water. If there were no oxygen present in the mitochondrion, the electrons could not be removed from the system, and the entire electron transport chain would back up and stop. The mitochondria would be unable to generate new ATP in this way, and the cell would ultimately die from lack of energy. This is the reason we must breathe to draw in new oxygen. In the electron transport chain, the free energy from the series of reactions just described is used to pump hydrogen ions across the membrane. The uneven distribution of H + ions across the membrane establishes an electrochemical gradient, owing to the H + ions’ positive charge and their higher concentration on one side of the membrane. Hydrogen ions diffuse through the inner membrane through an integral membrane protein called ATP synthase ( Figure 4.19 b ). This complex protein acts as a tiny generator, turned by the force of the hydrogen ions diffusing through it, down their electrochemical gradient from the intermembrane space, where there are many mutually repelling hydrogen ions to the matrix, where there are few. The turning of the parts of this molecular machine regenerate ATP from ADP. This flow of hydrogen ions across the membrane through ATP synthase is called chemiosmosis. Chemiosmosis ( Figure 4.19 c ) is used to generate 90 percent of the ATP made during aerobic glucose catabolism. The result of the reactions is the production of ATP from the energy of the electrons removed from hydrogen atoms. These atoms were originally part of a glucose molecule. At the end of the electron transport system, the electrons are used to reduce an oxygen molecule to oxygen ions. The extra electrons on the oxygen ions attract hydrogen ions (protons) from the surrounding medium, and water is formed. The electron transport chain and the production of ATP through chemiosmosis are collectively called oxidative phosphorylation. ATP Yield The number of ATP molecules generated from the catabolism of glucose varies. For example, the number of hydrogen ions that the electron transport chain complexes can pump through the membrane varies between species. Another source of variance stems from the shuttle of electrons across the mitochondrial membrane. The NADH generated from glycolysis cannot easily enter mitochondria. Thus, electrons are picked up on the inside of the mitochondria by either NAD + or FAD + . Fewer ATP molecules are generated when FAD + acts as a carrier. NAD + is used as the electron transporter in the liver and FAD + in the brain, so ATP yield depends on the tissue being considered. Another factor that affects the yield of ATP molecules generated from glucose is that intermediate compounds in these pathways are used for other purposes. Glucose catabolism connects with the pathways that build or break down all other biochemical compounds in cells, and the result is somewhat messier than the ideal situations described thus far. For example, sugars other than glucose are fed into the glycolytic pathway for energy extraction. Other molecules that would otherwise be used to harvest energy in glycolysis or the citric acid cycle may be removed to form nucleic acids, amino acids, lipids, or other compounds. Overall, in living systems, these pathways of glucose catabolism extract about 34 percent of the energy contained in glucose. Mitochondrial Disease Physician What happens when the critical reactions of cellular respiration do not proceed correctly? Mitochondrial diseases are genetic disorders of metabolism. Mitochondrial disorders can arise from mutations in nuclear or mitochondrial DNA, and they result in the production of less energy than is normal in body cells. Symptoms of mitochondrial diseases can include muscle weakness, lack of coordination, stroke-like episodes, and loss of vision and hearing. Most affected people are diagnosed in childhood, although there are some adult-onset diseases. Identifying and treating mitochondrial disorders is a specialized medical field. The educational preparation for this profession requires a college education, followed by medical school with a specialization in medical genetics. Medical geneticists can be board certified by the American Board of Medical Genetics and go on to become associated with professional organizations devoted to the study of mitochondrial disease, such as the Mitochondrial Medicine Society and the Society for Inherited Metabolic Disease. Section Summary The citric acid cycle is a series of chemical reactions that removes high-energy electrons and uses them in the electron transport chain to generate ATP. One molecule of ATP (or an equivalent) is produced per each turn of the cycle. The electron transport chain is the portion of aerobic respiration that uses free oxygen as the final electron acceptor for electrons removed from the intermediate compounds in glucose catabolism. The electrons are passed through a series of chemical reactions, with a small amount of free energy used at three points to transport hydrogen ions across the membrane. This contributes to the gradient used in chemiosmosis. As the electrons are passed from NADH or FADH 2 down the electron transport chain, they lose energy. The products of the electron transport chain are water and ATP. A number of intermediate compounds can be diverted into the anabolism of other biochemical molecules, such as nucleic acids, non-essential amino acids, sugars, and lipids. These same molecules, except nucleic acids, can serve as energy sources for the glucose pathway. Glossary acetyl CoA: the combination of an acetyl group derived from pyruvic acid and coenzyme A which is made from pantothenic acid (a B-group vitamin) ATP synthase: a membrane-embedded protein complex that regenerates ATP from ADP with energy from protons diffusing through it chemiosmosis: the movement of hydrogen ions down their electrochemical gradient across a membrane through ATP synthase to generate ATP citric acid cycle: a series of enzyme-catalyzed chemical reactions of central importance in all living cells that harvests the energy in carbon-carbon bonds of sugar molecules to generate ATP; the citric acid cycle is an aerobic metabolic pathway because it requires oxygen in later reactions to proceed electron transport chain: a series of four large, multi-protein complexes embedded in the inner mitochondrial membrane that accepts electrons from donor compounds and harvests energy from a series of chemical reactions to generate a hydrogen ion gradient across the membrane oxidative phosphorylation: the production of ATP by the transfer of electrons down the electron transport chain to create a proton gradient that is used by ATP synthase to add phosphate groups to ADP molecules 15 4.4 Fermentation \n",
      "-----------\n",
      "Describe the location of the citric acid cycle and oxidative phosphorylation in the cell\n",
      "Describe the overall outcome of the citric acid cycle and oxidative phosphorylation in terms of the products of each\n",
      "Describe the relationships of glycolysis, the citric acid cycle, and oxidative phosphorylation in terms of their inputs and outputs.\n",
      "--------------------------\n",
      "How to Grow Tomatoes from a Seedling Growing tomatoes is a simple and rewarding task, and more people should be growing them. This paper walks readers through the main steps for growing and maintaining patio tomatoes from a seedling. The first step in growing tomatoes is determining if you have the appropriate available space and sunlight to grow them. All tomato varieties require full sunlight, which means at least six hours of direct sun every day. If you have south facing windows or a patio or backyard that receives direct sunlight, you should be able to grow tomatoes. Choose the location that receives the most sun. Next, you need to find the right seedling. Growing tomatoes and other vegetables from seeds can be more complicated (though it is not difficult), so I am only discussing how to grow tomatoes from a seedling. A seedling, for those who do not know, is typically understood as a young plant that has only recently started growing from the seed. It can be anything from a newly germinated plant to a fully flowering plant. You can usually find tomato seedlings at your local nursery for an affordable price. Less than five dollars per plant is a common price. When choosing the best seedling, look for a plant that is short with healthy, full leaves and no flowers. This last point tends to be counterintuitive, but it is extremely important. You do not want a vegetable plant that has already started flowering in the nursery because it will have a more difficult time adapting to its new environment when you replant it. Additionally, choose a plant with one strong main stem. This is important because the fewer stems that a tomato plant has, the more easily it can transport nutrients to the fruit. Multiple stems tend to divide nutrients in less efficient ways, often resulting in either lower yields or smaller fruit. Once you have found the right seedlings to plant back home, you need to find the best way of planting them. I recommend that you plant your tomatoes in containers. If you have the space and sunlight, then you can certainly plant them in the ground, but a container has several advantages and is usually most manageable for the majority of gardeners. The containers can be used in the house, on a patio, or anywhere in the backyard, and they are portable. Containers also tend to better regulate moisture and drain excess water. Choose a container that is at least 10 inches in diameter and at least 1 foot deep. This will provide sufficient room for root development. In addition to the container, you also need the appropriate soil mixture and draining mechanisms. For the best drainage, fill the bottom of your container with 2 or 3 inches of gravel. On top of the gravel, fill ¾ of the container with soil. Choose a well-balanced organic soil. The three main ingredients you will find described on soil bags are N-P-K—that is, nitrogen, phosphorus, and potassium. Without going into too much detail about the role of each element in plant growth, I will tell you that an average vegetable will grow fine in a 10-5-5 mixture. This ratio, too, will be easy to find at your local nursery. Once you have the gravel in the bottom of the container and the soil on top, you are ready to transplant the tomato. Pick up the tomato in the plastic container it comes in from the nursery. Turn it upside down, and holding the stem between your fingers, pat the bottom lightly several times, and the plant should fall into your hand. Next, you should gently break up the root ball that formed in the nursery container with your hands. Be gentle, but be sure to rip them up a bit; this helps generate new root growth in the new container. Be careful not to damage the roots too much, as this could stunt the growth or even destroy the plant altogether. Next, carve out a hole in the soil to make space for the plant. Make it deep enough to go about an inch higher than it was previously buried and wide enough so all the roots can comfortably fit within and beneath it. Place the seedling in the hole and push the removed soil back on top to cover the base of the plant. After that, the final step in planting your tomato is mulch. Mulch is not necessary for growing plants, but it can be very helpful in maintaining moisture, keeping out weeds, and regulating soil temperature. Place 2–3 inches of mulch above the soil and spread it out evenly. Once the mulch is laid, you are mostly done. The rest is all watering, waiting, and maintenance. After you lay the mulch, pour the plant a heavy amount of water. Water the plant at its base until you see water coming through the bottom of the container. Wait ten minutes, and repeat. This initial watering is very important for establishing new roots. You should continue to keep the soil moist but never soaking wet. One healthy watering each morning should be sufficient for days without rain. You can often forego watering on days with moderate rainfall. Watering in the morning is preferable to the evening because it lessens mold and bacteria growth. Choosing to grow the patio variety of tomatoes is easiest because patio tomatoes do not require staking or training around cages. They grow in smaller spaces and have a determinate harvest time. As you continue to water and monitor your plant, prune unhealthy looking leaves to the main stem and cut your tomatoes down at the stem when they ripen to your liking. As you can see, growing tomatoes can be very easy and manageable for even novice gardeners. The satisfaction of picking and eating fresh food and doing it yourself, outweighs all the effort you put in over the growing season. A.7 Definition Essay \n",
      "-----------\n",
      "Read an example of the process analysis rhetorical mode\n",
      "--------------------------\n",
      "Watch a video about why we need oxygen and how it causes problems for living things. Do you ever wonder why scientists spend time looking for water on other planets? It is because water is essential to life; even minute traces of it on another planet can indicate that life could or did exist on that planet. Water is one of the more abundant molecules in living cells and the one most critical to life as we know it. Approximately 60–70 percent of your body is made up of water. Without it, life simply would not exist. Water Is Polar The hydrogen and oxygen atoms within water molecules form polar covalent bonds. The shared electrons spend more time associated with the oxygen atom than they do with hydrogen atoms. There is no overall charge to a water molecule, but there is a slight positive charge on each hydrogen atom and a slight negative charge on the oxygen atom. Because of these charges, the slightly positive hydrogen atoms repel each other and form the unique shape. Each water molecule attracts other water molecules because of the positive and negative charges in the different parts of the molecule. Water also attracts other polar molecules (such as sugars), forming hydrogen bonds. When a substance readily forms hydrogen bonds with water, it can dissolve in water and is referred to as hydrophilic (“water-loving”). Hydrogen bonds are not readily formed with nonpolar substances like oils and fats . These nonpolar compounds are hydrophobic (“water-fearing”) and will not dissolve in water. Figure 2.7 As this macroscopic image of oil and water shows, oil is a nonpolar compound and, hence, will not dissolve in water. Oil and water do not mix. Water Stabilizes Temperature The hydrogen bonds in water allow it to absorb and release heat energy more slowly than many other substances. Temperature is a measure of the motion (kinetic energy) of molecules. As the motion increases, energy is higher and thus temperature is higher. Water absorbs a great deal of energy before its temperature rises. Increased energy disrupts the hydrogen bonds between water molecules. Because these bonds can be created and disrupted rapidly, water absorbs an increase in energy and temperature changes only minimally. This means that water moderates temperature changes within organisms and in their environments. As energy input continues, the balance between hydrogen-bond formation and destruction swings toward the destruction side. More bonds are broken than are formed. This process results in the release of individual water molecules at the surface of the liquid (such as a body of water, the leaves of a plant, or the skin of an organism) in a process called evaporation . Evaporation of sweat, which is 90 percent water, allows for cooling of an organism, because breaking hydrogen bonds requires an input of energy and takes heat away from the body. Conversely, as molecular motion decreases and temperatures drop, less energy is present to break the hydrogen bonds between water molecules. These bonds remain intact and begin to form a rigid, lattice-like structure (e.g., ice) (Figure 2.8 a ). When frozen, ice is less dense than liquid water (the molecules are farther apart). This means that ice floats on the surface of a body of water (Figure 2.8 b ). In lakes, ponds, and oceans, ice will form on the surface of the water, creating an insulating barrier to protect the animal and plant life beneath from freezing in the water. If this did not happen, plants and animals living in water would freeze in a block of ice and could not move freely, making life in cold temperatures difficult or impossible. Figure 2.8 (a) The lattice structure of ice makes it less dense than the freely flowing molecules of liquid water. Ice’s lower density enables it to (b) float on water. (credit a: modification of work by Jane Whitney; credit b: modification of work by Carlos Ponte) Water Is an Excellent Solvent Because water is polar, with slight positive and negative charges, ionic compounds and polar molecules can readily dissolve in it. Water is, therefore, what is referred to as a solvent —a substance capable of dissolving another substance. The charged particles will form hydrogen bonds with a surrounding layer of water molecules. This is referred to as a sphere of hydration and serves to keep the particles separated or dispersed in the water. In the case of table salt (NaCl) mixed in water, the sodium and chloride ions separate, or dissociate, in the water, and spheres of hydration are formed around the ions. A positively charged sodium ion is surrounded by the partially negative charges of oxygen atoms in water molecules. A negatively charged chloride ion is surrounded by the partially positive charges of hydrogen atoms in water molecules. These spheres of hydration are also referred to as hydration shells. The polarity of the water molecule makes it an effective solvent and is important in its many roles in living systems. Figure 2.9 When table salt (NaCl) is mixed in water, spheres of hydration form around the ions. Water Is Cohesive Have you ever filled up a glass of water to the very top and then slowly added a few more drops? Before it overflows, the water actually forms a dome-like shape above the rim of the glass. This water can stay above the glass because of the property of cohesion . In cohesion, water molecules are attracted to each other (because of hydrogen bonding), keeping the molecules together at the liquid-air (gas) interface, although there is no more room in the glass. Cohesion gives rise to surface tension , the capacity of a substance to withstand rupture when placed under tension or stress. When you drop a small scrap of paper onto a droplet of water, the paper floats on top of the water droplet, although the object is denser (heavier) than the water. This occurs because of the surface tension that is created by the water molecules. Cohesion and surface tension keep the water molecules intact and the item floating on the top. It is even possible to “float” a steel needle on top of a glass of water if you place it gently, without breaking the surface tension. Figure 2.10 The weight of a needle on top of water pulls the surface tension downward; at the same time, the surface tension of the water is pulling it up, suspending the needle on the surface of the water and keeping it from sinking. Notice the indentation in the water around the needle. These cohesive forces are also related to the water’s property of adhesion , or the attraction between water molecules and other molecules. This is observed when water “climbs” up a straw placed in a glass of water. You will notice that the water appears to be higher on the sides of the straw than in the middle. This is because the water molecules are attracted to the straw and therefore adhere to it. Cohesive and adhesive forces are important for sustaining life. For example, because of these forces, water can flow up from the roots to the tops of plants to feed the plant. Concept in Action To learn more about water, visit the U.S. Geological Survey Water Science for Schools: All About Water! website. Buffers, pH, Acids, and Bases The pH of a solution is a measure of its acidity or alkalinity. You have probably used litmus paper , paper that has been treated with a natural water-soluble dye so it can be used as a pH indicator, to test how much acid or base (alkalinity) exists in a solution. You might have even used some to make sure the water in an outdoor swimming pool is properly treated. In both cases, this pH test measures the amount of hydrogen ions that exists in a given solution. High concentrations of hydrogen ions yield a low pH, whereas low levels of hydrogen ions result in a high pH. The overall concentration of hydrogen ions is inversely related to its pH and can be measured on the pH scale (Figure 2.11). Therefore, the more hydrogen ions present, the lower the pH; conversely, the fewer hydrogen ions, the higher the pH. The pH scale ranges from 0 to 14. A change of one unit on the pH scale represents a change in the concentration of hydrogen ions by a factor of 10, a change in two units represents a change in the concentration of hydrogen ions by a factor of 100. Thus, small changes in pH represent large changes in the concentrations of hydrogen ions. Pure water is neutral. It is neither acidic nor basic, and has a pH of 7.0. Anything below 7.0 (ranging from 0.0 to 6.9) is acidic, and anything above 7.0 (from 7.1 to 14.0) is alkaline. The blood in your veins is slightly alkaline (pH = 7.4). The environment in your stomach is highly acidic (pH = 1 to 2). Orange juice is mildly acidic (pH = approximately 3.5), whereas baking soda is basic (pH = 9.0). Figure 2.11 The pH scale measures the amount of hydrogen ions (H+) in a substance. Acids are substances that provide hydrogen ions (H + ) and lower pH, whereas bases provide hydroxide ions (OH – ) and raise pH. The stronger the acid, the more readily it donates H + . For example, hydrochloric acid and lemon juice are very acidic and readily give up H + when added to water. Conversely, bases are those substances that readily donate OH – . The OH – ions combine with H + to produce water, which raises a substance’s pH. Sodium hydroxide and many household cleaners are very alkaline and give up OH – rapidly when placed in water, thereby raising the pH. Most cells in our bodies operate within a very narrow window of the pH scale, typically ranging only from 7.2 to 7.6. If the pH of the body is outside of this range, the respiratory system malfunctions, as do other organs in the body. Cells no longer function properly, and proteins will break down. Deviation outside of the pH range can induce coma or even cause death. So how is it that we can ingest or inhale acidic or basic substances and not die? Buffers are the key. Buffers readily absorb excess H + or OH – , keeping the pH of the body carefully maintained in the aforementioned narrow range. Carbon dioxide is part of a prominent buffer system in the human body; it keeps the pH within the proper range. This buffer system involves carbonic acid (H 2 CO 3 ) and bicarbonate (HCO 3 – ) anion. If too much H + enters the body, bicarbonate will combine with the H + to create carbonic acid and limit the decrease in pH. Likewise, if too much OH – is introduced into the system, carbonic acid will rapidly dissociate into bicarbonate and H + ions. The H + ions can combine with the OH – ions, limiting the increase in pH. While carbonic acid is an important product in this reaction, its presence is fleeting because the carbonic acid is released from the body as carbon dioxide gas each time we breathe. Without this buffer system, the pH in our bodies would fluctuate too much and we would fail to survive. Section Summary Water has many properties that are critical to maintaining life. It is polar, allowing for the formation of hydrogen bonds, which allow ions and other polar molecules to dissolve in water. Therefore, water is an excellent solvent. The hydrogen bonds between water molecules give water the ability to hold heat better than many other substances. As the temperature rises, the hydrogen bonds between water continually break and reform, allowing for the overall temperature to remain stable, although increased energy is added to the system. Water’s cohesive forces allow for the property of surface tension. All of these unique properties of water are important in the chemistry of living organisms. The pH of a solution is a measure of the concentration of hydrogen ions in the solution. A solution with a high number of hydrogen ions is acidic and has a low pH value. A solution with a high number of hydroxide ions is basic and has a high pH value. The pH scale ranges from 0 to 14, with a pH of 7 being neutral. Buffers are solutions that moderate pH changes when an acid or base is added to the buffer system. Buffers are important in biological systems because of their ability to maintain constant pH conditions. Glossary acid: a substance that donates hydrogen ions and therefore lowers pH adhesion: the attraction between water molecules and molecules of a different substance base: a substance that absorbs hydrogen ions and therefore raises pH buffer: a solution that resists a change in pH by absorbing or releasing hydrogen or hydroxide ions cohesion: the intermolecular forces between water molecules caused by the polar nature of water; creates surface tension evaporation: the release of water molecules from liquid water to form water vapor hydrophilic: describes a substance that dissolves in water; water-loving hydrophobic: describes a substance that does not dissolve in water; water-fearing litmus paper: filter paper that has been treated with a natural water-soluble dye so it can be used as a pH indicator pH scale: a scale ranging from 0 to 14 that measures the approximate concentration of hydrogen ions of a substance solvent: a substance capable of dissolving another substance surface tension: the cohesive force at the surface of a body of liquid that prevents the molecules from separating temperature: a measure of molecular motion References Humphrey, W., Dalke, A. and Schulten, K., “VMD—Visual Molecular Dynamics”, J. Molec. Graphics , 1996, vol. 14, pp. 33-38. Media Attribution Figure 2.7 by Gautam Dogra Figure 2.8 ice lattice by Jane Whitney (b) by Carlos Ponte Figure 2.10 by Cory Zanker Figure 2.11 by Edward Stevens 5 2.3 Biological Molecules \n",
      "-----------\n",
      "Describe the properties of water that are critical to maintaining life\n",
      "--------------------------\n",
      "Figure 13.1 Plano del Archipielago de Clayocuat 1791 by Pfly is in the public domain . 117 13.2 Aboriginal Societies in the 18th Century Figure 13.2 For two years after his death, Haida leader Skowl’s body lay in state, surrounded by evidence of his wealth, including coppers (shields) and his slaves. (Photo by Albert P. Niblack, 1883) Simon Fraser’s arrival at Camchin (Lytton), at the confluence of the Thompson and Fraser Rivers was foretold. Among the Nlaka’pamux around the end of the 18th century there was a prophecy that foreigners would arrive from the east — although in some respects, they had already arrived. The Proto-Contact Years The fur trade on the Plains and the intrusion of Spanish goods — including horses — impacted Aboriginal peoples in the northern reaches of the Columbia basin (the Okanagan and Thompson Valleys) and in the Kootenay valleys. Knowing this, it is possible — indeed, probable — that smallpox arrived in the Cordillera long before the first European appeared. Epidemics in the 1730s and 1760s could have been passed along trade or raid routes, especially once so many of the neighbours to the south and east were able to travel on horseback. The 1780s smallpox epidemic definitely made an appearance. And when Fraser arrived in 1808 he found evidence of European trade commodities among the Nlaka’pamux, proof that there was no such thing as total isolation in this region. It remains uncertain as to when the proto-contact period precisely began in the Interior of what is now British Columbia, but we can be confident that the world encountered by Euro-North Americans from the 1770s on was one undergoing great change. Notwithstanding the proto-contact experience, Aboriginal societies in the Pacific Northwest enjoyed prolonged isolation from the European invasion taking place in Mexico, the Mississippi, the parklands of the North, and the eastern woodlands. From 1500 to the 1740s, indigenous cultures and populations continued to thrive. There is nothing in the written, oral, archaeological, or geological record to suggest any catastophes to rival the volcanic explosions of about 2,000 and 1,000 years earlier; nothing that would force a massive migration wave. (It is the case, to be sure, that seismic issues are a fact of life in the region. One local traditional understanding of their cause conveys a very usable image of what contemporary science believes occurs: “According to the Nuxalk … a giant supernatural being held the earth in ropes. When he adjusted his grip, or when the rope slipped in his hands, the Nuxalk could feel the tremors and performed a ceremonial earthquake dance.”) William J. Turkel, The Archive of Place: Unearthing the Pasts of the Chilcotin Plateau (Vancouver: UBC Press, 2007), 122. The southward movement of Athabaskan speakers appears to have been complete by 1400. After this time the pattern of culture groups seems to have coalesced into the form that enters the European record from the 1740s on. There are three culture areas in what is now British Columbia: Subarctic, Northwest Coast, and Interior Plateau. Each of these extends beyond the province’s boundaries to, respectively, the East and North, the Columbia Basin, and from California to Alaska. Each group made use of winter villages, which tended to be larger concentrations of population that combined food and fuel resources to make it through the season. Most, too, had summer villages or summer ranges where resources of all kinds would be gathered or harvested. This pattern implies the regular migration of significant numbers of people to sites of economic and cultural importance. A large range of land- and seascapes could be utilized without establishing permanence in any of them. Even the huge cedar longhouses that are the trademark of coastal cultures could be dismantled almost entirely and the heavy planks floated to another site. Records from the contact era of what appear to be abandoned villages continue to provoke debate among scholars and in the courtroom: were they truly abandoned, just swapped out temporarily for a second location, or ruined by war and/or disease? Figure 13.3 Despite efforts to rehouse Aboriginal people in Euro-Canadian structures, longhouses were still be built in the 20th century. This one is under construction in the Vancouver area around 1912. Village Cultures The longhouse was a defining feature of Aboriginal coastal life. Great numbers of people associated with distinct clans occupied these buildings that could be the size of a modern football field. As storehouses, homes, and theatres for celebrations and performances, longhouses were among the largest and grandest structures in North America into the 19th century. The Northwest Coast culture developed along stratified, hierarchical lines that included a nobility, a commoner class, and slaves; their relative status was reflected in their living space in the longhouse. The complexity and sophistication of longhouse decoration was also important. Population health and size was almost guaranteed by the wealth of food sources available along the coast — including whales on the west coast of Vancouver Island. Over time, large and prosperous populations developed a culture reflected in arts, sculpture, dance, storytelling, and specialized roles in hunting, fishing, and warfare. Village populations often grew to be more than 1,000 people, and the larger ethnic zones might include 10,000 to 20,000 individuals. Opitsaht in 1792 was said to contain “200  houses, generally well built” with an estimated population of 2,500. John Boit,1792, quoted in George Woodcock, British Columbia: A History of the Province (Vancouver: Douglas &amp; McIntyre, 1990), 57; Daniel W. Clayton, Islands of Truth: The Imperial Fashioning of Vancouver Island (Vancouver: UBC Press, 2000), 132. Figure 13.4 This ‘Nak’waxda’xw woman’s abalone earrings and inscribed metal bracelets mark her as a member of the Kwakwaka’wakw nobility. Photo by Edward Curtis, ca. 1910. Subarctic culture groups were much smaller and tended toward an egalitarian model. Families constituted the basic social unit and the favourable seasons were devoted to a wide-ranging hunting-gathering routine. Recent research has demonstrated that Subarctic peoples also engaged in horticulture, refashioning the landscape with fire to encourage the growth of berry patches and roots. Interior Plateau peoples focused on riverine resources, particularly the salmon runs. In the winter, they lived in the kekuli or pithouse. Populations were never as high as those on the coast, but winter villages were substantial and numbers were higher than among the Subarctic peoples. Access to the Columbia River system put this group into closer contact with peoples of the Plains tradition and with cultures deep in the American southwest. Trade across these three culture regions was extensive and regular, and they shared both linguistic and political connections: Interior peoples like the Nlaka’pamux had connections with Stó:lō peoples in the lower Fraser Valley, commercial and military alliances that were facilitated by their common language group (Salishan). In other instances, common language was no more a guarantee against rivalry than being part of the Iroquoian language pool protected the Wendat from the Haudenosaunee. And alliances crossed lingustic and culture zones: the Tsilhqot’in (Athabaskan speakers) and the Nuxalk (Salishan speakers) brought together Northwest Coast, Subarctic, and Interior Plateau traditions when they gathered for trade and support. Robert J. Muckle, The First Nations of British Columbia (Vancouver: UBC Press, 1998), 32-7. Figure 13.5 Stó:lō men dip netting for salmon on the Fraser River. Prime locations for fishing like this were the property of lineages to use and share as they liked. What marks the region as a whole is diversity of peoples and languages and a similarity of economies and food traditions. Almost everyone harvested salmon from the rivers and hunted for large land mammals. And everyone traded. On the coast in particular the accumulation of wealth was especially important because it served the ceremony known as the potlatch . Principally, the potlatch involved gift-giving to mark a key event, such as a succession, a coming of age, or a political anniversary. The scale of the gift-giving — the magnitude of generosity and hospitality — reflected the status of the host. These events also served as a means to announce changes or events of some importance, and the guests as recipients of gifts would be expected to bear witness. The potlatch was also a means of redistributing wealth. When the salmon runs were strong (at least once every four years), canyon peoples built up substantial surpluses; when the runs failed, as they did from time to time, coastal peoples were better positioned. Potlatching in this context was a kind of mutual support system. A useful discussion of potlatching can be found in Turkel, The Archive of Place , 131. Figure 13.6 A 19th century potlatch “Speaker Figure.” An announcer would have stood behind the figure, calling out the names of guests through the mouth. The Contact Era The arrival of the trans-Pacific sea otter trade, which opened up the West Coast to intercontinental commerce, had a significant impact on Aboriginal societies, not least of which was the introduction of exotic diseases. Although most if not all of these nations were impacted by smallpox (beginning probably in the 1780s, perhaps earlier), the magnitude of the mortality is both unknown and likely uneven. In some cases it was disastrous. (The Sinixt people of the Arrow Lakes are thought to have been reduced by 80% in the 1781 smallpox epidemic, for example.) As well, recovery rates are completely a mystery. Further and cataclysmic epidemics occurred in the 1830s and the 1860s, some of which are considered later in this chapter. Scholars, Aboriginal peoples, and the courts debate the probable pre-contact numbers west of the Rockies. Some estimates are modest, ranging from 80,000 to 100,000. Others are as high as 350,000, and there are outlier estimates in excess of 1 million. The matter is complicated by eyewitness accounts like those of George Vancouver, who saw abandoned villages, half disassembled, and assumed they indicated a disaster involving loss of life. But the business of seasonal movements between village and resource sites can account for some of the empty lands that were reported. Archaeological research has yet to provide a reliable means of estimating the pre-contact numbers. Nor can we be sure when smallpox first struck, partly because it doesn’t leave a “fingerprint” on the victim the way some skeletal diseases or bone trauma from combat might. What we know for sure is that wherever Europeans went on the coast, they reported the existence of large villages with equally impressive longhouses. Communities may have been farther apart in the Interior, but some were, according to NWC reports, nodes of 1,000 or more. We can also be confident that, given what we know about virgin soil diseases, those well-developed village communities with their high densities and even the kekuli pits of the Interior were a good environment for highly contagious diseases to thrive in. Around 1860 there were maybe 80,000 Aboriginal peoples in the region; not only did they outnumber the newcomers, they outnumbered all the other Aboriginal peoples in British North America combined. Their number at the time of contact could only have been larger. These numbers and the complexity of the Aboriginal world west of the Rockies would insulate indigenous cultures from externally imposed change for a while. Historians disagree on this point, but it is safe to say that much of the cultural change that occurred along the Pacific Northwest coast until the 1840s was controlled mainly by the Aboriginal peoples and not by the Europeans. Key Points Aboriginal societies west of the Rockies faced little to no direct exposure to Europeans prior to the 1740s. Indigenous cultures can be grouped into three broad categories: Subarctic, Northwest Coast, and Interior Plateau. While each share some common features, there are important distinctions as well. Trade between Aboriginal communities and nations was extensive both in terms of the distances travelled and the commodities exchanged. The potlatch is an important feature of the regional economy, political and social order, and wider cultural life on the West Coast, into which newcomer goods fit very well. Populations west of the Rockies and especially on the northwest coast were larger than anywhere else in North America. Figure 13.2 Haida by Albert P. Niblack is from the Canadian Museum of History and cannot be used for commercial purposes. Figure 13.3 Interior of longhouse under construction by Matthews, James Skitt, Major is in the public domain . This image is available from City of Vancouver Archives under item: In P105.2. Figure 13.4 Nakoaktok by Para is in the public domain . Figure 13.5 Stolo with dipnets by Themightyquill is in the public domain . Figure 13.6 Speaker Figure, 19th century was uploaded as a donation by the Brooklyn Museum , and is considered to have no known copyright restrictions by the institutions of the Brooklyn Museum. 118 13.3 Fur Trade and Empires Figure 13.7 This unflattering depiction of a sea otter comes from James Cook’s account, A Voyage to the Pacific Ocean (1776). (Attributed to S. Smith, after John Webber.) The Russians The catalyst for European interest in the Pacific Northwest in the 18th century was Russian exploration. The Sv. Petr , under the command of Vitus Bering (1681-1741) arrived in the Aleutian Islands in 1741 as part of an exploratory expedition. The ship was wrecked, Bering died, and just enough of his crew survived to get home in a makeshift boat cobbled together from what was left of the Sv. Petr. They went back with sufficient sea otter pelts to win a small fortune. Russian entrepreneurs and shipowners were soon following in Bering’s path. Enslaving much of the indigenous Aleut (a.k.a. Unangan) population and terrorizing much of the rest, the Russian traders established a presence that eventually stretched south to California. These events occurred against a backdrop of growing Russian expansionism. Under Elizabeth of Russia and her successor, Catherine the Great, Russia’s imperial ambitions and aggressive posture grew. All this alarmed the Spanish (see below), who first heard of the move into Alaska in the imperial Russian court. Bering and his successors may have had the blessings of the empresses, but they also faced great challenges, the first of which was supply lines. The huge cost of running their operation out of Okhotsk limited the Russians, which is one reason why they were largely uninterested in settlement until the 1780s and 1790s. The agricultural potential of Alaska, with its short growing season, was another impediment to self-sufficiency. The Russians faced further disadvantages in the marketplace. They were denied access to Guangzhou and had to carry their pelts across Siberia to Kyakhta, south of Lake Baikal, where they could cross the border into China. This added further costs. James R. Gibson, \"Bostonians and Muscovites on the Northwest Coast, 1788-1841,\" in British Columbia: Historical Readings, eds. W. Peter Ward and Robert A. J. McDonald (Vancouver: Douglas &amp; McIntyre, 1981), 70. Figure 13.8 Aleut (Unangan) seal hunter off the Alaskan coast, as painted by the Ukrainian artist, Louis Choris, ca. 1815-18. Some of the competitive elements of the Russian trade began to consolidate by the 1780s. In 1799 Czar Paul I decreed a Russian-American border at 55°N (near the southern limit of the Alaskan panhandle) and chartered a joint stock company to take monopolistic control of the fur trade: the Russian American Company (RAC). Almost immediately the company’s chief manager, Alexander Andreyevich Baranov (1746-1819), adopted a policy of contracting out to American ships in the region. In 1803 two Russians and some 40 Aleuts and Alutiiq otter hunters sailed to Baja California on board an American ship. Over the next decade, it is believed that tens of thousands of otters were captured along the California coast by Alaskan Aboriginals in the employ of — or, more typically, enslaved by — the RAC and working from American ships. The first permanent Russian (and thus the first European) settlement in Alaska was established at Novo-Arkhangelsk (New Archangel, or Sitka) in 1804, which hardened Russian claims to the territory. As well, in 1812 the Russians were able to leapfrog their British and American competition and establish Fort Ross (a.k.a. Fortress Ross) in what is now northern California. All of these events coloured the Russians as something of a wildcard on the coast: the vulnerabilities to RAC’s supply line sustained independent and sometimes reckless traders; Russian relations with the Lingít (Tlingit) were terrible and poisoned Aboriginal-newcomer relations south of the panhandle; and the Russians never entirely lost sight of the possibility of a Californian colony — Fort Ross remained in Russian hands until 1841. Figure 13.9 Old Sitka, ca. 1827. The most heavily fortified trading establishment on the northwest coast reflects the poor relations its Russian occupants had with Tlingit neighbours. The Spanish In 1774 a Spanish naval expedition under Juan Pérez (ca. 1725-1775) worked its way north from California in an effort to assess the threat posed by the Russian presence in Alaska. According to the Treaty of Tordesillas (1494), the whole of the West Coast was Spain’s to lose. The Portuguese honoured the treaty but the rest of Europe did not. Nor did the Aboriginal people of the northwest coast. And why should they? Spain had not ventured north of California, apart from the disputed 1592 voyage of Juan de Fuca in search of the legendary Strait of Anian. Word of the Russian intrusion worried the Spanish sufficiently that in 1767 they established a naval station at San Blas and posts at San Diego and San Francisco two years later. Five years after that, the Spanish mustered Perez’s small expedition to chart and claim the North Pacific. Although the Spanish made their way as far north as Alaska and erected a cross there, they made no other landfall north of what is now Washington State. The Spanish were satisfied that there was no Russian presence between Mexico and 57°N. A second expedition set out in 1779 under the Peruvian-born Juan Francisco Bodega y Quadra (1744-1794), sailing north again to Alaska. On this occasion the Spanish were looking for the outlet of a “northwest passage” that would lead to the Arctic Ocean or perhaps to the Saskatchewan or the Missouri Rivers. They sailed to 61°N and went ashore to ritually claim the territory, then returned home, assuming the job was done and that they could now relax or at least focus on the freshly announced war with Britain. Having run up the flag on the northwest coast in 1774 and 1779, the Spanish were surprised to find they needed to monitor and perhaps defend their position, though not, as they might have expected, against Russia. Britain’s appearance in 1778 in the form of James Cook’s third expedition alerted the Spanish to the need to establish a fixed position on the north coast. In 1788 a pair of Spanish ships made another voyage to Alaska, this time finding the Russians and discovering that they had plans to establish a post on Nootka Sound in the territory of the Mowachaht. Returning to Mexico, the Spanish launched yet another expedition, intent on claiming Nootka Sound for their own. When they arrived they found two American ships and one British; the Spanish banished the latter and then seized the North West America, a vessel owned by the British independent trader, John Meares, and built on Nootka Sound by a crew of Chinese workers brought to Yuquot by Meares — the first Chinese arrivals in British Columbia. The Spanish put the Chinese to work building Fort San Miguel, thereby creating a physical statement of sovereignty. These aggressive efforts to assert Spanish sovereignty provoked what became known as the Nootka Crisis , which began in 1789 and lasted five years. In terms of developing Aboriginal-European interaction, the Spanish had one advantage over their contemporaries: they alone of the European and North American visitors to the North Pacific had an interest in territory first and commercial ventures second. Once the British were disabused of the existence of a northwest passage their only concern was furs. The same was true, only more so, of the Russians and Americans. In contrast, Bodega y Quadra was looking at the long term, and therefore thinking about building lasting relationships with the Aboriginal people. This was what he hoped to do at Fort Miguel in 1791-93. Bodega y Quadra was, by all accounts — and certainly by George Vancouver’s account — charming, curious, and smart. The leading figure among the Mowachat, Maquinna (ca. 1795), was particularly impressed with Bodega y Quadra’s ability to assimilate local customs and to show respect to the local leaders. And Bodega y Quadra’s reports on matters in Nootka Sound from 1790 to 1793 were insightful. These include his belief that Euro-American traders cynically stirred up trouble in order to improve the market for guns and ammunition; that syphilis was spreading unchecked from British and American ships to the indigenous population; that traders from abroad were never above plundering the Nuu-chah-nulth villages if they didn’t get what they wanted under terms that they wanted; and that the European responses to minor thefts or single murders by the Aboriginal population was typically a violent overreaction. Bodega y Quadra spent two years repairing relations after Callicum, one of the Nuu-chah-nulth leaders and a close relation of Maquinna, was shot dead by the Spanish (under circumstances that remain unclear). Figure 13.10 A contemporary engraving shows Callicum and Maquinna greeting one another. Callicum’s murder at the hands of the Spanish nearly revived the European nation’s 300-year old reputation for brutality in its relations with indigenous peoples. Like the Russians, the Spanish operated under several important disadvantages. While they could trade into Chinese seaports (unlike the Russians) their objective was to obtain Asian mercury  to support their gold and silver processing operations in Mexico. The sea otter trade was, for the British, Americans, and Russians, about selling cheaply acquired pelts and obtaining highly desirable Chinese products — tea, silk, porcelain — for sale at a further profit in Europe. For the Spanish, it was about enhancing gold production in Mexico. The “Mercury Fleet,” as it was known, from Europe, however, could deliver materials more cheaply than the Spanish could in the Pacific. As well, the Spanish could hardly muster sufficient resources to blast British, American, and Russian competition off the coast. For that reason, and because they sensed that Mexico’s security might be compromised by Britain and/or America, they retreated. Christon I. Archer, “The Transient Presence: A Re-appraisal of Spanish Attitudes Toward the Northwest Coast in the Eighteenth Century,” in British Columbia: Historical Readings, eds. W. Peter Ward and Robert A. J. McDonald (Vancouver: Douglas &amp; McIntyre, 1981), 37-65. As one historian has put it, The Spanish regime lacked the motivation or the population to maintain its sovereign claims to the coastline and ocean north of California. Other than the northwest coast Natives sent to Mexico and perhaps a few mestizos born at Nootka Sound, the Spanish efforts left little impact upon the Native societies. […] Even before [the last of the Spanish and British ships left Yuquot in 1795], Maquinna’s people were hard at work erecting house posts for their summer village. Christon I. Archer, “Seduction before Sovereignty: Spanish Efforts to Manipulate the Natives in Their Claims to the Northwest Coast,” in From Maps to Metaphors: The Pacific World of George Vancouver , eds. Robin Fisher and Hugh Johnston (Vancouver: UBC Press, 1993), 159. Figure 13.11 Fort San Miguel at Yuquot, 1793. The Nuu-chah-nulth would continue to trade with Europeans for decades, but they did not permit the outsiders to re-establish themselves anywhere on their coast. Fort San Miguel would be the last European toehold on Vancouver Island until the 1840s. The British European claims to a territory could have the most tenuous foundation. In 1577 Sir Francis Drake (1540-1596) sailed from Plymouth Harbour in England with orders from Queen Elizabeth I to terrorize and pillage the Spanish gold fleet in the Pacific Ocean. The mission evolved into England’s first circumnavigation of the globe but, more importantly for the history of the Pacific Northwest, it allowed Britain to lay claim to lands north of Mexico. Drake’s account puts him just north of San Francisco Bay in 1579, which he named Nova Albion (New Albion). Scholars continue to debate whether Drake ventured farther north, but this 16th century interlude was the basis on which Britain built its claim 200 years later. When he mapped a place on the northwest coast in the 1790s, Captain George Vancouver’s notations would include the phrase “from that part of New Albion.” Cole Harris, The Resettlement of British Columbia: Essays on Colonialism and Geographical Change (Vancouver: UBC Press, 1997), 31. In 1774, James Cook (1728-1779) led a British expedition into the Pacific Northwest. Cook’s ships rounded South Africa, Australia, and New Zealand, set out for Hawaii, then reached the Americas at Alta California. Sailing north, he narrowly missed both the Columbia River and Juan de Fuca Strait but found his way to Yuquot (Friendly Cove). Cook spent a month there enjoying the hospitality of the Nuu-chah-nulth and becoming acquainted with their self-confident and sharp trading practices. The people of Yuquot and Tahsis weren’t satisfied with the cheaper goods that had been traded with the Hawaiians, and they controlled the terms of trade throughout. When they were done, Cook’s two vessels continued north and successfully rounded the North Pacific before heading back to Hawaii, where the captain was killed by the locals. The Resolution and the Discovery continued the voyage home, stopping in Guangzhou (Canton). There they discovered what the Russians already knew: the sea otter pelt market in China was extremely lucrative. British and American interest in the region was thereafter stimulated. Robin Fisher, Contact and Conflict: Indian-European Relations, 1774-1890 , 2nd ed. (Vancouver: UBC Press, 1992), 1-23. Figure 13.12 The launch of the North West America at Nootka Sound shows Europeans (presumably John Meares) and Aboriginal observers, but the Chinese labourers who built the ship are conspicuous by their absence. Cook’s voyages provoked the Spanish to press their regional claims. The British pressed right back. The two countries nearly went to war over the question of whose claim was the stronger. Captain George Vancouver (1757-1798), was the British representative on the scene at Yuquot; Juan Francisco de la Bodega y Quadra represented the Spanish. Various accounts of this meeting have been written, at least one fictionalizing the encounter. What they have in common is Vancouver’s moodiness and obstinance compared with Bodega y Quadra’s smoothly seductive hospitality. Events in Europe were to overtake them: in 1792 the French Revolution was threatening to spread beyond the borders of France, and the Spanish decided to sacrifice their northwest coast claim in exchange for British goodwill. As a result, the British gained nominal control of everything between Alta California and Russian Alaska. The negotiators at Yuquot agreed to mark the event by naming the island after themselves. For many years it appeared on European and American maps as “Bodega y Quadra and Vancouver’s Island” (shortened later to Vancouver’s Island, and finally Vancouver Island). In the Navy James Cook and his contemporaries were some of the most remarkable cartographers of all time. Their maps are still reliable today, and Cook’s 1760s maps of Newfoundland were the gold standard into the 20th century. Their careers intersect with the stories of British North America, Australia, New Zealand, and Hawaii. Cook was at Louisbourg when it fell in 1755 and commanded a ship under Wolfe at the Battle of Quebec four years later. George Vancouver joined the Royal Navy at 13 and served with Cook from the age of 14. William Bligh was only seven when he was signed up with the navy and his career would see more than the usual amount of drama. Cook once declared that his goal was to go “farther than any man has been before me, but as far as I think it is possible for a man to go.” Both Vancouver and Bligh had a chance to study under Cook and were with him on the last of his three voyages. They all kept their pencils pressed against map paper constantly. They were together on the Resolution in Hawaii when Cook made the fatal choice to go ashore one time too many. Vancouver’s career was just starting. He was barely 20 years old when he was given command of the Discovery, a four-year mission to explore the Pacific in greater detail, and a mandate to settle the practical terms of the Nootka Convention. Along with two Spanish captains, Dionisio Alcalá Galiano and Cayetano Valdés y Flores, he charted the Strait of Georgia (the Salish Sea) and passed within sight of the peninsula on which the city bearing his name was later built. Bligh, for his part, has an island bearing his name in Nootka Sound. He would take command of the Bounty in 1787, a ship irretrievably associated with mutiny. Having sovereignty on paper, however, did nothing to enhance the British position. They continued to engage in trade, but that didn’t stop others parties from arriving on the coast. Like Quadra, Vancouver had little use for the travelling fur traders, particularly those who were selling guns. He regarded their tactics as deplorable and wrote to his superiors: I am extremely concerned to be compelled to state here, that many of the traders from the civilised world have not only pursued a line of conduct, diametrically opposite to the true principles of justice in their commercial dealings, but have fomented discords, and stirred up contentions, between the different tribes, in order to increase the demand for these destructive engines… They have been likewise eager to instruct the natives in the use of European arms of all descriptions…. George Vancouver, A Voyage of Discovery to the North Pacific Ocean, and Round the World: In which the Coast of North-west America Has Been Carefully Examined and Accurately Surveyed : Undertaken by His Majesty's Command, Principally with a View to Ascertain the Existence of Any Navigable Communication Between the North Pacific and North Atlantic Oceans, and Performed in the Years 1790, 1791, 1792, 1793, 1794, and 1795, in the Discovery Sloop of War, and Armed Tender Chatham, Under the Command of Captain George Vancouver : in Three Volumes, Vol.2 (London: G.G. &amp; J. Robinson, 1798), 364. In terms of imperial diplomacy, the British had come out ahead, but the Americans (see below) had the whip in hand when it came to trade. The British would have to change their strategy dramatically and the incentive to do so would come from Canada. By 1830 British traders were back in the game, supported by forts on the Columbia River and at Langley. It would be another 10 years before they could claim real regional domination over the other intruder traders. Authority over the Aboriginal population would take longer still. James R. Gibson, Otter Skins, Boston Ships, and China Goods: The Maritime Fur trade of the Northwest Coast, 1785-1841 (Montreal &amp; Kingston: McGill-Queen’s University Press, 1992), table 1, pp.299-310. The Americans Even as the American Revolution was raging it was clear to shipowners in East Coast ports that their access to British markets might be in danger. Britain took steps to prohibit American access to the West Indies market, a move that favoured the new British North American colonies and that left American ship captains looking farther afield. Necessity took them out of the North Atlantic and into the Mediterranean and North Africa, down the east coast of South America and round Cape Horn into the Pacific. It found them trading in the South China Sea and, almost inevitably, along the northwest coast. Figure 13.13 “Winter Quarters.” by George Davidson (ca. 1793), depicts the American Captain Robert Gray and the crew of the Columbia Rediviva on Clayoquot Sound. There were two aspects to the American trade in the region. The first was its maritime face. The Americans put more ships into the region than any other nation. Although British ships dominated from 1785 to 1792, they were increasingly competing with American vessels (one-to-one in 1791 and 1792), as well as the occasional French or Portuguese ship. In the two decades that followed, the British presence slipped well behind that of the Americans. In 1801 more than 20 American vessels found their way to the Pacific Northwest; in the same year only three British ships and one Russian ship were in the area. Soon the British were down to one ship a year, although it was usually the same ship making repeat visits. The American fleet, by contrast, was made up of competing traders; often their name appears only once in the register. Continuity was an issue because one-timers tended to behave in ways that were not necessarily in the best interest of long-term trade relations. The sales of guns and alcohol were a particular problem. Ibid. In short, as far as the maritime trade was concerned, the Americans had the edge. It was, however, an uncoordinated edge. The independent ships from Boston and other New England ports had no imperial mandate, nor were they acting on behalf of the new republic. Later American claims to the territory might invoke some of the earliest expeditions in the region, but the fur trade fleets were of little value in this regard. The land-based trade posed different advantages and liabilities. John Jacob Astor (1763-1848), a German immigrant to the United States who saw an opportunity in shipping Canadian furs through New York to Europe in the 1790s, amassed a substantial fortune in just a few years and was eager to involve himself more directly in the fur trade. He developed a multi-pronged strategy, one part of which was the Pacific Fur Company (PFC) and the prospect of a fort on the Columbia River, which he named for himself. Astor’s company seemed fated from the outset. The Tonquin disaster (see section 13.7 Identity Crisis ) was the worst of it, but another of the PFC’s ships proved to be not seaworthy, a third was badly beat up by a storm, and a fourth was wrecked off the coast of Maui. One study estimates that the PFC lost 61 men in less than two years. The trade conducted from Fort Astor was negligible. Astor’s own employees were quickly turning against him, and war had broken out between the Americans and the British in North America. Richard Mackie, Trading Beyond the Mountains: The British Fur Trade on the Pacific, 1793-1843 (Vancouver, UBC Press, 1997), 15-16. A quick sale to the NWC in 1813 was the outcome. One legacy of Astor’s expeditions was picked up by several American traders — that of provisioning other fur trading outposts, regardless of who owned them. The cost of establishing, maintaining, and provisioning a trading post in the region was all but prohibitive, but American suppliers offered a solution. Every post in the Pacific Northwest at some point took advantage of the opportunity to restock with American goods, even though doing so was essentially underwriting the costs of the competition. Severing this link between American suppliers and the Russian traders in particular was key to British success in the region, but that goal was only achieved in the 1830s. Thereafter the prohibitively high costs of trade in the region combined with sharply declining sea otter stocks to reduce American shipping to no more than a couple of ships a year. Figure 13.14 A Russian stamp commemorates the 200th anniversary of the establishment of Fort Ross. The Imperial Coast At some point, Spain, Russia, Britain, and the United States all claimed the Pacific Northwest. Spain dropped its interests with the Nootka Convention of 1793. Russia’s RAC reinforced its positions from Sitka north and west, marking a boundary at 54’40″N latitude in agreements with the United States and Britain in 1824 and 1825 respectively.  American claims to the “Columbia Department” — which included New Caledonia (that is, most of modern British Columbia) along with the future states of Washington and Oregon — were to prove a problem in the 1840s, but otherwise American interest in the region was made up of individual merchant ships. British claims were based on prior discovery, exploration, and treaty rights. As is explored in the next section, the most important imperial agency was the Hudson’s Bay Company, which built on a foundation established by the NWC and engaged in active trade from the Lower Columbia River north to the Arctic Ocean.  From 1816 through to the 1840s, few Americans and Europeans settled in the region and it remained — for these outsiders at least — a venue for trade and they had aspirations to do little more. The Canadians were a different matter. Key Points European interest in the Pacific Northwest increased in the mid-18th century with the arrival of Russian sea otter traders in Alaska. Russian ambitions in the region included the establishment of permanent posts, subjugating much of the Native population and extending their reach to California. The Spanish were spurred into action in the northwest by the Russian presence and were far more interested in sovereignty than commerce. Nootka Sound (Mowachaht) was the intersection of commercial and diplomatic interests including the host Mowachaht/Nuu-chah-nulth people of Yuquot (Friendly Cove), the Spanish, the British, and nominally independent traders. The resolution of the Nootka Crisis gave Britain the pre-eminent European claim to Vancouver Island and the mainland coast from California to Alaska, but it would be nearly 40 years before they established a post in what is now British Columbia. American traders were the dominant force in the maritime fur trade into the 1830s and their supply lines sustained the Russian presence, making it difficult for the British to turn a profit. The American Pacific Fur Company was the first to establish a fixed presence on the mainland, at Fort Astoria, although this soon fell to the Canadians. The establishment of British forts from Fort Vancouver north to Fort Stikine was a response to the mobile American fur trade. Figure 13.7 Sea Otter by Trycatch is in the public domain . Figure 13.8 Choris, Saint Paul by Triggerhappy is in the public domain . Figure 13.9 1827 illustration of Castle Hill by File Upload Bot (Magnus Manske) is in the public domain . Figure 13.10 Callicum und Maquinna by Hans-Jürgen Hübner is in the public domain . Figure 13.11 Spanish fort San Miguel at Nootka in 1793 by Onofre Bouvila is in the public domain . Figure 13.12 The launch of the North West America at Nootka Sound by PawełMM is in the public domain . Figure 13.13 Columbia Winter Quarters by Pfly is in the public domain . Figure 13.14 Stamp of Russia 2012 No 1633 Fort Ross by Dmitry Ivanov is not an object of copyright. 119 13.4 The Canadian Cordillera David Thompson (1770-1857) is famous for two accomplishments: his work as an explorer and surveyor (which includes crossing the continent and descending the Columbia River to its mouth, as well as mapping a prodigious amount of North America) and for having the longest marriage on record in the history of pre-Confederation Canada (58 years). Thompson was raised in poverty in London, indentured to the HBC at 14 years, and spent much of the rest of his life in the fur trade. In 1797 he literally walked away from his job with the HBC, trudging 80 miles in the snow from one trading post to another where he took up work with the NWC. It was in his capacity as a surveyor for the Montrealers that he was dispatched to the far west in 1806 in order to block American plans to exploit the route mapped by Lewis and Clark, and to access the sea otter resources that had been enriching fur traders from other nations. Thompson arrived at the mouth of the Columbia on July 14, 1811, only to find Astor’s crew of Americans and defected Nor’westers already on the scene, building Fort Astoria. Their arrival preceded Thompson’s by a few months, but events in the east were to catch up with the Astorians. The War of 1812 would result in the loss of much of Astor’s operations in the Great Lakes and in the far west, to the benefit of the NWC. The NWC in the Interior The Montrealers purchased Astoria and its tributary posts in 1813 and changed the name to Fort George. They then renewed and extended a chain of forts up the Columbia with one branch heading east through the Arrow Lakes to the southern Prairies and the other through the Okanagan Valley to Tk’əmlúps (aka Kamloops), where they established Thompson Rivers Post in place of the PFC’s Fort Cumcloups. This early land-based fur trade was, thus, linked back to Canada and not to Britain. On the ground the NWC in the farthest west was mostly Canadien, not Canadian, with a large and growing share of Métis women as well. Regardless of its Laurentian links, it was very much a British claim nevertheless. One of Thompson’s contemporaries in the NWC, Simon Fraser (1776-1862), made a comparable assault on the far west in 1803-1808. Fraser came to Canada from New York as a child in the Loyalist diaspora, but he was conscious of his ancestral Scottish roots. While in the north he applied the name “ New Caledonia ” to the region, which later would have a broader use, covering much of what is now British Columbia. Before descending the river that now bears his name, Fraser’s expedition, made up of mostly Canadiens, Métis, and some Iroquois, established a chain of posts that included Fort St. James and Fort George (later Prince George). In 1808 the voyageurs took on the river, stopping briefly at Camchin (Lytton) where the Nlaka’pamux impressed them with their hospitality, their string of about 1,000 ponies, and a robust human population of roughly 1,200. Fraser and his crew carried on to near the mouth of the river where they irritated the Musqueam (a.k.a. Xwméthkwiyem or xʷməθkʷəy̓əm ), who chased them back up the river. Regardless of Fraser’s failure to complete his mission, he had laid the groundwork for the northern leg of a chain of forts that would complete the link between Fort George of the north and Fort George of the south (formerly Fort Astoria) and British North America. This was the setup that the HBC inherited in 1821. Fur trade society in New Caledonia and the Columbia District was consistent in many respects with personnel and practices east of the Rockies: Canadiens and Iroquois provided much of the muscle while direction was in the hands of a closely connected set of Anglo-Scots-Canadians and their métis or native wives. After the merger in 1821, the HBC’s structure made these distinctions even more apparent: the chief traders and factors were all drawn from the Anglo-Protestant side of the house while the voyageurs and traders were overwhelmingly Canadien, Métis, and Iroquois. Hierarchical social stations were reinforced through a dress code, the layout of the forts, and the size and state of employee accommodations. This sort of physical display of paternalistic rank was intended to impress upon the “servants” of the HBC their relative position; it was also ritualized in ways to impress the Aboriginal trading partners. The Interior posts were remarkably fragile. At the far end of supply lines originating in Montreal or perhaps even London, they were vulnerable to any number of events that might delay or prevent the arrival of food, gunpowder, clothing, and trade goods. Every one of the inland forts at some time or another depended heavily on local salmon fisheries, all of which were zealously controlled by Aboriginal peoples. And they were isolated from one another: boats could make it down the Columbia from the lower Okanagan (south of the 49th parallel) to the sea and canoe travel that was possible between Alexandria in the Cariboo to Stuart’s Lake in the north, but all of the rest required packhorses. Famine was common, as was the consequent eating of horses and dogs. Tina Loo, Making Law, Order and Authority in British Columbia, 1821-1871 (Toronto: University of Toronto Press, 1994), 28-9. According to one historian, New Caledonia (mainland British Columbia) was particularly despised for its “misery and privation” and “poverty of fare.” Chief Factor John Tod recalled that in HBC Governor George Simpson’s Day (1820-1860) the district was “looked on in the light of another Botany Bay Australia; the men were in dread of being send there.” Ibid. Fines, beatings, and jailings were part of life in the forts of the far west. Relations with the Aboriginal neighbours and trading partners were also often characterized by brutality. Cole Harris, The Resettlement of British Columbia: Essays on Colonialism and Geographical Change (Vancouver: UBC Press, 1997), 44. Obviously the Interior trade was not concerned with sea otters. Whatever was brought in at the Columbia River posts was part of the package sent northeast to Hudson Bay each spring, but beaver, wolf, wolverine, muskrat, and a great variety of other hides came from the inland posts. As for imported goods from European and Euro-North American sources, there was the usual stock of rifles and shot, blankets and axe heads. There was also a thriving trade in leather: whether for ecological reasons or due to overhunting, the Interior Plateau was home to few large mammals, so the import of moose, deer, elk, and bison hide was quickly regarded as essential. As one study states, “in the 1827-28 outfit year, New Caledonia required two thousand fathoms [3650 metres] of pack cords, seventy bounds of babiche [string], and thirty pounds of sinews.” James R. Gibson, The Lifeline of the Oregon Country: the Fraser- Columbia Brigade System, 1811-47 (Vancouver: UBC Press, 1997), 26. The HBC on the Coast The newly unified HBC after 1821 had growing concerns regarding the leakage of furs from the Interior to the coast, where they fetched higher prices. As well, the company under the leadership of George Simpson wanted to improve its position on the coastal market. So long as First Nations trading villages were prepared to wait for two or more competing vessels to arrive in port before initiating trade, they would be able to play off the newcomers against one another and drive up prices. American ships in particular were prepared to pay premium prices for furs, a practice that was hurting the HBC bottom line. The solution to this was the establishment of land-based trade in centres that would entail a shift from a maritime-based trade strategy. The HBC established regional headquarters at Fort Vancouver in 1824-25 and at Fort Langley among the Stó:lō and Kwantlen in 1827. Two successive forts, both named Fort Simpson, were erected in Ts’msyan territory in 1831 and 1834, Fort McLoughlin was built on Heiltsuk lands in 1833, and Fort Taku (a.k.a. Fort Durham) in 1830 and Fort Stikine in 1840 were both in Lingít (Tlingit) territory. The north coast posts were intended to provide a permanent trading presence in the hope that a deeper commitment to the locale, better intelligence on the marketplace and supply lines, and lowered costs (due to an end to wandering trading vessels) would result in higher profits. By the late 1830s the strategy was deemed a success. American shipping and competition in the region declined sharply. This had two collateral effects.  First, the Russians in Alaska were affected. The Lingít nation of what is often referred to as the Alaska panhandle resented Russian posts and resisted their presence in a long-running war. In the absence of friendly local suppliers and faced with intolerably long supply lines back to Russia, the Russian American Company purchased foodstuffs from American captains. Second, the Americans, for their part, could only afford to pay high prices for sea otter and beaver if their costs were covered by Russian purchases of groceries. James R. Gibson, \"Bostonians and Muscovites on the Northwest Coast, 1788-1841,\" in British Columbia: Historical Readings, eds. W. Peter Ward and Robert A.J. McDonald (Vancouver: Douglas &amp; McIntyre, 1981), 77. The new forts were intended to be self-sufficient and to produce a food surplus that could be sold to the Russian forts cheaply. This cut directly into the American coasters’ trade, removed them from the northwest coast equation, and made the Russians dependent on the HBC. Whatever the forts may or may not have become over time, the agenda of the HBC was never colonization. That was something forced upon them by the Colonial Office in the 1850s; the HBC was simply interested in business on the coast. However much fur trade society might have been evolving within the walls of the forts along the coast, there is no denying that they were little citadels. A description of Fort Simpson from 1850 provides a sense of the traders living uncomfortably in Aboriginal territory: The gates were massive structures about six or seven inches thick, studded with large nails, to guard against their being cut down by the natives. There were small doors within so as to admit only one person at a time…. The pickets surrounding the establishment were of cedar, about twenty-two feet long by nine to twelve inches thick; they were square internally, to prevent bullets from passing between…. An inside gallery ran around the whole enclosure of pickets at about four feet from the top, and afforded a capital promenade and a means of seeing everything…. A regular watch was kept all night in a small turret, surrounded by the flagstaff, over the gate. Captain David Wishart quoted in Daniel Clayton, \"Geographies of the Lower Skeena,\" in Home Truths: Highlights from BC History, eds. Richard Mackie and Graeme Wynn (Madeira Park: Harbour, 2012), 111. Fort Simpson was conceptualized by HBC Governor George Simpson as a means of starving out Russian and American traders in the region. Even if the returns on investment were not especially good, at least the furs traded at Lax Kw’alaams and from upcountry sources were not finding their way into the hands of competitors. Certainly the size of the traffic at the fort suggests the strategy was working: in 1841 roughly 14,000 Aboriginal people — mostly Ts’msyan but also Haida — came to Fort Simpson, and about 800 Ts’msyan formed the homeguard. Richard Mackie, Trading Beyond the Mountains: The British Fur Trade on the Pacific, 1793-1843 (Vancouver, UBC Press, 1997), 129. While Governor Simpson played a very direct role in choosing a direction for British trade on the coast, the day-to-day operations and initiatives came from officers, Canadiens, and Métis. These were the people who forged relationships with the local people, and whose marriages to indigenous women changed their circumstances. As Cole Harris points out, “As time went on, they learned Native languages and had kin in Native villages.” Cole Harris, The Resettlement of British Columbia: Essays on Colonialism and Geographical Change (Vancouver: UBC Press, 1997), 47. Fur trade society on the coast and in the Interior was invariably made up of women and men who had travelled across great distances, who had witnessed incredible landscapes and hardship, whose mothers may have spoken Cree, and whose fathers may have lived in stone houses in Montreal. The local women drawn into these relationships were often part of the local nobility and so came from backgrounds of some privilege. The company might object from time to time — after all, more marriages with Native women meant more profitless gift-giving to their families — but even Simpson perceived these arrangements as loss leaders, a cost that would be repaid with security and a guarantee of trade. Innovation and adaptation spread to business as well. Trade on the West Coast presented opportunities to handle different goods in different markets. Salmon, flour, and lumber were wanted in Hawaii and furs had markets in Guangzhou and London. The profits from the fur trade amassed in London and Montreal, not in the HBC’s trading posts on the Pacific; what they needed in return for their exports included sugar, molasses, tobacco, and salt in particular. Mackie, Trading Beyond the Mountains , 250-3. The sustainability of any of the northwest coast forts was a stretch until the 1840s, certainly were it not for the support of Aboriginal traders. An Account of Trading at Fort Simpson in the 1830s The Indians coming from distant parts to this fort, have large canoes, from thirty to fifty feet long.… Besides containing numerous Indians, their canoes are piled up with goods for barter. They remain mustered here for some weeks, making the fort a complete fair. It requires strict and good management, at this time, by the companies of officers, to protect the fort. On landing at the fort, their canoes are piled up in large heaps, covered over with mats, to keep the sun from cracking them. They bring provisions with them, to last during their stay and journey home. Feasts are given by the chiefs; and invitations sent regularly round to the different guests. Should any of the officers of the fort be invited, stools are placed by the side of the fire, covered over with cloth and fine calico; and they are introduced with great ceremony – the chiefs standing to receive them. Skins are given, as presents, to the officers; and in the course of a day or two, the trader returns the compliment, by making them presents of British manufactured clothing. – John Dunn, History of the Oregon territory and British North-American fur trade; with an Account of the Habits and Customs of the Principal Native Tribes on the Northern Continent (London: Edwards and Hughes, 1844): 281-2. Quoted in Ibid., 130-1. Key Points The NWC’s presence in New Caledonia and events in the War of 1812 led to the temporary elimination of American interests from the Columbia District and the Canadianizing of a chain of fur trade posts from the mouth of the Columbia north through the Okanagan, the Cariboo, and the Peace District as well as through the Arrow Lakes. New Caledonia was considered by many in the NWC/HBC as a hardship post. The HBC’s post-1821 strategy of building trading posts on the coast was intended to intercept furs headed from the Interior to the maritime-based trade for higher prices. The HBC’s land-based coastal trade strategy broke the back of American seaborne trade and crippled the Russian traders’ business model. Fur trade society west of the Rockies witnessed extensive intermarriage in the context of an often marginal trade. The HBC diversified in the 1830s and 1840s and did more to connect the peoples of the Pacific Northwest with those of Hawaii and China. 120 13.5 Aboriginal Traders Figure 13.15 Fort Simpson (Lax Kw’alaams), ca. 1857. Note the longhouses abutting the flank of the fort. (Painting by Sir Henry S. Wellcome.) Aboriginal trade leaders who would do much to set the tone and character of trade through the first half of the 19th century emerged across the region. The Legaic (or Ligeex) lineage in the Ts’msyan (Tsimshian) territories in the northwest, Kw’eh (or Kwah, ca. 1755-1840) of the Dakelh (Carrier) whose lands surrounded Fraser’s posts, and N’kwala (a.k.a. Hwistesmetxe’qen, ca. 1780-1865) in the Okanagan, Thompson, and Nicola Valleys dictated the location and circumstances under which fur trade posts could be established. In the case of the Legaics, they used marriage between daughters of the lineage to European traders (for example, between Sudaał and Dr. John Kennedy of the HBC in 1832) to secure long-term advantage and monopolies. This strategy of co-opting or adopting into a network of relations was coupled with tactics of bluster and power. Fort Simpson, near present-day Prince Rupert, provides another example. The HBC’s original plan was to build a fort on the Nass River, and while this might meet British trade objectives, it wasn’t satisfactory to the Ts’msyan who insisted that the first iteration be moved a substantial distance south to Lax Kw’alaams, a territory they preferred. Clarence Bolt, Thomas Crosby and the Tsimshian: Small Shoes for Feet Too Large (Vancouver: UBC Press, 1992): 15. Regional Powerhouses Mostly these Aboriginal trade strategies reflected centuries-old commercial practices. The arrival of European goods, however, created a new kind of wealth that brought the possibility of cultural and political innovations. Regional political relationships were certainly in flux. Competition for primacy in the the new global commerce prompted the consolidation and sometimes the growth of alliances and areas of sovereignty. Mowachaht domination of northern Vancouver Island under the leadership of Maquinna extended east from Yuquot from the 1790s through the 1820s to incorporate the Kwakwaka’wakw peoples, the ‘Namgis (Nimpkish), mostly by means of commercial and diplomatic agreement. By contrast, Maquinna’s cousin Wikaninnish launched a violent campaign that created a tribute zone through the Broken Group Islands and across Clayoquot Sound. This bloody campaign, which is referred to as the Long War, predates direct contact and continued almost unobserved by Europeans through the 1840s. In the second decade of the 19th century the focus of the fur trade had moved along, but the Mowachaht and Tla-o-qui-aht (Clayoquot) systems continued to evolve, driven not by European directives but by their own agendas. Similarly, regional power in the Interior was not static. In 1823 N’kwala, the hereditary leader of the Okanagan-Tk’emlups alliance, stormed across the southern valleys into Stl’atl’imc (Lillooet) territory at the head of what was reported to be a mounted cavalry of 500. The goals of the Okanagan were only partly informed by competition for fur trade primacy; the issues behind these conflicts had longer personal, diplomatic, and commercial histories. When the dust settled, N’kwala was confirmed by conquest and heredity as the head man of four nations with lands stretching from the Fraser River into the Rockies and from Soda Creek (Xats’ull) to Okanagan lands below the 49th parallel. All of these developments have in common the utilization of introduced assets: horses in the Interior, European vessels on the coast, and rifles at both places By the 1820s the fur trade was shifting away from the coast. So long as the trade was conducted seasonally by visiting ships from Britain or the United States, the Aboriginal annual routine remained largely unchanged. The same was true at the few trading posts in the Interior when supplies arrived via the Columbia Express or Brigade Trails each spring. The threats and opportunities presented to the Aboriginal peoples by immediate neighbours remained more constant than the traders and, therefore, more important. Political influence and economic power could be exerted as before but now with greater force — and not entirely in the service of maximizing profit in the fur trade. Aboriginal agendas remained vital and somewhat aloof from Euro-North American concerns. At the same time, Aboriginal peoples found ways to turn the newcomers’ trade strategies against the foreigners. Aboriginal traders recognized that fur fetched higher prices on the coast than in the Interior if there was competition by two or more trading ships in port. The price differential was sufficient to make it worthwhile for Interior traders to redirect their pelts down the grease trails to coastal markets. Coastal Aboriginal traders were thus positioned to gain more in this relationship, and they sought access to inland fur resources from the early 19th century. This had two effects. First, it rather obviously reduced the amount of furs available for trade to the NWC and HBC in the Interior. Second, it accelerated a process of what has been called “coastalization” among inland cultures. Coastal crests and clan systems were adopted as were potlatches and the labret. James R. Gibson, Otter Skins, Boston Ships, and China Goods: The Maritime Fur trade of the Northwest Coast, 1785-1841 (Montreal &amp; Kingston: McGill-Queen’s University Press, 1992), 270. Interior NWC and HBC traders, if they wanted to recover their position, would be obliged to offer more for furs. Figure 13.16 Portrait of a Haida woman with a labret, from George Dixon’s 1789 visit to Haida Gwai’i. Conditions for the fur trade were different in the Interior. There the societies were more egalitarian, and there was less likelihood of just one leader monopolizing the Aboriginal side of the trade. Euro-Canadian numbers were insignificant, so the newcomers had to either acquiesce to local practices or demonstrate absolute intolerance of transgressions. Duane Thomson and Marianne Ignace, \"'They Made Themselves Our Guests': Power Relationships in the Interior Plateau Region of the Cordillera in the Fur Trade Era,\" BC Studies 146 (Summer 2005): 3-35. There was certainly no hope of a gunboat sailing up the saltchuck, let alone a cavalry unit coming over the nearest hill to bail out troubled Euro-Canadians on the upper Columbia River, along the Thompson River, or north of the Cariboo Plateau. And while life in Interior Aboriginal communities might have been marked by egalitarianism, that was not the case in the HBC establishments. There, hierarchies prevailed and working conditions were demanding. Interior Aboriginal traders had to work within these constraints and were exposed to risks that were rare on the coast. The HBC’s transition to a coastal, land-based trade began in the 1820s and expanded in the 1830s. As we have seen, this served HBC interests, but it also worked to the advantage of Aboriginal trade leaders. Instead of allowing the HBC to select sites based on its priorities and needs, Aboriginal influence was exerted so that the setting for trade maximized Aboriginal control over the Europeans. Aboriginal clans established homeguards around the forts, ensuring that any furs that arrived from other Native groups had to pass through local middlemen. In this way leaders like Legaic were able to filter trade in and out of locations like Fort Simpson to ensure their continued prosperity and authority. Cultural Change The focus of the HBC west of the Rockies was, perhaps not surprisingly, the fur trade. The number of personnel in the field was small, their familiarity with local conditions was patchy, and they were often placed in locations that were inhospitable. In places like Boat Encampment on Kinbasket Lake, on the York/Columbia Express route, the spring came late and the autumns were short: the Company’s business obviated the possibility of raising sheep or planting hayfields. Coastal fort sites, by contrast, were chosen on the basis of defensibility, harbour depth and shelter, and proximity to trading partners; gigantic Douglas Firs and rocky terrain were clear impediments to agriculture. In short, the intruders lacked the time, knowledge, and resources to raise their own food. This was a constant lament into the 1840s. For these reasons the regional traders depended heavily on food resources provided by Aboriginal peoples. Salmon (fresh and dried), roots, and berries were an essential part of the fur trade, albeit one that literally ate into the profits. William J. Turkel, The Archive of Place: Unearthing the Pasts of the Chilcotin Plateau (Vancouver: UBC Press, 2007), 150-1. Faced with supply-line issues similar to those that were breaking the Russian American Company (RAC), the HBC encouraged local agriculture. The Fort Simpson Ts’msyan and even the Haida across Hecate Strait began growing potatoes, which they traded with fort personnel. Similarly, around Fort Langley  the local population began raising chickens and European vegetables in the late 1820s. In this way, as much as was possible, Aboriginal merchants/chieftains sought to establish, maintain, and — when needed — re-establish Euro-Canadian dependence. Figure 13.17 Fort Langley, ca. 1857-62, with the Kwantlen village across the river and “Langley Buttes” (Golden Ears) in the distance. As new farming practices emerged among Aboriginal peoples, so did new cultural practices. The shift to different tools of labour that had to be either manufactured or obtained and to new ways of working had a ripple effect on food preparation, diet, and the approach to land use and proprietorship. More immediately visible cultural changes were also occurring, particularly regarding the potlatch . Potlatches grew to become spectacles by the second decade of the 19th century. This occurred for several reasons. European implements enhanced the output of traditional goods for redistribution. Iron tools enabled more rapid production of elaborate wood carvings like house-poles and finer metalwork, resulting in greater art production and creativity generally. Weaving of blankets — a currency in the traditional economy — increased, too. Styles modified to include new elements as coastal and interior artisans took advantage of what some scholars have identified as an efflorescence of regional artistic expression. As well, exotic goods quickly worked their way into the heart of the potlatching culture.  Maquinna’s 1803 potlatch, for example, “dispensed 400 yards of cloth, 100 looking-glasses, 100 muskets, and 20 kegs of gunpowder.” Gibson, Otter Skins, 270. Massive displays of material wealth (and exotic material wealth at that) enhanced the status of the host. But the potlatch was changing due to local demographic conditions as well. The loss of population and particularly leaders through fur trade violence and disease created something of a scramble for position. Rivals tried to outdo one another, and village loyalties were divided by various claims to some chiefly status. Ibid., 270-1. Potlatches became larger occasions with vast amounts of exotic goods being distributed to guests and delegations. These events became competitions: more material wealth, whether manufactured locally or abroad, led to more ostentatious potlatches and “fighting with property.” The coastal fur trade impacted local cultures in other less obvious ways. For example, Maquinna’s brother Hannape and his four sons all learned both Spanish and English at the time of the Nootka Crisis. The speed with which they achieved facility in two foreign languages is remarkable. Elements of European languages were incorporated into the Chinook trade jargon but it is easy to overlook the widespread Aboriginal accomplishment of learning the newcomers’ tongues. As well, new ideas about technologies and the wider world worked their way into communities. Wickaninnish of the Tla-o-qui-aht and Tatoosh of the Makah at Neah Bay conspired (unsuccessfully) to seize a European vessel. One study speculates that their intention was to establish direct trade between the peoples of the northwest coast and the Chinese markets. And why not? They had heard a great deal about China from the Europeans and Americans and were sharp enough traders to realize where they stood in the larger economic relationship. What’s more, the rogue trader John Meares introduced the Nuu-chah-nulth to about 130 Chinese labourers in 1788. Contact between the Nuu-chah-nulth and China was, in this sense, an established fact. Contact with the outsiders and the diplomatic attentions of the British and Spanish in particular had the additional effect of challenging leadership norms in the region. Maquinna emerged as a powerful and popular leader because he headed a confederacy of partners who may, from time to time, have challenged his primacy but who generally approved of his consensus-based approach. Wickaninish, on the other hand, was an oligarch whose regime was much more centralized and, thus, more vulnerable. Yvonne Marshall, “Dangerous Liaisons: Maquinna, Quadra, and Vancouver in Nootka Sound, 1790-5,” in From Maps to Metaphors: The Pacific World of George Vancouver , eds. Robin Fisher and Hugh Johnston (Vancouver: UBC Press, 1993), 165-9. The Europeans’ dealings with Wickaninish were generally less predictable and less mutually satisfying, which worked to the advantage of Maquinna’s federation. Strategies of governance were in this way questioned and destabilized. Probably the key factor influencing the pace of change was the impact of exotic diseases, especially smallpox and measles. Epidemics caused by exotic viruses may have occurred as early as the 1780s. Robert Boyd, The Coming of the Spirit of Pestilence: Introduced Infectious Diseases and Population Decline among Northwest Coast Indians, 1774-1874 (Vancouver: UBC Press, 1999). There is no evidence to suggest these were all-encompassing, so some communities and sub-regions were weakened more than others. Venereal diseases may or may not have been indigenous to the Pacific Northwest but the presence of fur traders and sailors certainly didn’t help matters. It is thought that the establishment of Fort Langley (and, by extension, any fort) resulted in a local epidemic of sexually transmitted infections. Cole Harris, The Resettlement of British Columbia: Essays on Colonialism and Geographical Change (Vancouver: UBC Press, 1997), 77. Loss of life to disease created instabilities in leadership and military preparedness. It could reduce the fertility of a population and therefore oblige some consolidations of communities. Epidemic mortalities may also explain the apparent rise in slave-raiding from Lekwitok territory in the upper Strait of Georgia into the Juan de Fuca Strait and the Fraser Valley. On southern Vancouver Island in 1839 it was reckoned that slaves nearly outnumbered nobles and commoners among the Lekwungen, an indication perhaps that slaves were filling in gaps left by disease. At the very least it shows that slavery was not the exception to the rule. John Lutz, Makuk: A New History of Aboriginal-White Relations (Vancouver: UBC Press, 2008), 61. In each of these cases, cultural change or adaptation was necessary. These were, however, changes that were guided by Aboriginal principles and priorities, not by missionaries or colonial officials. Circumstances in this regard would begin to change in the 1840s. Key Points Aboriginal communities and leaders used a variety of strategies to exert control over the fur trade and over the foreign traders. Power structures in Native communities were continually evolving, though now with assets derived through trade with the newcomers. Aboriginal peoples largely controlled the cultural changes that arose because of contact. The potlatch, which was at the centre of economic, political, and social life on the coast, intensified and changed as a result of contact and trade. Figure 13.15 Fort Simpson, B.C. in 1857. – NARA by US National Archives bot is in the public domain . Figure 13.16 Voyage autour du monde by Spinster is in the public domain . Figure 13.17 H. B. Co. Fort Langley, left bank of Fraser River by US National Archives bot is in the public domain . 121 13.6 Boundary Disputes and Manifest Destiny Figure 13.18 The Oregon or Columbia District included parts of modern-day British Columbia, Idaho, and Montana as well as all of Washington and Oregon. This map shows, too, the respective claims of the British (42 degrees) and the Americans (5440′). Beginning in the early 1840s, “Oregon Fever” gripped the United States. Oregon was touted as a land of pleasant climates and fertile soil. Several thousand American settlers began a westward migration over the Oregon Trail. By the mid-1840s, some 5,000 Americans had populated the southern half of the Columbia Department, thus strengthening the U.S. claim to Oregon, and in 1843 the Americans declared a provisional government. The HBC’s James Douglas wrote to his superiors that “An American population will never willingly submit to British domination.” James Douglas to George Simpson (private correspondence), 23 October 1843, quoted in Daniel W. Clayton, Islands of Truth: The Imperial Fashioning of Vancouver Island (Vancouver: UBC Press, 2000), 219. Britain’s tenuous hold on the whole region was in danger of slipping away. Oregon Fever, moreover, fuelled the idea of Manifest Destiny in America, popularizing the  the notion that it was God’s will that the republic should control the whole of the continent. Fifty-Four Forty American territorial expansion became one of the paramount issues of the U.S. election of 1844. Democrat James K. Polk, a protege of the expansionist Andrew Jackson (president, 1829-37), won office in an election that revolved largely around the issues of the possible annexation of Texas and acquiring some or all of the HBC-administered Columbia Department, which the Americans referred to as the Oregon Territory. Polk won the election by a narrow majority, but the Democrats took both houses of Congress, causing many to read the result as a mandate for expansionism. Many Americans, Polk among them, set their sights on taking the Mexican provinces of New Mexico and California in addition to the Oregon Territory, which at that stage constituted most of the territory between California and the Alaska panhandle — that is, almost all of what is now British Columbia. Polk’s priority, however, was the Mexican territories and so he needed to quickly settle with the British on the issue of the Columbia Department in order to have the military strength for a war against Mexico. The process was further complicated by signs that Britain was considering an alliance with the Mexicans in Texas, so getting the British out of the picture was a priority. On taking office, Polk initiated talks with Britain. The president quickly found himself a prisoner of his own expansionist rhetoric: public opinion over the Oregon Territory had grown increasingly heated with expansionists demanding nothing less than the whole package and threatening war in the far northwest in order to achieve their ends. The slogan Fifty-Four Forty or Fight! was coined at this time, referring to the northernmost latitude of the territory that America might claim, some 30 kilometres north of present-day Prince Rupert. 49th Parallel British enthusiasm for war in the Pacific Northwest was understandably tepid. In 1845 and 1846 the fur trade was becoming less profitable and alternative economic engines were slow to emerge. Few politicians in Britain were prepared to go to bat for the monopolistic HBC, which was widely regarded as a bloated artifact of a pre-free trade era. There was little sign — not along the Fraser River or even in California — of the gold rushes that would transform the West Coast. Nor was there any indication of the potential coal mines of Vancouver Island. In this light it is not surprising that the British were prepared to concede as much as they did. Conveniently for the British, President Polk was more than willing to accept a boundary line along the 49th parallel. In terms of the British interest, as represented in the field by the HBC, the circumstances had changed since the Treaty of 1818, paving the way for joint occupation of the Columbia District. The fur trade in the whole region was in decline and the corridor that ran from York Factory to Fort Vancouver at the mouth of the Columbia had lost much of its significance. In its place, as historian Richard Mackie notes, the HBC had built a network of deep-sea trade that linked ports in Hawaii, Alaska, Guangzhou, and California to Fort Victoria. The mouth of the Columbia was treacherous with shifting sands and channels; Fort Victoria was better suited for this new kind of commerce under Britain’s growing philosophy of free trade. Richard Mackie, Trading Beyond the Mountains: The British Fur Trade on the Pacific, 1793-1843 (Vancouver: UBC Press, 1997), 256-61. Holding the line at the 49th parallel and keeping Vancouver Island was sufficient to the needs of the British and, if it could be done through diplomacy rather than at gunpoint, a peaceful outcome was preferable to war. Two important results of the Oregon Treaty of 1846 were not committed to any legal document. First, the principles by which Europeans had sorted out who owned what in the New World shifted. The British claim was based on commerce and, indeed, every expression of British policy in the region from the 1780s to the 1870s hinged on commerce. When the British laid claim to the region based on occupation, they were using the word to mean “business”; in other words, they were occupied with commerce in the region. For the Americans occupation meant settlement, and sending in thousands of squatters to take up land was a precursor to annexation. With that American interpretation in mind, the HBC moved in the late 1840s toward a policy of building settlements on Vancouver Island to forestall any American forays into the region. Clayton, Islands of Truth , 222-3. It was, as well, a lesson that James Douglas would remember at the right moment in 1858 and one that would focus Canadian minds when it came to holding Rupert’s Land against American intrusion from 1869 on. The map in Figure 13.19 shows those areas where American expansion in the West was a source of concern for British and Canadian interests. Figure 13.19 American expansion in the Red River Valley, the Cypress Hills, the Oregon Territory, and southern British Columbia. [Long description] The other result of the Oregon Treaty was a severely changed political landscape for Aboriginal nations. The 49th parallel cut through Native communities like a knife, effectively trapping populations on either side within rapidly emergent imperialist administrative structures. The change was not immediately apparent: the swoop of a pen 4,000 miles away makes little noise. By the late 19th century, however, both the American and the British-Canadian governments in the region were aggressively managing border peoples, some of whom found their societies divided. Key Points American imperial aspirations in the second quarter of the 19th century included annexation of the whole Pacific Northwest. The Oregon Treaty of 1846 resolved the potential conflict between Britain and the United States by continuing the border with British North America all the way to the West Coast and throwing in all of Vancouver Island on the British side. The HBC and the Colonial Office had to develop new strategies to continue exploiting and claiming the territory between the American and Russian territories. Figure 13.18 Oregon Country by Kmusser is used under a CC-BY-SA 2.5 license. Figure 13.19 United States Expansion by Peteforsyth is in the public domain . Long Descriptions Figure 13.19 long description: American expansion from the original 13 states ceded by Great Britain in 1783 to the west coast. 1803 marked the completion of the Louisiana Purchase from France. In 1819, the Spanish ceded three southern states. Texas was annexed in 1845. In 1846 and 1848, America gained all of the western block of what is now the United States. In 1867, America bought Alaska from Russia. [Return to FIgure 13.19] 122 13.7 Identity Crisis National histories tend to draw straight and uncomplicated lines. If one of the functions of a national history is to define or distill a national identity, then simplicity is of the first order. Loyalties ought to point in one direction, though occasionally a character in the past may be torn somewhat. But we have come to think of national and ethnic loyalties as instinctive and not all that negotiable. This is part of a tendency to essentialize people in the past: they behave as they do because of what they are in essence. One of the virtues of West Coast history is the ease with which those narratives may be broken up and thrown aside. People from around the globe collected on the West Coast in the 18th and 19th centuries, in assortments that were, for their time, unique. What’s more, the individuals themselves reveal interestingly complex backgrounds. The ways in which their lives bump up against those of others and then ricochet off in an unexpected direction remind us that stories are not highways but threads that bind and fray. Take the example of Marguerite Waddens (1775-1860) who was born in Montreal. Her father, Jean Étienne Waddens, was Swiss and a founding member of the NWC; her mother, Marie Josephe DeGuire, was Cree. Marguerite was a product of a fur trade marriage à la façon du pays , a late-18th century métis born in the East. One of Marguerite's sisters, Veronique, would marry the Rev. John Bethune; two of their descendants are Dr. Norman Bethune (the Canadian physician who achieved legendary status in the Chinese Revolution) and the accomplished actor, Christopher Plummer. Two of the men in Marguerite’s life would meet their ends in spectacularly violent ways. Her father died at the hands of fellow NWC trader and cartographer Peter Pond when an argument overheated. Marguerite’s first husband, Alexander MacKay (1770-1811) died under even more exceptional circumstances. Figure 13.20 Marguerite Wadin McLoughlin in her twilight years. MacKay was a child when his Loyalist parents became refugees in the Canadas. Entering the fur trade as a youth, he joined Alexander Mackenzie’s expedition to the Pacific coast (and was thus one of the first Euro-North Americans to cross the continent). MacKay amassed a fortune in the service of the NWC, married Marguerite, and retired to Montreal at 38 a wealthy man — probably without Marguerite. In 1810 the American fur trader and entrepreneur John Jacob Astor (1763-1848) signed  MacKay to work with the Pacific Fur Company — an emergent American rival to the British HBC and the Canadian NWC. Sailing on the Tonquin to the West Coast, MacKay was killed along with all but two of the ship’s crew when it stumbled into a political stew in Clayoquot Sound in 1811. Wikaninnish’s fleet made short work of the American crew, killing as many as they could lay their hands on. This may have been one of Wikaninnish’s attempts to obtain a European-style vessel.  If so, it failed: perhaps as many as a hundred of the Tla-o-qui-aht raiders perished when a Tonquin crew member detonated the ship’s gunpowder. Marguerite and Alexander’s son, Thomas,  narrowly missed sharing the horrors of the Tonquin because his father chose to leave him behind for a few days at the PFC’s new fort on the Columbia. Jean Morrison, “MacKAY, ALEXANDER,” in Dictionary of Canadian Biography , vol. 5 (University of Toronto/Université Laval, 2003). Accessed January 18, 2015, . The widow Marguerite remarried around 1810, which suggests that she had been abandoned by MacKay (a common enough experience for “country wives”). Her new husband was another fur trader, John McLoughlin (1784-1857). Born Jean-Baptiste in Trois-Rivières in 1784, McLoughlin came from Irish immigrant stock (his father) and Canadien ancestry (his mother). Raised by his Scottish uncle, McLoughlin’s spiritual life charted a course from Catholicism to Anglicanism and back. His marriage to Marguerite was not McLoughlin’s first: he was himself a widower, having been married briefly to a Chippewa woman who died giving birth to their son Joseph in 1809. Within a year of marriage (again, a la façon du pays ), Marguerite and John had a son, John Jr. The family continued to grow while they were stationed just west of Lake Superior. During this period McLoughlin senior’s relationship with his stepson Thomas deepened. Indeed both men were at Selkirk in the employ of the NWC during the Battle of Seven Oaks. McLoughlin was even implicated in the killing of Governor Semple, although the charges were later dismissed. He was a key player for the NWC side at the negotiations that led to the merger of the two fur trade giants in 1821. Figure 13.21 Fort Astoria (also known as Fort George), ca. 1813-1818. About seven years later, Marguerite Waddens MacKay McLoughlin relocated with her husband and both sons to the Columbia District where McLoughlin built Fort Vancouver, across the river from Fort Astoria (the PFC base in which Alexander MacKay played a small role). Fort Vancouver was as cosmopolitan as any HBC post and then some. Trade between the Columbia and the Hawaiian (or Sandwich) Islands brought Kanakas (Hawaiians) to Fort Vancouver in large numbers. Trade with Guangzhou occasionally brought Chinese men as crew to the West Coast, and Marguerite’s nephew, Angus Bethune, travelled to China on behalf of the HBC. Marguerite would have been on hand in 1834 when news of three shipwrecked Japanese sailors on the Olympic Peninsula reached Fort Vancouver. Enslaved by the Makah on Juan de Fuca Strait, the three men included a 15-year-old named Otokichi, who — thanks to the intervention of McLoughlin — was brought to Fort Vancouver. Otokichi would go on to play a small part in diplomatic efforts to open Japan to Western trade. (And, like Marguerite, Otokichi’s wide-ranging life would be marked by complete disregard for racial or national categories: his first wife was English, his second Malay.) Figure 13.22 A drawing of Otokichi on his return to Japan, wearing his disguise as a Chinese traveller. Marguerite was well acquainted with James Douglas, McLoughlin’s junior at Fort Vancouver. Born in the British colony of Demerara (Guyana), Douglas had both Scottish and African ancestors. He worked his way through the NWC into the HBC and at 25 years of age he married Amelia Connolly, a métis woman. Shortly after the Douglases were reassigned to Fort Vancouver where James worked under McLoughlin. Douglas observed in these years on the “respect and affection” that McLoughlin held for Marguerite. Margaret A. Ormsby, “DOUGLAS, Sir JAMES,” in Dictionary of Canadian Biography , vol. 10 (University of Toronto/Université Laval, 2003). Accessed August 7, 2014, . Douglas grew fiercely loyal to McLoughlin, even against Governor Simpson right up until 1846 at which point their paths diverged. McLoughlin decided to stay put on the Columbia and thus become an American after partition of the Oregon Territory. John Jr. carried on the family tradition for travel, moving to Paris to take up medical studies. In later years he would acquire a reputation for drunkenness and violence (John Sr. had a temper as well, according to Governor Simpson), which might provide a clue to why he left Paris under a cloud. Difficult to place in the HBC system, he found his way to Fort Vancouver for a spell, then to Fort McLoughlin (on the central coast and named for his father). Finally he was sent to Fort Stikine in the north. There, it was reported, he so terrified his colleagues that one of them shot him through the throat. He died from his wounds at barely 30 years of age. Thomas MacKay, for his part, had a better record, of sorts. Marguerite’s son by Alexander McKay married well in the Columbia District, partnering with Timmee, the daughter of Chinook chieftain Comcomly. Jean Barman, French Canadians, Furs, and Indigenous Women in the Making of the Pacific Northwest (Vancouver: UBC Press, 2014), 131. He played a key role in realizing Governor Simpson’s vision of a “fur desert” south of Fort Vancouver, a landscape completely denuded of commercial wildlife so as to block American trade in the region. This war against nature was for naught, as it simply made it easier for American settlers (rather than fur traders) to move into the region. Not much is known of David, Marguerite’s second son by John McLoughlin, except that he received some training in Paris as an engineer, spent much of his life in the Columbia District, and married a Kutenai woman named Anne Grizzly. Less still is known about John McLoughlin’s son from his first marriage, Joseph, and Marguerite’s three daughters by Alexander MacKay. Marguerite and John’s daughter Marie Eloisa McLoughlin, however, attained some prominence at Fort Vancouver. Born in 1817 at Fort William, Eloisa was educated in Canada and headed west in the 1830s. Young and energetic she took on many of the hostessing tasks that typically would have belonged to her mother. She and her husband opened Fort Stikine around 1841 and narrowly missed overlapping with her ill-fated brother John Jr. at that same location in 1842. Figure 13.23 Having spent his career trying to keep the Americans at bay, McLoughlin is celebrated in this 1948 U.S. stamp as a founder of Oregon. The loss of British sovereignty south of the 49th parallel in 1846 was overseen by McLoughlin, the French-Irish-Scots Catholic-Anglican Canadian who went on to become an American and is celebrated in the United States as the “Father of Oregon.” W. Kaye Lamb, “McLOUGHLIN, JOHN,” in Dictionary of Canadian Biography , vol. 8 (University of Toronto/Université Laval, 2003). Accessed January 18, 2015, . Marguerite’s final public role was that of mayor’s wife in Oregon City, where the couple are buried side-by-side. The Swiss-Cree Protestant-Catholic mother of seven children and stepmother to another (some of them, like their fathers, Scots-Irish or French or Loyalist), mother-in-law to women drawn from Aboriginal nations from the north coast to Idaho, and aunt to members of the Family Compact in Upper Canada, Marguerite’s life took place on a stage of enormous distances and great risks, one that involved a multitude of actors from across the globe. Tug on any one thread and any number of narratives unfold. Key Points The notion of national or ethnic identities of individuals in the Cordilleran fur trade prior to the 1850s is inherently problematic. Canadiens — who were often simultaneously métis — played a key role in what is often mislabelled the British fur trade in the farthest West. Remote posts were often connected by the presence of family members and within post communities themselves there was often a dense network of relationships between Euro-North Americans and Aboriginal peoples. Figure 13.20 Oregon Historical Society (OHS) #bb006496. This photo has been released under a CC-BY 4.0 International license by the OHS for this textbook. Figure 13.21 Fort George by Cropbot is in the public domain . Figure 13.22 Otokichi by Liftarn is in the public domain . Figure 13.23 Oregon Territory Centennial 3c 1948 issue by Gwillhickers is in the public domain . 123 13.8 The Island Colony Figure 13.24 The southwest bastion of the HBC fort at Victoria, 1860. (Watercolour by Sarah Crease.) The loss of the Oregon Territory was a blow to the HBC but not necessarily to British ambitions in the region. The former remained resilient while the latter remained modest. The HBC had experimented with commercial diversification for years, expanding its network across the Pacific. The arrival and employment of Kanakas throughout the Pacific Northwest reflected the diversity of marketplaces into which the HBC reached. Tom Koppel, Kanaka: The Untold Story of Hawaiian Pioneers in British Columbia and the Pacific Northwest (Vancouver: Whitecap Books, 1995). It was clearly about much more than beaver and sea otter pelts. One noteworthy (if Pyrrhic) victory in this regard was the Puget Sound Agricultural Company (PSAC) , a barely-at-arm’s-length subsidiary of the HBC created in 1840 and centred at Port Nisqually (Tacoma) in what is now Washington State. The PSAC had several goals, including the establishment of a loyal British settler community in the face of American intrusion into the Oregon Territory, improved self-sufficiency in terms of food supply to the northern forts, and an experiment in settler colonialism. Like Lord Selkirk’s project at Red River, the HBC conceived PSAC in part as an attractive retreat for retired employees and their families. The Oregon Treaty ended the PSAC experiment but its objectives were to continue to the north, on Vancouver Island. Fort Victoria Fort Camosun opened in 1843 and its name changed to Fort Victoria in 1846 in honour of the new queen. This was the first settlement of Europeans on the island since the Spanish abandoned Fort San Miguel at Yuquot in 1795. The HBC feared the Lekwungen (Songhees) and their neighbours, and there was little confidence that even a simple landfall would succeed. The priorities of the Lekwungen, however, included incorporating the British operations into their own. Some 300 to 400 Aboriginal men took on the task of building the fort and the band provided all the lumber required for the task. Historian John Lutz argues that this apparent welcome was a kind of appropriation by the Lekwungen. In their society, housebuilding was a communal activity and it was one that signified, importantly, community ownership of the structure. Building the HBC fort, therefore, signified a Lekwungen stake in the affair. John Lutz, Makuk: A New History of Aboriginal-White Relations (Vancouver: UBC Press, 2008), 70-71. Relations between Aboriginal peoples and the HBC entered a new phase after the construction of Fort Victoria. There were confrontations, some of which involved what Barry Gough describes as gunboat diplomacy. Barry M. Gough, Gunboat Frontier: British Maritime Authority and Northwest Coast Indians, 1856-1890 (Vancouver; UBC Press, 1984). Often the source of irritation was cultural differences. Many northwest coast peoples were horticulturists, though not farmers in a sense that newcomers instantly recognized. Europeans often witnessed them clearing the land with fire in order to create meadows, so the newcomers knew that land management was underway. For example, the West Coast camas bulb was an important source of food for Aboriginal peoples and a trade good in its own right. But the camas bulb is one of many indigenous foodstuffs that did not gain admittance to the Columbian Exchange: Europeans never really came to like its flavour. If they had, they might have done more to protect camas patches against the newly introduced cattle and pigs. Of course, a cleared patch of land is more attractive to a farming settler than a stand of towering Douglas firs: the gardens of northwest coast peoples were much sought after and were quickly seized by newcomers. Aboriginal peoples, for their part, regarded anything on four legs as potential game, which was predictably bad news for livestock and for the newcomer-Native relationship, but good news for the banquet table. Figure 13.25 The gundeck of the steam-powered vessel, the HMS Sutlej . Along with the aptly named Devastation , the Sutlej razed nine native villages in one mission during the 1860s. The Colony of Vancouver Island In 1849 the British extended to the HBC a 10-year lease on the proprietary colony of Vancouver Island, conditional on its settlement by newcomers. The new colonial paradigm was difficult for the HBC to accept. Settlers and furs and Natives were not viewed as a good mix, not by the HBC’s officers and not by the Aboriginal populations. The Whitman Massacre of 1847 was still at the forefront of everyone’s minds. Aware of the possibility of foot-dragging on the settlement front, the Colonial Office dispatched Richard Blanshard (1817-1894) to serve as governor. Blanshard was probably the only non-indigenous person on the whole island who did not work for the HBC and, as he was soon to discover, the company did not work for him. In the space of 10 years the HBC had experienced an enormous shift, one that had seen the end of their Oregon and Californian enterprises along with the loss of Fort Vancouver and the York Factory Express route. The company’s local operations were headed by Chief Factor James Douglas but he now had to take orders from London and the Colonial Office. What’s more, Westminster instructed the HBC to bring in significant numbers of non-company personnel to become settlers; it was likely that the newcomers’ relationship with the Aboriginals would be different from — which is to say, at odds with — that of the fur trading company. It is hardly any wonder, then, that Governor Blanshard found himself isolated and frustrated. If that weren’t enough, his timing was spectacularly bad. Figure 13.26 Richard Blanshard served briefly as the first governor of Vancouver Island. Gold fever had erupted in California in 1848. By 1849 eager prospectors were streaming into San Francisco, some of them from Fort Victoria. At around the same time, the HBC decided to pursue more aggressively a coal mining possibility at the northern tip of the island. The company established Fort Rupert in the late 1830s at Beaver Harbour, a Kwagu’ł (Kwakiutl) village site called ʦax̱is. This was the company’s only fort that existed for purposes other than trading furs or growing food. Kwagu’ł men and women dug out the coal or gathered it along the beach and traded it to the HBC, thus expanding their range of commerce. By 1848, however, the company was preparing to lurch into the industrial age by bringing out a party of experienced Scottish coal miners. The experiment was a disaster. It outraged the Kwagu’ł and they made common cause with the miners against the HBC. In 1850 the Scots were either chained up in the fort’s bastion or preparing to make a run for it. As this drama unfolded, another came into view. Two British sailors who hoped to hitch a ride to San Francisco and the riches of the Californian El Dorado jumped ship in Victoria and then, mistakenly, onto a vessel headed north. Arriving in a troubled Fort Rupert, they fled into the forest where they were murdered by parties unknown. Blanshard’s response was to sail a gunboat into Beaver Harbour and shell the nearby Nahwitti village as he pursued the killers. Fed up with his low wages, poor living conditions, and lack of real authority, he returned to Fort Victoria and submitted his resignation — which London was happy to accept, given his rampage at Nahwitti. Figure 13.27 A depiction of Kwagu’ł and Ts’msyan people at Fort Rupert on the north end of Vancouver Island, 1851. (Painting by Admiral Edward Gennys Fanshawe.) Douglas was now governor of the colony with orders to take material steps to settle the island with colonists loyal to the Crown. Recruitment efforts were modest, not least because the prospect of new settlers was viewed as inconsistent with diplomatic and commercial relations with the Aboriginal peoples. There was a veneer of theory applied to this hesitance. In the early 1850s the colonial theories of Edward Gibbon Wakefield (1769-1862) — one of members of Lord Durham’s expedition to the Canadas — gained wider support. Wakefield’s views resonated nicely with the HBC establishment on the island: he thought it was better to reproduce in colonies the kind of social relations found in Britain’s hierarchical culture than to open up the land to homesteading and an influx of commoners. As a result, land prices were set at a level that was seen as attractively exclusive. Only a certain class of settler would, in effect, be admitted. In the face of free land policies south of the border, the Wakefieldian approach on Vancouver Island failed. Tina Loo, Making Law, Order and Authority in British Columbia, 1821-1871 (Toronto: University of Toronto Press, 1994), 38. The number of land sales was acceptable, but the number of settlers was never great. What’s more, those HBC servants who might have had it in mind to achieve some independence on the land were kept in their social class by this expense, thus preserving a pool of labourers. Finally, the hierarchical society that Wakefield (and James Douglas) had in mind for Vancouver Island led to the creation of the “squirearchy,” an HBC-connected elite that occupied all the key appointed positions in the colony, including the whole of the judiciary. The Crown had been reluctant to hand authority to Douglas for fear that he was in a conflict of interest. Indeed he was. Douglas was mistrustful of settlers and defensive of Aboriginal rights as he saw them. He negotiated a suite of 14 agreements, known as the Douglas treaties . These were initiated under Blanshard’s watch and Douglas continued pulling treaties together through the decade. Each aimed at obtaining lands deemed suitable for settlement or HBC enterprise. The treaties preserved First Nations village sites intact and allowed for one-time compensation payments. Some First Nations actively sought treaties from the HBC but Douglas had a limited budget at his disposal and no interest in obtaining territory where there was no immediate likelihood of use by newcomers. These treaties stand as the only ones negotiated west of the Rockies until very recently. West Coast Industrialization The experiment in coal mining at Fort Rupert was a disappointment. The Kwagu’ł claimed ownership of the coal and obstructed the use of Scottish miners. The immigrant coal miners — who constitute the first group of foreigners delivered to the region for the purpose of settling or doing a particular job since Meares’s Chinese shipbuilders — objected to the way the work was organized, the conditions under which they were mining, and the whole culture of HBC fort life. The operation was wound down and a promising coal seam to the south was explored. Many of the miners subsequently wound up at Fort Nanaimo in the Sneneymuxw territory. Douglas signed a treaty with the Aboriginal community in 1854 and in that year a shipload of English miners from Staffordshire arrived, along with their families. In total, the HBC sponsored the immigration of 435 individuals for the coal mining projects until 1855, 85 of which were children. These immigrants and those who followed them were exceptional in the history of Canadian population: they were working-class people drawn from isolated communities in Britain and their voyage west by sea took them around the southern tip of South America, to Hawaii, and then to the island colony. There was effectively no going back. In a colony where the “squirearchy” looked down its nose at agricultural labour, the status of the miners and their families was lower still. The success of the coal mining enterprise was slow in coming. It was helped along, indirectly, by the Russians. The island’s proximity to Russian waters pulled the colony briefly into the orbit of the Crimean War (1854). A joint British-French assault on the Russian Pacific port of Petropavlovsk ended in disaster and the injured troops were evacuated to Fort Victoria. These events advanced the case for a Royal Navy base and one was established next to Victoria Harbour at Esquimalt in 1865. Naval officers subsequently developed close links with the coal mining operations around Nanaimo. As more steam-powered naval vessels arrived in the Pacific, the coal resources became more important; as the coal mines grew in strategic significance so too did the value of having a naval base nearby to protect them. Figure 13.28 Coal miners at the Nanaimo mine pithead, ca. 1870. The gold rush on the mainland also helped the coal mines, as did the growing demand for household fuel in San Francisco and Victoria. In the early 1860s the HBC sold its interest in Nanaimo to a London-based company and the chartered company gave way to industrial capitalism. A former HBC employee, Robert Dunsmuir, found his own coal seam nearby in 1869 and began building an industrial empire and dynasty. Two years earlier the first Chinese mine workers arrived at Nanaimo, the beginning of a migration wave that would continue through the rest of the century. By the third quarter of the century Nanaimo and environs was one of the largest industrial nodes in British North America. Christianizers Missionary activity on the coast also began at the mid-century. William Duncan (1832-1918), a controversial and mercurial representative of the Church of England’s Church Missionary Society (CMS) , arrived in 1857. He set up shop at Fort Simpson (also known as Lax Kw’alaams and Port Simpson, near current-day Prince Rupert) and subsequently relocated hundreds of Ts’msyan to a mission town of his creation: Metlakatla. “Duncan shaped a landscaped place,” at Metlakatla, according to one source, “with rows of identical, single-family dwellings. Each house had a small garden, glass windows, sash curtains, and was fitted with beds and clocks. The church and other public offices were Metlakatla’s largest and most imposing buildings.” The overall effect was that of a European community built around ideals of individualism, the nuclear family, and “slum clearance.” Daniel Clayton, \"Geographies of the Lower Skeena,\" in Home Truths: Highlights from BC History, eds. Richard Mackie and Graeme Wynn (Madeira Park: Harbour, 2012), 114-115. Duncan aimed to change people by changing their environment first: notably his idea of appropriate housing, individualism, and patrilineal inheritance was a direct critique of local Aboriginal culture. Duncan took the view that good Christians came out of nuclear households with a strong patriarchal legal and belief system in place. Clarence Bolt, Thomas Crosby and the Tsimshian: Small Shoes for Feet Too Large (Vancouver: UBC Press, 1992), 24. While cultural change among Aboriginal people on the northwest coast had been occurring throughout the fur trade period, the arrival of missionaries like Duncan and his successor at Fort Simpson, the Methodist Thomas Crosby (1840-1914), witnessed the first concerted efforts by newcomers to transform Aboriginal societies and beliefs on the West Coast. Figure 13.29 St. Paul’s the Anglican church at Metlakatla, n.d. The 1850s were marked, then, by a rising colonial administrative presence, the beginnings of cultural assaults, some increase in newcomer settlement, and further decline in the fur economy counterbalanced somewhat by increased diversification of HBC activities. Where Fort Rupert failed as a mining operation, Fort Nanaimo succeeded and new arrivals from British coal fields continued the process of industrial resource extraction. The decade also witnessed diversification of Aboriginal economies, a greater number of Aboriginal peoples trading their labour for goods, and significant instances of resistance to newcomer transgressions. All of this change would be very suddenly eclipsed by events in 1858. Key Points The HBC established the Colony of Vancouver’s Island to replace Fort Vancouver and as a starting point for a joint HBC-Colonial Office settlement project. The presence of newcomers in their midst both enriched and endangered Aboriginal peoples of the island and the central coast. Agriculture, harvesting coal, and other economic activities were undertaken to further trade with the foreigners and also to increase their dependence. Settlement in the colony took two forms: a patriarchal and pastoral echo of the relationship between British gentry and commoners, and an industrial, proletarian townscape. The industrial revolution arrived on Vancouver Island in the late 1840s and spread in the 1850s to the mid- and south island. Missionary efforts on the West Coast accelerated in the 1840s, richly funded in the first instance by the CMS. Figure 13.24 Fort Victoria watercolour by Bonas is in the public domain . Figure 13.25 HMS Sutlej gun deck LAC by Rcbutcher is in the public domain . Figure 13.26 Blanshard by Fishhead64 is in the public domain . Figure 13.27 Edward Gennys Fanshawe, Indians at Fort Rupert, Vancouver’s Island, July 1851 (Canada) by KAVEBEAR is in the public domain . Figure 13.28 Nanaimo Mine Explosion-1 by Drovosekk is used under a CC-BY-SA 3.0 license. Figure 13.29 William Duncan’s church, Metlakahtla, B.C. is in the public domain . This image is available from the holdings of the National Archives and Records Administration , cataloged under the ARC Identifier (National Archives Identifier) 297830. 124 13.9 The Gold Colony Figure 13.30 A whimsical, almost Tolkein-esque map of “The New El Dorado.” Tranquille Creek pours into Kamloops Lake about 15 kilometres west of the HBC’s fort at the confluence of the two branches of the Thompson River. In the 1850s the Tk’emlúps people retrieved small quantities of gold from the creek and canyon and offered it in trade at Fort Kamloops. After amassing a considerable nest egg’s worth of minerals, the HBC traders became concerned that it might be nothing more than fool’s gold. James Douglas (who still played the role of leading trader on the mainland, as well as governor of Vancouver Island) quietly shipped out a sample to the mint at San Francisco for assaying. Word of the gold’s quality leaked out of the mint within hours of testing and the Fraser River gold rush was underway. The Rush The earliest phase of the Fraser gold rush included production of gold by Aboriginal labour on a commodity-trade basis from 1856, if not earlier. The Nlaka’pamux in particular were industriously pulling gold ore from their river (which appeared on European maps as the Thompson beginning in the 19th century) in 1857 and were already fighting off Americans from the old Oregon Territory who had followed rumours of gold in the north. What happened in 1858, however, was of a different order of magnitude. No other event in Canadian history so transformed a region and its people in such a short period of time. This story goes well beyond the 15,000 to 20,000 who sailed out of San Francisco to Victoria and the mainland in the summer of 1858. It is much more than the administrative and political changes entailed in the creation of the new Crown colony of British Columbia, the appointment of Douglas as its first governor, and the establishment of a capital at New Westminster. And it goes well beyond the thousands of newcomers who added to the existing non-Aboriginal community as permanent residents. The gold rush had severe environmental implications. Miners compromised salmon runs by flushing sand and silt into the spawning grounds as they tried to extract gold. They stripped hillsides of trees needed for mine posts, flumes, and houses; erosion followed. Extensive and sterile rock piles throughout the interior even now indicate where Chinese miners painstakingly piled river rocks after they had been carefully washed clean of gold dust. There was, too, bloodshed in the Okanagan by American prospectors accustomed to killing off Aboriginal people who got in their way, and that was followed by warfare in the Fraser Canyon as the Nlaka’pamux resisted foreign incursions. Daniel P. Marshall, “No Parallel: American Miner-Soldiers at War with the Nlaka’pamux of the Canadian West,” in John M. Findlay and Ken S. Coates, ed., Parallel Destinies: Canadian-American Relations West of the Rockies (Seattle: University of Washington Press, 2002), 64-65. The Fraser Canyon War was instigated by French miners who allegedly raped a Nlaka’pamux girl; their bodies were subsequently found downstream, decapitated. Claims at the time of huge mortalities must be taken with a grain of salt, but it is clear that skirmishes did take place, lives were lost, and the event could have easily cost Britain its new colony. Douglas could not afford to wait for the Colonial Office to send instructions. He raced a gunboat to the mouth of the Fraser and imposed a licensing system on the incoming miners, a way of demonstrating British sovereignty and gathering revenues. Shortly thereafter the Colonial Office made Douglas governor of the new colony of British Columbia and insisted he cut his ties with the HBC. A new capital was established at New Westminster (at the Kwantlen village of Sxwoyimelth) and Fort Langley enjoyed a brief renaissance. A corps of Royal Engineers were introduced and acted as a kind of police force throughout the colony. Steamboats were soon plying the river to the height of navigation at Yale. Figure 13.31 Chinese miners introduced machinery like this “rocker” on the Fraser River ca. 1875. The Cariboo The gold frontier rapidly spread north, one arm diverting east to reincorporate Tranquille Canyon and the main part headed into the Cariboo Plateau. Barkerville emerged in these years as the largest centre of population in both British Columbia and Vancouver Island with numbers in excess of 10,000 (Victoria held barely 6,000 in 1863). The boomtowns of Likely, Richfield, and Quesnel also appeared at this time, many of them heavily populated by Chinese miners from Taishan. Few of the gold prospectors made the fortunes they’d hope to. The cost of supplies was grotesquely inflated, the miners chased off much of the game they might have lived off, and Aboriginal communities tended to give them a wide berth. Survival became the chief preoccupation of many prospectors. Shopkeepers and saloon keepers, however, did quite well, though never well enough to pay for the infrastructure needed to sustain the gold rush. The Cariboo Wagon Road was the major government initiative of the day, connecting Lillooet and Lytton (Camchin) with Barkerville. Way stations appeared (the many Mile Houses of the interior) and the whole was policed by a regiment of British Royal Engineers, called the Sappers. Figure 13.32 The Cariboo Wagon Road made possible the much more rapid movement of people, goods, and colonial power through the interior of British Columbia. The Fraser and Cariboo gold rushes peaked in 1863 and were in decline by 1865. Thousands of newcomers drawn from dozens of countries remained in its wake, some continuing to prospect in the area of Likely and Quesnel Forks. There are two noteworthy aspects of this population influx. First, despite the appearance of a map of newly named locales, very few of the gold rush towns were, in fact, new human settlements. New Westminster (the capital of the new mainland colony), Hope, Yale, Port Douglas, and Lillooet were — like Kamloops — Aboriginal village sites before they were newcomer villages and towns. Barkerville and its neighbour Richfield were exceptions, being two of very few entirely new settlements. Second, this population infusion was overwhelmingly young and male, a foretaste of life in a resource-extraction and industrial frontier. The pattern would be reinforced by smaller gold rushes in the Boundary District in 1860, on the Stikine River in 1861-62 (which briefly produced the separate administrative district, Stikine Territory), and in a few smaller pockets in 1871. Gum Shan , the Gold Mountain This was, too, the most international community that would be seen in any part of British North America for a century. Thousands of Taishanese could be found in the Cariboo, the two colonial capitals, and the coal mines of Nanaimo. Kanakas were working and living everywhere and increasingly in concentrations on the Gulf Islands. African-Americans fleeing slavery and its possible extension to California arrived in large numbers, some establishing a volunteer rifle regiment in Victoria. Continental Europeans, Scandinavians, and even Australians fleshed out the population made up mostly of British, Americans, and even Canadians and Maritimers. The majority of the gold rush influx, however, exited. For colonists and colonial political figures, the loss of the newcomers meant that the colony was bankrupt and teetering once again on the brink of annexation by the United States. The feeling that British Columbia’s days as a Crown Colony were numbered was particularly strong after the Americans purchased Alaska in 1868. The trappings of imperial power — a few officers of the judiciary (including Judge Matthew Baillie Begbie, who was unafraid of applying gallows law), a Royal Navy base at Esquimalt, and a small legislative council in Victoria — were not entirely reassuring. Voices in the Colonial Office suggested that it was time to cut their losses and hand over the region to the Americans. The Asian population found itself increasingly marginalized physically in the towns and cities as “Chinatowns” appeared, reflecting Euro-North American policies of containment and exclusion. Indeed, as discussion over the wisdom of “confederating” with other British North American colonies and provinces developed, the peoples of British Columbia were roughly a third each of Aboriginal, Asian, and European (with Kanakas and Blacks mostly counted among the Whites). After the Gold Rush By the mid-1860s, the Aboriginal world was in the midst of seismic transformation. The whirlwind of the gold rush years changed much in the region. Newcomer towns appeared and newcomer institutions arose. Newspapermen arrived with their printing presses: the New Westminster British Columbian and the Victoria Daily British Colonist gave voice to familiar Euro-North American ways of understanding law, order, civilization, politics, and power. Catering to a newcomer population, they had little or nothing to say to the majority of people in the region who were Aboriginal. According to a study of the impact of colonization on one Aboriginal nation, The most enduring effect of the gold rush was the entrenchment in language and thought of two categories of people, “shama” (semeʔ) and “Indian.” Within a short time the Nlaka’pamux language also had specific terms for Chinese, African American, and Jewish people, but all were shama. Before the arrival of Europeans, the concept of “Indian” simply did not exist. People were simply seyknmx. Andrea Laforet and Annie York, Spuzzum: Fraser Canyon Histories, 1808-1939 (Vancouver: UBC Press, 1998), 56-7. The colonial regime certainly distinguished the groups of people under its watch. It was suspicious of Americans, contemptuous of the Chinese, dismissive of Canadians, and uncertain about what it should do with or to the Aboriginal population. Douglas did not bring his treaty process to the mainland colony. Historians have theorized that he lacked the budget to do so, needed a larger bureaucracy to manage the time-consuming negotiations (the Nanaimo Treaty took two years to work out), and determined that drawing up generous reserves was a better and more effective way to address the problem than treaties. Cole Harris, Making Native Space: Colonialism, Resistance, and Reserves in British Columbia (Vancouver: UBC Press, 2002), 32-37. In 1864 Douglas retired, leaving the outlines of a Native policy but little more. Joseph Trutch (1826-1904) was appointed chief commissioner of Lands and Works and worked under Douglas’s successor on the mainland, Frederick Seymour (1820-1869), to move Aboriginal peoples out of the way of settlers and ranchers. When Seymour died, Anthony Musgrave (1828-1888) was appointed to the office of governor, with a mandate to unify the colonies. Musgrave married Trutch’s sister and the brothers-in-law worked to minimize Aboriginal title, a process that carried over into the Confederation era. Almost overnight, Aboriginal people lost a variety of liberties and freedom of movement. Douglas had promised to protect their villages, farms, and homes; Trutch actively sought to dispossess them. How could this happen only a few short years after the Nlaka’pamux, the Secwepemc, and the Okanagan demonstrated considerable military ability and capacity? The answer is a familiar one: smallpox. Key Points The British Columbia gold rush consists of distinct phases including the pre-1858 mining of gold by Aboriginal people, the 1858-59 stampede into the Fraser Canyon, and the 1860-63 Cariboo phenomenon. The gold rush brought roughly 20,000 newcomers into the mainland colony. This population comprised people from around the world. The presence of large numbers of Americans posed a threat to British sovereignty, and the Colonial Office responded with strategies aimed at entrenching British power. New colonial institutions and the physical disruption entailed in the gold rush had severe repercussions for Aboriginal peoples in south and central British Columbia. Figure 13.30 BC-New_Eldorado by DarkEvil is in the public domain . Figure 13.31 Chinese man washing gold by LibraryArchives is used under a CC-BY 2.0 license. Figure 13.32 Barnards Express at Yale by Ras67 is in the public domain . Figure 13.E1 Cariboo camel by Magnus Manske is in the public domain . 125 13.10 A Shrinking Aboriginal Landscape in the 1860s Figure 13.33 U’magalis (Margaret Wilson Frank), ca. 1914, a Kwagu’ł woman posed in pre-contact style by 20th century photographer Edward S. Curtis. Her abalone shell earrings indicate her noble status. We begin this chapter with a photograph (Figure 13.33) by well known “Native” photographer, Edward Curtis. His work has attracted controversy and criticism because of the way in which he staged each shot to create, in his view, a sense of “timelessness” and lack of progress. See Margaret B. Blackman, \"'Copying People': Northwest Coast Native Response to Early Photography,\" BC Studies, 52 (Winter 1981-82): 104. Smallpox, 1862-63 In the spring of 1862 “patient zero” stepped off a ship from San Francisco and into the streets of Victoria, the capital and trademart of the Colony of Vancouver Island. He was carrying smallpox and the harbour was crowded with Aboriginal traders. Rather than quarantine that community and apply the kinds of practices modelled 80 years earlier at Cumberland House (see Chapter 5 ), the colonial administration ordered the encampments cleared. They sent traders home to their villages up the coast, which proved to be a lethal error. Smallpox travelled with them and claimed about 20,000 lives, virtually all of them Aboriginal. A third to two-thirds of the Aboriginal population was gone almost overnight. This isn’t merely a statistical note: the psychological trauma can barely be imagined. Kekulis (pithouses) piled high with the dead were simply abandoned and allowed to collapse on themselves; above-ground houses and whole villages were torched in the hope that doing so would halt the march of smallpox. Survivors, particularly children, starved to death with no one left to feed them. There were literally bodies everywhere.  One account from the Cariboo gold district describes seeing canoes floating past on the Fraser River, filled with bloated corpses. This was near-extinction for many communities and some of them have never recovered. Smallpox made subsequent appearances in British North America and post-Confederation Canada, but they were minor events by comparison. The 1860s epidemic was, for once, well documented by newcomers and as a result historians have a good sense of its enormity, particularly for those who survived. In the Pentlatch village on Vancouver Island, there was one survivor. That individual was adopted into the K’ómoks (Comox), a Kwakwakw’wakw band that moved south into the vacuum left behind by smallpox. But the K’ómoks themselves were badly reduced. There was no Aboriginal community in the Comox Valley strong enough to resist the intrusion of newcomers in the decade that followed. The colonists stripped the hillsides of cedars and firs, they opened up the ground and its seams of coal, they claimed the fisheries, and confined the indigenous people to a postage-stamp sized reserve. The experience of the K’ómoks  was fairly typical of events as they unfolded on Vancouver Island and in British Columbia. Smallpox made space. The newcomers were themselves fewer in number than they had been at the height of the gold rush but some were optimistic about colonialism. The Chilcotin War The smallpox story continued with the Bute Inlet crisis (also known as the Chilcotin War or Bute Inlet Massacre). Thinking that a road to the Cariboo goldfields from the central coast would save both time and money and would open up new areas for resource extraction, a party of surveyors was sent up Bute Inlet in 1864 with an eye to exploring possible routes. When they encountered some resistance from the Tsilhqot’in (Chilcotin) people, the White surveyors threatened to introduce smallpox. Given the recent plague, this was both a cruel and stupid strategy. The Tsilhqot’in responded by killing 14 road workers and two other Whites in the region. In the colonial capital of New Westminster there was outrage, but it was tempered with concern that “civilized” people should respond to “savagery” with justice, not blind vengeance. With this event, as historian Tina Loo has demonstrated, the colonialists were defining themselves as representatives of British (not American) values and as bearing the responsibility to create what they regarded as a better society atop what they saw as a declining, irredeemable, and doomed Aboriginal world. Tina Loo, \"The Road from Bute Inlet: Crime and Colonial Identity in British Columbia,\" in Essays in the History of Canadian Law , vol.5: Crime and Criminal Justice , eds. Jim Phillips, Tina Loo, and Susan Lewthwaite (Toronto: Osgoode Society, 1994), 112-42. The White response to the incident was largely ineffectual until the leader of the Tsilhqot’in party, Klatsassin, and his immediate followers voluntarily surrendered themselves to the commissioner at Quesnel Forks on the understanding they would be treated as prisoners of war. Presumably they hoped to move to a diplomatic phase in the disagreement, but this did not occur. The colonial power arrested the eight men, charged most of them with murder, and hanged Klatsassin, his son, and three others. These two events — the smallpox epidemic of 1862-63 and the Chilcotin War of 1864 — point to a severe and abrupt reduction in Aboriginal power in the farthest West. But they also point to continued resistance to newcomer authority and newcomer willingness to exert authority through violence. From the perspective of the Tsilhqot’in, a people whose system of justice was traditionally more personal and whose system of government was kin-based, the very concept of a state that would seek out and execute people in their own territory who were, in their minds, guilty only of protecting that territory, could hardly have seemed more alien. The repressive laws that followed — restrictions on where Aboriginal peoples might live and what land they might own (the reserve system) — was only possible because of the epidemic. And it was made necessary (as the colonialists saw it) by the potential for violence and disorder on the part of the people whose lands were being seized. Figure 13.34 In the 1850s the colonial regime in British Columbia started carving out reserves and reducing the mobility of Aboriginal people like the St’at’imc of the Lillooet area. In the next decade the colony would reduce many of the reserves and then happily hand over responsibility for Aboriginal affairs to a distant and underinformed bureaucracy in Ottawa. The execution of Klatassin and his son Pierre, is conspicuously inconsistent with the character of Aboriginal-newcomer relations in the early part of the century. There were, to be sure, instances of gunboat diplomacy in earlier decades but the colonists’ discourse surrounding the Chilcotin War was one of conquest, not co-existence. Newcomers took full advantage of the space cleared by smallpox and reserves in the late 1860s. The colony, however, remained a nervous place. For Aboriginal people the fear of smallpox, measles, whooping cough, and other diseases, as well as the armed might of the newcomers, made them more receptive to the blandishments and promises of missionaries and government officials. Missionaries on the Mainland Missionary work across most of British North America until the mid-19th century was conducted by Catholics. The rise of the “non-conformist” denominations changed the landscape in Canadian and Maritime towns. In British Columbia, however, there was a missionary stampede to compete with the gold rush. Unofficially, the HBC regime favoured the Anglican Church and it was clearly preferred among the colonists. In the missionary field, however, the Anglicans faced the forces of the Oblate (Catholic), Methodist, Presbyterian, and even Salvation Army missionaries (although this last group did not arrive on the scene until after Confederation). The governors who succeeded Douglas — Seymour for the mainland, Arthur Edward Kennedy (1809-1883) for the island, and Musgrave for the united colony — were tolerant of all sects in terms of their mission activity. Their reasoning was that more missionaries meant a greater likelihood of “peace and order among the colony’s Natives.” Brett Christophers, Positioning the Missionary: John Booth Good and the Confluence of Cultures in Nineteenth-Century British Columbia (Vancouver: UBC Press, 1998), 10-14. Put in other terms, missionaries brought acceptance of the new colonial regime and compliance. The message of peace was not, however, consistently modelled by the missionaries. Competition broke out between the clergymen and accusations of poaching were not infrequent. Aboriginal groups were subjected to one largely intolerant version of Christianity after the next. In more than a few instances, however, Aboriginal peoples sought out missionary support. Oblates set up chapels throughout the interior of the colony but, in most locations, priests came by only infrequently. Enthusiasm for the latest missionary was, therefore, easily dissipated. In the case of the Nlaka’pamux at Lytton, their relationship with the Oblates soured when the itinerant Catholic clergy demanded control over the chapel; the Nlaka’pamux believed it was their property. The Oblate neglect of Lytton and their misunderstanding of Nlaka’pamux notions of ownership resulted in the band rejecting one set of missionaries and seeking out an Anglican alternative. Ibid. As was the case with Duncan and Crosby on the island and on the north coast, Interior missionary activity was usually predicated on an Aboriginal welcome. Those looking for explanations for the cataclysmic experiences they were witnessing turned to ministers who claimed to have answers. Aboriginal spirituality, moreover, was not monotheistic, so a European belief system (or elements of it) could be grafted on to traditional ideas. Missionaries, perhaps more than anything else, could function as cultural intermediaries. Throughout the fur trade era Aboriginal protocols applied; almost overnight British civil and criminal law was being enforced across British Columbia and up and down the coast as well. A resident cultural interpreter who might also provide some English language training was viewed in many communities as an asset. These were transformational days indeed. The naval base at Esquimalt tilted the power balance definitively toward the newcomers, at least on the coast. In the Interior, “Hanging Judge” Begbie was able to stifle Aboriginal resistance and enforce conformity to colonial law. As the populations thinned, these executions had greater and greater impact. One historian, Jean Barman, has described the policing of Aboriginal women’s morality on the streets of Victoria in the 1860s. Viewed as sexually “transgressive,” they were characterized as prostitutes and treated as such by the colonial legal system. More than that, their reputation (earned or not) made them useful bait in newcomer-run dance halls (where miners and dockworkers could be parted from their money) and in the pulpit (where clergymen could rail on about the moral dangers of frontier life). Jean Barman, \"Aboriginal Women on the Streets of Victoria: Rethinking Transgressive Sexuality during the Colonial Encounter,\" in Contact Zones: Aboriginal Women and Settler Women in Canada's Colonial Past, eds. Katie Pickles and Myra Rutherdale (Vancouver: UBC Press, 2005), 205-227. The 1860s saw, as well, continuing decline in the acceptance among non-Aboriginals of intermarriage. Prominent women like Lady Amelia Douglas, who grew up speaking Cree (her mother’s language) and Canadien French (her father’s), was only 16 when she married a rising HBC trader. In her dotage she would be exposed to the pearl-clutching racist snobbery and outright racism of settler society, despite being the late governor’s widow. The advent of prejudices of this kind paved the way for the marginalization of Aboriginal people generally in the last quarter of the 19th century. Key Points The 1862-63 smallpox epidemic claimed one- to two-thirds of the Aboriginal population in British Columbia and Vancouver Island, significantly reducing the ability of the indigenous peoples to resist further colonial intrusion. Efforts at resistance continued, as in the Chilcotin, but these were met with executions of the leadership. The process of cultural change imposed by the colonial regime took many forms, including missionary Christianization, Western-style education, new land-ownership strategies, stripping of resources, and the application of a foreign judicial system. Figure 13.33 A Kwakwaka’wakw girl wearing abalone earrings and a cedar bark cloak by Magnus Manske is in the public domain . Figure 13.34 Charles Gentile-Lillooet Indians by Themightyquill is in the public domain . This image cannot be used for commercial purposes. It is available from Library and Archives Canada under the reproduction reference number C-088930. 126 13.11 Summary Figure 13.35 A staged photograph from a Kwakwaka’wakw potlatch in the early 20th century shows the survival and resilience of northwest coast cultural practices. (Photo by Edward S. Curtis, ca. 1915.) The territory that became British Columbia joined the Canadian federation in 1871. Until that time, however, Canada was very distant and rather foreign and mostly irrelevant. The orientations of the Pacific Northwest were toward Asia, the Pacific Islands, Mexico and Chile, and round Cape Horn to England. For the many Aboriginal peoples and cultures in the region, Canada was a country with which they had effectively no contact and hardly more knowledge. The challenge, then, is to understand these pre-Confederation years as an era in which other priorities and possibilities presented themselves. The colonies of British Columbia and Vancouver Island were expensive to maintain, especially as the gold rush ended and the population diminished. From a peak of 10,000 the Cariboo population fell to about 1,000 by 1870. It is estimated that there were only about 2,000 Chinese left in the colony. The Cariboo Wagon Road had cost the mainland colony dearly and pitched it into debt. The capital at New Westminster — dominated by merchant houses, a colonial elite, and a Royal Engineers’ community ensconced at Sapperton — was desperate to hold onto its administrative role. In 1866 the mainland and the island colonies were consolidated. Bits and pieces of New Caledonia, the Stikeen Territory, the Colony of the Queen Charlotte Islands, and the post-Rupert’s Land North-Western Territory had been gradually grafted onto British Columbia and this was the final piece. And — much like Lower Canada in 1841 — Vancouver Island inherited British Columbia’s debt. Figure13.36 Newspaperman John Robson imported the vocabulary of Upper Canadian reform politics to New Westminster. The political culture that developed west of the Rockies was, like the population, multifaceted. There were powerful British themes promoted by the Colonial Office alongside Canadian traditions brought west by Upper Canadians like the reformer John Robson. There was a democratic tradition that can be ascribed, in part, to the Americans and Nova Scotians, such as Amor de Cosmos, a harsh critic of the squirearchy in Victoria. The HBC’s tradition of hierarchy and discipline was increasingly caricatured as a West Coast variant of the Family Compact. It was in some respects — in terms of the close bonds between the chief administrator and the members of the Victoria elite — even more of a family compact than ever existed in Upper Canada. Well-positioned individuals like Joseph Trutch were vitriolic in their opposition to democratic reforms. The four years after Confederation in the East would see the colonists in British Columbia pulled in different directions. While that debate was underway, Aboriginal communities continued to stagger from hardship to hardship. As early as 1852 Douglas had witnessed privation and perhaps starvation among the Lekwungen with whom he had signed an early treaty. They were no longer at the centre of the local economy, a change that had taken place in a matter of 10 years. It is possible to argue that the fur trade on the West Coast was a period of mutual benefit. This is the position taken by Robin Fisher in his landmark book Contact and Conflict , in 1977. Robin Fisher, Contact and Conflict: Indian-European Relations, 1774-1890 , 2nd ed. (Vancouver: UBC Press, 1992). He argues that both sides profited from the trade and whatever cultural change occurred in Aboriginal societies was mediated and controlled by Aboriginal peoples themselves. The absence of missionaries and/or imperial power until the 1840s is at the heart of this argument. Other historians have taken the position that the epidemic waves beginning in the 1780s, if not earlier, meant that the odds were stacked against Aboriginal ability to adapt. Still others point to the extent of Aboriginal authority in the fur trade, the extent to which indigenous people were able to exploit newcomer dependence, and the ways in which Aboriginal peoples managed newcomer behaviours as a sign of ongoing autonomy. The gold rush of 1858 and the smallpox epidemic of 1862 rendered much of this moot. A territory over which Britain and Spain were once prepared to go to war had so fallen off the European radar that the events of 1858-63 threw it all up in the air again. As Douglas and his colleagues in the HBC retired from public life and passed away, links with the pre-gold rush past evaporated. For the British Columbians of 1858-1871 there was not much in the way of a history to their colony, and what history they saw they generally didn’t like. The future was the thing, and they would sacrifice much to get there. Key Terms Cariboo Wagon Road: A road constructed from 1860 to 1885 to connect the Lower Mainland of British Columbia with the Cariboo goldfields. The original 1860-63 road ran from Port Douglas at the north end of Harrison Lake via Lillooet to Clinton and then north across the Cariboo Plateau to Alexandria. An amended version in 1865 connected Yale to Ashcroft and then Clinton and the older road, having passed through the Fraser Canyon. Chilcotin War: Also referred to as the Chilcotin Massacre, Chilcotin Uprising, and Bute Inlet Massacre. Occurred in 1864 when Tsilqot’in people asserted their control of their ancestral territory by murdering several members of a road-building crew and some colonists. The colonial authorities responded with a fruitless and expensive campaign that only ended when several of the Tsilqot’in leaders presented themselves for negotiations and were summarily arrested and subsequently hanged. Church Missionary Society (CMS): Established in London, England, in 1799. Began sending Anglican missionaries to Rupert’s Land in the 1820s. In 1857 William Duncan was dispatched to the northwest coast on behalf of the CMS. Douglas treaties: Also known as the Fort Victoria Treaties, 14 agreements between the Colony of Vancouver Island (under the leadership of James Douglas) and Aboriginal communities. These were one-time land purchase treaties that protected Aboriginal village sites and fields, as well as access to resources. Fifty-Four Forty or Fight!: Slogan coined in 1844 or 1845 by American expansionists eager to claim the whole of the Oregon Territory to the Alaska panhandle (54°40’N). Fort George: The name of two forts in the Pacific northwest. The first replaced the American Fort Astoria near the mouth of the Columbia River (at what is now Astoria, Oregon), and the  second was established in 1807 by Simon Fraser at the site of what is now the city of Prince George, British Columbia. Fort Rupert: Located at the north end of Vancouver Island near modern-day Port Hardy. Established by the HBC as a coal harvesting/mining experiment. It is an important Kwagu’ł community today and should not be confused with the city of Prince Rupert, much farther north on the mainland, nor with Waskaganish in northern Quebec, which was formerly called Fort Rupert. Fort Vancouver: An HBC fort established in 1824-25 about 60 kilometres up the Columbia River from Fort George (formerly Fort Astoria). Now the site of the city of Vancouver, Washington. The city of Vancouver, British Columbia, was never a fort and there is no relation between the two other than the name. Fraser River gold rush: A mining boom beginning in 1858 characterized by large numbers of independent prospectors using simple mining technologies to extract gold flakes, dust, and nuggets from the Fraser River. This gold rush was superseded by better finds in the Cariboo in the 1860s. gold fever: Term used to describe the opportunistic individualism found in gold rushes. Gold was discovered and mined by independent prospectors around the Pacific Rim beginning in Australia from the 1840s, California from 1848, a brief flurry in Haida Gwaii in the 1850s followed by the British Columbia rush from 1858-63, and New Zealand in the 1860s. After Confederation there were smaller rushes in British Columiba  and these were surpassed by the Klondike/Alaska gold rush of 1896-1909. The close succession of gold rushes meant that many of the personnel in the goldfields had experience in other gold rushes and many of the gold field institutions followed in their wake. gunboat diplomacy: The achievement of colonial political goals in dealings with Aboriginal communities by means of superior naval firepower. land-based fur trade: Refers to the HBC’s strategy in the 1830s to establish permanent fur-trading establishments on land, rather than rely on ships cruising the coast looking for trade. (See maritime-based fur trade .) Manifest Destiny: Widespread belief in the United States during the 19th century that America was destined — that is, intended by God — to conquer and occupy most if not all of North America. maritime-based fur trade: The European and American practice dating from the 1770s of trading up and down the coast from ships, rather than establishing fixed positions on land. Nootka Crisis: A diplomatic incident due to conflicting between Spanish and British claims to sovereignty and the right to trade along the Pacific northwest coast. The disagreement was resolved in the Nootka Conventions of 1790-1794. Despite the negotiations taking place at Yuquot, Mowachat interests and claims to sovereignty were disregarded. Oregon Treaty, 1846: Settled the boundary between the United States and the British territories west of the Rockies at 49°N. potlatch: An Aboriginal ceremonial event common across the Pacific Northwest. Involves the giving of gifts by the host to mark a life event like an inheritance or succession. Puget Sound Agricultural Company (PSAC): Established in 1838-39 by the HBC to provide food for its posts and surpluses for sale to the Russian American Company. Russian American Company (RAC): Chartered in 1799, the RAC was principally focused on the sea otter fur trade and also established outposts in Alta California and Hawaii. sea otter pelts: On the West Coast the principal fur traded by Aboriginal communities to European and American buyers for sale in the Chinese marketplace. Suggested Readings Barman, Jean. “Taming Aboriginal Sexuality: Gender, Power, and Race, 1850-1900.” BC Studies ,115/116 (Autumn/Winter 1997): Audio .  Belshaw, John Douglas. “The West We Have Lost: First Nations Depopulation.” In Becoming British Columbia: A Population History, 72-90 . Vancouver: UBC Press, 2010. Harris, Cole. “The Native Land Policies of Governor James Douglas.” BC Studies 174 (Summer 2012): 101-122. Perry, Adele. “Hardy Backwoodsmen, Wholesome Women, and Steady Families: Immigration and the Construction of a White Society in Colonial British Columbia, 1849–1871.” Histoire Sociale/Social History 33, no.66 (November 2000): 343-360. Wickwire, Wendy C. “To See Ourselves as the Other’s Other: Nlaka’pamux Contact Narratives.” Canadian Historical Review LXXV, no.1 (March 1994): 1-20. Figure 13.35 Showing of masks at Kwakwaka’wakw potlatch by User:Deadstar is in the public domain . Figure 13.36 Portrait de John Robson by Digging.holes is in the public domain . XIV Chapter 14. The 1860s: Confederation and Its Discontents 127 14.1 Introduction Figure 14.1 Images on stamps were common and widely shared representations of an emerging British North American identity. In the 1850s and 1860s, cracks began to appear in the relationship between British North America and Britain. The 1859 New Brunswick stamp shown in Figure 14.1 makes two revealing breaks with imperial norms. First, its value is shown in cents, not British pence. Currency issues had plagued colonies in the West Indies and the rest of the British Empire for centuries, and there was no unity on this subject even among the colonies of British North America at mid-century. Second, the new postmaster for New Brunswick, Charles Connell, unsure of the shifting protocols, scandalously chose to put his own face on the stamp, rather than Queen Victoria’s. This was too much change far too soon, and Connell demonstrated remorse by buying up as many of the stamps as could be found and burning them on his front lawn. Connell wasn’t the only one receiving mixed signals from Britain. The Colonial Office was increasingly demanding loyalty while services and benefits were being systematically withdrawn. Free trade and greater political autonomy obliged the colonial leadership in British North America to think more strategically about their future, including alternative political structures. But it would be a mistake to think that Confederation was the only outcome being considered, or that it was an inevitability. It was neither. Several options presented themselves, the foremost being joining the United States. Together or separately, by the 1860s all of the colonies at some point considered annexation. Barely a decade had passed since the campaign for annexation had been at the height of popular discourse and held its widest appeal. Since then, the idea had lost much of its support, but there were still many enthusiasts for the idea. As we shall see, it was an option considered very seriously in the Red River Colony as the prospect of union with the Americans held the allure of better access to large and expanding markets. Even in Canada it was easy to see that union with, say, Prince Edward Island would never have the same economic impact as closer trade ties with the United States. Another option was the status quo, which was the choice Newfoundland made for another 80 years. Carrying on without change in the Province of Canada would mean thrashing through some pernicious constitutional and operational difficulties, but couldn’t be ruled out. Those who supported this option looked to other jurisdictions — Italy comes to mind — that had survived and even thrived under governments made of fragile coalitions. Many of Confederation’s critics, Nova Scotia’s Joseph Howe for one, argued for this: “Now my proposition is very simple,” he said, “It is to let well enough alone.” Quoted in Ged Martin, \"The Case Against Canadian Confederation 1864-1867,\" in The Causes of Canadian Confederation (Fredericton: Acadiensis Press, 1990), 27. Smaller unions were also considered. Maritime union was, briefly, a very real prospect, one that would have created a single colony out of three (four if Newfoundland joined in). Union was thrust on the two West Coast colonies in 1866: Vancouver Island became just another region in the colony of British Columbia, although it did win the capital away from the mainland. And in Canada proper, George Brown made it clear that the minimal change he would accept in exchange for his cooperation was a federal reorganization of Canada West and East. This would have necessitated the dissolution of the Act of Union only to create a voluntary union of equal partners with separate legislatures and a central administration. From eight separate colonies in 1865, four could have coalesced by 1867. One must ask, too, if any of these solutions really addressed the question at hand. If the issue was replacing British trade and/or American reciprocity, then the colonies could have pursued a customs union (sometimes called by the German term, zollverein ). If it was the business of getting a loan to build a railway, then better finances, not a constitutional change, would do the job. If the issue was the defence of British North America against the Americans, who housed a huge post-Civil War army, then the only conceivable answer was closer ties with Britain, not semi-independence. In short, under these alternative scenarios, the 1870s could have opened with a federal Canada stretching from Lake Huron to the Gaspé, a reunited Acadia on the East Coast, and Red River (or perhaps Assiniboia) added on to the U.S. Midwest. British Columbia could well have vanished into what, in the 20th century, was promoted as Cascadia, a region stretching from California to Alaska. Or the colonies might have clung more tightly to the hem of Mother Britain’s skirt in an imperial federation and eschewed any kind of union at all. Every one of these options was serious considered in the 1860s. The solution at which political leaders arrived was influenced mainly by external factors and specific ambitions. This chapter surveys those elements and the implications of the new constitutional configuration. It also explores the emerging relationship between Canada and the West, without which the proposal for a union of colonies might not have proceeded. (Turning it on its head, if there had been no colonial union, there would likely have been no Canadian annexation of the West either.) Finally, this chapter pays some attention to the changes underway in the economy among Aboriginal peoples and culturally in British North America as the 1860s drew to a close. It is important to realize that while this decade is usually dominated in Canadian history by the achievement of a new constitutional arrangement, it was also a springboard for vast, sweeping changes in social and economic life. By the 1880s, Canada as a whole was experiencing a full-blown industrial revolution while Aboriginal peoples on the Plains faced famine and landlessness. These and other critical moments in Canada’s history have their roots in the 1860s. Figure 14.2 William Raphael’s Behind Bonsecours Market, Montreal (ca. 1866) shows women and children in a public space, ships under sail and steam, farm products, and a sense of both busy-ness and leisure. \n",
      "-----------\n",
      "Broadly describe regional Aboriginal cultures and their differences.\n",
      "Explain outsider interest in the region from 1740 to Confederation.\n",
      "Describe some of the advantages and disadvantages held by, respectively, the Russians, the Spanish, the British, and the Americans.\n",
      "Demonstrate an understanding of Aboriginal autonomy and resistance from the 18th century through the 1860s.\n",
      "Explain the colonial administrations’ approach to Aboriginal peoples.\n",
      "Describe the economies of the two West Coast colonies.\n",
      "Account for and describe the social and political fracture lines in the region.\n",
      "Describe and comment on the gold rush and its effects.\n",
      "--------------------------\n",
      "The first part of this text focused on the pre-Confederation history of Indigenous peoples’ interaction with the Canadian government. This serves as the foundational context to develop an understanding of Indigenous peoples’ interactions with business interests and the legal system. Some interactions with industry are positive. Many are not. Significant tracts of British Columbia have not been ceded by Indigenous groups (see the section on The Numbered Treaties ). These lands frequently find themselves as the sites of resource extraction (forestry, fishing, mining), thoroughfares (pipelines), or as collateral damage in other projects (pollution runoff, hydro dam flooding). The Supreme Court of Canada has developed the “Duty to Consult” in response to successful Indigenous arguments that the Crown has acted inconsistently with Indigenous rights. These rights arise from Indigenous peoples occupying British Columbia first. In 1982, these rights were further reaffirmed when, in Canada’s new constitution , section 35 was included: 35 (1) The existing aboriginal and treaty rights of the aboriginal peoples of Canada are hereby recognized and affirmed. These developments have been positive, but a lot remains to be explored. What is “consultation”? Who consults whom? When has consultation been achieved? What are government’s obligations? What are the current issues facing the “Duty to Consult”? The following text explores these questions and more, but you’ll find that plenty of ambiguity remains in this area of law. For Indigenous peoples and Industry that wishes to respectfully work on their territory, much work remains to be done in ensuring the “Duty to Consult” does not serve as cover to affirm exploitative practices. 19 The Nature of Aboriginal Title \n",
      "-----------\n",
      "Describe the nature of Aboriginal title and the Duty to Consult\n",
      "Analyze current issues related to the Duty to Consult\n",
      "Consider best practices for industry to respectfully engage with Indigenous communities\n",
      "--------------------------\n",
      "8.4. Theoretical Perspectives on Media and Technology Understand and discuss how media and technology are analyzed through various sociological perspectives. Introduction to Media and Technology How many good friends do you have? How many people do you meet for coffee or a movie? How many would you call with news about an illness or invite to your wedding? Now, how many “friends” do you have on Facebook? Technology has changed how we interact with each other. It has turned “friend” into a verb and has made it possible to share mundane news (“My dog just threw up under the bed! Ugh!”) with hundreds or even thousands of people who might know you only slightly, if at all. Through the magic of Facebook, you might know about an old elementary school friend’s new job before her mother does. By thinking of everyone as fair game in networking for personal gain, we can now market ourselves professionally to the world with LinkedIn. At the same time that technology is expanding the boundaries of our social circles, various media are also changing how we perceive and interact with each other. We do not only use Facebook to keep in touch with friends; we also use it to “like” certain TV shows, products, or celebrities. Even television is no longer a one-way medium but an interactive one. We are encouraged to tweet, text, or call in to vote for contestants in everything from singing competitions to matchmaking endeavours — bridging the gap between our entertainment and our own lives. How does technology change our lives for the better? Or does it? When you tweet a social cause or cut and paste a status update about cancer awareness on Facebook, are you promoting social change? Does the immediate and constant flow of information mean we are more aware and engaged than any society before us? Or are TV reality shows and talent competitions today’s version of ancient Rome’s “bread and circuses” — distractions and entertainment to keep the lower classes indifferent to the inequities of our society? Do media and technology liberate us from gender stereotypes and provide us with a more cosmopolitan understanding of each other, or have they become another tool in promoting misogyny ?  Is ethnic and gay and lesbian intolerance being promoted through a ceaseless barrage of minority stereotyping in movies, video games, and websites? These are some of the questions that interest sociologists. How might we examine these issues from a sociological perspective? A structural functionalist would probably focus on what social purposes technology and media serve. For example, the web is both a form of technology and a form of media, and it links individuals and nations in a communication network that facilitates both small family discussions and global trade networks. A functionalist would also be interested in the manifest functions of media and technology, as well as their role in social dysfunction. Someone applying the critical perspective would probably focus on the systematic inequality created by differential access to media and technology. For example, how can Canadians be sure the news they hear is an objective account of reality, unsullied by moneyed political interests? Someone applying the interactionist perspective to technology and the media might seek to understand the difference between the real lives we lead and the reality depicted on “reality” television shows, such as the U.S., based but Canadian MTV production Jersey Shore, with up to 800,000 Canadian viewers (Vlessing, 2011). Throughout this chapter, we will use our sociological imagination to explore how media and technology impact society. 8.1. Technology Today Figure 8.2. Technology is the application of science to address the problems of daily life, from hunting tools and agricultural advances, to manual and electronic ways of computing, to today’s tablets and smartphones. [Long Description] (Photo (a) courtesy of Wikimedia Commons; Photo (b) courtesy Martin Pettitt/flickr; Photo (c) courtesy Whitefield d./flickr; Photo (d) courtesy Andrew Parnell/flickr; Photo (e) courtesy Jemimus/flickr; Photo (f) courtesy digitpedia/flickr) It is easy to look at the latest sleek tiny Apple product and think that technology is only recently a part of our world. But from the steam engine to the most cutting-edge robotic surgery tools, technology describes the application of science to address the problems of daily life. We might look back at the enormous and clunky computers of the 1970s that had about as much storage as an iPod Shuffle and roll our eyes in disbelief. But chances are 30 years from now our skinny laptops and MP3 players will look just as archaic. What Is Technology? While most people probably picture computers and cell phones when the subject of technology comes up, technology is not merely a product of the modern era. For example, fire and stone tools were important forms of technology developed during the Stone Age. Just as the availability of digital technology shapes how we live today, the creation of stone tools changed how premodern humans lived and how well they ate. From the first calculator, invented in 2400 BCE in Babylon in the form of an abacus, to the predecessor of the modern computer, created in 1882 by Charles Babbage, all of our technological innovations are advancements on previous iterations. And indeed, all aspects of our lives today are influenced by technology. In agriculture, the introduction of machines that can till, thresh, plant, and harvest greatly reduced the need for manual labour, which in turn meant there were fewer rural jobs, which led to the urbanization of society, as well as lowered birthrates because there was less need for large families to work the farms. In the criminal justice system, the ability to ascertain innocence through DNA testing has saved the lives of people on death row. The examples are endless: technology plays a role in absolutely every aspect of our lives. Technological Inequality Figure 8.3. Some schools sport cutting-edge computer labs, while others sport barbed wire. Is your academic technology at the cusp of innovation, relatively disadvantaged, or somewhere in between? (Photo courtesy of Carlos Martinez/flickr) As with any improvement to human society, not everyone has equal access. Technology, in particular, often creates changes that lead to ever greater inequalities. In short, the gap gets wider faster. This technological stratification has led to a new focus on ensuring better access for all. There are two forms of technological stratification. The first is differential class-based access to technology in the form of the digital divide . This digital divide has led to the second form, a knowledge gap , which is, as it sounds, an ongoing and increasing gap in information for those who have less access to technology. The Organisation for Economic Co-operation and Development (OECD) defines the digital divide as “the gap between individuals, households, businesses and geographic areas at different socio-economic levels with regard to both their opportunities to access information and communication technology (ICTs) and to their use of the Internet for a wide variety of activities.” (OECD, 2001, p.5) For example, students in well-funded schools receive more exposure to technology than students in poorly funded schools. Those students with more exposure gain more proficiency, making them far more marketable in an increasingly technology-based job market, leaving our society divided into those with technological knowledge and those without. Even as we improve access, we have failed to address an increasingly evident gap in e-readiness, the ability to sort through, interpret, and process knowledge (Sciadas, 2003). Since the beginning of the millennium, social science researchers have tried to bring attention to the digital divide, the uneven access to technology along race, class, and geographic lines. The term became part of the common lexicon in 1996, when then U.S. Vice-President Al Gore used it in a speech. In part, the issue of the digital divide had to do with communities that received infrastructure upgrades that enabled high-speed internet access, upgrades that largely went to affluent urban and suburban areas, leaving out large swaths of the country. At the end of the 20th century, technology access was also a big part of the school experience for those whose communities could afford it. Early in the millennium, poorer communities had little or no technology access, while well-off families had personal computers at home and wired classrooms in their schools. In Canada we see a clear relationship between youth computer access and use and socioeconomic status in the home. As one study points out, about a third of the youth whose parents have no formal or only elementary school education have no computer in their home compared to 13% of those whose parent has completed high school (Looker and Thiessen, 2003). In the 2000s, however, the prices for low-end computers dropped considerably, and it appeared the digital divide was ending. And while it is true that internet usage, even among those with low annual incomes, continues to grow, it would be overly simplistic to say that the digital divide has been completely resolved. In fact, new data from the Pew Research Center (2011) suggest the emergence of a new divide. As technological devices gets smaller and more mobile, larger percentages of minority groups are using their phones to connect to the internet. In fact, about 50% of people in these minority groups connect to the web via such devices, whereas only one-third of whites do (Washington, 2011). And while it might seem that the internet is the internet, regardless of how you get there, there is a notable difference. Tasks like updating a résumé or filling out a job application are much harder on a cell phone than on a wired computer in the home. As a result, the digital divide might not mean access to computers or the internet, but rather access to the kind of online technology that allows for empowerment, not just entertainment (Washington, 2011). Liff and Shepard (2004) found that although the gender digital divide has decreased in the sense of access to technology, it remained in the sense that women, who are accessing technology shaped primarily by male users, feel less confident in their internet skills and have less internet access at both work and home. Finally, Guillen and Suarez (2005) found that the global digital divide resulted from both the economic and sociopolitical characteristics of countries. Planned Obsolescence: Technology That’s Built to Crash Figure 8.4. People have trouble keeping up with technological innovation. But people may not be to blame, as manufacturers intentionally develop products with short life spans. (Photo courtesy of Troy Kelly/flickr) Chances are your mobile phone company, as well as the makers of your DVD player and MP3 device, are all counting on their products to fail. Not too quickly, of course, or consumers would not stand for it — but frequently enough that you might find that when the built-in battery on your iPod dies, it costs far more to fix it than to replace it with a newer model. Or you find that the phone company emails you to tell you that you’re eligible for a free new phone because yours is a whopping two years old. Appliance repair people say that while they might be fixing some machines that are 20 years old, they generally are not fixing the ones that are seven years old; newer models are built to be thrown out. This is called planned obsolescence , and it is the business practice of planning for a product to be obsolete or unusable from the time it is created ( The Economist, 2009). To some extent, this is a natural extension of new and emerging technologies. After all, who is going to cling to an enormous and slow desktop computer from 2000 when a few hundred dollars can buy one that is significantly faster and better? But the practice is not always so benign. The classic example of planned obsolescence is the nylon stocking. Women’s stockings — once an everyday staple of women’s lives — get “runs” or “ladders” after a few wearings. This requires the stockings to be discarded and new ones purchased. Not surprisingly, the garment industry did not invest heavily in finding a rip-proof fabric; it was in their best interest that their product be regularly replaced. Those who use Microsoft Windows might feel that they, like the women who purchase endless pairs of stockings, are victims of planned obsolescence. Every time Windows releases a new operating system, there are typically not many changes that consumers feel they must have. However, the software programs are upwardly compatible only. This means that while the new versions can read older files, the old version cannot read the newer ones. Even the ancillary technologies based on operating systems are only compatible upward. In 2014, the Windows XP operating system, off the market for over five years, stopped being supported by Microsoft when in reality is has not been supported by newer printers, scanners, and software add-ons for many years. Ultimately, whether you are getting rid of your old product because you are being offered a shiny new free one (like the latest smartphone model), or because it costs more to fix than to replace (like an iPod), or because not doing so leaves you out of the loop (like the Windows system), the result is the same. It might just make you nostalgic for your old Sony Walkman and VCR. But obsolescence gets even more complex. Currently, there is a debate about the true cost of energy consumption for products. This cost would include what is called the embodied energy costs of a product. Embodied energy is the calculation of all the energy costs required for the resource extraction, manufacturing, transportation, marketing, and disposal of a product. One contested claim is that the energy cost of a single cell phone is about 25% of the cost of a new car. We love our personal technology but it comes with a cost. Think about the incredible social organization undertaken from the idea of manufacturing a cell phone through to its disposal after about two years of use (Kedrosky, 2011). Figure 8.5. The United Nations estimates that Canadians generated 25 kg of electronic waste per person in 2012 (StEP, 2012). About 70% of e-waste is either illegally disposed of or rudimentarily processed in poorer Asian and African countries. Workers in e-waste salvage operations are constantly exposed to toxic substances like lead, mercury, cadmium, arsenic, and flame retardants that are byproducts of dismantling components. (Photo courtesy of Curtis Palmer/Flickr) 8.2. Media and Technology in Society Figure 8.6. The modern printing press (as well as its dated counterparts) embodies the intertwined nature of technology and media. (Photo courtesy of Anuj Biyani/flickr) Technology and the media are interwoven, and neither can be separated from contemporary society in most developed and developing nations. Media is a term that refers to all print, digital, and electronic means of communication. From the time the printing press was created (and even before), technology has influenced how and where information is shared. Today, it is impossible to discuss media and the ways that societies communicate without addressing the fast-moving pace of technology. Twenty years ago, if you wanted to share news of your baby’s birth or a job promotion, you phoned or wrote letters. You might tell a handful of people, but probably you would not call up several hundred, including your old high school chemistry teacher, to let them know. Now, by tweeting or posting your big news, the circle of communication is wider than ever. Therefore, when we talk about how societies engage with technology we must take media into account, and vice versa. Technology creates media. The comic book you bought your daughter at the drugstore is a form of media, as is the movie you rented for family night, the internet site you used to order dinner online, the billboard you passed on the way to get that dinner, and the newspaper you read while you were waiting to pick up your order. Without technology, media would not exist; but remember, technology is more than just the media we are exposed to. Categorizing Technology There is no one way of dividing technology into categories. Whereas once it might have been simple to classify innovations such as machine-based or drug-based or the like, the interconnected strands of technological development mean that advancement in one area might be replicated in dozens of others. For simplicity’s sake, we will look at how the U.S. Patent Office, which receives patent applications for nearly all major innovations worldwide, addresses patents. This regulatory body will patent three types of innovation. Utility patents are the first type. These are granted for the invention or discovery of any new and useful process, product, or machine, or for a significant improvement to existing technologies. The second type of patent is a design patent . Commonly conferred in architecture and industrial design, this means someone has invented a new and original design for a manufactured product. Plant patents , the final type, recognize the discovery of new plant types that can be asexually reproduced. While genetically modified food is the hot-button issue within this category, farmers have long been creating new hybrids and patenting them. A more modern example might be food giant Monsanto, which patents corn with built-in pesticide (U.S. Patent and Trademark Office, 2011). Such evolving patents have created new forms of social organization and disorganization. Efforts by Monsanto to protect its patents have led to serious concerns about who owns the food production system, and who can afford to participate globally in this new agrarian world. This issue was brought to a head in a landmark Canadian court case between Monsanto and Saskatchewan farmer Percy Schmeiser. Schmeiser found Monsanto’s genetically modified “Roundup Ready” canola growing on his farm. He saved the seed and grew his own crop, but Monsanto tried to charge him licensing fees because of their patent. Dubbed a true tale of David versus Goliath, both sides are claiming victory (Mercola, 2011; Monsanto, N.d.). What is important to note is that through the courts, Monsanto established its right to the ownership of its genetically modified seeds even after multiple plantings. Each generation of seeds harvested still belonged to Monsanto. For millions of farmers globally, such a new market model for seeds represents huge costs and dependence on a new and evolving corporate seed supply system. Anderson and Tushman (1990) suggest an evolutionary model of technological change , in which a breakthrough in one form of technology leads to a number of variations. Once those are assessed, a prototype emerges, and then a period of slight adjustments to the technology, interrupted by a breakthrough. For example, floppy disks were improved and upgraded, then replaced by zip disks, which were in turn improved to the limits of the technology and were then replaced by flash drives. This is essentially a generational model for categorizing technology, in which first-generation technology is a relatively unsophisticated jumping-off point leading to an improved second generation, and so on. Types of Media and Technology Media and technology have evolved hand in hand, from early print to modern publications, from radio to television to film. New media emerge constantly, such as we see in the online world. Print Newspaper Early forms of print media, found in ancient Rome, were hand-copied onto boards and carried around to keep the citizenry informed. With the invention of the printing press, the way that people shared ideas changed, as information could be mass produced and stored. For the first time, there was a way to spread knowledge and information more efficiently; many credit this development as leading to the Renaissance and ultimately the Age of Enlightenment. This is not to say that newspapers of old were more trustworthy than the Weekly World News and National Enquirer are today. Sensationalism abounded, as did censorship that forbade any subjects that would incite the populace. The invention of the telegraph, in the mid-1800s, changed print media almost as much as the printing press. Suddenly information could be transmitted in minutes. As the 19th century became the 20th, American publishers such as Hearst redefined the world of print media and wielded an enormous amount of power to socially construct national and world events. Of course, even as the Canadian media empires of Max Aitken (Lord Beaverbrook) and Roy Thomson or the U.S. empires of William Randolph Hearst and Joseph Pulitzer were growing, print media also allowed for the dissemination of counter-cultural or revolutionary materials. Internationally, Vladimir Lenin’s Irksa ( The Spark ) newspaper was published in 1900 and played a role in Russia’s growing communist movement (World Association of Newspapers, 2004). With the invention and widespread use of television in the mid-20th century, newspaper circulation steadily dropped off, and in the 21st century, circulation has dropped further as more people turn to internet news sites and other forms of new media to stay informed. This shift away from newspapers as a source of information has profound effects on societies. When the news is given to a large diverse conglomerate of people, it must (to appeal to them and keep them subscribing) maintain some level of broad-based reporting and balance. As newspapers decline, news sources become more fractured, so that the audience can choose specifically what it wants to hear and what it wants to avoid. But the real challenge to print newspapers is that revenue sources are declining much faster than circulation is dropping. With an anticipated decline in revenue of over 20% by 2017, the industry is in trouble (Ladurantaye, 2013). Unable to compete with digital media, large and small newspapers are closing their doors across the country. Something to think about is the concept of embodied energy mentioned earlier. The print newspapers are responsible for much of these costs internally. Digital media has downloaded much of these costs onto the consumer through personal technology purchases. Television and Radio Radio programming obviously preceded television, but both shaped people’s lives in much the same way. In both cases, information (and entertainment) could be enjoyed at home, with a kind of immediacy and community that newspapers could not offer. Prime Minister Mackenzie King broadcast his radio message out to Canada in 1927. He later used radio to promote economic cooperation in response to the growing socialist agitation against the abuses of capitalism both outside and within Canada (McGivern, 1990). Radio was the first “live” mass medium. People heard about the Japanese attack on Pearl Harbor as it was happening. Hockey Night in Canada was first broadcast live in 1932. Even though people were in their own homes, media allowed them to share these moments in real time. Unlike newspapers, radio is a survivor. As Canada’s globally renowned radio marketing guru Terry O’Reilly asserts, radio survives “because it is such a ‘personal’ medium. Radio is a voice in your ear. It is a highly personal activity.” He also points out that “radio is local. It broadcasts news and programming that is mostly local in nature. And through all the technological changes happening around radio, and in radio, be it AM moving to FM moving to satellite radio and internet radio, basic terrestrial radio survives into another day” (O’Reilly, 2014). This same kind of separate-but-communal approach occurred with other entertainment too. School-aged children and office workers still gather to discuss the previous night’s instalment of a serial television or radio show. The influence of Canadian television has always reflected a struggle with the influence of U.S. television dominance, the language divide, and strong federal government intervention into the industry for political purposes. There were thousands of televisions in Canada receiving U.S. broadcasting a decade before the first two Canadian stations began broadcasting in 1952 (Wikipedia, N.d.). Public television, in contrast, offered an educational nonprofit alternative to the sensationalization of news spurred by the network competition for viewers and advertising dollars. Those sources — PBS (Public Broadcasting Service) in the United States, the BBC (British Broadcasting Corporation), and CBC (Canadian Broadcasting Corporation), which straddled the boundaries of public and private, garnered a worldwide reputation for quality programming and a global perspective. Al Jazeera, the Arabic independent news station, has joined this group as a similar media force that broadcasts to people worldwide. The impact of television on North American society is hard to overstate. By the late 1990s, 98% of homes had at least one television set. All this television has a powerful socializing effect, with these forms of visual media providing reference groups while reinforcing social norms, values, and beliefs. Film The film industry took off in the 1930s, when colour and sound were first integrated into feature films. Like television, early films were unifying for society: As people gathered in theatres to watch new releases, they would laugh, cry, and be scared together. Movies also act as time capsules or cultural touchstones for society. From tough-talking Clint Eastwood to the biopic of Facebook founder and Harvard dropout Mark Zuckerberg, movies illustrate society’s dreams, fears, and experiences. The film industry in Canada has struggled to maintain its identity while at the same time embracing the North American industry by actively competing for U.S. film production in Canada. Today, a significant number of the recognized trades occupations requiring apprenticeship and training are in the film industry. While many North Americans consider Hollywood the epicentre of moviemaking, India’s Bollywood actually produces more films per year, speaking to the cultural aspirations and norms of Indian society. New Media Figure 8.7. Twitter has fascinated the world in 140 characters or less. What media innovation will next take the world by storm? (Photo courtesy of West McGowan/Flickr) New media encompasses all interactive forms of information exchange. These include social networking sites, blogs, podcasts, wikis, and virtual worlds. The list grows almost daily. New media tends to level the playing field in terms of who is constructing it (i.e., creating, publishing, distributing, and accessing information) (Lievrouw and Livingstone, 2006), as well as offering alternative forums to groups unable to gain access to traditional political platforms, such as groups associated with the Arab Spring protests (van de Donk et al., 2004). However, there is no guarantee of the accuracy of the information offered. In fact, the immediacy of new media coupled with the lack of oversight means that we must be more careful than ever to ensure our news is coming from accurate sources. New media is already redefining information sharing in ways unimaginable even a decade ago. New media giants like Google and Facebook have recently acquired key manufacturers in the aerial drones market creating an exponential ability to reach further in data collecting and dissemination. While the corporate line is benign enough, the implications are much more profound in this largely unregulated arena of aerial monitoring. With claims of furthering remote internet access, “industrial monitoring, scientific research, mapping, communications, and disaster assistance,” the reach is profound (Claburn, 2014). But when aligned with military and national surveillance interests these new technologies become largely exempt from regulations and civilian oversight. Making Connections: Sociological Research Please “Friend” Me: Students and Social Networking The phenomenon known as Facebook was designed specifically for students. Whereas earlier generations wrote notes in each other’s printed yearbooks at the end of the academic year, modern technology and the internet ushered in dynamic new ways for people to interact socially. Instead of having to meet up on campus, students can call, text, and Skype from their dorm rooms. Instead of a study group gathering weekly in the library, online forums and chat rooms help learners connect. The availability and immediacy of computer technology has forever changed the ways students engage with each other. Now, after several social networks have vied for primacy, a few have established their place in the market and some have attracted niche audience. While Facebook launched the social networking trend geared toward teens and young adults, now people of all ages are actively “friending” each other. LinkedIn distinguished itself by focusing on professional connections, serving as a virtual world for workplace networking. Newer offshoots like Foursquare help people connect based on the real-world places they frequent, while Twitter has cornered the market on brevity. These newer modes of social interaction have also spawned questionable consequences, such as cyberbullying and what some call FAD, or Facebook addiction disorder. In an international study of smartphone users aged 18 to 30, 60% say they are “compulsive” about checking their smartphones and 42% admit to feeling “anxious” when disconnected; 75% check their smartphones in bed; more than 33% check them in the bathroom and 46% email and check social media while eating (Cisco, 2012). An International Data Corporation (IDC) study of 7,446 smartphone users aged 18 to 44 in the United States in 2012 found that: Half of the U.S. population have smartphones and of those 70% use Facebook. Using Facebook is the third most common smartphone activity, behind email (78%) and web browsing (73%). 61% of smartphone users check Facebook every day. 62% of smartphone users check their device first thing on waking up in the morning and 79% check within 15 minutes. Among 18-to-24-year-olds the figures are 74% and 89%, respectively. Smartphone users check Facebook approximately 14 times a day. 84% of the time using smartphones is spent on texting, emailing and using social media like Facebook, whereas only 16% of the time is spent on phone calls. People spend an average of 132 minutes a day on their smartphones including 33 minutes on Facebook. People use Facebook throughout the day, even in places where they are not supposed to: 46% use Facebook while doing errands and shopping; 47% when they are eating out; 48% while working out; 46% in meetings or class; and 50% while at the movies. The study noted that the dominant feeling the survey group reported was “a sense of feeling connected” (IDC, 2012). Yet, in the international study cited above, two-thirds of 18- to 30-year-old smartphone users said they spend more time with friends online than they do in person. All of these social networks demonstrate emerging ways that people interact, whether positive or negative. Sociologists ask whether there might be long-term effects of replacing face-to-face interaction with social media. In an interview on the Conan O’Brian Show that ironically circulated widely through social media, the comedian Louis CK described the use of smartphones as “toxic.” They do not allow for children who use them to build skills of empathy because the children do not interact face to face, or see the effects their comments have on others. Moreover, he argues, they do not allow people to be alone with their feelings. “The thing is, you need to build an ability to just be yourself and not be doing something. That’s what the phones are taking away” (NewsComAu, 2013). What do you think? How do social media like Facebook and communication technologies like smartphones change the way we communicate? How could this question be studied? Violence in Media and Video Games: Does It Matter? Figure 8.8. One of the most popular video games, Grand Theft Auto, has frequently been at the centre of debate about gratuitous violence in the gaming world. (Photo courtesy of Meddy Garnet/Flickr) A glance through popular video game and movie titles geared toward children and teens shows the vast spectrum of violence that is displayed, condoned, and acted out. It may hearken back to Popeye and Bluto beating up on each other, or Wile E. Coyote trying to kill and devour the Road Runner, but the graphics and actions have moved far beyond Acme’s cartoon dynamite. As a way to guide parents in their programming choices, the motion picture industry put a rating system in place in the 1960s. But new media — video games in particular — proved to be uncharted territory. In 1994, the Entertainment Software Rating Board (ESRB) set a ratings system for games that addressed issues of violence, sexuality, drug use, and the like. California took it a step further by making it illegal to sell video games to underage buyers. The case led to a heated debate about personal freedoms and child protection, and in 2011, the U.S. Supreme Court ruled against the California law, stating it violated freedom of speech (ProCon, 2012). With somewhat more muted responses to claims of violations of freedoms, the Canadian rating system through provincial regulation reflects the diversity of interests in connecting media to cultural interests. With the exception of Quebec, most provinces tend to follow the voluntary Canadian Home Video Ratings System established by the Motion Picture Industry-Canada. Quebec has developed internal legislation and policies for motion picture distribution. Children’s play has often involved games of aggression — from soldiers at war, to cops and robbers, to water-balloon fights at birthday parties. Many articles report on the controversy surrounding the linkage between violent video games and violent behaviour. Are these charges true? Psychologists Anderson and Bushman (2001) reviewed 40-plus years of research on the subject and, in 2003, determined that there are causal linkages between violent video game use and aggression. They found that children who had just played a violent video game demonstrated an immediate increase in hostile or aggressive thoughts, an increase in aggressive emotions, and physiological arousal that increased the chances of acting out aggressive behaviour (Anderson, 2003). Ultimately, repeated exposure to this kind of violence leads to increased expectations regarding violence as a solution, increased violent behavioural scripts, and making violent behaviour more cognitively accessible (Anderson, 2003). In short, people who play a lot of these games find it easier to imagine and access violent solutions than nonviolent ones, and are less socialized to see violence as a negative. While these facts do not mean there is no role for video games, it should give players pause. Clearly, when it comes to violence in gaming, it’s not “only a game.” Product Advertising Companies use advertising to sell to us, but the way they reach us is changing. Increasingly, synergistic advertising practices ensure you are receiving the same message from a variety of sources. For example, you may see billboards for Molson’s on your way to a stadium, sit down to watch a game preceded by a beer commercial on the big screen, and watch a halftime ad in which people are frequently shown holding up the trademark bottles. Chances are you can guess which brand of beer is for sale at the concession stand. Advertising has changed, as technology and media have allowed consumers to bypass traditional advertising venues. From the invention of the remote control, which allows us to ignore television advertising without leaving our seats, to recording devices that let us watch television programs but skip the ads, conventional advertising is on the wane. And print media is no different. As mentioned earlier, advertising revenue in newspapers and on television have fallen significantly showing that companies need new ways of getting their message to consumers. With Google alone earning over US$55 billion a year in revenue, the big players in new media are responding in innovative ways (Google Investor Relations, 2014). This interest from media makes sense when you consider that subscribers pay over $40 each for pay-per-click keywords such as “insurance,” “loans,” and “mortgages” (Wordstream, N.d.). Today, Google alone earns over 50% of the mobile device revenue generated worldwide (Google Investor Relations, 2014). What is needed for successful new media marketing is research. In Canada, market research is valued at almost a billion dollars a year, in an industry employing over 1,800 professional research practitioners with a strong professional association. From market segmentation research to online focus groups, meta-data analysis to crowdsourcing, market research has embraced new media to create winning and profitable revenue streams for web-based corporations. (MRIA-ARIM, N.d.) As an aside, researchers trained in the social sciences, including sociology are well represented with successful careers in this industry (the author is a Certified Marketing Research Professional with the MRIA). 8.3. Global Implications Figure 8.9. These Twitter updates — a revolution in real time — show the role social media can play on the political stage. [Long Description] (Photo courtesy of Cambodia4kidsorg/Flickr) Technology, and increasingly media, has always driven globalization. Thomas Friedman (2005), in a landmark study, identified several ways in which technology “flattened” the globe and contributed to our global economy. The first edition of The World Is Flat , written in 2005, posits that core economic concepts were changed by personal computing and high-speed internet. Access to these two technological shifts has allowed core-nation corporations to recruit workers in call centres located in China or India. Using examples like a Midwestern American woman who runs a business from her home via the call centres of Bangalore, India, Friedman warns that this new world order will exist whether core-nation businesses are ready or not, and that in order to keep its key economic role in the world, North America will need to pay attention to how it prepares workers of the 21st century for this dynamic. Of course not everyone agrees with Friedman’s theory. Many economists pointed out that, in reality, innovation, economic activity, and population still gather in geographically attractive areas, continuing to create economic peaks and valleys, which are by no means flattened out to mean equality for all. China’s hugely innovative and powerful cities of Shanghai and Beijing are worlds away from the rural squalour of the country’s poorest denizens. It is worth noting that Friedman is an economist, not a sociologist. His work focuses on the economic gains and risks this new world order entails. In this section, we will look more closely at how media globalization and technological globalization play out in a sociological perspective. As the names suggest, media globalization is the worldwide integration of media through the cross-cultural exchange of ideas, while technological globalization refers to the cross-cultural development and exchange of technology. Media Globalization Lyons (2005) suggests that multinational corporations are the primary vehicle of media globalization. These corporations control global mass-media content and distribution (Compaine, 2005). It is true, when looking at who controls which media outlets, that there are fewer independent news sources as larger and larger conglomerates develop. On the surface, there is endless opportunity to find diverse media outlets. But the numbers are misleading. Mass media control and ownership is highly concentrated in Canada. Bell, Telus, and Rogers control over 80% of the wireless and internet service provider market; 70% of the daily and community newspapers are owned by seven corporations; and 10 companies control over 80% of the private sector radio and television market (CMCRP, N.d.; Newspapers Canada, 2013).  As was pointed out in a Parliamentary report in 2012, an example of increased vertical control is a company that “might own a broadcast distributor (Rogers Cable), conventional television stations, pay and specialty television channels, and even the content for its broadcasters (Rogers owns the Toronto Blue Jays, whose games are shown on conventional and pay and specialty television channels)” (Theckedath and Thomas, 2012). While some social scientists predicted that the increase in media forms would break down geographical barriers and create a global village (McLuhan, 1964), current research suggests that the public sphere accessing the global village will tend to be rich, Caucasian, and English-speaking (Jan, 2009). As shown by the spring 2011 uprisings throughout the Arab world, technology really does offer a window into the news of the world. For example, here in the West we saw internet updates of Egyptian events in real time, with people tweeting, posting, and blogging on the ground in Tahrir Square. Still, there is no question that the exchange of technology from core nations to peripheral and semi-peripheral ones leads to a number of complex issues. For instance, someone using a critical sociology approach might focus on how much political ideology and cultural colonialism occurs with technological growth. In theory at least, technological innovations are ideology-free; a fibre optic cable is the same in a Muslim country as a secular one, in a communist country or a capitalist one. But those who bring technology to less developed nations — whether they are nongovernment organizations, businesses, or governments — usually have an agenda. A functionalist, in contrast, might focus on how technology creates new ways to share information about successful crop-growing programs, or on the economic benefits of opening a new market for cell phone use. Interpretive sociologists might emphasize the way in which the global exchange of views creates the possibility of mutual understanding and consensus. In each case, there are cultural and societal assumptions and norms being delivered along with those high-speed connections. Cultural and ideological biases are not the only risks of media globalization. In addition to the risk of cultural imperialism and the loss of local culture, other problems come with the benefits of a more interconnected globe. One risk is the potential censoring by national governments that let in only the information and media they feel serves their message, as can be seen in China. In addition, core nations such as Canada have seen the use of international media such as the internet circumvent local laws against socially deviant and dangerous behaviours such as gambling, child pornography, and the sex trade. Offshore or international websites allow citizens to seek out whatever illegal or illicit information they want, from 24-hour online gambling sites that do not require proof of age, to sites that sell child pornography. These examples illustrate the societal risks of unfettered information flow. China and the Internet: An Uncomfortable Friendship Figure 8.10. What information is accessible to these patrons of an internet café in China? What is censored from their view? (Photo Courtesy of Kai Hendry/flickr) Today, the internet is used to access illegal gambling and pornography sites, as well as to research stocks, crowd-source what car to buy, or keep in touch with childhood friends. Can we allow one or more of those activities, while restricting the rest? And who decides what needs restricting? In a country with democratic principles and an underlying belief in free-market capitalism, the answer is decided in the court system. But globally, the questions — and the government’s responses — are very different. China is in many ways the global poster child for the uncomfortable relationship between internet freedom and government control. A country with a tight rein on the dissemination of information, China has long worked to suppress what it calls “harmful information,” including dissent concerning government politics, dialogue about China’s role in Tibet, or criticism of the government’s handling of events. With sites like Twitter, Facebook, and YouTube blocked in China, the nation’s internet users — some 500 million strong in 2011 — turn to local media companies for their needs. Renren.com is China’s answer to Facebook. Perhaps more importantly from a social-change perspective, Sina Weibo is China’s version of Twitter. Microblogging, or weibo , acts like Twitter in that users can post short messages that can be read by their subscribers. And because these services move so quickly and with such wide scope, it is difficult for government overseers to keep up. This tool was used to criticize government response to a deadly rail crash and to protest a chemical plant. It was also credited with the government’s decision to report more accurately on the air pollution in Beijing, which occurred after a high-profile campaign by a well-known property developer (Pierson, 2012). There is no question of China’s authoritarian government ruling over this new form of internet communication. The nation blocks the use of certain terms, such as “human rights,” and passes new laws that require people to register with their real names, making it more dangerous to criticize government actions. Indeed, 56-year-old microblogger Wang Lihong was sentenced to nine months in prison for “stirring up trouble,” as her government described her work helping people with government grievances (Bristow, 2011). But the government cannot shut down this flow of information completely. Foreign companies, seeking to engage with the increasingly important Chinese consumer market, have their own accounts: the NBA has more than 5 million followers, and probably the most famous foreigner in China, Canadian comedian and Order of Canada recipient Mark Rowswell boasts almost 3 million Weibo followers (2014). The government, too, uses Weibo to get its own message across. As the years progress, the rest of the world anxiously watches China’s approach to social media and the freedoms it offers — on Sina Weibo and beyond — by the rest of the world. Technological Globalization Technological globalization is impacted in large part by technological diffusion , the spread of technology across borders. In the last two decades, there has been rapid improvement in the spread of technology to peripheral and semi-peripheral nations, and a 2008 World Bank report discusses both the benefits and ongoing challenges of this diffusion. In general, the report found that technological progress and economic growth rates were linked, and that the rise in technological progress has helped improve the situations of many living in absolute poverty (World Bank, 2008). The report recognizes that rural and low-tech products such as corn can benefit from new technological innovations, and that, conversely, technologies like mobile banking can aid those whose rural existence consists of low-tech market vending. In addition, technological advances in areas like mobile phones can lead to competition, lowered prices, and concurrent improvements in related areas such as mobile banking and information sharing. However, the same patterns of social inequality that create a digital divide in the West also create digital divides in peripheral and semi-peripheral nations. While the growth of technology use among countries has increased dramatically over the past several decades, the spread of technology within countries is significantly slower among peripheral and semi-peripheral nations. In these countries, far fewer people have the training and skills to take advantage of new technology, let alone access it. Technological access tends to be clustered around urban areas, leaving out vast swaths of peripheral-nation citizens. While the diffusion of information technologies has the potential to resolve many global social problems, it is often the population most in need that is most affected by the digital divide. For example, technology to purify water could save many lives, but the villages in peripheral nations most in need of water purification don’t have access to the technology, the funds to purchase it, or the technological comfort level to introduce it as a solution. The Mighty Cell Phone: How Mobile Phones Are Impacting Sub-Saharan Africa In many of Africa’s poorest countries there is a marked lack of infrastructure. Bad roads, limited electricity, minimal schools — the list goes on. Access to telephones has long been on that list. But while landline access has not changed appreciably during the past 10 years, there’s been a marked fivefold increase in mobile phone access; more than a third of people in sub-Saharan Africa have the ability to access a mobile phone (Katine, 2010). Even more can access a “village phone” — a shared phone program created by the Grameen Foundation. With access to mobile phone technology, a host of benefits are available that have the potential to change the dynamics in these poorest nations. Sometimes that change is as simple as being able to make a phone call to neighbouring market towns. By finding out which markets have vendors interested in their goods, fishers and farmers can ensure they travel to the market that will serve them best, avoiding a wasted trip. Others can use mobile phones and some of the emerging money-sending systems to securely send money from one place to a family member or business partner elsewhere (Katine, 2010). These programs are often funded by businesses like Germany’s Vodafone or Britain’s Masbabi, which hope to gain market share in the region. Phone giant Nokia points out that worldwide there are 4 billion mobile phone users — that’s more than twice as many bank accounts that exist — meaning there is ripe opportunity to connect banking companies with people who need their services (ITU News, 2009). Not all access is corporate-based, however. Other programs are funded by business organizations that seek to help peripheral nations with tools for innovation and entrepreneurship. But this wave of innovation and potential business comes with costs. There is, certainly, the risk of cultural imperialism, and the assumption that core nations (and core-nation multinationals) know what is best for those struggling in the world’s poorest communities. Whether well intentioned or not, the vision of a continent of Africans successfully chatting on their iPhone may not be ideal. As with all aspects of global inequity, technology in Africa requires more than just foreign investment. There must be a concerted effort to ensure the benefits of technology get to where they are needed most. 8.4. Theoretical Perspectives on Media and Technology It is difficult to conceive of any one theory or theoretical perspective that can explain the variety of ways that people interact with technology and the media. Technology runs the gamut from the match you strike to light a candle all the way up to sophisticated nuclear power plants that might power the factory where that candle was made. Media could refer to the television you watch, the ads wrapping the bus you take to work or school, or the magazines you flip through in a waiting room, not to mention all the forms of new media, including Twitter, Facebook, blogs, YouTube, and the like. Are media and technology critical to the forward march of humanity? Are they pernicious capitalist tools that lead to the exploitation of workers worldwide? Are they the magic bullet the world has been waiting for to level the playing field and raise the world’s poor out of extreme poverty? Each perspective generates understandings of technology and media that help us examine the way our lives are affected. Structural Functionalism Because functionalism focuses on how media and technology contribute to the smooth functioning of society, a good place to begin understanding this perspective is to write a list of functions you perceive media and technology to perform. Your list might include the ability to find information on the internet, television’s entertainment value, or how advertising and product placement contribute to social norms. Commercial Function Figure 8.11. TV commercials can carry significant cultural currency. For some, the ads during the Super Bowl are more water cooler-worthy than the game itself. (Photo courtesy of Dennis Yang/Flickr) As you might guess, with nearly every U.S. household possessing a television, and the 250 billion hours of television watched annually by Americans, companies that wish to connect with consumers find television an irresistible platform to promote their goods and services (Nielsen Wire, 2011). Television advertising is a highly functional way to meet a market demographic where it lives. Sponsors can use the sophisticated data gathered by network and cable television companies regarding their viewers and target their advertising accordingly. It certainly doesn’t stop with television. Commercial advertising precedes movies in theatres and shows up on and inside of public transportation, as well as on the sides of buildings and roadways. Major corporations such as Coca-Cola bring their advertising into public schools, sponsoring sports fields or tournaments, as well as filling the halls and cafeterias of those schools with vending machines hawking their goods. With the rising concerns about childhood obesity and attendant diseases, the era of pop machines in schools may be numbered. But not to worry. Coca-Cola’s filtered tap water, Dasani, and its juice products will remain standards in many schools. Entertainment Function An obvious manifest function of media is its entertainment value. Most people, when asked why they watch television or go to the movies, would answer that they enjoy it. Within the 98% of households that have a TV, the amount of time spent watching is substantial, with the average adult Canadian viewing time of 30 hours a week (TVB, 2014). Clearly, enjoyment is paramount. On the technology side, as well, there is a clear entertainment factor to the use of new innovations. From online gaming to chatting with friends on Facebook, technology offers new and more exciting ways for people to entertain themselves. Social Norm Functions Even while the media is selling us goods and entertaining us, it also serves to socialize us, helping us pass along norms, values, and beliefs to the next generation. In fact, we are socialized and resocialized by media throughout our life course. All forms of media teach us what is good and desirable, how we should speak, how we should behave, and how we should react to events. Media also provide us with cultural touchstones during events of national significance. How many of your older relatives can recall watching the explosion of the space shuttle Challenger on television? How many of those reading this textbook followed the events of September 11 or Hurricane Katrina on the television or internet? But debate exists over the extent and impact of media socialization. Krahe and colleagues (2011) demonstrated that violent media content has a desensitizing affect and is correlated with aggressive thoughts. Another group of scholars (Gentile, Mathieson, and Crick, 2011) found that among children, exposure to media violence led to an increase in both physical and relational aggression. Yet, a meta-analysis study covering four decades of research (Savage, 2003) could not establish a definitive link between viewing violence and committing criminal violence. It is clear from watching people emulate the styles of dress and talk that appear in media that media has a socializing influence. What is not clear, despite nearly 50 years of empirical research, is how much socializing influence the media has when compared to other agents of socialization, which include any social institution that passes along norms, values, and beliefs (such as peers, family, religious institutions, and the like). Life-Changing Functions Like media, many forms of technology do indeed entertain us, provide a venue for commercialization, and socialize us. For example, some studies suggest the rising obesity rate is correlated with the decrease in physical activity caused by an increase in use of some forms of technology, a latent function of the prevalence of media in society (Kautiainen et al., 2005). Without a doubt, a manifest function of technology is to change our lives, sometimes for the better and sometimes for the worse. Think of how the digital age has improved the ways we communicate. Have you ever used Skype or another webcast to talk to a friend or family member far away? Or maybe you have organized a fund drive, raising thousands of dollars, all from your desk chair. Of course, the downside to this ongoing information flow is the near impossibility of disconnecting from technology, leading to an expectation of constant convenient access to information and people. Such a fast-paced dynamic is not always to our benefit. Some sociologists assert that this level of media exposure leads to narcotizing dysfunction , a term that describes when people are too overwhelmed with media input to really care about the issue, so their involvement becomes defined by awareness instead of by action about the issue at hand (Lazerfeld and Merton, 1948). Critical Sociology In contrast to theories in the functional perspective, the critical perspective focuses on the creation and reproduction of inequality — social processes that tend to disrupt society rather than contribute to its smooth operation. When taking a critical perspective, one major focus is the differential access to media and technology embodied in the digital divide. Critical sociologists also look at who controls the media, and how media promotes the norms of upper-middle-class white demographics while minimizing the presence of the working class, especially people of colour. Control of Media and Technology Powerful individuals and social institutions have a great deal of influence over which forms of technology are released, when and where they are released, and what kind of media is available for our consumption, a form of gatekeeping. Shoemaker and Voss (2009) define gatekeeping as the sorting process by which thousands of possible messages are shaped into a mass media–appropriate form and reduced to a manageable amount. In other words, the people in charge of the media decide what the public is exposed to, which, as C. Wright Mills (1956) famously noted, is the heart of media’s power. Take a moment to think of the way that “new media” evolves and replaces traditional forms of hegemonic media. With a hegemonic media, culturally diverse society can be dominated by one race, gender, or class through the manipulation of the media imposing its worldview as a societal norm. New media renders the gatekeeper role less of a factor in information distribution. Popular sites such as YouTube and Facebook engage in a form of democratized self-policing. Users are encouraged to report inappropriate behaviour that moderators will then address. In addition, some conflict theorists suggest that the way North American media is generated results in an unbalanced political arena. Those with the most money can buy the most media exposure, run smear campaigns against their competitors, and maximize their visual presence. The Conservative Party began running attack ads on Justin Trudeau moments after his acceptance speech on winning the leadership of the Liberal Party in 2013. It is difficult to avoid the Enbridge and Cenovus advertisements that promote their controversial Northern Gateway pipeline and tar sands projects. What do you think a critical perspective theorist would suggest about the potential for the non-rich to be heard in politics? Technological Social Control and Digital Surveillance Social scientists take the idea of the surveillance society so seriously that there is an entire journal devoted to its study, Surveillance and Society . The panoptic surveillance envisioned by Jeremy Bentham and later analyzed by Michel Foucault (1975) is increasingly realized in the form of technology used to monitor our every move. This surveillance was imagined as a form of complete visibility and constant monitoring in which the observation posts are centralized and the observed are never communicated with directly. Today, digital security cameras capture our movements, observers can track us through our cell phones, and police forces around the world use facial-recognition software. Feminist Perspective Figure 8.12. What types of women are we exposed to in the media? Some would argue that the range of female images is misleadingly narrow. (Photo courtesy of Cliff1066/Flickr) Take a look at popular television shows, advertising campaigns, and online game sites. In most, women are portrayed in a particular set of parameters and tend to have a uniform look that society recognizes as attractive. Most are thin, white or light-skinned, beautiful, and young. Why does this matter? Feminist perspective theorists believe it is crucial in creating and reinforcing stereotypes. For example, Fox and Bailenson (2009) found that online female avatars (the characters you play in online games like World of Warcraft or Second Life) conforming to gender stereotypes enhances negative attitudes toward women, and Brasted (2010) found that media (advertising in particular) promotes gender stereotypes. The gender gap in tech-related fields (science, technology, engineering, and math) is no secret. A 2011 U.S. Department of Commerce report suggested that gender stereotyping is one reason for this gap, acknowledging the bias toward men as keepers of technological knowledge (U.S. Department of Commerce, 2011). But gender stereotypes go far beyond the use of technology. Press coverage in the media reinforces stereotypes that subordinate women, giving airtime to looks over skills, and disparaging women who defy accepted norms. Recent research in new media has offered a mixed picture of its potential to equalize the status of men and women in the arenas of technology and public discourse. A European agency, the Advisory Committee on Equal Opportunities for Men and Women (2010), issued an opinion report suggesting that while there is the potential for new media forms to perpetuate gender stereotypes and the gender gap in technology and media access, at the same time new media could offer alternative forums for feminist groups and the exchange of feminist ideas. Still, the committee warned against the relatively unregulated environment of new media and the potential for antifeminist activities, from pornography to human trafficking, to flourish there. Increasingly prominent in the discussion of new media and feminism is cyberfeminism , the application to, and promotion of, feminism online. Research on cyberfeminism runs the gamut from the liberating use of blogs by women living in Iraq during the second Gulf War (Pierce, 2011) to the analysis of postmodern discourse on the relationship between the body and technology (Kerr, 2014). Symbolic Interactionism Technology itself may act as a symbol for many. The kind of computer you own, the kind of car you drive, whether or not you can afford the latest Apple product — these serve as a social indicator of wealth and status. Neo-Luddites are people who see technology as symbolizing the coldness and alienation of modern life. But for technophiles , technology symbolizes the potential for a brighter future. For those adopting an ideological middle ground, technology might symbolize status (in the form of a massive flat-screen television) or failure (in owning a basic old mobile phone with no bells or whistles). Social Construction of Reality Meanwhile, media create and spread symbols that become the basis for our shared understanding of society. Theorists working in the interactionist perspective focus on this social construction of reality, an ongoing process in which people subjectively create and understand reality. Media constructs our reality in a number of ways. For some, the people they watch on a screen can become a primary group, meaning the small informal groups of people who are closest to them. For many others, media becomes a reference group: a group that influences an individual and to which an individual compares himself or herself, and by which we judge our successes and failures. We might do very well without an Android smartphone, until we see characters using it on our favourite television show or our classmates whipping one out between classes. While media may indeed be the medium to spread the message of the rich white males, Gamson, Croteau, Hoynes, and Sasson (1992) point out that some forms of media discourse allow the appearance of competing constructions of reality. For example, advertisers find new and creative ways to sell us products we do not need and probably would not want without their prompting, but some networking sites such as Freecycle offer a commercial-free way of requesting and trading items that would otherwise be discarded. Additionally, the web is full of blogs chronicling lives lived “off the grid,” or without participation in the commercial economy. Social Networking and Social Construction While Twitter and Facebook encourage us to check in and provide details of our day through online social networks, corporations can just as easily promote their products on these sites. Even supposedly crowd-sourced sites like Yelp (which aggregates local reviews) are not immune to corporate shenanigans. That is, we think we are reading objective observations when in reality we may be buying into one more form of advertising. Facebook, which started as a free social network for college students, is increasingly a monetized business, selling you goods and services in subtle ways. But chances are you do not think of Facebook as one big online advertisement. What started out as a symbol of coolness and insider status, unavailable and inaccessible to parents and corporate shills, now promotes consumerism in the form of games and fandom. For example, think of all the money spent to upgrade popular Facebook games like Farmville. Notice that whenever you become a “fan,” you likely receive product updates and special deals that promote online and real-world consumerism. It is unlikely that millions of people want to be “friends” with Pampers. But if it means a weekly coupon, they will, in essence, rent out space on their Facebook page for Pampers to appear. Thus, we develop both new ways to spend money and brand loyalties that will last even after Facebook is considered outdated and obsolete. What cannot be forgotten with new technology is the dynamic tension between the liberating effects of these technologies in democratizing information access and flow, and the newly emerging corporate ownership and revenue models that necessitate control of the same technologies. Key Terms cyberfeminism: Application to and promotion of feminism online. design patents: Patents that are granted when someone has invented a new and original design for a manufactured product. digital divide: The uneven access to technology around race, class, and geographic lines. e-readiness: The ability to sort through, interpret, and process digital knowledge. embodied energy: The sum of energy required for a finished product including the resource extraction, transportation, manufacturing, distribution, marketing, and disposal. evolutionary model of technological change: A breakthrough in one form of technology that leads to a number of variations, from which a prototype emerges, followed by a period of slight adjustments to the technology, interrupted by a breakthrough. gatekeeping: The sorting process by which thousands of possible messages are shaped into a mass media–appropriate form and reduced to a manageable amount. knowledge gap: The gap in information that builds as groups grow up without access to technology. media: All print, digital, and electronic means of communication. media globalization: The worldwide integration of media through the cross-cultural exchange of ideas. misogyny: Personal, social, and cultural manifestations of the hatred of girls and women. narcotizing dysfunction: When people are too overwhelmed with media input to really care about the issue, so their involvement becomes defined by awareness instead of by action about the issue at hand. neo-Luddites: Those who see technology as a symbol of the coldness of modern life. new media: All interactive forms of information exchange. panoptic surveillance: A form of constant monitoring in which the observation posts are decentralized and the observed is never communicated with directly. planned obsolescence: When a technology company plans for a product to be obsolete or unable to be repaired from the time it’s created. plant patents: Patents that recognize the discovery of new plant types that can be asexually reproduced. technological diffusion: The spread of technology across borders. technological globalization: The cross-cultural development and exchange of technology. technology: The application of science to solve problems in daily life. technophiles: Those who see technology as symbolizing the potential for a brighter future. utility patents: Patents that are granted for the invention or discovery of any new and useful process, product, or machine. Section Summary 8.1. Technology Today Technology is the application of science to address the problems of daily life. The fast pace of technological advancement means the advancements are continuous, but that not everyone has equal access. The gap created by this unequal access has been termed the digital divide. The knowledge gap refers to an effect of the “digital divide”: the lack of knowledge or information that keeps those who were not exposed to technology from gaining marketable skills 8.2. Media and Technology in Society Media and technology have been interwoven from the earliest days of human communication. The printing press, the telegraph, and the internet are all examples of their intersection. Mass media has allowed for more shared social experiences, but new media now creates a seemingly endless amount of airtime for any and every voice that wants to be heard. Advertising has also changed with technology. New media allows consumers to bypass traditional advertising venues, causing companies to be more innovative and intrusive as they try to gain our attention. 8.3. Global Implications Technology drives globalization, but what that means can be hard to decipher. While some economists see technological advances leading to a more level playing field where anyone anywhere can be a global contender, the reality is that opportunity still clusters in geographically advantaged areas. Still, technological diffusion has led to the spread of more and more technology across borders into peripheral and semi-peripheral nations. However, true technological global equality is a long way off. 8.4. Theoretical Perspectives on Media and Technology There are myriad theories about how society, technology, and media will progress. Functionalism sees the contribution that technology and media provide to the stability of society, from facilitating leisure time to increasing productivity. Conflict theorists are more concerned with how technology reinforces inequalities among communities, both within and among countries. They also look at how media typically give voice to the most powerful, and how new media might offer tools to help those who are disenfranchised. Symbolic interactionists see the symbolic uses of technology as signs of everything from a sterile futuristic world to a successful professional life. Short Answer 8.1. Technology Today Can you think of people in your own life who support or defy the premise that access to technology leads to greater opportunities? How have you noticed technology use and opportunity to be linked, or does your experience contradict this idea? Should a government be responsible for providing all citizens with access to the internet? Or is gaining internet access an individual responsibility? How has digital media changed social interactions? Do you believe it has deepened or weakened human connections? Defend your answer. Conduct sociological research. Google yourself. How much information about you is available to the public? How many and what types of companies offer private information about you for a fee? Compile the data and statistics you find. Write a paragraph or two about the social issues and behaviours you notice. 8.2. Media and Technology in Society Where and how do you get your news? Do you watch network television? Read the newspaper? Go online? How about your parents or grandparents? Do you think it matters where you seek out information? Why or why not? Do you believe new media allows for the kind of unifying moments that television and radio programming used to? If so, give an example. Where are you most likely to notice advertisements? What causes them to catch your attention? 8.3. Global Implications Do you believe that technology has indeed flattened the world in terms of providing opportunity? Why or why not? Give examples to support your reason. Where do you get your news? Is it owned by a large conglomerate (you can do a web search and find out!)? Does it matter to you who owns your local news outlets? Why or why not? Who do you think is most likely to bring innovation and technology (like cell phone businesses) to sub-Saharan Africa: nonprofit organizations, governments, or businesses? Why? 8.4. Theoretical Perspectives on Media and Technology Contrast a functionalist viewpoint of digital surveillance with a conflict perspective viewpoint. In what ways has the internet affected how you view reality? Explain using a symbolic interactionist perspective. Describe how a cyberfeminist might address the fact that powerful female politicians are often demonized in traditional media. The issue of new media ownership is an issue of growing media concern. Select a theoretical perspective and describe how it would explain this. Would you characterize yourself as a technophile or a neo-Luddite? Explain, using examples. Further Research 8.1. Technology Today To learn more about the digital divide and why it matters, check out these websites: and 8.2. Media and Technology in Society Check out this website to get a sense of the timeline of technology : Visit this website to learn more about new media : 8.4. Theoretical Perspectives on Media and Technology To learn more about cyberfeminism, check out the interdisciplinary artist collective, subRosa : To explore the implications of panoptic surveillance, review some surveillance studies at the free, open source Surveillance and Society site: References 8. Introduction to Media and Technology Vlessing, Etan. (2011). ‘Jersey Shore’ continues record MTV Canada run. The Hollywood Reporter , Retrieved April 04, 2014, from 8.1. Technology Today Guillen, M.F., and S.L. Suárez. (2005). Explaining the global digital divide: Economic, political and sociological drivers of cross-national internet use. Social Forces, 84:681–708. Kedrosky, Paul. (2011, June 15). Cars vs cell phone embodied energy . Retrieved July 7, 2016, from Liff, Sonia, and Adrian Shepard. (2004, July). An evolving gender digital divide? [PDF] Oxford Internet Institute, Internet Issue, Brief No. 2. Retrieved July 7, 2016 from  Looker, Dianne and Thiessen, Victor. (2003). The digital divide in Canadian schools: factors affecting student access to and use of information technology. [PDF] Statistics Canada, Research Paper , Catalogue no. 81-597-XIE. Retrieved April 07, 2014, from OECD. (2001, July 13). Bridging the digital divide: Issues and policies in OECD Countries . DSTI/ICCP(2001)9/FINAL. OECD: Paris. Pew Research Center. (2011, May). Demographics of internet users. Pew Internet and American Life Project . Retrieved January 12, 2012, from The Economist. (2009, March 23). Planned Obsolescence. The Economist Newspaper Limited . Retrieved January 12, 2012, from Sciadas, George. (2003). Monitoring the digital divide … and beyond. InfoDev/World Bank Group . Retrieved January 22, 2012, from StEP. (2014). Canada: Overview of E-waste related information. StEP: Solving the E-Waste problem . Retrieved April 23, 2014, from Washington, Jesse. (2011, January 10). For minorities, New ‘digital divide’ seen. Pew Internet and American Life Project . Retrieved July 12, 2016, from 8.2. Media and Technology in Society Anderson, C.A., and B.J. Bushman. (2001). Effects of violent video games on aggressive behavior, aggressive cognition, aggressive affect, physiological arousal, and prosocial behavior: A meta-analytic review of the scientific literature. Psychological Science, 12:353–359. Anderson, Craig. (2003, October). Violent video games: Myths, facts and unanswered questions. American Psychological Association . Retrieved January 13, 2012, from Anderson, Philip and Michael Tushman. (1990). Technological discontinuities and dominant designs: A cyclical model of technological change. Administrative Science Quarterly, 35:604–633. Cisco. (2012). Gen Y: New Dawn for Work, Play, Identity. Cisco Connected world technology report PDF . Retrieved February 4, 2012 from  Claburn, Thomas. (2014, April). Google has plans for Titan drones. Information Week . Retrieved April 16, 2014, from Alphabet. (2014). Google invester relations: Financial tables 2014. Alphabet Investor Relations . Retrieved April 14, 2014, from IDC Custom Solutions. (2012). Always connected: How smartphones and social media keep us connected. [PDF] Always connected for Facebook Case Study (IDC Research Report). Retrieved February 4, 2014, from Ladurantaye, Steve. (2013, June 05). Newspaper revenue to drop 20 per cent by 2017, report predicts. The Globe and Mail . Retrieved April 07, 2014, from Lievrouw, Leah A. and Sonia Livingstone. (Eds.). (2006). Handbook of new media: Social shaping and social consequences. London: SAGE Publications. McGivern, Ronald. (1990). Catholic ideals and populist self-help: Ideology and action in the Antigonish Cooperative Adult Education Movement in Eastern Nova Scotia, 1920-1940. M.A. Thesis, Simon Fraser University. Mercola, Dr. Joseph. (2011, December 25). Finally… Solo farmer fights Monsanto and wins. Mercola.com . Retrieved April 07, 2014, from Monsanto, (N.d.). Percy Schmeiser . Retrieved April 07, 2014, from (MRIA) Marketing Research and Intelligence Association of Canada [website] . (N.d.). Retrieved April 15, 2014: ( NewsComAu. (2013, September 21). Gadgets – Cell phones: Comedian Louis CK’s compelling philosophy: ‘Smartphones are toxic’. NewsComAu. Retrieved February 4, 2014 from O’Reilly, Terry. (2014, February 22). Radio is dead. Long live radio. CBC : Under the Influence. Retrieved, April 09, 2014, from ProCon. (2012, January 5). Video games . Retrieved January 12, 2012, from U.S. Patent and Trademark Office. (2011). General information concerning patents . Retrieved January 12, 2012, from  van de Donk, W., B.D. Loader, P.G. Nixon, and D. Rucht. (Eds.). (2004). Cyberprotest: New media, citizens, and social movements . New York: Routledge. Wordstream. (N.d.). How does Google make its money: The 20 most expensive keywords in Google AdWords. Retrieved April 14, 2014, from Wikipedia. (2010). “Television in Canada” Retrieved April 09, 2014, from World Association of Newspapers. (2004). Newspapers: A brief history.” Retrieved January 12, 2012, from 8.3. Global Implications Bristow, Michael. (2011, November 3). Can China control social media revolution? BBC News China . Retrieved January 14, 2012, from CMCRP, Canadian Media Concentration Research Project . (N.d.). Retrieved April 15, 2014, from Compaine, B. (2005). Global media. In living in the information age: A new media reader (pp. 97-101). Belmont: Wadsworth Thomson Learning. Friedman, Thomas. (2005). The world is flat: A brief history of the twenty-first century . New York: Farrar, Straus, and Giroux. ITU News. (2009, November). ITU Telecom World 2009: Special report: Reflecting new needs and realities . Retrieved January 14, 2012, from Jan, Mirza. (2009). Globalization of media: Key issues and dimensions. European Journal of Scientific Research, 29:66–75. Perkins, Anne. (2010, January 14). Are mobile phones Africa’s silver bullet? The Guardian, Katine Chronicles blog, Livelihoods . Retrieved January 12, 2012 from McLuhan, Marshall. (1964). Understanding media: The extensions of man . New York: McGraw-Hill. Newspapers Canada. (2013). Ownership . Retrieved April 15, 2014, from Pierson, David. (2012, January 16). Number of web users in China hits 513 million. Los Angeles Times. Retrieved January 16, 2012, from  Rowswell, Mark. (2014). Dashan Live [online]. Retrieved April 15, 2014, from Theckedath, Dillan and Thomas, Terrence J. (2012). Media ownership and convergence in Canada. [PDF] In Brief† No. 2012-17-E, Library of Parliament Research Publications, Parliament of Canada. Retrieved April 15, 2014, from World Bank. (2008). Global economic prospects 2008: Technology diffusion in the developing world. [PDF] World Bank . Retrieved January 24, 2012, from 8.4. Theoretical Perspectives on Media and Technology Brasted, Monica. (2010). Care Bears vs. Transformers: Gender stereotypes in advertisements. The Socjourn . Retrieved January 10, 2012, from Foucault, Michel. (1975). Discipline and punish: The birth of the prison . New York: Vintage Books. Fox, Jesse and Jeremy Bailenson. (2009). Virtual virgins and vamps: The effects of exposure to female characters’ sexualized appearance and gaze in an immersive virtual environment. Sex Roles, 61:147–157. Gamson, William, David Croteau, William Hoynes, and Theodore Sasson. (1992). Media images and the social construction of reality. Annual Review of Sociology, 18:373–393. Gentile, Douglas, Lindsay Mathieson, and Nikki Crick. (2011). Media violence associations with the form and function of aggression among elementary school children. Social Development 20:213–232. Kautiainen, S., L. Koivusilta, T. Lintonen, S. M. Virtanen, and A. Rimpelä. (2005). Use of information and communication technology and prevalence of overweight and obesity among adolescents. International Journal of Obesity, 29:925–933. Kerr, Elizabeth. (2014, February 07). Cyberfeminism and postmodern technological discourse. 24th Annual Thinking Gender Conference, UCLA Center for the Study of Women . Retrieved April 18, 2014, from Krahe, Barbara, Ingrid Moller, L. Huesmann, Lucyna Kirwil, Julianec Felber, and Anja Berger. (2011). Desensitization to media violence: Links with habitual media violence exposure, aggressive cognitions, and aggressive behavior. Journal of Personality and Social Psychology, 100:630–646. Lazerfeld, Paul F. and Robert K. Merton. (1948). Mass communication, popular taste, and organized social action. The Communication of Ideas . New York: Harper &amp; Bros. Mills, C. Wright. (2000). The Power Elite . New York: Oxford University Press. (Original work published 1956) NielsenWire. (2011, May 3). Nielsen estimates number of U.S. television homes to be 114.7 million. The Nielsen Company, Media and Entertainment . Retrieved January 15, 2012, from Pierce, Tess. (2011). Singing at the digital well: Blogs as cyberfeminist sites of resistance. Feminist Formations, 23:196–209. Savage, Joanne. (2003). Does viewing violent media really cause criminal violence? Science Direct [Website]. Retrieved July 8, 2016, from Shoemaker, Pamela and Tim Voss. (2009). Media gatekeeping. In D. Stacks and M. Salwen (Eds.), An Integrated Approach to Communication Theory and Research. (2nd ed.). (pp. 75–89). New York: Routledge. TVB. (2014). TV basics, 2013-2014. [PDF] Television Bureau of Canada , Retrieved April 15, 2014, from Economics and Statistic Administration. (2011, August). Women in STEM: A gender gap to innovation. [PDF] U.S. Department of Commerce . Retrieved February 22, 2012, from Solutions to Section Quiz 1 C, | 2 B, | 3 D, | 4 A, | 5 C, | 6 B, | 7 D, | 8 A, | 9 D, | 10 A, | 11 B, | 12 A, | 13 D, | 14 B, | 15 A, | 16 D, | 17 A, | 18 B, | 19 C, | 20 A, [Return to Quiz] Figure 8.5. Electronic waste by Curtis Palmer ( used under CC BY 2.0 license ( Long Descriptions Figure 8.2 Long Description: Photo (A) a stone arrow head, Photo (B) Draft horses pulling a plow, Photo (C) An abacus, Photo (D) computer servers, Photo (E) a laptop, Photo (F) a smart phone. [Return to Figure 8.2] . Figure 8.9 Long Description: A twitter post reading: 5 ways to help: call Egypt consul in SF, host petition on your blog, write a letter 2 editor, Digg the CNN story, email. In the replies, people are calling on authorities to release Mohammed, who was still missing. [Return to Figure 8.9] . 9 Chapter 9. Social Inequality in Canada Figure 9.1. The car a person drives can be seen as a symbol of money and power. What does a Rolls-Royce signify about its owner? Why? (Photo courtesy of dave_7/Flickr) \n",
      "-----------\n",
      "8.1. Technology Today Define technology and describe its evolution.\n",
      "Understand technological inequality and issues related to unequal access to technology.\n",
      "Describe the role of planned obsolescence in technological development.\n",
      "8.2. Media and Technology in Society Describe the evolution and current role of different media, like newspapers, television, and new media.\n",
      "Understand the function of product advertising in media.\n",
      "Demonstrate awareness of the social homogenization and social fragmentation that are occurring via modern society’s use of technology and media.\n",
      "8.3. Global Implications Explain the advantages and concerns of media globalization.\n",
      "Understand the globalization of technology.\n",
      "--------------------------\n",
      "Psychologists agree that if their ideas and theories about human behaviour are to be taken seriously, they must be backed up by data. However, the research of different psychologists is designed with different goals in mind, and the different goals require different approaches. These varying approaches, summarized in Table 3.2, are known as research designs . A research design is the specific method a researcher uses to collect, analyze, and interpret data . Psychologists use three major types of research designs in their research, and each provides an essential avenue for scientific investigation. Descriptive research is research designed to provide a snapshot of the current state of affairs . Correlational research is research designed to discover relationships among variables and to allow the prediction of future events from present knowledge . Experimental research is research in which initial equivalence among research participants in more than one group is created, followed by a manipulation of a given experience for these groups and a measurement of the influence of the manipulation . Each of the three research designs varies according to its strengths and limitations, and it is important to understand how each differs. Table 3.2 Characteristics of the Three Research Designs [Skip Table] Research design Goal Advantages Disadvantages Descriptive To create a snapshot of the current state of affairs Provides a relatively complete picture of what is occurring at a given time. Allows the development of questions for further study. Does not assess relationships among variables. May be unethical if participants do not know they are being observed. Correlational To assess the relationships between and among two or more variables Allows testing of expected relationships between and among variables and the making of predictions. Can assess these relationships in everyday life events. Cannot be used to draw inferences about the causal relationships between and among the variables. Experimental To assess the causal impact of one or more experimental manipulations on a dependent variable Allows drawing of conclusions about the causal relationships among variables. Cannot experimentally manipulate many important variables. May be expensive and time consuming. Source: Stangor, 2011. Descriptive Research: Assessing the Current State of Affairs Descriptive research is designed to create a snapshot of the current thoughts, feelings, or behaviour of individuals. This section reviews three types of descriptive research : case studies , surveys , and naturalistic observation (Figure 3.4). Sometimes the data in a descriptive research project are based on only a small set of individuals, often only one person or a single small group. These research designs are known as case studies — descriptive records of one or more individual’s experiences and behaviour . Sometimes case studies involve ordinary individuals, as when developmental psychologist Jean Piaget used his observation of his own children to develop his stage theory of cognitive development. More frequently, case studies are conducted on individuals who have unusual or abnormal experiences or characteristics or who find themselves in particularly difficult or stressful situations. The assumption is that by carefully studying individuals who are socially marginal, who are experiencing unusual situations, or who are going through a difficult phase in their lives, we can learn something about human nature. Sigmund Freud was a master of using the psychological difficulties of individuals to draw conclusions about basic psychological processes. Freud wrote case studies of some of his most interesting patients and used these careful examinations to develop his important theories of personality. One classic example is Freud’s description of “Little Hans,” a child whose fear of horses the psychoanalyst interpreted in terms of repressed sexual impulses and the Oedipus complex (Freud, 1909/1964). Figure 3.4 Descriptive Research. Political polls reported in newspapers and on the Internet are descriptive research designs that provide snapshots of the likely voting behaviour of a population. Another well-known case study is Phineas Gage, a man whose thoughts and emotions were extensively studied by cognitive psychologists after a railroad spike was blasted through his skull in an accident. Although there are questions about the interpretation of this case study (Kotowicz, 2007), it did provide early evidence that the brain’s frontal lobe is involved in emotion and morality (Damasio et al., 2005). An interesting example of a case study in clinical psychology is described by Rokeach (1964), who investigated in detail the beliefs of and interactions among three patients with schizophrenia, all of whom were convinced they were Jesus Christ. In other cases the data from descriptive research projects come in the form of a survey — a measure administered through either an interview or a written questionnaire to get a picture of the beliefs or behaviours of a sample of people of interest . The people chosen to participate in the research (known as the sample) are selected to be representative of all the people that the researcher wishes to know about (the population). In election polls, for instance, a sample is taken from the population of all “likely voters” in the upcoming elections. The results of surveys may sometimes be rather mundane, such as “Nine out of 10 doctors prefer Tymenocin” or “The median income in the city of Hamilton is $46,712.” Yet other times (particularly in discussions of social behaviour), the results can be shocking: “More than 40,000 people are killed by gunfire in the United States every year” or “More than 60% of women between the ages of 50 and 60 suffer from depression.” Descriptive research is frequently used by psychologists to get an estimate of the prevalence (or incidence ) of psychological disorders. A final type of descriptive research — known as naturalistic observation — is research based on the observation of everyday events . For instance, a developmental psychologist who watches children on a playground and describes what they say to each other while they play is conducting descriptive research, as is a biopsychologist who observes animals in their natural habitats. One example of observational research involves a systematic procedure known as the strange situation , used to get a picture of how adults and young children interact. The data that are collected in the strange situation are systematically coded in a coding sheet such as that shown in Table 3.3. Table 3.3 Sample Coding Form Used to Assess Child’s and Mother’s Behaviour in the Strange Situation [Skip Table] Coder name: Olive This table represents a sample coding sheet from an episode of the “strange situation,” in which an infant (usually about one year old) is observed playing in a room with two adults — the child’s mother and a stranger. Each of the four coding categories is scored by the coder from 1 (the baby makes no effort to engage in the behaviour) to 7 (the baby makes a significant effort to engage in the behaviour). More information about the meaning of the coding can be found in Ainsworth, Blehar, Waters, and Wall (1978). Coding categories explained Proximity The baby moves toward, grasps, or climbs on the adult. Maintaining contact The baby resists being put down by the adult by crying or trying to climb back up. Resistance The baby pushes, hits, or squirms to be put down from the adult’s arms. Avoidance The baby turns away or moves away from the adult. Episode Coding categories Proximity Contact Resistance Avoidance Mother and baby play alone 1 1 1 1 Mother puts baby down 4 1 1 1 Stranger enters room 1 2 3 1 Mother leaves room; stranger plays with baby 1 3 1 1 Mother re-enters, greets and may comfort baby, then leaves again 4 2 1 2 Stranger tries to play with baby 1 3 1 1 Mother re-enters and picks up baby 6 6 1 2 Source: Stang0r, 2011. The results of descriptive research projects are analyzed using descriptive statistics — numbers that summarize the distribution of scores on a measured variable . Most variables have distributions similar to that shown in Figure 3.5 where most of the scores are located near the centre of the distribution, and the distribution is symmetrical and bell-shaped. A data distribution that is shaped like a bell is known as a normal distribution . Figure 3.5 Height Distribution. The distribution of the heights of the students in a class will form a normal distribution. In this sample the mean (M) = 67.12 inches and the standard deviation (s) = 2.74. A distribution can be described in terms of its central tendency — that is, the point in the distribution around which the data are centred — and its dispersion, or spread . The arithmetic average, or arithmetic mean , symbolized by the letter M , is the most commonly used measure of central tendency . It is computed by calculating the sum of all the scores of the variable and dividing this sum by the number of participants in the distribution (denoted by the letter N ). In the data presented in Figure 3.5 the mean height of the students is 67.12 inches (170.5 cm). The sample mean is usually indicated by the letter M . In some cases, however, the data distribution is not symmetrical. This occurs when there are one or more extreme scores (known as outliers ) at one end of the distribution. Consider, for instance, the variable of family income (see Figure 3.6), which includes an outlier (a value of $3,800,000). In this case the mean is not a good measure of central tendency. Although it appears from Figure 3.6 that the central tendency of the family income variable should be around $70,000, the mean family income is actually $223,960. The single very extreme income has a disproportionate impact on the mean, resulting in a value that does not well represent the central tendency. The median is used as an alternative measure of central tendency when distributions are not symmetrical. The median is the score in the center of the distribution, meaning that 50% of the scores are greater than the median and 50% of the scores are less than the median . In our case, the median household income ($73,000) is a much better indication of central tendency than is the mean household income ($223,960). Figure 3.6 Family Income Distribution. The distribution of family incomes is likely to be nonsymmetrical because some incomes can be very large in comparison to most incomes. In this case the median or the mode is a better indicator of central tendency than is the mean. [Long Description] A final measure of central tendency, known as the mode , represents the value that occurs most frequently in the distribution . You can see from Figure 3.6 that the mode for the family income variable is $93,000 (it occurs four times). In addition to summarizing the central tendency of a distribution, descriptive statistics convey information about how the scores of the variable are spread around the central tendency. Dispersion refers to the extent to which the scores are all tightly clustered around the central tendency , as seen in Figure 3.7. Figure 3.7 Or they may be more spread out away from it, as seen in Figure 3.8. Figure 3.8 One simple measure of dispersion is to find the largest (the maximum ) and the smallest (the minimum ) observed values of the variable and to compute the range of the variable as the maximum observed score minus the minimum observed score. You can check that the range of the height variable in Figure 3.5 is 72 – 62 = 10. The standard deviation , symbolized as s , is the most commonly used measure of dispersion . Distributions with a larger standard deviation have more spread. The standard deviation of the height variable is s = 2.74, and the standard deviation of the family income variable is s = $745,337. An advantage of descriptive research is that it attempts to capture the complexity of everyday behaviour. Case studies provide detailed information about a single person or a small group of people, surveys capture the thoughts or reported behaviours of a large population of people, and naturalistic observation objectively records the behaviour of people or animals as it occurs naturally. Thus descriptive research is used to provide a relatively complete understanding of what is currently happening. Despite these advantages, descriptive research has a distinct disadvantage in that, although it allows us to get an idea of what is currently happening, it is usually limited to static pictures. Although descriptions of particular experiences may be interesting, they are not always transferable to other individuals in other situations, nor do they tell us exactly why specific behaviours or events occurred. For instance, descriptions of individuals who have suffered a stressful event, such as a war or an earthquake, can be used to understand the individuals’ reactions to the event but cannot tell us anything about the long-term effects of the stress. And because there is no comparison group that did not experience the stressful situation, we cannot know what these individuals would be like if they hadn’t had the stressful experience. Correlational Research: Seeking Relationships among Variables In contrast to descriptive research, which is designed primarily to provide static pictures, correlational research involves the measurement of two or more relevant variables and an assessment of the relationship between or among those variables. For instance, the variables of height and weight are systematically related (correlated) because taller people generally weigh more than shorter people. In the same way, study time and memory errors are also related, because the more time a person is given to study a list of words, the fewer errors he or she will make. When there are two variables in the research design, one of them is called the predictor variable and the other the outcome variable . The research design can be visualized as shown in Figure 3.9, where the curved arrow represents the expected correlation between these two variables. Figure 3.9 Predictor and Outcome Variables. One way of organizing the data from a correlational study with two variables is to graph the values of each of the measured variables using a scatter plot . As you can see in Figure 3.10 a scatter plot is a visual image of the relationship between two variables . A point is plotted for each individual at the intersection of his or her scores for the two variables. When the association between the variables on the scatter plot can be easily approximated with a straight line , as in parts (a) and (b) of Figure 3.10 the variables are said to have a linear relationship . When the straight line indicates that individuals who have above-average values for one variable also tend to have above-average values for the other variable , as in part (a), the relationship is said to be positive linear . Examples of positive linear relationships include those between height and weight, between education and income, and between age and mathematical abilities in children. In each case, people who score higher on one of the variables also tend to score higher on the other variable. Negative linear relationships , in contrast, as shown in part (b), occur when above-average values for one variable tend to be associated with below-average values for the other variable. Examples of negative linear relationships include those between the age of a child and the number of diapers the child uses, and between practice on and errors made on a learning task. In these cases, people who score higher on one of the variables tend to score lower on the other variable. Relationships between variables that cannot be described with a straight line are known as nonlinear relationships . Part (c) of Figure 3.10 shows a common pattern in which the distribution of the points is essentially random. In this case there is no relationship at all between the two variables, and they are said to be independent . Parts (d) and (e) of Figure 3.10 show patterns of association in which, although there is an association, the points are not well described by a single straight line. For instance, part (d) shows the type of relationship that frequently occurs between anxiety and performance. Increases in anxiety from low to moderate levels are associated with performance increases, whereas increases in anxiety from moderate to high levels are associated with decreases in performance. Relationships that change in direction and thus are not described by a single straight line are called curvilinear relationships . Figure 3.10 Examples of Scatter Plots. Some examples of relationships between two variables as shown in scatter plots. Note that the Pearson correlation coefficient (r) between variables that have curvilinear relationships will likely be close to zero. [Long Description] Source: Adapted from Stangor (2011). The most common statistical measure of the strength of linear relationships among variables is the Pearson correlation coefficient , which is symbolized by the letter r . The value of the correlation coefficient ranges from r = –1.00 to r = +1.00. The direction of the linear relationship is indicated by the sign of the correlation coefficient. Positive values of r (such as r = .54 or r = .67) indicate that the relationship is positive linear (i.e., the pattern of the dots on the scatter plot runs from the lower left to the upper right), whereas negative values of r (such as r = –.30 or r = –.72) indicate negative linear relationships (i.e., the dots run from the upper left to the lower right). The strength of the linear relationship is indexed by the distance of the correlation coefficient from zero (its absolute value). For instance, r = –.54 is a stronger relationship than r = .30, and r = .72 is a stronger relationship than r = –.57. Because the Pearson correlation coefficient only measures linear relationships, variables that have curvilinear relationships are not well described by r , and the observed correlation will be close to zero. It is also possible to study relationships among more than two measures at the same time. A research design in which more than one predictor variable is used to predict a single outcome variable is analyzed through multiple regression (Aiken &amp; West, 1991). Multiple regression is a statistical technique, based on correlation coefficients among variables, that allows predicting a single outcome variable from more than one predictor variable . For instance, Figure 3.11 shows a multiple regression analysis in which three predictor variables (Salary, job satisfaction, and years employed) are used to predict a single outcome (job performance). The use of multiple regression analysis shows an important advantage of correlational research designs — they can be used to make predictions about a person’s likely score on an outcome variable (e.g., job performance) based on knowledge of other variables. Figure 3.11 Prediction of Job Performance from Three Predictor Variables. Multiple regression allows scientists to predict the scores on a single outcome variable using more than one predictor variable. An important limitation of correlational research designs is that they cannot be used to draw conclusions about the causal relationships among the measured variables. Consider, for instance, a researcher who has hypothesized that viewing violent behaviour will cause increased aggressive play in children. He has collected, from a sample of Grade 4 children, a measure of how many violent television shows each child views during the week, as well as a measure of how aggressively each child plays on the school playground. From his collected data, the researcher discovers a positive correlation between the two measured variables. Figure 3.12 Although this positive correlation appears to support the researcher’s hypothesis, it cannot be taken to indicate that viewing violent television causes aggressive behaviour. Although the researcher is tempted to assume that viewing violent television causes aggressive play, there are other possibilities. One alternative possibility is that the causal direction is exactly opposite from what has been hypothesized. Perhaps children who have behaved aggressively at school develop residual excitement that leads them to want to watch violent television shows at home (Figure 3.13): Figure 3.13 Although this possibility may seem less likely, there is no way to rule out the possibility of such reverse causation on the basis of this observed correlation. It is also possible that both causal directions are operating and that the two variables cause each other (Figure 3.14). Figure 3.14 Still another possible explanation for the observed correlation is that it has been produced by the presence of a common-causal variable (also known as a third variable ). A common-causal variable is a variable that is not part of the research hypothesis but that causes both the predictor and the outcome variable and thus produces the observed correlation between them . In our example, a potential common-causal variable is the discipline style of the children’s parents. Parents who use a harsh and punitive discipline style may produce children who like to watch violent television and who also behave aggressively in comparison to children whose parents use less harsh discipline (Figure 3.15) Figure 3.15 In this case, television viewing and aggressive play would be positively correlated (as indicated by the curved arrow between them), even though neither one caused the other but they were both caused by the discipline style of the parents (the straight arrows). When the predictor and outcome variables are both caused by a common-causal variable, the observed relationship between them is said to be spurious . A spurious relationship is a relationship between two variables in which a common-causal variable produces and “explains away” the relationship . If effects of the common-causal variable were taken away, or controlled for, the relationship between the predictor and outcome variables would disappear. In the example, the relationship between aggression and television viewing might be spurious because by controlling for the effect of the parents’ disciplining style, the relationship between television viewing and aggressive behaviour might go away. Common-causal variables in correlational research designs can be thought of as mystery variables because, as they have not been measured, their presence and identity are usually unknown to the researcher. Since it is not possible to measure every variable that could cause both the predictor and outcome variables, the existence of an unknown common-causal variable is always a possibility. For this reason, we are left with the basic limitation of correlational research: correlation does not demonstrate causation. It is important that when you read about correlational research projects, you keep in mind the possibility of spurious relationships, and be sure to interpret the findings appropriately. Although correlational research is sometimes reported as demonstrating causality without any mention being made of the possibility of reverse causation or common-causal variables, informed consumers of research, like you, are aware of these interpretational problems. In sum, correlational research designs have both strengths and limitations. One strength is that they can be used when experimental research is not possible because the predictor variables cannot be manipulated. Correlational designs also have the advantage of allowing the researcher to study behaviour as it occurs in everyday life. And we can also use correlational designs to make predictions — for instance, to predict from the scores on their battery of tests the success of job trainees during a training session. But we cannot use such correlational information to determine whether the training caused better job performance. For that, researchers rely on experiments. Experimental Research: Understanding the Causes of Behaviour The goal of experimental research design is to provide more definitive conclusions about the causal relationships among the variables in the research hypothesis than is available from correlational designs. In an experimental research design, the variables of interest are called the independent variable (or variables ) and the dependent variable . The independent variable in an experiment is the causing variable that is created (manipulated) by the experimenter . The dependent variable in an experiment is a measured variable that is expected to be influenced by the experimental manipulation . The research hypothesis suggests that the manipulated independent variable or variables will cause changes in the measured dependent variables. We can diagram the research hypothesis by using an arrow that points in one direction. This demonstrates the expected direction of causality (Figure 3.16): Figure 3.16 Research Focus: Video Games and Aggression Consider an experiment conducted by Anderson and Dill (2000). The study was designed to test the hypothesis that viewing violent video games would increase aggressive behaviour. In this research, male and female undergraduates from Iowa State University were given a chance to play with either a violent video game (Wolfenstein 3D) or a nonviolent video game (Myst). During the experimental session, the participants played their assigned video games for 15 minutes. Then, after the play, each participant played a competitive game with an opponent in which the participant could deliver blasts of white noise through the earphones of the opponent. The operational definition of the dependent variable (aggressive behaviour) was the level and duration of noise delivered to the opponent. The design of the experiment is shown in Figure 3.17 Figure 3.17 An Experimental Research Design. Two advantages of the experimental research design are (a) the assurance that the independent variable (also known as the experimental manipulation ) occurs prior to the measured dependent variable, and (b) the creation of initial equivalence between the conditions of the experiment (in this case by using random assignment to conditions). Experimental designs have two very nice features. For one, they guarantee that the independent variable occurs prior to the measurement of the dependent variable. This eliminates the possibility of reverse causation. Second, the influence of common-causal variables is controlled, and thus eliminated, by creating initial equivalence among the participants in each of the experimental conditions before the manipulation occurs. The most common method of creating equivalence among the experimental conditions is through random assignment to conditions, a procedure in which the condition that each participant is assigned to is determined through a random process, such as drawing numbers out of an envelope or using a random number table . Anderson and Dill first randomly assigned about 100 participants to each of their two groups (Group A and Group B). Because they used random assignment to conditions, they could be confident that, before the experimental manipulation occurred, the students in Group A were, on average, equivalent to the students in Group B on every possible variable, including variables that are likely to be related to aggression, such as parental discipline style, peer relationships, hormone levels, diet — and in fact everything else. Then, after they had created initial equivalence, Anderson and Dill created the experimental manipulation — they had the participants in Group A play the violent game and the participants in Group B play the nonviolent game. Then they compared the dependent variable (the white noise blasts) between the two groups, finding that the students who had viewed the violent video game gave significantly longer noise blasts than did the students who had played the nonviolent game. Anderson and Dill had from the outset created initial equivalence between the groups. This initial equivalence allowed them to observe differences in the white noise levels between the two groups after the experimental manipulation, leading to the conclusion that it was the independent variable (and not some other variable) that caused these differences. The idea is that the only thing that was different between the students in the two groups was the video game they had played. Despite the advantage of determining causation, experiments do have limitations. One is that they are often conducted in laboratory situations rather than in the everyday lives of people. Therefore, we do not know whether results that we find in a laboratory setting will necessarily hold up in everyday life. Second, and more important, is that some of the most interesting and key social variables cannot be experimentally manipulated. If we want to study the influence of the size of a mob on the destructiveness of its behaviour, or to compare the personality characteristics of people who join suicide cults with those of people who do not join such cults, these relationships must be assessed using correlational designs, because it is simply not possible to experimentally manipulate these variables. Key Takeaways Descriptive, correlational, and experimental research designs are used to collect and analyze data. Descriptive designs include case studies, surveys, and naturalistic observation. The goal of these designs is to get a picture of the current thoughts, feelings, or behaviours in a given group of people. Descriptive research is summarized using descriptive statistics. Correlational research designs measure two or more relevant variables and assess a relationship between or among them. The variables may be presented on a scatter plot to visually show the relationships. The Pearson Correlation Coefficient ( r ) is a measure of the strength of linear relationship between two variables. Common-causal variables may cause both the predictor and outcome variable in a correlational design, producing a spurious relationship. The possibility of common-causal variables makes it impossible to draw causal conclusions from correlational research designs. Experimental research involves the manipulation of an independent variable and the measurement of a dependent variable. Random assignment to conditions is normally used to create initial equivalence between the groups, allowing researchers to draw causal conclusions. There is a negative correlation between the row that a student sits in in a large class (when the rows are numbered from front to back) and his or her final grade in the class. Do you think this represents a causal relationship or a spurious relationship, and why? Think of two variables (other than those mentioned in this book) that are likely to be correlated, but in which the correlation is probably spurious. What is the likely common-causal variable that is producing the relationship? Imagine a researcher wants to test the hypothesis that participating in psychotherapy will cause a decrease in reported anxiety. Describe the type of research design the investigator might use to draw this conclusion. What would be the independent and dependent variables in the research? Figure 3.4: “ Reading newspaper ” by Alaskan Dude ( is licensed under CC BY 2.0 References Aiken, L., &amp; West, S. (1991). Multiple regression: Testing and interpreting interactions . Newbury Park, CA: Sage. Ainsworth, M. S., Blehar, M. C., Waters, E., &amp; Wall, S. (1978). Patterns of attachment: A psychological study of the strange situation . Hillsdale, NJ: Lawrence Erlbaum Associates. Anderson, C. A., &amp; Dill, K. E. (2000). Video games and aggressive thoughts, feelings, and behavior in the laboratory and in life. Journal of Personality and Social Psychology, 78 (4), 772–790. Damasio, H., Grabowski, T., Frank, R., Galaburda, A. M., Damasio, A. R., Cacioppo, J. T., &amp; Berntson, G. G. (2005). The return of Phineas Gage: Clues about the brain from the skull of a famous patient. In Social neuroscience: Key readings. (pp. 21–28). New York, NY: Psychology Press. Freud, S. (1909/1964). Analysis of phobia in a five-year-old boy. In E. A. Southwell &amp; M. Merbaum (Eds.), Personality: Readings in theory and research (pp. 3–32). Belmont, CA: Wadsworth. (Original work published 1909). Kotowicz, Z. (2007). The strange case of Phineas Gage. History of the Human Sciences, 20 (1), 115–131. Rokeach, M. (1964). The three Christs of Ypsilanti: A psychological study . New York, NY: Knopf. Stangor, C. (2011). Research methods for the behavioural sciences (4th ed.). Mountain View, CA: Cengage. Long Descriptions Figure 3.6 long description: There are 25 families. 24 families have an income between $44,000 and $111,000 and one family has an income of $3,800,000. The mean income is $223,960 while the median income is $73,000. [Return to Figure 3.6] Figure 3.10 long description: Types of scatter plots. Positive linear, r=positive .82. The plots on the graph form a rough line that runs from lower left to upper right. Negative linear, r=negative .70. The plots on the graph form a rough line that runs from upper left to lower right. Independent, r=0.00. The plots on the graph are spread out around the centre. Curvilinear, r=0.00. The plots of the graph form a rough line that goes up and then down like a hill. Curvilinear, r=0.00. The plots on the graph for a rough line that goes down and then up like a ditch. [Return to Figure 3.10] 14 3.3 You Can Be an Informed Consumer of Psychological Research \n",
      "-----------\n",
      "Differentiate the goals of descriptive, correlational, and experimental research designs and explain the advantages and disadvantages of each.\n",
      "Explain the goals of descriptive research and the statistical techniques used to interpret it.\n",
      "Summarize the uses of correlational research and describe why correlational research cannot be used to infer causality.\n",
      "Review the procedures of experimental research and explain how it can be used to draw causal inferences.\n",
      "--------------------------\n",
      "Figure 20.0.1 The open pit (background) and waste-rock piles (middle) of the Highland Valley Copper Mine at Logan Lake, British Columbia. It has been said that “if you can’t grow it, you have to mine it,” meaning that anything we can’t grow we have to extract from Earth in one way or another. This includes water, of course, our most important resource, but it also includes all the other materials that we need to construct things like roads, dams, and bridges, or manufacture things like plates, toasters, and telephones. Even most of our energy resources come from Earth, including uranium and fossil fuels, and much of the infrastructure of this electrical age depends on copper (Figure 20.0.1). Figure 20.0.2 The main components of a tablet computer. Virtually everything we use every day is made from resources from Earth. For example, let’s look at a tablet computer (Figure 20.0.2). Most of the case is made of a plastic known as ABS, which is made from either gas or petroleum. Some tablets have a case made from aluminum. The glass of a touch screen is made mostly from quartz combined with smaller amounts of sodium oxide (Na 2 O), sodium carbonate (Na 2 CO 3 ), and calcium oxide (CaO). To make it work as a touch screen, the upper surface is coated with indium tin oxide. When you touch the screen you’re actually pushing a thin layer of polycarbonate plastic (made from petroleum) against the coated glass—completing an electrical circuit. The computer is then able to figure out exactly where you touched the screen. Computer processors are made from silica wafers (more quartz) and also include a significant amount of copper and gold. Gold is used because it is a better conductor than copper and doesn’t tarnish the way silver or copper does. Most computers have nickel-metal-hydride (NiMH) batteries, which contain nickel, of course, along with cadmium, cobalt, manganese, aluminum, and the rare-earth elements lanthanum, cerium, neodymium, and praseodymium. The processor and other electronic components are secured to a circuit board, which is a thin layer of fibreglass sandwiched between copper sheets coated with small amounts of tin and lead. Various parts are put together with steel screws that are made of iron and molybdenum. That’s not everything that goes into a tablet computer, but to make just those components we need a pure-silica sand deposit, a salt mine for sodium, a rock quarry for calcium, an oil well, a gas well, an aluminum mine, an iron mine, a manganese mine, a copper-molybdenum-gold mine, a cobalt-nickel mine, a rare-earth element and indium mine, and a source of energy to transport all of the materials, process them, put them together, and finally transport the computer to your house or the store where you bought it. Figure 20.0.1: © Russell Hartlaub. CC BY. Figure 20.0.2: “ Ipad Air ” © Zach Vega . Adapted by Steven Earle. CC BY-SA. Figure 20.0.3: “ Ballpoint pen parts ” by unknown. CC BY-SA. 112 20.1 Metal Deposits Mining has always been a major part of Canada’s economy. Canada has some of the largest mining districts and deposits in the world, and for the past 150 years, we have been one of the world’s most important suppliers of metals. Extraction of Earth’s resources goes back a long way in Canada. For example, the First Nations of British Columbia extracted obsidian from volcanic regions for tools and traded it up and down the coast. In the 1850s, gold was discovered in central British Columbia, and in the 1890s, even more gold was discovered in the Klondike area of Yukon. These two events were critical to the early development of British Columbia, Yukon, and Alaska. Figure 20.1.1 The value of various Canadian mining sectors in 2017.  The total value of these products was about $44 billion in 2017. [Image Description] Canada’s mining sector had revenues in the order of $44 billion in 2017 (Figure 20.1.1). The 4 most valuable commodities were gold, coal, copper and potash, with important amounts from iron, nickel, diamonds, sand and gravel aggregates, stone and zinc. Revenues from the petroleum sector are significantly higher, at over $100 billion per year. A metal deposit is a body of rock in which one or more metals have been concentrated to the point of being economically viable for recovery. Some background levels of important metals in average rocks are shown on Table 20.1, along with the typical grades necessary to make a viable deposit, and the corresponding concentration factors. Looking at copper, for example, we can see that while average rock has around 40 ppm (parts per million) of copper, a grade of around 10,000 ppm or 1% is necessary to make a viable copper deposit. In other words, copper ore has about 250 times as much copper as typical rock. For the other elements in the list, the concentration factors are much higher. For gold, it’s 2,000 times and for silver it’s around 10,000 times. Table 20.1 Typical background and ore levels of some important metals. Metal Typical Background Level Typical Economic Grade* Concentration Factor Copper 40 ppm 10,000 ppm (1%) 250 times Gold 0.003 ppm 6 ppm (0.006%) 2,000 times Lead 10 ppm 50,000 ppm (5%) 5,000 times Molybdenum 1 ppm 1,000 ppm (0.1%) 1,000 times Nickel 25 ppm 20,000 ppm (2%) 800 times Silver 0.1 ppm 1,000 ppm (0.1%) 10,000 times Uranium 2 ppm 10,000 ppm (1%) 5,000 times Zinc 50 ppm 50,000 ppm (5%) 1,000 times *It’s important to note that the economic viability of any deposit depends on a wide range of factors including its grade, size, shape, depth below the surface, and proximity to infrastructure, the current price of the metal, the labour and environmental regulations in the area, and many other factors. It is clear that some very significant concentration must take place to form a mineable deposit. This concentration may occur during the formation of the host rock, or after the rock forms, through a number of different types of processes. There is a very wide variety of ore-forming processes, and there are hundreds of types of mineral deposits. The origins of a few of them are described below. Magmatic Nickel Deposits Figure 20.1.2 The nickel smelter at Thompson, Manitoba. A magmatic deposit is one in which the metal concentration takes place primarily at the same time as the formation and emplacement of the magma. Most of the nickel mined in Canada comes from magmatic deposits such as those in Sudbury (Ontario), Thompson (Manitoba) (Figure 20.1.2), and Voisey’s Bay (Labrador). The magmas from which these deposits form are of mafic or ultramafic composition (derived from the mantle), and therefore they had relatively high nickel and copper contents to begin with (as much as 100 times more than normal rocks in the case of nickel). These elements may be further concentrated within the magma as a result of the addition of sulphur from partial melting of the surrounding rocks. The heavy nickel and copper sulphide minerals are then concentrated further still by gravity segregation (i.e., crystals settling toward the bottom of the magma chamber). In some cases, there are also significant concentrations of platinum-bearing minerals in magmatic deposits. Most of these types of deposits around the world are Precambrian in age; the mantle was significantly hotter at that time, and the necessary mafic and ultramafic magmas were more likely to be emplaced in the continental crust. Volcanogenic Massive Sulphide Deposits Much of the copper, zinc, lead, silver, and gold mined in Canada is mined from volcanic-hosted massive sulphide (VHMS) deposits associated with submarine volcanism (VMS deposits). Examples are the deposits at Kidd Creek, Ontario, Flin Flon on the Manitoba-Saskatchewan border, Britannia on Howe Sound, and Myra Falls (within Strathcona Park) on Vancouver Island. Figure 20.1.3 Left: A black smoker on the Juan de Fuca Ridge off the west coast of Vancouver Island. Right: A model of the formation of a volcanogenic massive sulphide deposit on the sea floor. VMS deposits are formed from the water discharged at high temperature (250° to 300°C) at ocean-floor hydrothermal vents, primarily in areas of subduction-zone volcanism. The environment is comparable to that of modern-day black smokers (Figure 20.1.3), which form where hot metal- and sulphide-rich water issues from the sea floor. They are called massive sulphide deposits because the sulphide minerals (including pyrite (FeS2) , sphalerite (ZnS), chalcopyrite (CuFeS 2 ), and galena (PbS)) are generally present in very high concentrations (making up the majority of the rock in some cases). The metals and the sulphur are leached out of the sea-floor rocks by convecting groundwater driven by the volcanic heat, and then quickly precipitated where that hot water enters the cold seawater, causing it to cool suddenly and change chemically. The volcanic rock that hosts the deposits is formed in the same area and at the same general time as the accumulation of the ore minerals. Porphyry Deposits Porphyry deposits are the most important source of copper and molybdenum in British Columbia, the western United States, and Central and South America. Most porphyry deposits also host some gold, and in rare cases gold is the primary commodity. B.C. examples include several large deposits within the Highland Valley mine (Figure 20.0.1) and numerous other deposits scattered around the central part of the province. Figure 20.1.4 A model for the formation of a porphyry deposit around an upper-crustal porphyritic stock and associated vein deposits. A porphyry deposit forms around a cooling felsic stock in the upper part of the crust. They are called “porphyry” because upper crustal stocks are typically porphyritic in texture, the result of a two-stage cooling process. Metal enrichment results in part from convection of groundwater related to the heat of the stock, and also from metal-rich hot water expelled by the cooling magma (Figure 20.1.4). The host rocks, which commonly include the stock itself and the surrounding country rocks, are normally highly fractured and brecciated. During the ore-forming process, some of the original minerals in these rocks are altered to potassium feldspar, biotite, epidote, and various clay minerals. The important ore minerals include chalcopyrite (CuFeS 2 ), bornite (Cu 5 FeS 4 ), and pyrite in copper porphyry deposits, or molybdenite (MoS 2 ) and pyrite in molybdenum porphyry deposits. Gold is present as minute flakes of native gold. This type of environment (i.e., around and above an intrusive body) is also favourable for the formation of other types of deposits—particularly vein-type gold deposits (a.k.a. epithermal deposits ). Some of the gold deposits of British Columbia (such as in the Eskay Creek area adjacent to the Alaska panhandle), and many of the other gold deposits situated along the western edge of both South and North America are of the vein type shown in Figure 20.1.4, and are related to nearby magma bodies. Banded Iron Formation Figure 20.1.5 Banded iron formation from an unknown location in North America on display at a museum in Germany. The rock is about 2 m across. The dark grey layers are magnetite and the red layers are hematite. Chert is also present. Most of the world’s major iron deposits are of the banded iron formation type, and most of these formed during the initial oxygenation of Earth’s atmosphere between 2,400 and 1,800 Ma. At that time, iron that was present in dissolved form in the ocean (as Fe2+) became oxidized to its insoluble form (Fe3+) and accumulated on the sea floor, mostly as hematite interbedded with chert (Figure 20.1.5). Unlike many other metals, which are economically viable at grades of around 1% or even much less, iron deposits are only viable if the grades are in the order of 50% iron and if they are very large. Unconformity-Type Uranium Deposits Figure 20.1.6 Model of the formation of unconformity-type uranium deposits of the Athabasca Basin, Saskatchewan. There are several different types of uranium deposits, but some of the largest and richest are those within the Athabasca Basin of northern Saskatchewan. These are called unconformity-type uranium deposits because they are all situated very close to the unconformity between the Proterozoic Athabasca Group sandstone and the much older Archean sedimentary, volcanic, and intrusive igneous rock (Figure 20.1.6). The origin of unconformity-type U deposits is not perfectly understood, but it is thought that two particular features are important: (1) the relative permeability of the Athabasca Group sandstone, and (2) the presence of graphitic schist within the underlying Archean rocks. The permeability of the sandstone allowed groundwater to flow through it and leach out small amounts of U, which stayed in solution in the oxidized form U 6+ . The graphite (C) created a reducing (non-oxidizing) environment that converted the uranium from U 6+ to insoluble U 4+ , at which point it was precipitated as the mineral uraninite (UO 2 ). Mining and Mineral Processing Figure 20.1.7 Underground at the Myra Falls Mine, Vancouver Island. Figure 20.1.8 Schematic cross-section of a typical underground mine. [Image Description] Metal deposits are mined in a variety of different ways depending on their depth, shape, size, and grade. Relatively large deposits that are quite close to the surface and somewhat regular in shape are mined using open-pit mine methods (Figure 20.0.1). Creating a giant hole in the ground is generally cheaper than making an underground mine, but it is also less precise, so it is necessary to mine a lot of waste rock along with the ore. Relatively deep deposits or those with elongated or irregular shapes are typically mined from underground with deep vertical shafts , declines (sloped tunnels), and levels (horizontal tunnels) (Figures 20.1.7 and 20.1.9). In this way, it is possible to focus the mining on the ore body itself. However, with relatively large ore bodies, it may be necessary to leave some pillars to hold up the roof. In many cases, the near-surface part of an ore body is mined with an open pit, while the deeper parts are mined underground (Figures 20.1.8 and 20.1.9). Figure 20.1.9 Entrance to an exploratory decline (white arrow) for the New Afton Mine situated in the side of the open pit of the old Afton Mine, near Kamloops, B.C. A typical metal deposit might contain a few percent of ore minerals (e.g., chalcopyrite or sphalerite), mixed with the minerals of the original rock (e.g., quartz or feldspar). Other sulphide minerals are commonly present within the ore, especially pyrite. When ore is processed (typically very close to the mine), it is ground to a fine powder and the ore minerals are physically separated from the rest of the rock to make a concentrate . At a molybdenum mine, for example, this concentrate may be almost pure molybdenite (MoS 2 ). The rest of the rock is known as tailings . It comes out of the concentrator as a wet slurry and must be stored near the mine, in most cases, in a tailings pond. The tailings pond at the Myra Falls Mine on Vancouver Island and the settling ponds for waste water from the concentrator are shown in Figure 20.1.10. The tailings are contained by an embankment. Also visible in the foreground is a pile of waste rock, which is non-ore rock that was mined in order to access the ore. Although this waste rock contains little or no ore minerals, at many mines it contains up to a few percent pyrite. The tailings and the waste rock at most mines are an environmental liability because they contain pyrite plus small amounts of ore minerals. When pyrite is exposed to oxygen and water, it generates sulphuric acid—also known as acid rock drainage (ARD). Acidity itself is a problem to the environment, but because the ore elements, such as copper or lead, are more soluble in acidic water than neutral water, ARD is also typically quite rich in metals, many of which are toxic. Figure 20.1.10 The tailings pond at the Myra Falls Mine on Vancouver Island. The dry rock in the middle of the image is waste rock. Myra Creek flows between the tailings pond and the headframe. The settling ponds (right) are used for processing water from the concentrator. Tailings ponds and waste-rock storage piles must be carefully maintained to ensure their integrity and monitored to ensure that acidic and metal-rich water is not leaking out. In August 2014, the tailings pond at the Mt. Polley Mine in central B.C. failed and 10 million cubic metres of waste water along with 4.5 million cubic metres of tailings slurry was released into Polley Lake, Hazeltine Creek, and Quesnel Lake (Figure 20.1.11, a and b). As of 2019, the environmental implications of this event are still not fully understood. Figure 20.1.11 The Mt. Polley Mine area before and after to the dam breach of August 2014. The tailings were stored in the area labelled “retention basin.”   The retention dam failed and water and tailings released flowed into Polley Lake, Hazeltine Creek, and  Quesnel Lakes. Most mines have concentrators on site because it is relatively simple to separate ore minerals from non-ore minerals and this significantly reduces the costs and other implications of transportation. But separation of ore minerals is only the preliminary stage of metal refinement, for most metals the second stage involves separating the actual elements within the ore minerals. For example, the most common ore of copper is chalcopyrite (CuFeS 2 ). The copper needs to be separated from the iron and sulphur to make copper metal and that involves complicated and very energy-intensive processes that are done at smelters or other types of refineries. Because of their cost and the economies of scale, there are far fewer refineries than there are mines. There are several metal refineries (including smelters) in Canada; some examples are the aluminum refinery in Kitimat, B.C. (which uses ore from overseas); the lead-zinc smelter in Trail, B.C.; the nickel smelter at Thompson, Manitoba; numerous steel smelters in Ontario, along with several other refining operations for nickel, copper, zinc, and uranium; aluminum refineries in Quebec; and a lead smelter in New Brunswick. Image Descriptions Figure 20.1.1 image description: The value of the different mining sectors in Canada. Mining Sector Value (in billions) Total value $36.7 Potash $6.1 Gold $5.9 Iron $5.3 Copper $4.6 Nickel $3.5 Diamonds $2.0 Sand and gravel $1.7 Cement $1.6 Stone $1.5 Zinc $0.8 Uranium $0.7 Salt $0.6 Other metals $2.4 [Return to Figure 20.1.1] Figure 20.1.8 image description: An open-pit mine is dug to access the ore that is near the surface. For ore farther down, an underground mine will be constructed to access the ore. This diagram shows the main shaft (a large vertical tunnel) with four levels (horizontal tunnels) connected to it. The levels run from the main shaft into the ore body. A ventilation shaft runs up through the four levels in between the main shaft and the ore for air circulation. [Return to Figure 20.1.8] Figure 20.1.1: © Steven Earle. CC BY. Based on data from Natural Resources Canada . Figure 20.1.2: “ Vale Nickel Mine ” © Timkal . CC BY-SA. Figure 20.1.3 (left): “ Black Smoker ” by D. Butterfield, Univ. of Washington and J. Holden, Univ. Massachusetts Amherst. Public domain. Figure 20.1.3 (right): © Steven Earle. CC BY. Figure 20.1.4: © Steven Earle. CC BY. Figure 20.1.5: “ Bestand: Black-band ironstone ” © Aka . CC BY-SA. Figures 20.1.6, 20.1.7, 20.1.8, 20.1.9, 20.1.10, 20.1.11: © Steven Earle. CC BY. Figure 20.1.11 (left): “ Mount Polley Mine site ” by Visible Earth, NASA . Public domain. Figure 20.1.11 (right): “ Mount Polley Mine site dam breach 2014 ” by Visible Earth, NASA . Public domain. Table by Steven Earle. 113 20.2 Industrial Materials Metals are critical for our technological age, but there are a lot of other not-so-shiny materials that are needed to facilitate our way of life. For everything made out of concrete or asphalt, we need sand and gravel. To make the cement that holds concrete together, we also need limestone. For the glass in our computer screens and for glass-sided buildings, we need silica sand plus sodium oxide (Na 2 O), sodium carbonate (Na 2 CO 3 ), and calcium oxide (CaO). Potassium is an essential nutrient for farming in many areas, and for a wide range of applications (e.g., ceramics and many industrial processes), we also need various types of clay. The best types of aggregate (sand and gravel) resources are those that have been sorted by streams, and in Canada the most abundant and accessible fluvial deposits are associated with glaciation. That doesn’t include till of course, because it has too much silt and clay, but it does include glaciofluvial outwash, which is present in thick deposits in many parts of the country, similar to the one shown in Figure 20.2.2. In a typical gravel pit, these materials are graded on-site according to size and then used in a wide range of applications from constructing huge concrete dams to filling children’s sandboxes. Sand is also used to make glass, but for most types of glass, it has to be at least 95% quartz (which the sandy layers shown in Figure 20.2.1 are definitely not), and for high-purity glass and the silicon wafers used for electronics, the source sand has to be over 98% quartz. Figure 20.2.1 Sand and gravel in an aggregate pit near Nanaimo, BC. Approximately 80 million tonnes of concrete are used in Canada each year—a little over 2 tonnes per person. The cement used for concrete is made from approximately 80% calcite (CaCO 3 ) and 20% clay. This mixture is heated to 1450°C to produce the required calcium silicate compounds (e.g., Ca 2 SiO 4 ). The calcite typically comes from limestone quarries like the one on Texada Island, B.C. (Figure 20.2.2). Limestone is also used as the source material for many other products that require calcium compounds, including steel and glass, pulp and paper, and plaster products for construction. Figure 20.2.2 Triassic Quatsino Formation limestone being quarried on Texada Island, B.C. Sodium is required for a wide range of industrial processes, and the most convenient source is sodium chloride (rock salt), which is mined from evaporite beds in various parts of Canada. The largest salt mine in the world is at Goderich, Ontario, where salt is recovered from the 100 m thick Silurian Salina Formation. The same formation is mined in the Windsor area. Rock salt is also used as a source of sodium and chlorine in the chemical industry to melt ice on roads, as part of the process of softening water, and as a seasoning. Under certain conditions, the mineral sylvite (KCl) accumulates in evaporite beds, and this rock is called potash. This happened across the Canadian prairies during the Devonian, creating the Prairie evaporite formation (Figure 6.2.8). Potassium is used as a crop fertilizer, and Canada is the world’s leading supplier, with most of that production coming from Saskatchewan. Figure 20.2.3 Slate used as a facing material on a concrete building column in Vancouver. Another evaporite mineral, gypsum (CaSO 4 .2H 2 0), is the main component of plasterboard (drywall) that is widely used in the construction industry. One of the main mining areas for gypsum in Canada is in the Milford Station area of Nova Scotia, site of the world’s largest gypsum mine. Rocks are quarried or mined for many different uses, such as building facades (Figure 20.2.3), countertops, stone floors, and headstones. In most of these cases, the favoured rock types are granitic rocks, slate, and marble. Quarried rock is also used in some applications where rounded gravel isn’t suitable, such as the ballast (road bed) for railways, where crushed angular rock is needed. Figures 20.2.1, 20.2.2, 20.2.3: © Steven Earle. CC BY. 114 20.3 Fossil Fuels There are numerous types of fossil fuels, but all of them involve the storage of organic matter in sediments or sedimentary rocks. Fossil fuels are rich in carbon and almost all of that carbon ultimately originates from CO 2 taken out of the atmosphere during photosynthesis. That process, driven by solar energy, involves reduction (the opposite of oxidation) of the carbon, resulting in it being combined with hydrogen instead of oxygen. The resulting organic matter is made up of complex and varied carbohydrate molecules. Most organic matter is oxidized back to CO 2 relatively quickly (within weeks or years in most cases), but any of it that gets isolated from the oxygen of the atmosphere (for example, deep in the ocean or in a stagnant bog) may last long enough to be buried by sediments and, if so, may be preserved for tens to hundreds of millions of years. Under natural conditions, that means it will be stored until those rocks are eventually exposed at the surface and weathered. In this section, we’ll discuss the origins and extraction of the important fossils fuels, including coal, oil, and gas. Coal, the first fossil fuel to be widely used, forms mostly on land in swampy areas adjacent to rivers and deltas in areas with humid tropical to temperate climates. The vigorous growth of vegetation leads to an abundance of organic matter that accumulates within stagnant water, and thus does not decay and oxidize. This situation, where the dead organic matter is submerged in oxygen-poor water, must be maintained for centuries to millennia in order for enough material to accumulate to form a thick layer (Figure 20.3.1a). At some point, the swamp deposit is covered with more sediment — typically because a river changes its course or sea level rises (Figure 20.3.1b). As more sediments are added, the organic matter starts to become compressed and heated. Low-grade lignite coal forms at depths between a few 100 m and 1,500 m and temperatures up to about 50°C (Figure 20.3.1c). At between 1,000 m to 5,000 m depth and temperatures up to 150°C m, bituminous coal forms (Figure 20.3.1d). At depths beyond 5,000 m and temperatures over 150°C, anthracite coal forms. Figure 20.3.1 Formation of coal: (a) accumulation of organic matter within a swampy area; (b) the organic matter is covered and compressed by deposition of a new layer of clastic sediments; (c) with greater burial, lignite coal forms; and (d) at even greater depths, bituminous and eventually anthracite coal form. There are significant coal deposits in many parts of Canada, including the Maritimes, Ontario, Saskatchewan, Alberta, and British Columbia. In Alberta and Saskatchewan, much of the coal is used for electricity generation. Coal from the Highvale Mine (Figure 20.3.2), Canada’s largest, is used to feed the Sundance and Keephills power stations west of Edmonton. Almost all of the coal mined in British Columbia is exported for use in manufacturing steel. Figure 20.3.2 The Highvale Mine (background) and the Sundance (right) and Keephills (left) generating stations on the southern shore of Wabamun Lake, Alberta. While almost all coal forms on land from terrestrial vegetation, most oil and gas is derived primarily from marine micro-organisms that accumulate within sea-floor sediments. In areas where marine productivity is high, dead organic matter is delivered to the sea floor fast enough that some of it escapes oxidation. This material accumulates in the muddy sediments, which become buried to significant depth beneath other sediments. Figure 20.3.3 The depth and temperature limits for biogenic gas, oil, and thermogenic gas. As the depth of burial increases, so does the temperature—due to the geothermal gradient—and gradually the organic matter within the sediments is converted to hydrocarbons (Figure 20.3.3). The first stage is the biological production (involving anaerobic bacteria) of methane. Most of this escapes back to the surface, but some is trapped in methane hydrates near the sea floor. At depths beyond about 2 km, and at temperatures ranging from 60° to 120°C, the organic matter is converted by chemical processes to oil. This depth and temperature range is known as the oil window . Beyond 120°C most of the organic matter is chemically converted to methane. Figure 20.3.4 Migration of oil and gas from source rocks into traps in reservoir rocks. The organic matter-bearing rock within which the formation of gas and oil takes place is known to petroleum geologists as the source rock . Both liquid oil and gaseous methane are lighter than water, so as liquids and gases form, they tend to move slowly toward the surface, out of the source rock and into reservoir rocks . Reservoir rocks are typically relatively permeable because that allows migration of the fluids from the source rocks, and also facilitates recovery of the oil or gas. In some cases, the liquids and gases make it all the way to the surface, where they are oxidized, and the carbon is returned to the atmosphere. But in other cases, they are contained by overlying impermeable rocks (e.g., mudrock) in situations where anticlines, faults, stratigraphy changes, and reefs or salt domes create traps (Figure 20.3.4). The liquids and gases that are trapped within reservoirs become separated into layers based on their density, with gas rising to the top, oil below it, and water underneath the oil. The proportions of oil and gas depend primarily on the temperature in the source rocks. Some petroleum fields, such as many of those in Alberta, are dominated by oil, while others, notably those in northeastern B.C., are dominated by gas. Figure 20.3.5 Seismic section through the East Breaks Field in the Gulf of Mexico. The dashed red line marks the approximate boundary between deformed rocks and younger undeformed rocks. The wiggly arrows are interpreted migration paths. The total thickness of this section is approximately 5 km. In general, petroleum fields are not visible from the surface, and their discovery involves the search for structures in the subsurface that have the potential to form traps. Seismic surveys are the most commonly used tool for early-stage petroleum exploration, as they can reveal important information about the stratigraphy and structural geology of subsurface sedimentary rocks. An example from the Gulf of Mexico south of Texas is shown in Figure 20.3.5. In this area, a thick evaporite deposit (“salt”) has formed domes because salt is lighter than other sediments and tends to rise slowly toward the surface; this has created traps. The sequence of deformed rocks is capped with a layer of undeformed rock. The type of oil and gas reservoirs illustrated in Figures 20.3.4 and 20.3.5 are described as conventional reserves. Some unconventional types of oil and gas include oil sands, shale gas, and coal-bed methane. Figure 20.3.7 Schematic cross-section of northern Alberta showing the source rocks and location of the Athabasca Oil Sands. Oil sands are important because the reserves in Alberta are extremely large (the largest single reserve of oil in the world), but they are very controversial from an environmental and social perspective. They are “unconventional” because the oil is exposed near the surface and is highly viscous because of microbial changes that have taken place at the surface. The hydrocarbons that form this reserve originated in deeply buried Paleozoic rocks adjacent to the Rocky Mountains and migrated up and toward the east (Figure 20.3.7). The oil sands are controversial primarily because of the environmental cost of their extraction. Since the oil is so viscous, it requires heat to make it sufficiently liquid to process. This energy comes from gas; approximately 25 m 3 of gas is used to produce 0.16 m 3 (one barrel) of oil. (That’s not quite as bad as it sounds, as the energy equivalent of the required gas is about 20% of the energy embodied in the produced oil.) The other environmental cost of oil sands production is the devastation of vast areas of land where strip-mining is taking place and tailings ponds are constructed, and the unavoidable release of contaminants into the groundwater and rivers of the region. At present, most oil recovery from oil sands is achieved by mining the sand and processing it on site. Exploitation of oil sand that is not exposed at the surface depends on in situ processes, an example being the injection of steam into the oil-sand layer to reduce the viscosity of the oil so that it can be pumped to the surface. Shale gas is gas that is trapped within rock that is too impermeable for the gas to escape under normal conditions, and it can only be extracted by fracturing the reservoir rock using water and chemicals under extremely high pressure. This procedure is known as hydraulic fracturing or “ fracking .” Fracking is controversial because of the volume of water used, and because, in some jurisdictions, the fracking companies are not required to disclose the nature of the chemicals used. Although fracking is typically done at significant depths, there is always the risk that overlying water-supply aquifers could be contaminated (Figure 20.3.8). Fracking also induces low-level seismicity. Figure 20.3.8 Depiction of the process of directional drilling and fracking to recover gas from impermeable rocks. The light blue arrows represent the potential for release of fracking chemicals to aquifers. During the process that converts organic matter to coal, some methane is produced, which is stored within the pores of the coal. When coal is mined, methane is released into the mine where it can become a serious explosion hazard. Modern coal-mining machines have methane detectors on them and actually stop operating if the methane levels are dangerous. It is possible to extract the methane from coal beds without mining the coal; gas recovered this way is known as coal-bed methane . Figures 20.3.1, 20.3.2, 20.3.3, 20.3.4: © Steven Earle. CC BY. Figure 20.3.5: “ Sedimentary basin analysis ” © AAPG. Based on data from Lovely and Ruggiero. CC BY-SA. Figure 20.3.6: Image from the USGS. Public domain. Figure 20.3.7: © Steven Earle. CC BY. Figure 20.3.8: “ HydroFrac2 ” © Mikenorton . Adapted by Steven Earle. CC BY-SA. 115 20.4 Diamonds Although Canada’s diamond mining industry didn’t get started until 1998, diamonds are currently the seventh most valuable product mined in the country (Figure 20.4.1), and Canada ranks third in the world in diamond production. Diamonds form deep in the mantle (approximately 200 km to 250 km depth) under very specific pressure and temperature conditions, from carbon that is naturally present in mantle rock (not from coal!). The diamond-bearing rock is brought to the surface coincidentally via a type of volcanism that is extremely rare (the most recent kimberlite eruption is thought to have taken place 10,000 years ago and prior to that at around 30 Ma). There is more on the volcanology of kimberlites in section 4.3. All of the world’s kimberlite diamond deposits are situated within ancient shield areas ( cratons ) in Africa, Australia, Russia, South America, and North America. It has long been known that diamonds could exist within the Canadian Shield, but up until 1991, exploration efforts had been unsuccessful. In 1980 two geologists, Chuck Fipke and Stu Blusson, started searching in the Northwest Territories by sampling glacial sediments looking for some of the minerals that are normally quite abundant within kimberlites : chromium-bearing garnet, chromium-bearing pyroxene, chromite (FeCr 2 O 4 ), and ilmenite (FeTiO 3 ). These distinctive minerals are used for this type of exploration because they are many times more abundant in kimberlite than diamond is. After more than a decade of exploration, Fipke and Blusson finally focused their search on an area 250 km northeast of Yellowknife, and, in 1991, they announced the discovery of a diamond-bearing kimberlite body at Lac de Gras. That discovery is now the Diavik Mine.  The Ekati mine is situated 25 km to the northwest (Figure 20.4.1). There are two separate mines at Diavik accessing three different kimberlite bodies, and there are five at Ekati. See Figure 4.3.16 for a close-up view of the Ekati Mine. As of 2019 there are seven operating diamond mines in Canada, four in the Northwest Territories (including Diavik and Ekati), and one each in Nunavut, Ontario and Quebec. Figure 20.4.1 Diamond mines in the Lac de Gras region, Nunavut. The twin pits of the Diavik Mine are visible in the lower right on an island within Lac de Gras. The five pits of the Ekati mine are also visible, on the left and the upper right. The two main mine centres are 25 km apart. Figure 20.4.1: “ Diamonds in the Sub-Arctic Rough ” by Robert Simmon and NASA. Public domain. 116 Summary The main topics of this chapter can be summarized as follows: Section Summary 20.1 Metal Deposits Geological resources are critical to our way of life and important to the Canadian economy. Gold, coal, iron, copper, nickel, and potash are Canada’s most valuable mined commodities. The concentrations of metals in mineral deposits are typically several thousand times higher than those in average rocks, and such concentrations only form through specific geological processes. Some deposits form within a magma chamber, others during volcanism or adjacent to a pluton, and some are related to sedimentary processes. Mining involves both surface and underground methods, but in either case, rock is brought to surface that can react with water and oxygen to produce acid rock drainage and metal contamination. 20.2 Industrial Materials Non-metallic materials are very important to infrastructure and agriculture. Some of the major industrial minerals include sand and gravel, limestone for cement and agriculture, salt for a range of applications, potash fertilizer, and decorative stone. 20.3 Fossil Fuels The main fossil fuels are coal, oil, and gas. Coal forms on land in wet environments where organic matter can remain submerged and isolated from oxygen for millennia before it is buried by more sediments. The depth of that burial influences the grade of coal produced. Oil and gas originate from organisms living in marine environments, and again, fairly rapid burial is required to preserve the organic matter on the sea floor. At moderate burial depth (2 km to 4 km), oil is produced, and at greater depth, gas is produced. Both oil and gas migrate toward the surface and can be trapped beneath impermeable rock layers in structural features, such as anticlines or faults. Some unconventional fossil fuel resources include oil sands, shale gas, and coal-bed methane. 20.4 Diamonds Diamonds originate in the mantle and are only brought to the surface by the very rare eruption of kimberlitic volcanoes. The relatively recent discovery of diamonds in Canada was based on the exhaustive search for diamond indicator minerals in glacial sediments. There are now six diamond mines in Canada. Figure A (left): “ Spiral CFL Bulb 2010-03-08 (white black) ” © Sun Ladder. CC BY-SA. Figure A (right): “ Elektronstarterp ” © Anton . CC BY-SA. Figure B: © Steven Earle. CC BY. XXI Chapter 21 Geological History of Western Canada \n",
      "-----------\n",
      "Describe the importance of geological resources to our way of life\n",
      "Summarize the types of materials mined in Canada and explain some of the processes involved in the formation of metal deposits\n",
      "Explain how a metal deposit is developed into a mine\n",
      "Define acid rock drainage (ARD) and discuss why some mines can lead to ARD and contamination of the environment by metals\n",
      "Summarize some of the important industrial materials extracted in Canada and describe what they are used for\n",
      "Describe the processes that lead to the formation of coal deposits\n",
      "Explain the processes that lead to the formation of oil and gas, the distinction between source rocks and reservoir rocks, and the importance of traps\n",
      "Describe the origins and recovery of some of the unconventional fossil fuels\n",
      "Describe the origins, discovery, and extraction of diamonds in Canada\n",
      "--------------------------\n",
      "Planning combinations of woody and herbaceous plants with different life cycles and high visual impact generates year round interest in exterior and interior plantings. When visual interest is planned for one period such as early summer, borders and containers can have a poor appearance the rest of the year. Optimizing the use of grasses, bulbs, perennials, annuals, biennials, shrubs, climbers, and trees can provide a succession of plant forms, colours, textures, and habits throughout the seasons. In temperate regions, year round interest is maximized by selecting plants with at least two, and even three or four seasons of interest. Conifers and broadleaf evergreens shrubs are often used for year round colour and spatial structure. For example, Taxus cuspidata ‘Capitata’ (upright yew) provides reliable winter colour and a framework that can be enhanced with other shapes, textures, and colours. On the other hand, a planting of broadleaf evergreens such as Skimmia japonica (Japanese skimmia) offers winter colour and structure as well as showy spring flowers and colourful fruit in the autumn. Distinctive plant shapes and the bark of trees such as Cryptomeria japonica (Japanese cedar) and Morus alba ‘Pendula’ or species with persistent fruit like Sorbus aucuparia (European mountain ash) also contribute structure and winter interest. Practice Recognize woody plants for winter interest. Some deciduous shrubs and trees like Caryopteris x clandonensis (bluebeard), Cercidiphyllum japonicum (katsura), and Rhus typhina (staghorn sumac) have interesting branching patterns throughout all seasons. The bark and buds of Ribes sanguineum (flowering currant, winter currant), Magnolia x soulangeana (saucer magnolia), Liriodendron tulipifera, and Styrax japonicus (Japanese snowbell, Japanese snowcone) provide winter interest and interesting buds forecast the appearance of foliage and flowers. Climbers with variegated or textured foliage and colourful flowers like Actinidia kolomikta (actinitdia) and Campsis radicans (trumpet vine) also contribute vertical structure. View the images seasonal plant characteristics available at this link to the KPU Plant Database [New Tab] . The appearance of plants before, during, and after flowering is an important consideration for planning seasonal interest. For example, the herbaceous specimen plant Gunnera manicata (gunnera, giant rhubarb) provides a bold shape and texture for at least half to perhaps three quarters of the year. With planning, the eye-catching winter stems and seed heads of grasses and perennial species such as Pennisetum alopecuroides (fountain grass), Pennisetum setaceum ‘Rubrum’ (red fountain grass), and Perovskia atriplicifolia (Russian sage) can serve as distractions from seasonal voids. Layering various heights of ground covers, bulbs, annuals and perennials under and around woody shrubs and trees allows a succession of foliage shapes, sizes, textures, and colours to become prominent as the year progresses. In this way, emphasis is placed on year round interest and not only the seasonal show of flowers. A planting calendar is a useful tool for working out the succession of flowers and colour palettes as well as other planting design features. Figure 8.1 shows an example of a basic planting calendar that allows the planner to visualize the times of the year that are most colourful and interesting and those that could use additional development. Figure 8.1 Sample planting calendar As the succession of spring bulbs like Anemone blanda (Greek windflower, blue wood) and Hyacinthus cvs. (hyacinth) finish flowering and foliage fades, deciduous shrubs such as Spiraea x vanhouttei (bridal wreath spirea) and an array of herbaceous annuals, biennials and perennials come into flower in early and mid spring. Examples of spring blooming perennials include Aubrieta x cultorum (common rock cress), Brunnera macrophylla (Siberian bugloss), Papaver orientale (oriental poppy), Pulmonaria saccharata (lungwort), and Dicentra spectabilis (bleeding heart). From late spring and early to mid summer, the flowers and foliage of broadleaf evergreen shrubs such as Daphne cneorum (garland daphne) and herbaceous species like Thymus pseudolanuginosus (woolly thyme), Heuchera cvs. (coralbells, alumroot), and Phlox paniculata (common phlox) take prominence. The progression of seasonal foliage and bloom continues in mid to late summer and through autumn with perennials such as Actaea simplex Atropurpurea Group (cimicifuga), Aster spp. (common aster), Astrantia major (masterwort, astrantia), Coreopsis spp. &amp; cvs. ( coreopsis), Geranium spp. &amp; cvs. (geranium), and Gaillardia cvs. (blanket flower). The texture and seed heads of perennials like Hylotelephium spectabile (autumn joy sedum, stonecrop), and grasses such as Andropogon gerardii (big bluestem), Calamagrostis x acutiflora (feather reed grass), and Molinia arundinacea ‘Skyracer’ (tall moor grass) extend the visual interest from late autumn into winter. Year round interest is fulfilled by evergreens and the flowers of winter blooming shrubs and perennials. View images of the seasonal plant characteristics available at this link to the KPU Plant Database [New Tab] . Read more about seasonal plant combinations at this link to Gardenia Seasonal Garden Ideas [New Tab] . Practice Recognize plants for seasonal interest. 32 Plants for Green Infrastructure Projects \n",
      "-----------\n",
      "Describe seasonal plants common to the horticulture industry.\n",
      "--------------------------\n",
      "The plant family taxon is a grouping of plants consisting of one or more related genera that are more like each other than to other genera, and that includes the entire surviving lineage of the ancestral population. Family names always end with the suffix -aceae, except in a few notable cases where use of traditional names is also acceptable. Newer family names are based on the “type-genus” concept which means that for every family there is a genus that best represents the characteristics of the family. For example, Brassica (the cabbage genus) is the base for the family Brassicaceae, as is Rosa (the rose genus) for the family Rosaceae. Older family names are still used since many are somewhat descriptive and may be more familiar than their newer counterparts. For example, Cruciferae (from the Latin crucifer, a cross) refers to the four-petal arrangement of flowers characteristic of the mustard family. The revised family names for some familiar plant groups are listed in Table 3.1. Table  3.1:  Revised family names Traditional Name New Name Common Name Compositae Asteraceae Aster Cruciferae Brassicaceae Mustard Graminae Poaceae Grass Labiatae Lamiaceae Mint Umbelliferae Apiaceae Carrot Because of new discoveries and technological advancements for determining plant genetics and other markers, some genera and family names have been reclassified under new names, as shown in Table 3.2. Updates to  plant information publications and online resources takes time and overlaps in established and reclassified family names can be expected. Table 3.2:  Reclassified family names Family Name Reclassified Name Common Name Aceraceae Sapindaceae Soapberry Asclepiadaceae Apocynaceae Dogbane Taxodiaceae Cupressaceae Cypress Taxonomic Example The list of ten Pacific Northwest native conifers can be grouped into three families.  Within each family, there are a different number of genera, as represented by the common names. Within each genus, unless a monospecific (single) genus as with Taxus and Pseudotsuga, there are a number of different species. Pinaceae – pine family Douglas fir ( Pseudotsuga , 1 species) hemlock ( Tsuga , 2 species) larch ( Larix , 3 species) true fir ( Abies , 3 species) spruce ( Picea , 4 species) pine ( Pinus , 7 species) Cupressaceae – cypress family arborvitae ( Thuja , 1 species) yellow cedar ( Cupressus , 1 species) juniper ( Juniperus , 3 species) Taxaceae – yew family yew ( Taxus , 1 species) Review 4 Introduction to Binomial Nomenclature \n",
      "-----------\n",
      "Identify characteristics of taxons.\n",
      "--------------------------\n",
      "35 6.1 Test Anxiety and How to Manage It Taking tests and exams can be stressful. Some people get very anxious before or during a test and it can impact their test results. Anxiety overwhelms If you answered true to any of the statements in the table above, you have suffered some of the symptoms of test anxiety. Most people have experienced this. It is normal to feel stress before an exam, and in fact, that may be a good thing. Stress motivates you to study and review, generates adrenaline to help sharpen your reflexes and focus while taking the exam, and may even help you remember some of the material you need. But suffering too many stress symptoms or suffering any of them severely will impede your ability to show what you have learned. Test anxiety can be defined as “a state of uneasiness and distress before and during a test that often lowers performance.” Anxiety during a test interferes with your ability to recall knowledge from memory as well as your ability to use higher-level thinking skills effectively. To learn more about  critical thinking and study skills, see Chapter 5 Study Skills . There are steps you should take if you find that stress is getting in your way: Be prepared. A primary cause of test anxiety is not knowing the material and not knowing what to expect. If you use good study habits and review regularly, this stressor should be greatly reduced if not eliminated. You should be confident going into your exam. Cramming at the last minute, or feeling unsure of your knowledge of course material can increase your stress level.  Make sure to find out how the exam is structured and what material to study. Double check the exam time and location. Address negative thoughts. Your own negative thoughts—“I’ll never pass this exam” or “I can’t figure this out, I must be really stupid!”—may move you into spiraling stress cycle that in itself causes enough anxiety to block your best efforts. When you feel you are brewing a storm of negative thoughts, stop what you are doing and clear your mind. Go for a walk. Confide in a friend. Meditate. Do some deep breathing.  Don’t go back to work until you feel the tension release. Sometimes it helps to take a deep breath and shout “STOP!” and then proceed with clearing your mind. Once your mind is clear, repeat a reasonable affirmation to yourself—“I know this stuff” or “I will study hard until I know this stuff”—before continuing your work. Visualize success. Picture what it will feel like to get the grade you want. Translate that vision into specific, reasonable goals and work toward each individual goal. Visualize success of each goal. Take one step at a time and reward yourself for each goal you complete. It’s all about you! Don’t waste your time comparing yourself to other students in the class, especially during the exam. Keep focused on your own work and your own plan. Exams are not a race, so it doesn’t matter who turns in their paper first. In fact, those who take more time have the ability to explain their points more fully or to check their work for mistakes. Worrying about why someone turned their paper in early is counterproductive and will only cause additional anxiety. Have a plan and follow it. As soon as you know that an exam is coming, you can develop a plan for studying. As soon as you get your exam paper, you should develop a plan for the exam itself. This will be discussed further later in this chapter. Don’t wait to cram for an exam at the last minute; the pressure you put on yourself and the late night will cause more anxiety, and you won’t learn or retain much. Make sure you eat well and get a good night’s sleep before the exam. Hunger, poor eating habits, energy drinks, and lack of sleep all contribute to test anxiety. Going to bed early with the assurance that you worked hard to prepare for the test goes a long way to experiencing peace going into an exam. Arrive early. Trying to cram or leaving things to the last minute can cause a huge amount of stress if you end up frantically racing to the exam. It increases anxiety when you are worried about being late. It’s even worse if you actually are late. You’ll have the added stress of entering the exam room late and you’ll lose valuable time that could have been spent doing the test. This kind of anxiety can last all the way through the test.  Prepare for the unexpected so that a late bus or a traffic jam doesn’t throw you into a state of anxiety. Be early! Chill! You perform best when you are relaxed, so learn some relaxation exercises you can use during an exam. Before you begin your work, take a moment to listen to your body. Which muscles are tense? Move them slowly to relax them. Tense them and relax them. Try it right now. Exhale, then continue to exhale for a few more seconds until you feel that your lungs are empty. Inhale slowly through your nose and feel your rib cage expand as you do. This will help oxygenate your blood and re-energize your mind. Go online for many more ways to deal with stress. Get help. If exam anxiety is persistent and debilitating, and if it is getting worse despite your best effort to address it, seek help from Student Services. Video: “Calm Test Anxiety &amp; Relaxation Breathing Technique” (length 3:23) A YouTube element has been excluded from this version of the text. You can view it online here: Key Takeaways Some stress before a test or exam is common and beneficial. Test anxiety is stress that gets in the way of performing effectively. The most common causes of test anxiety are lack of preparation and negative attitudes. The key to combating test anxiety is to try to reduce stressors to a manageable level rather than try to eliminate them totally. This chapter has been adapted and remixed from the following sources: “ Test Anxiety and How to Control It ” in University Success by N. Mahoney, B. Klassen, and M. D’Eon. Adapted by Mary Shier. CC BY-NC-SA . “ Taking Tests ” in Strategies for Academic Success by Liv Marken. Adapted by Mary Shier. CC BY-NC-SA . “ Calm Test Anxiety and Relaxation Breathing Technique ” by PsycheTruth . Standard YouTube Licence. Anxiety tiles is licensed under a CC BY (Attribution) license Anxiety Model © Kevin Dooley is licensed under a CC BY (Attribution) license 36 6.2 Test Preparation Techniques: Leading up to the Test Pre-Test Strategies When should you start preparing for the first test? Choose one of the following answers: The night before The week prior The first day of classes If you answered “3. The first day of classes,” you are correct. If you circled all three, you are also correct. Preparing to pass tests is something that begins when learning begins and continues all the way through to the final exam. Many students, however, don’t start thinking about test taking, whether weekly exams, mid-terms, or finals, until the day before when they engage in an all-nighter. This is an inefficient way to study. Not only is it not enough time to learn a whole unit or chapter, but the brain can only process an average of 5-7 new pieces of information at a time. Additionally, unless memory devices are used to aid memory and to cement information into long term memory (or at least until the test is over tomorrow!) chances are slim that students who cram will effectively learn and remember the information. Additionally, a lot of students are unaware of the many strategies available to help with the test-taking experience before, during, and after. For starters, take a look at what has helped you so far. You will notice that many of the strategies listed above have already been mentioned in the Study Skills chapter. This is no co-incidence. Good study habits help lead to good test results! “By failing to prepare, you are preparing to fail.” — Benjamin Franklin Discipline, Preparation, and Execution Being successful at tests comes down to discipline, preparation and execution. Students wanting to be successful have to have the self-discipline to schedule time to study well in advance of the exam. They have to actually do the work – the preparation needed in order to have the best opportunity for success on the exam. Then they must execute – they have to be able to apply their preparation accordingly and perform well on the exam. Preparation for an exam is not glamorous. It’s easy to find other things to do that are more interesting and fun. Students need to keep themselves motivated with their “eyes on the prize.” Think of it like this: If the most important event of your life was coming up and you wanted to perform to the best of your ability in that event, you would likely spend some time preparing for it, rehearsing for it, practicing it, etc. A student may argue that an exam would not be the most important event of their life, but if you’re already spending the time, effort, energy and money to attend college, why not do it to the best of your ability? It would be beneficial to spread this preparation and practice out over time and prepare periodically rather than wait until the last minute and binge study or cram. Your preparation would not be of the same quality and this will likely affect your test score. Binge studying and cramming also are not healthy. Staying up late puts stress on our brain and body, and not getting adequate sleep places our bodies at risk for getting sick. “One of the most important keys to success is having the discipline to do what you know you should do, even when you don’t feel like doing it.” — Unknown “The will to succeed is important, but what’s more important is the will to prepare.” — Bobby Knight Everyone wants to be successful. When the exam is passed out, everyone wants to perform well. But what often separates successful students and less successful students is the preparation time put in. Studying the right thing is a process and a skill. As you gain more experience, you will learn how to become better at knowing what to study. It can be very frustrating to spend a lot of time preparing and studying and then finding out that what you studied was not on the exam. You will see a lot of variance with exams due to different instructors, classes and types of tests. The better you become at predicting what will be on the exam and study accordingly, the better you will perform on your exams. Try placing yourself in your instructor’s shoes and design questions you think your instructor would ask. It’s often an eye-opening experience for students and a great study strategy. The more information you have about the exam, the better you can prepare for content, allocation of time spent on aspects of the exam, and the more confident you will be in knowing how and when to attempt to answer questions. Preparation for Exam Strategies Find Out as Much about the Exam in Advance as You Can Some professors and instructors will tell you how many questions there will be, what format the exam will be in, how much time you will have, etc., and others will not. Students should ask questions about the exam if there is not information given. Students should also ask those questions before class, after class, in professors’ office hours or via email if it doesn’t happen during class. Ask about the format. Is it open book? Is it timed? What types of questions will be on it? What material will it cover? (e.g. chapters 1-3, or only chapter 3) If you’re lucky an instructor will give you areas to focus your study on. How will it be scored? Knowing these things will make it easier to prepare for the test. Anticipate Questions What kind of questions would you include if you were the instructor? What areas did the instructor personally show the most interest in? Brainstorm possible questions with your study group. Look for possible questions in your notes. Review past quizzes and test to see what kinds of questions the instructor likes to ask. Above all, take it seriously whenever your instructor says, “This will be on the test.” or “Make sure you know this for the test.” They are giving you a huge study hint. Make sure to have your highlighter handy for these occasions. Take Care of Your Body Go for a short snowshoe with your dog and review the parts of the digestive system in your mind to prepare for your biology test tomorrow. Before the exam, it is important to prepare your brain and body for optimal performance for your exam. Do not cram the night before. Cramming is not a substitute for doing your assignments and studying consistently over time. Get a good night’s sleep. It is far more important to get a good night’s sleep and face your test fresh and well rested so that you can think clearly. Make sure you eat (nutritiously) before the exam to give you energy and concentration to do well on the exam. Include brain foods, such as those rich in omega-3 oils, and avoid heavy foods that are rich in fat and sugar. (After the exam, you can celebrate with a cheeseburger, fries, and milkshake – but not before the exam!) It’s healthy to exercise the day before and if possible a few hours before the exam, even if it’s just going for a walk outside. You can use the time to summarize concepts and recall things in your mind. (e.g. as you are walking you can list the parts of the respiratory system as you visualize the diagram in your mind.) This is a great way of reviewing. Types of Tests All tests are designed to determine how much you know about a particular subject at a particular point in time. But you should be aware of differences in types of tests because this will help guide how you prepare for them. Tests can be grouped into various categories based on how they are delivered. Each type has its own unique strategies. Paper tests are still a very common type of test, requiring students to write answers on the test pages or in a separate test booklet. They are typically used for in-class tests. Neatness and good grammar count, even if it’s not an English exam. Remember that the instructor will be reading dozens of test papers and will not likely spend much time trying to figure out your hieroglyphics, arrows, and cross-outs. Open-book tests allow the student to consult their notes, textbook, or both while taking the exam. Students often mistakenly think that they don’t have to study much because all the information will be in front of them. The contrary is true. Instructors often give this type of test when they are more interested in seeing your thoughts and critical thinking than your memory power. Be prepared to expose and defend your own viewpoints. You’ll need to understand the themes and main ideas about the text. When preparing, know where key material is located in your book and notes; create an index for your notes and use sticky notes to flag key pages of your textbook before the exam. Another strategy is to highlight key sections in your index so you can easily find them. People who don’t know their text book well, will spend fruitless precious time searching through the book for that thing they are trying to find. Multiple-choice tests affect the way you should prepare. You will not have to memorize the names of terms and their spelling, but you will have to recognize them and know what they mean. This impacts studying techniques. Take-home tests are like open-book tests except you have the luxury of time on your side. Make sure you submit the exam on time. Know what the instructor’s expectations are about the content of your answers. The instructor will likely expect more detail and more complete work because you are not under a strict time limit and because you have access to reference materials. Be clear about when the test is due. (Some instructors will ask you to email your exam to them by a specific time.) Also find out if the instructor allows or expects you to collaborate with classmates. Be sure to type your exam and don’t forget to spell-check! Online tests Find out if you will be allowed to move freely between test sections to go back and check your work or to complete questions you might have skipped. Some testing software does not allow you to return to sections once they are “submitted.” Unless your exam needs to be taken at a specific time, don’t wait until the last minute to take the test. Should you have technical problems, you want to have time to resolve the issues. To avoid any conflicts with the testing software, close all other software applications before beginning the test. Watch the time carefully. They will often have a clock counting down for you. Many online tests will submit the test at exactly the time the test is over, so make sure you’ve finished prior to the clock running out. Electronic tests in the classroom are becoming more common as universities install “smart classrooms” with technology such as wireless “clicker” technology that instructors may use to get a quick read of students’ understanding of a lecture. This testing method allows for only true-or-false and multiple-choice questions, so it is rarely used for summative assessments. When taking this kind of quick quiz, take notes on questions you miss so that you can focus on them when you do your own review. Presentations and oral tests are the most complete means for instructors to evaluate students’ mastery of material, because the evaluation is highly interactive. The instructor can (and likely will) probe you on certain points, question your assumptions, or ask you to defend your point of view. Make sure you practice your presentation many times with and without an audience (your study group is good for this). Have a clear and concise point of view and keep to the allotted time. (You don’t want to miss delivering a killer close if your instructor cuts you off because you weren’t aware of the time!) Key Takeaways Stay caught up throughout the term and review often. Make a study schedule before the test and stick to it. Prepare for exams and quizzes by getting plenty of rest, eating well, and getting some exercise the day before the exam. Cramming is seldom a good strategy. Before the exam, learn as much as you can about the kinds of questions your instructor will be asking and the specific material that will be covered. The text under the “Pre-Test Strategies” heading has been adapted from “ Pre- Mid- and Post-Test-Taking Strategies ” in Blueprint for Success in College and Career by Dave Dillon. Adapted by Mary Shier. CC BY . Text under “Types of Tests” has been adapted from “ Taking Tests ” in University Success by N. Mahoney, B. Klassen, and M. D’Eon. Adapted by Mary Shier. CC BY-NC-SA . 37 6.3 Techniques During a Test You’ve done all you can within reason and within your circumstances to prepare for the test. You’ve studied hard, practised questions, and got a good night’s sleep; you ate nutritiously, and arrived to the test early and prepared. Now it’s time to write the test. There are specific strategies you can use in the midst of the test that will help you do the best you can do. During-Test Strategies Here is a list of the most common–and useful–strategies for test-taking. Choose your seat wisely. Sit where you are most comfortable. Scan the room and look for considerations that might affect you (e.g. sitting away from windows or doors that may be drafty or distracting). That said, sitting near the front has a couple of advantages: you will hear directions more easily; you may be less distracted by other students; and if a classmate comes up with a question for the instructor and there is an important clarification given, you will be better able to hear it and apply it, if needed. Cut down on distractions. Wear ear plugs, if noise distracts you. Put your phone on do not disturb before you arrive. Bring water. This helps calm the nerves, for one thing, and water is also needed for optimum brain function. Listen carefully to instructions given by the instructor or test invigilator. Write it down. Take a couple minutes to write down key facts, dates, principles, statistics, concepts, memory cues and formulas that you memorized to help you on the test. Write them on a piece of scratch paper or in the margin of the exam paper. Do this right at the start. Then you can refer to these notes as you take the exam. Scan the test. Before starting to do any of the questions, scan the test so you know how many test items there are, what types there are (multiple choice, matching, essay, etc.), and the point values of each item or group of items. There is nothing worse than getting a big surprise when you have no time left to do anything about it. You don’t want to think you’ve almost finished the test, and then with five minutes left, you discover the last question is a forty mark essay. Mark the questions as you scan the test. Star or highlight the questions that you know really well. Put question marks beside the ones that you might have more trouble with. Always focus your attention on the questions you know well first. It ensures that you get the questions done that you have the most chance of getting high marks on, and it builds your confidence from the start. Spending time on a question that you are struggling with is wasting your time which could be spent answering the questions you know the answers to. Skip the ones you don’t know and come back to them later if you have time. You might even get some clues to the answers from some of the other questions covering similar information. On computerized tests or answer sheets where you can’t or shouldn’t make marks – write down the numbers of the questions you skipped or weren’t sure of on scrap paper so you can find them easily later. Create a Plan. Evaluate the importance of each section as you scan the test. Determine which way you want to approach the test. Some students start with the easy questions first, that is, the ones they immediately know the answers to, saving the difficult ones for later, knowing they can spend the remaining time on them. Some students begin with the biggest-point items first, to make sure they get the most points. Determine a schedule that takes into consideration how long you have for the test and the types of questions on the test. Essay questions, for example, will require more time than multiple choice or matching questions. Keep your eye on the clock. Create a Test Plan Look for opportunities where some areas of the exam are worth more points than others. For example: An exam consists of 21 questions, with 10 being True/False, 10 being multiple choice, and one essay question. The T/F questions are worth 1 point each (10 points), the multiple-choice questions are worth 2 points each (20 points), and the essay question is worth 30 points. You know that the essay question is the most valuable (it is worth half of the value of the exam). And we should allocate our time for it accordingly. Do a quick analysis of time to be able to spend your time on the exam wisely. You want to spend some time with the essay question since it is so valuable, without sacrificing adequate time to ensure the T/F and multiple-choice questions are answered. Often, the order of the exam in this scenario will be: T/F first, multiple choice second and essay third. Most students will go in the chronological order of the exam, but you may want to start with the essay, or at least decide on the essay question (if there is a choice between given options) and write the outline (plan) for the essay with key points before diving into the rest of the exam. If this exam were to last for 40 minutes, a student could make a rough plan to spend 15-20 minutes on the essay question, ten minutes on the multiple choice, three-five minutes on the T/F and 5-10 minutes reviewing answers, checking over the essay, and going back to questions that were skipped. Read the directions carefully. Then reread them. Do you understand what is expected of you? If not, re-read the questions, or ask the instructor to be sure you are clear.  Common errors from not reading directions carefully include either missing one part of the question (e.g. answered the first part but forgot about the second part) or not noticing that you only needed to answer 3 out of 5 of the short-answer questions (hence wasting time that could have been spent somewhere else on the test). Too many students lose points simply by not following directions completely! Read the questions carefully. Underline key words in each question. Think about where you have heard these key words before. Think about other questions on the test for clues. When you have finished writing your answer, go back and read the question again to make sure you actually answered it. (It is not uncommon for students to go off on a tangent and then not actually answer the question.) Do the easy questions first. By getting the easy questions out of the way, you’ll feel more confident about the test and have more time to think about the tougher questions. Start with the objective sections of the exam first (multiple choice, true or false, and matching columns). As you answer these questions, keep an eye out for facts, terms, or concepts you may want to use later in an essay question. You’ll know because you read the essay question already and did your outline. Circle key concepts and jot them into your essay outline as you answer questions throughout the test. Keep an eye on the time. Keep as close to your plan as possible. If you see that you are running out of time, don’t panic. Move to those questions you think you can still answer accurately within the remaining time. Move. Try to stretch in your chair from time to time to relieve tension and assist the blood to the brain! Roll your shoulders, circle your feet and hands, clench your butt, circle your neck. Reduce anxiety . Remember to employ strategies to reduce test-taking anxiety (covered earlier in the Chapter 6.1 Test Anxiety and How to Manage It ). Check your work. This doesn’t mean going through all your calculations again. Start by ensuring that you have complete answers according to the directions. Then look for other common mistakes, such as a misplaced decimal point, dropped words (especially those that can modify the answer, like “not”), and any incomplete or incomprehensible phrases. Video: “Mr. Bean – The Exam” (length 5:56) A YouTube element has been excluded from this version of the text. You can view it online here: Strategies for Specific Exam Formats As well as using the above strategies during the test, it is important to be aware of the five principal types of questions on tests and to know specific strategies for each type to help maximize success. True or False Questions Look for qualifiers. A qualifier is a word that is absolute. Examples are: all, never, no, always, none, every, only, entirely. They are often seen in false statements. This is because it is more difficult to create a true statement using a qualifier like never, no, always, etc. For example, “All cats chase mice.” Cats may be known for chasing mice, but not all of them do so. The answer here is false and the qualifier “all” gave us a tip. Qualifiers such as: sometimes, many, some, most, often, and usually are commonly found in true statements. For example: “Most cats chase mice.” This is true and the qualifier “most” gave us a tip. Here is another example. “Delia flirts with every man she meets.” Though the statement may seem true because you know Delia, there was a time 5 years ago that she met a man named Bob, and she didn’t flirt with him.  Though the temptation is to say, “true”, the one instance that it didn’t happen (when she met Bob) makes the actual answer, “false”. Similarly in a test, if you can think of one exception in a statement with an absolute qualifier (i.e. even one instance that the statement wouldn’t be true), then the answer is false. Make sure to read the entire statement. All parts of a sentence must be true if the whole statement is to be true. If one part of it is false, the whole sentence is false. Long sentences are often false for this reason. If students don’t know the answer, they should guess on True or False questions unless there is a penalty for an incorrect answer. There is a fifty percent chance of guessing correctly! And if you have to guess, guess the one that seems to make the most sense to you, and if you still have no idea, guess True, because most tests include more true statements than false. Multiple Choice Questions It is important to read each statement carefully. Think of multiple choice questions as four (or five) true or false statements in one. One of the statements is true (the correct answer) and the others will be false. If you have options such as “all of the above,” or “both A and B,” make sure each item is completely true (no exceptions) before selecting those options. If you know your material well, you will be able to pick out the true statements. If you are unsure of the material, there are some strategies to help you come up with the right answer. Apply the same strategy toward qualifiers as you did in the True False questions. If you see an absolute qualifier in one of the answer choices, it is probably false. If a statement says something “always” happens and you can think of even one exception, then it is false. Try to identify the true statement, but before you choose it as the right answer,  always read the other statements because you may find another statement that sounds true. Eliminate answers you know to be false.  Then discern between the two true-sounding statements. While working through a question, it is helpful to x-out the ones you know are false; it will save time if you need to go over the question again. If there is no penalty for incorrect answers,  guess if you are not certain of the answer. If there is a penalty for incorrect answers, common logic is to guess if you can eliminate two of the answers as incorrect (pending what the penalty is). If there’s a penalty and you cannot narrow down the answers, it’s best to leave it blank. You may wish to ask your instructor for clarification. Answers that are strange and unrelated to the question are usually false. If two answers have a word that looks or sounds similar, one of those is usually correct. For example: abductor/ adductor. If you see these as two of the four or five choices, one of them is usually correct. Also look for answers that are grammatically incorrect. These are usually incorrect answers. Matching Questions Although less common than the other types of exams, you will likely see some matching exams during your time in college. First, read the instructions and take a look at both lists to determine what the items are and their relationship. It is especially important to determine if both lists have the same number of items and if all items are to be used, and used only once. Matching exams become much more difficult if one list has more items than the other or if items either might not be used or could be used more than once. If your exam instructions do not discern this, you may wish to ask your instructor for further clarification. Students should take a look at the whole list before selecting an answer because a more correct answer may be found further into the list. If one column is short phrases and the other column is single words, work from the column with phrases and look for the single words to match (not the other way around). If both columns have single words, group them by parts of speech (nouns with nouns, verbs with verbs etc.). Mark items when you are sure you have a match and cross out these options to eliminate answers for the remainder of the matching. Guessing (if needed) should take place once you have selected answers you are certain about. Short-Answer Questions Short-answer questions are designed for you to recall and provide very specific information (unlike essay questions that ask you to apply critical thinking to that information.) Read all of the instructions first. Budget your time and then read all of the questions. Answer the ones you know best or feel the most confident with. Then go back to the other ones. If you do not know the answer and there is no penalty for incorrect answers, guess. Use common sense. Sometimes instructors will award partial credit for a logical answer that is related even if it is not the correct answer. Make sure to look at the marking system. If short answer questions are worth 3-5 marks out of 100, then likely the instructor is looking for about 2-3 relevant sentences, not a full paragraph. If they are out of twenty marks, you’ll want to include more information in more depth. Author’s Story I have a tendency to write too much on short-answer test questions. I want to write down everything I know about the topic. It’s great because I’ll usually get full marks on the question, but an instructor once told me that I would have had full marks with my first few sentences. The trouble is that if you spend too long on a short-answer question, you may run out of time for other questions, especially a long-answer essay style question that really does require you to go into depth. Write down a few of the most relevant things on your short-answer question and come back and write more later if there’s time at the end. — Mary Shier, College of the Rockies Essay Questions Knowing the format of the exam can help you determine how to study. If you know that you are taking a True-False or Multiple Choice exam, you will need to discern whether a statement is True or False. You will need to know subject content for the course. But if you are studying for short answer and especially for essay questions, you must know a lot more. For essay questions, you must have much greater content knowledge and be able to make a coherent argument that answers the question using information from textbooks, lectures or other course materials. You will have to connect themes with examples. Essay questions evaluate your thinking and reasoning skills applied to the course material. You will have to place a lot more time and thought into studying for an essay exam than for True-False or Multiple Choice exams. Read the essay question(s) and the instructions first. Underline or circle key words in the question. Plan your time wisely and organize your answer before you start to write. Make a quick outline to organize the essay and include all key points. Address the answer to the question in your first paragraph and reiterate it in your last paragraph (conclusion). You would be surprised how many essays are written that discuss all kinds of things about the topic, but actually never answer the question! It may help to restate the original question. Write clearly and legibly. Instructors have difficulty grading essays that they cannot read. Clearly state what you are trying to say. Don’t expect that the instructor knows what you mean. Write the essay as if you are explaining it to someone who knows nothing about the topic. Please note that essay questions often have multiple acceptable answers, so don’t question whether your answer is correct or not. Just make sure you’ve backed up what you’ve said. Save some time for review when you have finished writing to check spelling, grammar and coherent thought in your answer. Inevitably you will find things that need to be clarified. Write your essay double-spaced. This leaves room to add in words or phrases in the proof-reading stage without making a mess of your paper. Finally, make sure you have addressed all parts of the essay question. Words to Watch for in Essay Questions Word What It Means What the Instructor Is Looking For Analyze Break concept into key parts. Don’t just list the parts; show how they work together and illustrate any patterns. Compare Show similarities (and sometimes differences) between two or more concepts or ideas. Define the similarities and clearly describe how the items or ideas are similar. Do these similarities lead to similar results or effects? Note that this word is often combined with “contrast.” If so, make sure you do both. Contrast Show differences between two or more concepts or ideas. Define the differences and clearly describe how the items or ideas are different. How do these differences result in different outcomes? Note that this word is often combined with “compare.” If so, make sure you do both. Critique Judge and analyze. Explain what is wrong—and right—about a concept. Include your own judgments, supported by evidence and quotes from experts that support your point of view. Define Describe the meaning of a word, phrase, or concept. Define the concept or idea as your instructor did in class—but use your own words. If your definition differs from what the instructor presented, support your difference with evidence. Keep this essay short. Examples can help illustrate a definition, but remember that examples alone are not a definition. Discuss Explain or review. Define the key questions around the issue to be discussed and then answer them. Another approach is to define pros and cons on the issue and compare and contrast them. In either case, explore all relevant data and information. Explain Clarify, give reasons for something. Clarity is key for these questions. Outline your thoughts carefully. Proofread, edit, proofread, and proofread again! Good explanations are often lost in too many words. Illustrate Offer examples. Use examples from class material or reading assignments. Compare and contrast them to other examples you might come up with from additional reading or real life. Prove Provide evidence and arguments that something is true. Instructors who include this prompt in an exam question have often proven the hypothesis or other concepts in their class lectures. Think about the kind of evidence the instructor used and apply similar types of processes and data. Summarize Give a brief, precise description of an idea or concept. Keep it short, but cover all key points. This is one essay prompt where examples should not be included unless the instructions specifically ask for them. (For example, “Summarize the steps of the learning cycle and give examples of the main strategies you should apply in each one.”) Key Takeaways Be prepared. Get a good night’s sleep! Arrive early and get comfortable. Scan the entire exam before starting to answer questions. Develop a plan (including a “time budget”) for completing the exam. Read questions carefully. Underline keywords in questions, particularly in essay questions and science questions. Do the questions you know well first. Unless points are deducted for wrong answers, it pays to take educated guesses. Pay attention to specific strategies for different types of questions. Keep a close eye on the time. Don’t be caught off guard. Lastly, if you finish the test early, use the remaining time to review your answers and make corrections or additions before submitting your exam. Make sure you have written your full name on the test. It’s shocking how many students write their first name only and expect the instructor to figure it out. It’s also shocking how many students forget to write their names at all. You don’t want to go through all that preparation and stress and then not get credit for your work. Lastly, make sure to hand your paper in! Video: “Funny school video of kid taking a test” (length 1:04) A YouTube element has been excluded from this version of the text. You can view it online here: Answers to crossword puzzle above: Across: 2. false; 3. outline; 6. specific; 8. define; 9. summarize; 10. essay; 11. neatly Down: 1. parts of speech; 4. explain; 5. acceptable; 7. compare; 12. true Points under the “During-Test Strategies” heading has been adapted from “ Taking Tests ” in University Success by N. Mahoney, B. Klassen, and M. D’Eon. Adapted by Mary Shier. CC BY-NC-SA . The “Words to Watch for in Essay Questions” table and the Crossword puzzle activity have been adapted from “ The Secrets of the Q and A’ s” in University Success by N. Mahoney, B. Klassen, and M. D’Eon. Adapted by Mary Shier. CC BY-NC-SA . Text under “Strategies for Specific Exam Formats” has been adapted from “ Test-Taking Strategy Specifics ” in Blueprint for Success in College and Career by Dave Dillon. Adapted by Mary Shier. CC BY . “ The Exam | Mr. Bean Official ” by Mr. Bean . Standard YouTube licence. “ Funny school video of kid taking a test ” by jerodtnt . Standard YouTube licence. Crossword © University of Saskatchewan is licensed under a CC BY-NC-SA (Attribution NonCommercial ShareAlike) license 38 6.4 After the Test So far, we have focused on how to study for and take tests effectively. This section discusses how to use test results to their greatest benefit. Some of your most important learning begins when your graded test paper is returned to you. Your first reaction, of course, is to see what grade you received and how you did compared with your classmates. This is a natural reaction. Make sure you listen to the instructor as the papers are returned. What is the instructor saying about the test? Is there a particular point everyone had trouble with? Does the instructor generally think everyone did well? The instructor’s comments at this point may give you important information about what you should study more, about the value of review sessions, and even about possible questions for the next exam. Although you may be tempted to throw away the exam, don’t. It is a very helpful tool for the next phase of preparing for learning. This is a three-step process, beginning with evaluating your results. Evaluating Your Test Results When you receive your test back, sit quietly and take a close look at it. What questions did you get wrong? What kind of mistakes were they? (See Table 6.41 “Exam Errors and How to Correct Them” below.) Do you see a pattern? What questions did you get right? What were your strengths? What can you learn from the instructor’s comments? Now think of the way in which you prepared for the exam and the extent to which you applied the exam strategies described earlier in this module. Were you prepared for the exam? Did you study the right material? What surprised you? Did you read the entire test before starting? Did your time allocation work well, or were you short of time on certain parts of the exam? Exam Errors and How to Correct Them Study and Preparation Errors Examples Corrective Steps I did not study the material for that question (enough). Practice predicting possible questions better. I did not prepare enough. Join a study group. Create a study schedule. Review the study skills chapter. Focus Errors or Carelessness Examples Corrective Steps I ran out of time. Read the entire test before starting. Make a plan and allocate your time. Watch the clock. I did not read the directions carefully. Read carefully and reread to ensure you got it right. I misread or misunderstood the question. Read carefully and reread to ensure you got it right. I confused terms or concepts that I actually know well. Read carefully and think before answering a question. Go back and check answers at the end and you will often catch these mistakes. Content Errors Examples Corrective Steps I studied the material but couldn’t make it work with the question. Seek additional help from the instructor. I didn’t understand what the instructor wanted. Go to all classes, labs, and review sessions. Get caught up on any missed classes. I confused terms or concepts. Join a study group. Review concepts throughout the term. I didn’t understand why I got the question wrong. Ask your instructor for clarification. Everything seemed to be a jumble in my mind and I mixed up what connected with what. Don’t cram. Schedule regular study time for this course. Mechanical Errors Examples Corrective Steps The instructor misread my writing. Slow down! Don’t rush through the exam. Take the time to do things right the first time. I didn’t erase a wrong answer completely. Cross things out clearly rather than use an eraser. It is more time efficient. I forgot to go back to a question I had skipped over. Use the last 5 minutes of a test to go over it and check you have answered all the questions. I miscopied some calculations or facts from my worksheet. Copy things carefully. This is a frustrating way to lose marks. Based on your analysis of your test, identify the kind of corrective steps you should take to improve your learning and test performance. Implement those steps as you begin your preparation for your next class. If you don’t learn from your mistakes, you are doomed to repeat them; if you don’t learn from your successes, it will be harder to repeat them. Correcting Your Mistakes The second step in making your test work for you is to correct your wrong answers. The last time you wrote the information (when you took the test), you created a link to wrong information in your memory, so that must be corrected. For multiple-choice questions, write out the question stem with the correct answer to form a single correct sentence or phrase. For true-or-false questions, write the full statement if it is true; if it is false, reword it in such a way that it is true (such as by inserting the word “not”). Then write the new statement. For math and science questions involving calculations, redo the entire solution with the calculations written out fully. You need not rewrite an entire essay question if you did not do well, but you should create a new outline for what would be a correct answer. Make sure you incorporate any ideas triggered by your instructor’s comments. When you have rewritten all your answers, read them all out loud before incorporating your new answers in your notes. Integrating Your Test into Your Study Guide Your corrected quizzes and midterm exams are an important study tool for final exams. Make sure you file them with your notes for the study unit. Take the time to annotate your notes based on the exam. Pay particular attention to any gaps in your notes on topics that appeared in the quiz or exam. Research those points in your text or online and complete your notes. Review your exams throughout the term (not just before the final) to be sure you cement the course material into your memory. When you prepare for the final exam, start by reviewing your quizzes and other tests to predict the kinds of questions the instructor may ask on the final. This will help focus your final studying when you have a large amount of coursework to cover. If You Don’t Get Your Test Back If your instructor chooses not to return tests to students, make an appointment to see the instructor soon after the test to review it and your performance. Take notes on what you had trouble with and the expected answers. Add these notes into your study guide. Make sure you don’t lose out on the opportunity to learn from your results. Key Takeaways Working with exams does not end when your instructor hands back your graded test. Quizzes and midterms are reliable predictors of the kind of material that will be on the final exam. When evaluating your test performance, don’t look only at the content you missed. Identify the types of mistakes you commonly make and formulate plans to prevent these mistakes in future assessments. This chapter is adapted from “ Using Test Results ” in University Success by N. Mahoney, B. Klassen, and M. D’Eon. Adapted by Mary Shier. CC BY-NC-SA . 39 6.5 The Honest Truth Academic Integrity and Academic Dishonesty Throughout this book, we have focused on the active process of learning , not just on how to get good grades. The attitude of some students that grades are the be-all and end-all in academics has led many students to resort to academic dishonesty to try to get the best possible grades or handle the pressure of an academic program. Some cultures have a much more relaxed attitude towards cheating, and with the rise of international students in Canadian post-secondary institutions, students must be aware that Canadian institutions take this very seriously. No matter what your reason, it is never OK to cheat. Although you may be tempted if you’ve heard people say, “Everybody does it,” or “It’s no big deal at my school,” you should be mindful of the consequences of cheating: You don’t learn as much. Cheating may get you the right answer on a particular exam question, but it won’t teach you how to apply knowledge in the world after school, nor will it give you a foundation of knowledge for learning more advanced material. When you cheat, you cheat yourself out of opportunities. Cheating raises test anxiety which impedes performance. You risk failing the course or even expulsion from school. Each institution has its own definitions of and penalties for academic dishonesty, but most include cheating, plagiarism, and fabrication or falsification. The exact details of what is or is not allowed vary somewhat among different universities and colleges, and even among instructors, so you should be sure to check your school’s website and your instructor’s guidelines to see what rules apply. Ignorance of the rules is seldom considered a valid defense. Cheating causes stress. Fear of getting caught will cause you stress and anxiety; this will get in the way of performing well using the information you do know. You’re throwing away your money and time. Getting a university education is a big investment of money and effort. You’re simply not getting your full value when you cheat, because you don’t learn as much. You are trashing your integrity. Cheating once and getting away with it makes it easier to cheat again, and the more you cheat, the more comfortable you will be giving up your integrity in other areas of life—with perhaps even more serious consequences. Cheating lowers your self-esteem. If you cheat, you are telling yourself that you are simply not smart enough to handle learning. It also robs you of the feeling of satisfaction from genuine success. Resist the temptation to cheat by “borrowing” others’ work from the internet. Technology has made it easier to cheat. Your credit card and an internet connection can procure a paper for you on just about any subject and length. You can copy and paste for free from various websites. Students have made creative use of texting and video on their cell phones to gain unauthorized access to material for exams, but be aware that technology has also created ways for instructors to easily detect these forms of academic dishonesty. Most universities make these tools available to their instructors. Instructors are also modifying their testing approaches to reduce potential academic misconduct by using methods that are harder to cheat at (such as in-class essays that evaluate your thinking and oral presentations). If you feel uneasy about doing something in your university or college work, trust your instincts. Confirm with the instructor that your intended form of research or use of material is acceptable. Cheating just doesn’t pay. Examples of Academic Dishonesty Academic dishonesty can take many forms, and you should be careful to avoid them. The following list is a clear and complete compilation of what most institutions will consider unacceptable academic behaviour: Cheating: using unauthorized notes, study aids, or information on an examination; altering a graded work after it has been returned, then submitting the work for regrading; allowing another person to do one’s work and submitting that work under one’s own name; submitting identical or similar papers for credit in more than one course without prior permission from the course instructors. Plagiarism: submitting material that in part or as a whole is not entirely one’s own work without attributing those same portions to their correct sources. Fabrication: falsifying or inventing any information, data or citation; presenting data that were not gathered in accordance with standard guidelines defining the appropriate methods for collecting or generating data and failing to include an accurate account of the method by which the data were gathered or collected. Obtaining an Unfair Advantage: stealing, reproducing, circulating or otherwise gaining access to examination materials prior to the time authorized by the instructor; stealing, destroying, defacing or concealing library materials with the purpose of depriving others of their use; unauthorized collaboration on an academic assignment; retaining, possessing, using or circulating previously given examination materials, where those materials clearly indicate that they are to be returned to the instructor at the conclusion of the examination; intentionally obstructing or interfering with another student’s academic work; or otherwise undertaking activity with the purpose of creating or obtaining an unfair academic advantage over other students’ academic work. Aiding and Abetting Academic Dishonesty: providing material, information, or other assistance to another person with knowledge that such aid could be used in any of the violations stated above, or providing false information in connection with any inquiry regarding academic integrity. Falsification of Records and Official Documents: altering documents affecting academic records; forging signatures of authorization or falsifying information on an official academic document, grade report, letter of permission, petition, drop/add form, ID card, or any other official university document. Unauthorized Access: accessing computerized academic or administrative records or systems; viewing or altering computer records; modifying computer programs or systems; releasing or dispensing information gained via unauthorized access; or interfering with the use or availability of computer systems or information. Key Takeaways Being dishonest can have major consequences that can affect not only your university career, but also your life beyond university. “Everybody does it” and “It’s no big deal at my school” are not valid reasons for cheating. When you cheat, you are primarily cheating yourself. This chapter was adapted from “ The Honest Truth ” in University Success by N. Mahoney, B. Klassen, and M. D’Eon. Adapted by Mary Shier. CC BY-NC-SA . Exam cheating © Santeri Viinamäki is licensed under a CC BY-SA (Attribution ShareAlike) license 40 6.6 Chapter Review and Activities Key Takeaways Test taking is stressful, but salient concepts and strategies help make it go smoother. Rather than thinking of it as a stressful source of angst, think of it as an opportunity to demonstrate all that you have learned. Recognize test anxiety and be pro-active in reducing it by being well-prepared for tests and by re-aligning negative attitudes. Use key strategies for test preparation prior to your tests. Keep up throughout the term. Stick to your study plan. Prepare well for your tests. Use key strategies during your tests to ensure you use your time efficiently and that you get the most marks that you can. Learn from your mistakes on tests and from the types of questions that your instructor usually asks. Incorporate this into your future study plans after each test. Academic dishonesty including cheating and plagiarism has serious consequences and is never worth it. This chapter has been adapted from “ Chapter 6 Activities ” in University Success by N. Mahoney, B. Klassen, and M. D’Eon. Adapted by Mary Shier. CC BY-NC-SA . VIII Chapter 7 Time Management time management © Gordon Shier is licensed under a CC BY (Attribution) license 41 Introduction A great aspect of time is its equality. Regardless of race, religion, or age, everyone has the same amount of time in a day, week, month and year. Wealthy people cannot buy more time and poor people do not receive less time. A minute for a tall person is the same amount of time for a short person. An hour for a woman is the same amount of time for a man. Regardless of how many languages someone speaks, their sexual orientation, ethnicity, educational background, income or experience, everyone has 365 days in a year. Granted some people will live longer than others, but everyone has the same amount of time every day as everyone else. Time is also how we keep track of when we’re supposed to be and where we’re supposed to be (work, home, class, meeting friends and family, etc.). Think about how many measures of time you have in your home (clocks, watches, cell phones, TVs, DVRs, computers, microwaves, ovens, thermostats, etc.). It is obvious time is important to us. Time: A Limited and Precious Commodity We cannot go back in time. If I used my time poorly last Wednesday, I can do nothing to get it back. Other commodities may allow for accumulating more or starting over, but time does not. We cannot “save” time or earn more time. “If you had a bank that credited your account each morning with $86,400, but carried no balance from day to day and allowed you to keep no cash in your account, and every evening cancelled whatever part of the amount you had failed to use during the day, what would you do? Draw out every cent, of course! Well, you have such a bank, and its name is time. Every morning it credits you with 86,400 seconds. Every night it writes off as lost whatever of these you have failed to invest to good purpose. It carries no balance; it allows no overdrafts. Each day it opens a new account with you. Each night it burns the record of the day. If you fail to use the day’s deposit, the loss is yours. There is no going back. There is no drawing against the morrow. You must live in the present – on today’s deposit. Invest it so as to get the utmost in health and happiness and success.” — Anonymous We often bring up efficiency and effectiveness to describe how people spend their time. What is your relationship with time? Are you usually early, right on time or late? Do you find yourself often saying, “I wish I had more time?” Are you satisfied with your relationship with time or would you like to change it? One of the challenges many adult students face is being over-committed. Some are working full-time and going to school full-time. Students may be taking care of children, siblings, parents, or be care-givers for loved ones with health needs. Students can have a multitude of other commitments and responsibilities. It can be difficult to take action to complete goals when there are so many areas competing for our time. And sometimes we cannot “do it all.” Sometimes we need to prioritize, let something go, adjust and reevaluate what the most important things are to us. Other students may struggle because college does not have as much structure as they may have been used to in high school. They may think, “Why should I start a homework assignment now when I don’t have anything I have to do for the next three days?” This mindset usually leads to the student waiting until the last minute to start the assignment and as a result, the quality of work is not high. Time management for successful university studying involves these factors: Determining how much time you need to spend studying Knowing how much time you actually have for studying and increasing that time if needed Being aware of the times of day you are at your best and most focused Using effective long-term and short-term study strategies Scheduling study activities in realistic segments Using a system to plan ahead and set priorities Staying motivated to follow your plan and avoid procrastination For every hour in the classroom, university students should spend, on average, about two additional hours on that class reading, studying, writing papers, and so on. If you’re a full-time student with fifteen hours a week in class, then you need another thirty hours for the rest of your academic work. That forty-five hours is about the same as a typical full-time job. If you work part time, time management skills are even more essential. These skills are still more important for part-time university students who work full time and commute or have a family. To succeed in university, virtually everyone has to develop effective strategies for dealing with time. In this chapter, you will learn strategies for time management and discover tools to help you implement them. \n",
      "-----------\n",
      "Identify sources and effects of test anxiety.\n",
      "Use effective strategies to manage test anxiety.\n",
      "Use effective techniques leading up to a test.\n",
      "Use effective strategies during a test.\n",
      "Use effective strategies after the test.\n",
      "Identify common types of academic dishonesty and their consequences.\n",
      "List the advantages and demonstrate the importance of academic integrity.\n",
      "--------------------------\n",
      "Both evergreen and deciduous leaves exhibit characteristic broad blades in angiosperms, and narrow needle, scale-like, or awl-shaped leaves in the conifers. Figure 15.1 illustrates  the different types of conifer leaves. Leaves may be borne singly on the shoot as in Picea spp. (spruce), in tufts or clusters as in Larix spp. (larch), or in fascicles (bundles) of 2-5 as in Pinus spp. (pines). The awl-shape and scale-like foliage of Juniperus spp. exhibits leaf dimorphism where a juvenile leaf form differs from the mature leaves of the same plant. Figure 15.1 Types of conifer leaves. Dichotomous Key for Some Common Conifers Click the links for plant images. 1.a. leaves long, needle-like ……………………………………………….. go to 2 1.b. leaves lanceolate, awl or scale-like, overlapping, not needle-like ……………………………………………………………………………… go to 5 2.a. needles in bundles or tufts …………………………………………….. go to 3 2.b. needles borne singly …………………………………………………… go to 7 3.a. needles in bundles of 2 to 5 ……………………………………………. go to 4 3.b. needles deciduous, many in a tuft ……………….. Larix decidua [New Tab] 4.a. 5 needles per bundle ……………………………… Pinus strobus [New Tab] 4.b. 2 needles per bundle …………………………………………………. go to 10 5.a. scales imbricate (overlapping) cones small, upright… Thuja plicata [New Tab] 5.b. scales imbricate, cones spherical or oval, opening along sutures at maturity ………………………………………………………………………………. go to 6 6.a. cones small, spherical; cone scales with a prominent point ………………………………………………. Cupressus nootkatensis [New Tab] 6.b. cones larger, oval, cone scales thick, deeply pitted ………………………………………….. Sequoiadendron giganteum [New Tab] 7.a. needles stiff and sharp, 4-sided ………………………………………… go to 8 7.b. needles flat and pliable …………………………………………………. go to 9 8.a. needles extremely sharp, new growth coated with bluish wax…………………………………….. Picea pungens Glauca Group [New Tab] 8.b. needles not extremely sharp, not coated with bluish wax …………………………………………………………… Picea abies [New Tab] 9.a. needles dull green, 2 cm long, borne on short pegs that persist after the needles fall ……………………………………………….. Tsuga heterophylla [New Tab] 9.b. needles shining green, 2 cm long, not borne on pegs ……………………………………………….. Pseudotsuga menziesii [New Tab] 10.a. needles &lt; 7 cm long ………………………………………………….. go to 11 10.b. needles &gt; 7 cm long ………………………………. Pinus nigra [New Tab] 11.a. needles dark green, 3-6 cm long, cone scales with a small recurved prickle ……………………………………………………….. Pinus contorta [New Tab] 11.b. needles bluish green 5-7 cm long, slightly twisted, cone scales without a prickle ……………………………………………………… Pinus sylvestris [New Tab] 16 Plant Morphology – Flowers and Fruit \n",
      "-----------\n",
      "Use a dichotomous key to identify conifers.\n",
      "--------------------------\n",
      "A plant will go through a sequence of stages from seed germination to seed production as a mature plant.  For some plants, this sequence, or life cycle may take a few weeks  while others continue to grow and flower repeatedly over many years. Plant life cycles are classified as annual, biennial, or perennial. Annuals complete their life cycle of germination from seed, growing, flowering, fruiting and dying within a single season of growth. Biennials require two seasons to complete their life cycle. In the first season, foliage production and storage of food reserves takes place followed by flowering, seed production and death in the next. Perennials typically flower annually once established and may live for several to a great number of years. Types of Annuals While the annual life cycle is completed within a single season of growth, the term annual or bedding plant may also be used to describe any plant that is grown outdoors in the spring and summer for one growing season. Annual flowers differ in their tolerance to cold weather and frost. Hardy annuals are the most cold tolerant; they will take light frost and some freezing weather without being killed. In most cases, hardy annuals can be planted in the fall or in the spring before the last frost date. Examples of hardy annuals include Lathyrus (sweet pea), Viola (pansy), and Tagetes (marigold) cultivars. Most hardy annuals are not heat tolerant and usually decline and die with the onset of hot summer temperatures. Another type of hardy annual is the winter annual that germinates in the fall, overwinters as a rosette of leaves, and flowers in late winter and early spring. Species of Stellaria (chickweed) and Cardamine (snapweed) are examples of winter annuals. Half-hardy annuals will tolerate periods of cold damp weather, but will be damaged by frost. Most half-hardy annuals can be seeded outdoors in early spring since they do not require warm soil temperatures to germinate. Seeds or plants are normally planted after the last spring frost. Examples of plants grown as half-hardy annuals are Cosmos (cosmos) and Tropaeolum (nasturtium). Some half-hardy annuals may decline in the midsummer heat but may re-bloom in late summer or fall. Because most tender annuals are native to warm tropical regions of the world, they are sensitive to cold soil temperatures and are easily damaged by frost. Most seeds will not survive freezing soils temperatures and will not germinate when soil temperatures are below 15°C.  It is recommended to wait two to three weeks after the last spring frost to sow seeds or transplant outdoors. Tender annuals include species of Begonia (begonia)and Impatiens (impatiens). While some plants may be perennial in tropical regions, they are categorized as cool- or warm-season annuals when planted in colder regions. Cool-season annuals, such as Pelargonium (geranium) , Petunia (petunia), and Antirrhinum (snapdragon), grow best when temperatures are in between 20° and 25° C. during the day. Best flower production is in the spring and fall; flower production tends to decline in the middle of a hot summer. Warm-season annuals, such as Zinnia (zinnia) perform well when day time temperatures are between 26° and 32°C. and night time temperatures are between 15° and 20°C. Biennials The life cycle of biennial plants is completed over two growing seasons. During the first season, they produce only leaves—usually in a rosette. Following a winter cold period, they flower in the second growing season, produce seeds, and then die. Popular biennials include Digitalis (foxglove) and Oenothera (evening primrose). Cultural practices are basically the same as for annuals, except that the plants are alive for two growing seasons. Biennials present the obvious disadvantage of producing only foliage the first year. One solution is to sow biennial seeds in mid-summer so that the plants will develop during the summer and fall. After exposure to the winter cold, they will develop flowers in the spring. Perennials Perennial plants can be either short-lived or long-lived herbaceous or woody plants. Short-lived herbaceous plants such as Gaillardia (blanket flower) may live for only a few years, or they can be long-lived like Paeonia (peony). Woody plants also classify as perennials, though they are rarely referred to as such. Woody species have stems that continue to grow, developing a permanent structure that the plant cannot ‘replace’ once removed. Some woody plants live tremendously long lives, such as the 9500 year old Picea sp. (spruce) in Sweden and British Columbia’s 1000 year old Thuja plicata (western red cedar) . Perennials that flower and fruit only once and then die are termed monocarpic . However, most perennials are polycarpic, flowering over many seasons in their lifespan. Common hardy herbaceous plant families include: Asteraceae – sunflowers Brassicaceae – mustards Crassulaceae – sedums Liliaceae – lilies Lamiaceae – mints Poaceae – grasses Ranunculaceae – buttercups Review 11 Introduction to Dichotomous Keys \n",
      "-----------\n",
      "Describe characteristics of plant life cycle classifications.\n",
      "--------------------------\n",
      "Like other medical problems, psychological disorders may in some cases be treated biologically. Biomedical therapies are treatments designed to reduce psychological disorder by influencing the action of the central nervous system . These therapies primarily involve the use of medications but also include direct methods of brain intervention, including electroconvulsive therapy (ECT) , transcranial magnetic stimulation (TMS) , and psychosurgery . Drug Therapies Psychologists understand that an appropriate balance of neurotransmitters in the brain is necessary for mental health. If there is a proper balance of chemicals, then the person’s mental health will be acceptable, but psychological disorder will result if there is a chemical imbalance. The most frequently used biological treatments provide the patient with medication that influences the production and reuptake of neurotransmitters in the central nervous system (CNS). The use of these drugs is rapidly increasing, and drug therapy is now the most common approach to treatment of most psychological disorders. Unlike some medical therapies that can be targeted toward specific symptoms, current psychological drug therapies are not so specific; they don’t change particular behaviours or thought processes, and they don’t really solve psychological disorders. However, although they cannot “cure” disorders, drug therapies are nevertheless useful therapeutic approaches, particularly when combined with psychological therapy, in treating a variety of psychological disorders. The best drug combination for the individual patient is usually found through trial and error (Biedermann &amp; Fleischhacker, 2009). The major classes and brand names of drugs used to treat psychological disorders are shown in Table 14.2. Table 14.2 Common Medications Used to Treat Psychological Disorders. [Skip Table] Class Type Brand names Disorder Notes Psychostimulants Ritalin, Adderall, Dexedrine Attention-deficit/hyperactivity disorder (ADHD) Very effective in most cases, at least in the short term, at reducing hyperactivity and inattention Antidepressants Tricyclics Elavil, Tofranil Depression and anxiety disorders Less frequently prescribed today than are the serotonin reuptake inhibitors (SSRIs) Monamine oxidase inhibitors (MAIOs) Ensam, Nardil, Parnate, Marpaln Depression and anxiety disorders Less frequently prescribed today than are the SSRIs SSRIs Prozac, Paxil, Zoloft Depression and anxiety disorders The most frequently prescribed antidepressant medications; work by blocking the reuptake of serotonin Other reuptake inhibitors Effexor, Celexa, Wellbutrin Depression and anxiety disorders Prescribed in some cases; work by blocking the reuptake of serotonin, norepinephrine, and dopamine Mood stabilizers Eskalith, Lithobid, Depakene Bipolar disorder Effective in reducing the mood swings associated with bipolar disorder Anti-anxiety drugs Tranquilizers (benzodiazepines) Valium, Xanax Anxiety, panic, and mood disorders Work by increasing the action of the neurotransmitter GABA (gamma-aminobutyric acid) Anti-psychotics (neuroleptics) Thorazine, Haldol, Clozaril, Risperdal, Zyprexa Schizophrenia Treat the positive and to some extent, the negative symptoms of schizophrenia by reducing the transmission of dopamine and increasing the transmission of serotonin Using Stimulants to Treat ADHD Attention-deficit/hyperactivity disorder (ADHD) is frequently treated with biomedical therapy, usually along with cognitive behavioural therapy (CBT). The most commonly prescribed drugs for ADHD are psychostimulants, including Ritalin, Adderall, and Dexedrine. Short-acting forms of the drugs are taken as pills and last between four and 12 hours, but some of the drugs are also available in long-acting forms (skin patches) that can be worn on the hip and last up to 12 hours. The patch is placed on the child early in the morning and worn all day. Stimulants improve the major symptoms of ADHD, including inattention, impulsivity, and hyperactivity, often dramatically, in about 75% of the children who take them (Greenhill, Halperin, &amp; Abikof, 1999). But the effects of the drugs wear off quickly. Additionally, the best drug and best dosage varies from child to child, so it may take some time to find the correct combination. It may seem surprising to you that a disorder that involves hyperactivity is treated with a psychostimulant, a drug that normally increases activity. The answer lies in the dosage. When large doses of stimulants are taken, they increase activity, but in smaller doses the same stimulants improve attention and decrease motor activity (Zahn, Rapoport, &amp; Thompson, 1980). The most common side effects of psychostimulants in children include decreased appetite, weight loss, sleeping problems, and irritability as the effect of the medication tapers off. Stimulant medications may also be associated with a slightly reduced growth rate in children, although in most cases growth isn’t permanently affected (Spencer, Biederman, Harding, &amp; O’Donnell, 1996). Antidepressant Medications Antidepressant medications are drugs designed to improve moods . Although they are used primarily in the treatment of depression, they are also effective for patients who suffer from anxiety, phobias, and obsessive-compulsive disorders. Antidepressants work by influencing the production and reuptake of neurotransmitters that relate to emotion, including serotonin, norepinephrine, and dopamine. Although exactly why they work is not yet known, as the amount of the neurotransmitters in the CNS is increased through the action of the drugs, the person often experiences less depression. The original antidepressants were the tricyclic antidepressants , with the brand names of Tofranil and Elavil, and the monamine oxidase inhibitors (MAOIs) . These medications work by increasing the amount of serotonin, norepinephrine, and dopamine at the synapses , but they also have severe side effects including potential increases in blood pressure and the need to follow particular diets. The antidepressants most prescribed today are the selective serotonin reuptake inhibitors (SSRIs) , including Prozac, Paxil, and Zoloft, which are designed to selectively block the reuptake of serotonin at the synapse, thereby leaving more serotonin available in the CNS . SSRIs are safer and have fewer side effects than the tricyclics or the MAOIs (Fraser, 2000; Hollon, Thase, &amp; Markowitz, 2002). SSRIs are effective, but patients taking them often suffer a variety of sometimes unpleasant side effects, including dry mouth, constipation, blurred vision, headache, agitation, drowsiness, as well as a reduction in sexual enjoyment. There has been concern that SSRIs may increase the risk of suicide among teens and young adults, probably because when the medications begin working they give patients more energy, which may lead them to commit the suicide that they had been planning but lacked the energy to go through with (Barbui, Esposito, &amp; Cipriani, 2009). This concern has led  doctors to be more selective about prescribing antidepressants to this age group (Healy &amp; Whitaker, 2003; Simon, 2006; Simon, Savarino, Operskalski, &amp; Wang, 2006). Because the effects of antidepressants may take weeks or even months to develop, doctors usually work with each patient to determine which medications are most effective, and may frequently change medications over the course of therapy. In some cases other types of antidepressants may be used instead of or in addition to the SSRIs. These medications also work by blocking the reuptake of neurotransmitters, including serotonin, norepinephrine, and dopamine. Brand names of these medications include Effexor and Wellbutrin. Patients who are suffering from bipolar disorder are not helped by the SSRIs or other antidepressants because their disorder also involves the experience of overly positive moods. Treatment is more complicated for these patients, often involving a combination of antipsychotics and antidepressants along with mood stabilizing medications (McElroy &amp; Keck, 2000). The most well-known mood stabilizer, lithium carbonate (or lithium), is used widely to treat mania associated with bipolar disorder. Available in Canada for more than 60 years, the medication is used to treat acute manic episodes and as a long-term therapy to reduce their frequency and severity. Anticonvulsant medications can also be used as mood stabilizers. Another drug, Depakote, has also proven very effective, and some bipolar patients may do better with it than with lithium (Kowatch et al., 2000). People who take lithium must have regular blood tests to be sure that the levels of the drug are in the appropriate range. Potential negative side effects of lithium are loss of coordination, slurred speech, frequent urination, and excessive thirst. Though side effects often cause patients to stop taking their medication, it is important that treatment be continuous, rather than intermittent. Recently, Health Canada updated safety information and treatment recommendations for lithium after finding that taking lithium carries a risk of high blood calcium, or hypercalcemia, and is sometimes associated with a hormone disorder known as hyperparathyroidism (Canadian Press, 2014). There is no cure for bipolar disorder, but drug therapy does help many people. Antianxiety Medications Antianxiety medications are drugs that help relieve fear or anxiety . They work by increasing the action of the neurotransmitter GABA. The increased level of GABA helps inhibit the action of the sympathetic division of the autonomic nervous system, creating a calming experience. The most common class of antianxiety medications is the tranquilizers , known as benzodiazepines . These drugs, which are prescribed millions of times a year, include Ativan, Valium, and Xanax. The benzodiazepines act within a few minutes to treat mild anxiety disorders but also have major side effects. They are addictive, frequently leading to tolerance, and they can cause drowsiness, dizziness, and unpleasant withdrawal symptoms including relapses into increased anxiety (Otto et al., 1993). Furthermore, because the effects of the benzodiazepines are very similar to those of alcohol, they are very dangerous when combined with it. Antipsychotic Medications Until the middle of the 20th century, schizophrenia was inevitably accompanied by the presence of positive symptoms, including bizarre, disruptive, and potentially dangerous behaviour. As a result, schizophrenics were locked in asylums to protect them from themselves and to protect society from them. In the 1950s, a drug called chlorpromazine (Thorazine) was discovered that could reduce many of the positive symptoms of schizophrenia. Chlorpromazine was the first of many antipsychotic drugs . Antipsychotic drugs (neuroleptics) are drugs that treat the symptoms of schizophrenia and related psychotic disorders . Today there are many antipsychotics, including Thorazine, Haldol, Clozaril, Risperdal, and Zyprexa. Some of these drugs treat the positive symptoms of schizophrenia, and some treat the positive, negative, and cognitive symptoms. The discovery of chlorpromazine and its use in clinics has been described as the single greatest advance in psychiatric care, because it has dramatically improved the prognosis of patients in psychiatric hospitals worldwide. Using antipsychotic medications has allowed hundreds of thousands of people to move out of asylums into individual households or community mental health centres, and in many cases to live near-normal lives. Antipsychotics reduce the positive symptoms of schizophrenia by reducing the transmission of dopamine at the synapses in the limbic system, and they improve negative symptoms by influencing levels of serotonin (Marangell, Silver, Goff, &amp; Yudofsky, 2003). Despite their effectiveness, antipsychotics have some negative side effects, including restlessness, muscle spasms, dizziness, and blurred vision. In addition, their long-term use can cause permanent neurological damage, a condition called tardive dyskinesia that causes uncontrollable muscle movements, usually in the mouth area (National Institute of Mental Health, 2008). Newer antipsychotics treat more symptoms with fewer side effects than older medications do (Casey, 1996). Direct Brain Intervention Therapies In cases of severe disorder it may be desirable to directly influence brain activity through electrical activation of the brain or through brain surgery. Electroconvulsive therapy (ECT) is a medical procedure designed to alleviate psychological disorder in which electric currents are passed through the brain, deliberately triggering a brief seizure (Figure 14.4, “Electroconvulsive Therapy (ECT)”). ECT has been used since the 1930s to treat severe depression. When it was first developed, the procedure involved strapping the patient to a table before the electricity was administered. The patient was knocked out by the shock, went into severe convulsions, and awoke later, usually without any memory of what had happened. Today ECT is used only in the most severe cases when all other treatments have failed, and the practice is more humane. The patient is first given muscle relaxants and a general anesthesia, and precisely calculated electrical currents are used to achieve the most benefit with the fewest possible risks. ECT is very effective; about 80% of people who undergo three sessions of ECT report dramatic relief from their depression. ECT reduces suicidal thoughts and is assumed to have prevented many suicides (Kellner et al., 2005). On the other hand, the positive effects of ECT do not always last; over one-half of patients who undergo ECT experience relapse within one year, although antidepressant medication can help reduce this outcome (Sackheim et al., 2001). ECT may also cause short-term memory loss or cognitive impairment (Abrams, 1997; Sackheim et al., 2007). Figure 14.4 Electroconvulsive Therapy (ECT). Today’s ECT uses precisely calculated electrical currents to achieve the most benefit with the fewest possible risks. Although ECT continues to be used, newer approaches to treating chronic depression are also being developed. A newer and gentler method of brain stimulation is transcranial magnetic stimulation (TMS) , a medical procedure designed to reduce psychological disorder that uses a pulsing magnetic coil to electrically stimulate the brain (Figure 14.5, “Transcranial Magnetic Stimulation [TMS]”). TMS seems to work by activating neural circuits in the prefrontal cortex, which is less active in people with depression, causing an elevation of mood. TMS can be performed without sedation, does not cause seizures or memory loss, and may be as effective as ECT (Loo, Schweitzer, &amp; Pratt, 2006; Rado, Dowd, &amp; Janicak, 2008). TMS has also been used in the treatment of Parkinson’s disease and schizophrenia. Figure 14.5 Transcranial Magnetic Stimulation (TMS). TMS is a noninvasive procedure that uses a pulsing magnetic coil to electrically stimulate the brain. Recently, TMS has been used in the treatment of Parkinson’s disease. Still other biomedical therapies are being developed for people with severe depression that persists over years. One approach involves implanting a device in the chest that stimulates the vagus nerve, a major nerve that descends from the brain stem toward the heart (Corcoran, Thomas, Phillips, &amp; O’Keane, 2006; Nemeroff et al., 2006). When the vagus nerve is stimulated by the device, it activates brain structures that are less active in severely depressed people. Psychosurgery , that is, surgery that removes or destroys brain tissue in the hope of improving disorder, is reserved for the most severe cases. The most well-known psychosurgery is the prefrontal lobotomy . Developed in 1935 by Nobel Prize winner Egas Moniz to treat severe phobias and anxiety, the procedure destroys the connections between the prefrontal cortex and the rest of the brain. Lobotomies were performed on thousands of patients. The procedure — which was never validated scientifically — left many patients in worse condition than before, subjecting the already suffering patients and their families to further heartbreak (Valenstein, 1986). Perhaps the most notable failure was the lobotomy performed on Rosemary Kennedy, the sister of U.S. President John F. Kennedy, which left her severely incapacitated. There are very few centres that still conduct psychosurgery today, and when such surgeries are performed they are much more limited in nature and called cingulotomy (Dougherty et al., 2002). The ability to more accurately image and localize brain structures using modern neuroimaging techniques suggests that new, more accurate, and more beneficial developments in psychosurgery may soon be available (Sachdev &amp; Chen, 2009). Key Takeaways Psychostimulants are commonly prescribed to reduce the symptoms of ADHD. Antipsychotic drugs play a crucial role in the treatment of schizophrenia. They do not cure schizophrenia, but they help reduce the positive, negative, and cognitive symptoms, making it easier to live with the disease. Antidepressant drugs are used in the treatment of depression, anxiety, phobias, and obsessive-compulsive disorder. They gradually elevate mood by working to balance neurotransmitters in the CNS. The most commonly prescribed antidepressants are the SSRIs. Antianxiety drugs (tranquilizers) relieve apprehension, tension, and nervousness and are prescribed for people with diagnoses of generalized anxiety disorder (GAD), obsessive-compulsive disorder (OCD), post-traumatic stress disorder (PTSD), and panic disorder. The drugs are effective but have severe side effects including dependence and withdrawal symptoms. Electroconvulsive therapy (ECT) is a controversial procedure used to treat severe depression, in which electric currents are passed through the brain, deliberately triggering a brief seizure. A newer method of brain stimulation is transcranial magnetic stimulation (TMS), a noninvasive procedure that employs a pulsing magnetic coil to electrically stimulate the brain. What are your opinions about taking drugs to improve psychological disorders? Would you take an antidepressant or antianxiety medication if you were feeling depressed or anxious? Do you think children with ADHD should be given stimulants? Why or why not? Based on what you have just read, would you be willing to undergo ECT or TMS if you were chronically depressed and drug therapy had failed? Why or why not? References Abrams, R. (1997). Electroconvulsive therapy (3rd ed.). Oxford, England: Oxford University Press. Barbui, C., Esposito, E., &amp; Cipriani, A. (2009). Selective serotonin reuptake inhibitors and risk of suicide: a systematic review of observational studies. Canadian Medical Association Journal, 180( 3), pp.  291-97. Biedermann, F., &amp; Fleischhacker, W. W. (2009). Antipsychotics in the early stage of development. Current Opinion Psychiatry, 22 , 326–330. Canadian Press. (2014). Health Canada updates safety profile of bipolar drug . Canada.com Retrieved July 2014 from Casey, D. E. (1996). Side effect profiles of new antipsychotic agents. Journal of Clinical Psychiatry, 57 (Suppl. 11), 40–45. Corcoran, C. D., Thomas, P., Phillips, J., &amp; O’Keane, V. (2006). Vagus nerve stimulation in chronic treatment-resistant depression: Preliminary findings of an open-label study. The British Journal of Psychiatry, 189 , 282–283. Dougherty, D., Baer, L., Cosgrove, G., Cassem, E., Price, B., Nierenberg, A.,…Rauch, S. L. (2002). Prospective long-term follow-up of 44 patients who received cingulotomy for treatment-refractory obsessive-compulsive disorder. American Journal of Psychiatry, 159 (2), 269. Fraser, A. R. (2000). Antidepressant choice to minimize treatment resistance. The British Journal of Psychiatry, 176 , 493. Greenhill, L. L., Halperin, J. M., &amp; Abikof, H. (1999). Stimulant medications. Journal of the American Academy of Child &amp; Adolescent Psychiatry, 38 (5), 503–512. Healy, D., &amp; Whitaker, C. J. (2003). Antidepressants and suicide: Risk-benefit conundrums. Journal of Psychiatry &amp; Neuroscience, 28 , 331–339. Hollon, S. D., Thase, M. E., &amp; Markowitz, J. C. (2002). Treatment and prevention of depression. Psychological Science in the Public Interest, 3 , 39–77. Kellner, C. H., Fink, M., Knapp, R., Petrides, G., Husain, M., Rummans, T.,…Malur, C. (2005). Relief of expressed suicidal intent by ECT: A consortium for research in ECT study. The American Journal of Psychiatry, 162 (5), 977–982. Kowatch, R. A., Suppes, T., Carmody, T. J., Bucci, J. P., Hume, J. H., Kromelis, M.,…Rush, A. J. (2000). Effect size of lithium, divalproex sodium, and carbamazepine in children and adolescents with bipolar disorder. Journal of the American Academy of Child &amp; Adolescent Psychiatry, 39 , 713–20. Loo, C. K., Schweitzer, I., &amp; Pratt, C. (2006). Recent advances in optimizing electroconvulsive therapy. Australian and New Zealand Journal of Psychiatry, 40 , 632–638. Marangell, L. B., Silver, J. M., Goff, D. C., &amp; Yudofsky, S. C. (2003). Psychopharmacology and electroconvulsive therapy. In R. E. Hales &amp; S. C. Yudofsky (Eds.), The American Psychiatric Publishing textbook of clinical psychiatry (4th ed., pp. 1047–1149). Arlington, VA: American Psychiatric Publishing. McElroy, S. L., &amp; Keck, P. E. (2000). Pharmacologic agents for the treatment of acute bipolar mania. Biological Psychiatry, 48 , 539–557. National Institute of Mental Health. (2008). Mental health medications (NIH Publication No. 08-3929). Retrieved from  Nemeroff, C., Mayberg, H., Krahl, S., McNamara, J., Frazer, A., Henry, T.,…Brannan, S. (2006). VNS therapy in treatment-resistant depression: Clinical evidence and putative neurobiological mechanisms. Neuropsychopharmacology, 31 (7), 1345–1355. Otto, M. W., Pollack, M. H., Sachs, G. S., Reiter, S. R., Meltzer-Brody, S., &amp; Rosenbaum, J. F. (1993). Discontinuation of benzodiazepine treatment: Efficacy of cognitive-behavioral therapy for patients with panic disorder. American Journal of Psychiatry, 150 , 1485–1490. Rado, J., Dowd, S. M., &amp; Janicak, P. G. (2008). The emerging role of transcranial magnetic stimulation (TMS) for treatment of psychiatric disorders. Directions in Psychiatry, 28 (4), 315–332. Sachdev, P. S., &amp; Chen, X. (2009). Neurosurgical treatment of mood disorders: Traditional psychosurgery and the advent of deep brain stimulation. Current Opinion in Psychiatry, 22 (1), 25–31. Sackheim, H. A., Prudic, J., Fuller, R., Keilp, J., Philip, W., Lavori, P. W., &amp; Olfson, M. (2007). The cognitive effects of electroconvulsive therapy in community settings. Neuropsychopharmacology, 32 , 244–254. Sackheim, H. A., Haskett, R. F., Mulsant, B. H., Thase, M. E., Mann, J. J., Pettinati, H.,…Prudic, J. (2001). Continuation pharmacotherapy in the prevention of relapse following electroconvulsive therapy: A randomized controlled trial. Journal of the American Medical Association, 285 , 1299–1307. Simon, G. E. (2006). The antidepressant quandary—Considering suicide risk when treating adolescent depression. The New England Journal of Medicine, 355 , 2722–2723. Simon, G. E., Savarino, J., Operskalski, B., &amp; Wang, P. S. (2006). Suicide risk during antidepressant treatment. American Journal of Psychiatry, 163 , 41–47. Spencer, T. J., Biederman, J., Harding, M., &amp; O’Donnell, D. (1996). Growth deficits in ADHD children revisited: Evidence for disorder-associated growth delays? Journal of the American Academy of Child &amp; Adolescent Psychiatry, 35 (11), 1460–1469. Valenstein, E. (1986). Great and desperate cures: The rise and decline of psychosurgery and other radical treatments for mental illness . New York, NY: Basic Books. Zahn, T. P., Rapoport, J. L., &amp; Thompson, C. L. (1980). Autonomic and behavioral effects of dextroamphetamine and placebo in normal and hyperactive prepubertal boys. Journal of Abnormal Child Psychology, 8 (2), 145–160. 79 14.3 Reducing Disorder by Changing the Social Situation \n",
      "-----------\n",
      "Classify the different types of drugs used in the treatment of mental disorders and explain how they each work to reduce disorder.\n",
      "Critically evaluate direct brain intervention methods that may be used by doctors to treat patients who do not respond to drug or other therapy.\n",
      "--------------------------\n",
      "What Is Nonexperimental Research? Nonexperimental research is research that lacks the manipulation of an independent variable, random assignment of participants to conditions or orders of conditions, or both. In a sense, it is unfair to define this large and diverse set of approaches collectively by what they are not . But doing so reflects the fact that most researchers in psychology consider the distinction between experimental and nonexperimental research to be an extremely important one. This distinction is because although experimental research can provide strong evidence that changes in an independent variable cause differences in a dependent variable, nonexperimental research generally cannot. As we will see, however, this inability does not mean that nonexperimental research is less important than experimental research or inferior to it in any general sense. When to Use Nonexperimental Research As we saw in Chapter 6 , experimental research is appropriate when the researcher has a specific research question or hypothesis about a causal relationship between two variables—and it is possible, feasible, and ethical to manipulate the independent variable and randomly assign participants to conditions or to orders of conditions. It stands to reason, therefore, that nonexperimental research is appropriate—even necessary—when these conditions are not met. There are many ways in which preferring nonexperimental research can be the case. The research question or hypothesis can be about a single variable rather than a statistical relationship between two variables (e.g., How accurate are people’s first impressions?). The research question can be about a noncausal statistical relationship between variables (e.g., Is there a correlation between verbal intelligence and mathematical intelligence?). The research question can be about a causal relationship, but the independent variable cannot be manipulated or participants cannot be randomly assigned to conditions or orders of conditions (e.g., Does damage to a person’s hippocampus impair the formation of long-term memory traces?). The research question can be broad and exploratory, or it can be about what it is like to have a particular experience (e.g., What is it like to be a working mother diagnosed with depression?). Again, the choice between the experimental and nonexperimental approaches is generally dictated by the nature of the research question. If it is about a causal relationship and involves an independent variable that can be manipulated, the experimental approach is typically preferred. Otherwise, the nonexperimental approach is preferred. But the two approaches can also be used to address the same research question in complementary ways. For example, nonexperimental studies establishing that there is a relationship between watching violent television and aggressive behaviour have been complemented by experimental studies confirming that the relationship is a causal one (Bushman &amp; Huesmann, 2001) . Similarly, after his original study, Milgram conducted experiments to explore the factors that affect obedience. He manipulated several independent variables, such as the distance between the experimenter and the participant, the participant and the confederate, and the location of the study (Milgram, 1974) . Types of Nonexperimental Research Nonexperimental research falls into three broad categories: single-variable research, correlational and quasi-experimental research, and qualitative research. First, research can be nonexperimental because it focuses on a single variable rather than a statistical relationship between two variables. Although there is no widely shared term for this kind of research, we will call it single-variable research . Milgram’s original obedience study was nonexperimental in this way. He was primarily interested in one variable—the extent to which participants obeyed the researcher when he told them to shock the confederate—and he observed all participants performing the same task under the same conditions. The study by Loftus and Pickrell described at the beginning of this chapter is also a good example of single-variable research. The variable was whether participants “remembered” having experienced mildly traumatic childhood events (e.g., getting lost in a shopping mall) that they had not actually experienced but that the research asked them about repeatedly. In this particular study, nearly a third of the participants “remembered” at least one event. (As with Milgram’s original study, this study inspired several later experiments on the factors that affect false memories.) As these examples make clear, single-variable research can answer interesting and important questions. What it cannot do, however, is answer questions about statistical relationships between variables. This detail is a point that beginning researchers sometimes miss. Imagine, for example, a group of research methods students interested in the relationship between children’s being the victim of bullying and the children’s self-esteem. The first thing that is likely to occur to these researchers is to obtain a sample of middle-school students who have been bullied and then to measure their self-esteem. But this design would be a single-variable study with self-esteem as the only variable. Although it would tell the researchers something about the self-esteem of children who have been bullied, it would not tell them what they really want to know, which is how the self-esteem of children who have been bullied compares with the self-esteem of children who have not. Is it lower? Is it the same? Could it even be higher? To answer this question, their sample would also have to include middle-school students who have not been bullied thereby introducing another variable. Research can also be nonexperimental because it focuses on a statistical relationship between two variables but does not include the manipulation of an independent variable, random assignment of participants to conditions or orders of conditions, or both. This kind of research takes two basic forms: correlational research and quasi-experimental research. In correlational research , the researcher measures the two variables of interest with little or no attempt to control extraneous variables and then assesses the relationship between them. A research methods student who finds out whether each of several middle-school students has been bullied and then measures each student’s self-esteem is conducting correlational research. In quasi-experimental research , the researcher manipulates an independent variable but does not randomly assign participants to conditions or orders of conditions. For example, a researcher might start an antibullying program (a kind of treatment) at one school and compare the incidence of bullying at that school with the incidence at a similar school that has no antibullying program. The final way in which research can be nonexperimental is that it can be qualitative. The types of research we have discussed so far are all quantitative, referring to the fact that the data consist of numbers that are analyzed using statistical techniques. In qualitative research , the data are usually nonnumerical and therefore cannot be analyzed using statistical techniques. Rosenhan’s study of the experience of people in a psychiatric ward was primarily qualitative. The data were the notes taken by the “pseudopatients”—the people pretending to have heard voices—along with their hospital records. Rosenhan’s analysis consists mainly of a written description of the experiences of the pseudopatients, supported by several concrete examples. To illustrate the hospital staff’s tendency to “depersonalize” their patients, he noted, “Upon being admitted, I and other pseudopatients took the initial physical examinations in a semipublic room, where staff members went about their own business as if we were not there” (Rosenhan, 1973, p. 256). Qualitative data has a separate set of analysis tools depending on the research question. For example, thematic analysis would focus on themes that emerge in the data or conversation analysis would focus on the way the words were said in an interview or focus group. Internal Validity Revisited Recall that internal validity is the extent to which the design of a study supports the conclusion that changes in the independent variable caused any observed differences in the dependent variable. Figure 7.1 shows how experimental, quasi-experimental, and correlational research vary in terms of internal validity. Experimental research tends to be highest because it addresses the directionality and third-variable problems through manipulation and the control of extraneous variables through random assignment. If the average score on the dependent variable in an experiment differs across conditions, it is quite likely that the independent variable is responsible for that difference. Correlational research is lowest because it fails to address either problem. If the average score on the dependent variable differs across levels of the independent variable, it could be that the independent variable is responsible, but there are other interpretations. In some situations, the direction of causality could be reversed. In others, there could be a third variable that is causing differences in both the independent and dependent variables. Quasi-experimental research is in the middle because the manipulation of the independent variable addresses some problems, but the lack of random assignment and experimental control fails to address others. Imagine, for example, that a researcher finds two similar schools, starts an antibullying program in one, and then finds fewer bullying incidents in that “treatment school” than in the “control school.” There is no directionality problem because clearly the number of bullying incidents did not determine which school got the program. However, the lack of random assignment of children to schools could still mean that students in the treatment school differed from students in the control school in some other way that could explain the difference in bullying. Figure 7.1 Internal Validity of Correlation, Quasi-Experimental, and Experimental Studies. Experiments are generally high in internal validity, quasi-experiments lower, and correlation studies lower still. Notice also in Figure 7.1 that there is some overlap in the internal validity of experiments, quasi-experiments, and correlational studies. For example, a poorly designed experiment that includes many confounding variables can be lower in internal validity than a well designed quasi-experiment with no obvious confounding variables. Internal validity is also only one of several validities that one might consider, as noted in Chapter 5. Key Takeaways Nonexperimental research is research that lacks the manipulation of an independent variable, control of extraneous variables through random assignment, or both. There are three broad types of nonexperimental research. Single-variable research focuses on a single variable rather than a relationship between variables. Correlational and quasi-experimental research focus on a statistical relationship but lack manipulation or random assignment. Qualitative research focuses on broader research questions, typically involves collecting large amounts of data from a small number of participants, and analyses the data nonstatistically. In general, experimental research is high in internal validity, correlational research is low in internal validity, and quasi-experimental research is in between. Bushman, B. J., &amp; Huesmann, L. R. (2001). Effects of televised violence on aggression. In D. Singer &amp; J. Singer (Eds.), Handbook of children and the media (pp. 223–254). Thousand Oaks, CA: Sage. Milgram, S. (1974). Obedience to authority: An experimental view . New York, NY: Harper &amp; Row. Rosenhan, D. L. (1973). On being sane in insane places. Science, 179 , 250–258. 21 Correlational Research \n",
      "-----------\n",
      "Define nonexperimental research, distinguish it clearly from experimental research, and give several examples.\n",
      "Explain when a researcher might choose to conduct nonexperimental research as opposed to experimental research.\n",
      "--------------------------\n",
      "Introduction to Work and the Economy Ever since the first people traded one item for another, there has been some form of economy in the world. It is how people optimize what they have to meet their wants and needs. Economy refers to the social institutions through which a society’s resources (goods and services) are managed. Goods are the physical objects we find, grow, or make in order to meet our needs and the needs of others. Goods can meet essential needs, such as a place to live, clothing, and food, or they can be luxuries — those things we do not need to live but want anyway. Goods produced for sale on the market are called commodities . In contrast to these objects , services are activities that benefit people. Examples of services include food preparation and delivery, health care, education, and entertainment. These services provide some of the resources that help to maintain and improve a society. The food industry helps ensure that all of a society’s members have access to sustenance. Health care and education systems care for those in need, help foster longevity, and equip people to become productive members of society. Economy is one of human society’s earliest social structures. Our earliest forms of writing (such as Sumerian clay tablets) were developed to record transactions, payments, and debts between merchants. As societies grow and change, so do their economies. The economy of a small farming community is very different from the economy of a large nation with advanced technology. In this chapter, we will examine different types of economic systems and how they have functioned in various societies. 18.1 Economic Systems Figure 18.2. Vladimir Ilyich Lenin was one of the founders of Russian communism. J.P. Morgan was one of the most influential capitalists in history. They had very different views on how economies should be run. (Photos (a) and (b) courtesy of Wikimedia Commons) The dominant economic systems of the modern era have been capitalism and socialism, and there have been many variations of each system across the globe. Countries have switched systems as their rulers and economic fortunes have changed. For example, Russia has been transitioning to a market-based economy since the fall of communism in that region of the world. Vietnam, where the economy was devastated by the Vietnam War, restructured to a state-run economy in response, and more recently has been moving toward a socialist-style market economy. In the past, other economic systems reflected the societies that formed them. Many of these earlier systems lasted centuries. These changes in economies raise many questions for sociologists. What are these older economic systems? How did they develop? Why did they fade away? What are the similarities and differences between older economic systems and modern ones? Economics of Agricultural, Industrial, and Postindustrial Societies Figure 18.3. In an agricultural economy, crops are the most important commodity. In a postindustrial society, the most valuable resource is information. (Photo (a) courtesy Wikimedia Commons; Photo (b) courtesy AntanaBhadraLamichhane/flickr) Our earliest ancestors lived as hunter-gatherers. Small groups of extended families roamed from place to place looking for means to subsist. They would settle in an area for a brief time when there were abundant resources. They hunted animals for their meat and gathered wild fruits, vegetables, and cereals. They distributed and ate what they caught or gathered as soon as possible because they had no way of preserving or transporting it. Once the resources of an area ran low, the group had to move on, and everything they owned had to travel with them. Food reserves only consisted of what they could carry. Groups did not typically trade essential goods with other groups due to scarcity. The use of resources was governed by the practice of usufruct , the distribution of resources according to need. Bookchin (1982) notes that in hunter-gatherer societies “property of any kind, communal or otherwise, has yet to acquire independence from the claims of satisfaction” (p. 50). The Agricultural Revolution The first true economies arrived when people started raising crops and domesticating animals. Although there is still a great deal of disagreement among archeologists as to the exact timeline, research indicates that agriculture began independently and at different times in several places around the world. The earliest agriculture was in the Fertile Crescent in the Middle East around 11,000–10,000 years ago. Next were the valleys of the Indus, Yangtze, and Yellow Rivers in India and China, between 10,000 and 9,000 years ago. The people living in the highlands of New Guinea developed agriculture between 9,000 and 6,000 years ago, while people were farming in sub-Saharan Africa between 5,000 and 4,000 years ago. Agriculture developed later in the western hemisphere, arising in what would become the eastern United States, central Mexico, and northern South America between 5,000 and 3,000 years ago (Diamond and Bellwood, 2003). Figure 18.4. Agricultural practices have emerged in different societies at different times. (Information courtesy of Wikimedia Commons) Agriculture began with the simplest of technologies — for example, a pointed stick to break up the soil — but really took off when people harnessed animals to pull an even more efficient tool for the same task: a plow. With this new technology, one family could grow enough crops not only to feed themselves but others as well. Knowing there would be abundant food each year as long as crops were tended led people to abandon the nomadic life of hunter-gatherers and settle down to farm. The improved efficiency in food production meant that not everyone had to toil all day in the fields. As agriculture grew, new jobs emerged, along with new technologies. Excess crops needed to be stored, processed, protected, and transported. Farming equipment and irrigation systems needed to be built and maintained. Wild animals needed to be domesticated and herds shepherded. Economies begin to develop because people now had goods and services to trade. As more people specialized in nonfarming jobs, villages grew into towns and then into cities. Urban areas created the need for administrators and public servants. Disputes over ownership, payments, debts, compensation for damages, and the like led to the need for laws and courts — and the judges, clerks, lawyers, and police who administered and enforced those laws. At first, most goods and services were traded as gifts or through bartering between small social groups (Mauss, 1922). Exchanging one form of goods or services for another was known as bartering . This system only works when one person happens to have something the other person needs at the same time. To solve this problem, people developed the idea of a means of exchange that could be used at any time: that is, money. Money refers to an object that a society agrees to assign a value to so it can be exchanged for payment. In early economies, money was often objects like cowry shells, rice, barley, or even rum. Precious metals quickly became the preferred means of exchange in many cultures because of their durability and portability. The first coins were minted in Lydia in what is now Turkey around 650–600 BCE (Goldsborough, 2010). Early legal codes established the value of money and the rates of exchange for various commodities. They also established the rules for inheritance, fines as penalties for crimes, and how property was to be divided and taxed (Horne, 1915). A symbolic interactionist would note that bartering and money are systems of symbolic exchange. Monetary objects took on a symbolic meaning, one that carries into our modern-day use of cheques and debit cards. Making Connections: Case Study The Lady Who Lives without Money Imagine having no money. If you wanted some french fries, needed a new pair of shoes, or were due to get an oil change for your car, how would you get those goods and services? This is not just a theoretical question. Think about it. What do those on the outskirts of society do in these situations? Think of someone escaping domestic abuse who gave up everything and has no resources. Or an immigrant who wants to build a new life but who had to leave another life behind to find that opportunity. Or a homeless person who simply wants a meal to eat. This last example, homelessness, is what caused Heidemarie Schwermer to give up money (2011). A divorced high school teacher in Germany, Schwermer’s life took a turn when she relocated her children to a rural town with a significant homeless population. She began to question what serves as currency in a society and decided to try something new. Schwermer founded a business called Gib und Nimm — in English, “give and take.” It operated on a moneyless basis and strived to facilitate people swapping goods and services for other goods and services — no cash allowed (Schwermer, 2007). What began as a short experiment has become a new way of life. Schwermer says the change has helped her focus on people’s inner value instead of their outward wealth. It has also led to two books telling her story (she’s donated all proceeds to charity) and, most importantly, a richness in her life she was unable to attain with money. In the early 1980s, a similar system ran on Vancouver Island. Known as L.E.T.S. (Local Exchange Trading System), the system ran on the moneyless principle of exchanges of services (Boxall, 2006). People did not have to directly swap services or goods — “I’ll mow your lawn if you edit my English grammar” — but could provide goods or perform services and bank the credits in “green dollars” for later use. It was not meant to replace the money economy entirely but to supplement it and provide a means of support and economic activity, especially in times of paid work scarcity. The founder of the system in Courtenay, B.C., Michael Linton, said that the system petered out on the central island by the late 1980s (a group still exists in Victoria), but not before spreading to almost 3,000 communities around the world. How might our three sociological perspectives view L.E.T.S. systems? What would most interest them about this form of unconventional economics? Would a functionalist consider them an aberration of norms or social dysfunction that upsets the normal balance, or would they note the substantial community building aspect of the direct provision of services and goods between people? How would a critical sociologist approach the concept of an alternative, moneyless economy? Is it a means of further exploiting labour or of escaping the alienation of commodified labour? What might a symbolic interactionist make of the choice not to use money — such an important symbol in the modern world? What do you make of Gib und Nimm ? As city-states grew into countries and countries grew into empires, their economies grew as well. When large empires broke up, their economies broke up too. The governments of newly formed nations sought to protect and increase their markets. They financed voyages of discovery to find new markets and resources all over the world, ushering in a rapid progression of economic development. Colonies were established to secure these markets, and wars were financed to take over territory. These ventures were funded in part by raising capital from investors who were paid back from the goods obtained. Governments and private citizens also set up large trading companies that financed their enterprises around the world by selling stocks and bonds. Governments tried to protect their share of the markets by developing a system called mercantilism. Mercantilism is an economic policy based on accumulating silver and gold by controlling colonial and foreign markets through taxes and other charges. The resulting restrictive practices and exacting demands included monopolies, bans on certain goods, high tariffs, and exclusivity requirements. Mercantilistic governments also promoted manufacturing and, with the ability to fund technological improvements, they helped create the equipment that led to the Industrial Revolution. The Industrial Revolution Up until the end of the 18th century, most manufacturing was done using manual labour. This changed as research led to machines that could be used to manufacture goods. A small number of innovations led to a large number of changes in the British economy. In the textile industries, the spinning of cotton, worsted yarn, and flax could be done more quickly and less expensively using new machines with names like the Spinning Jenny and the Spinning Mule (Bond et al., 2003). Another important innovation was made in the production of iron: coke from coal could now be used in all stages of smelting rather than charcoal from wood, dramatically lowering the cost of iron production while increasing availability (Bond, 2003). James Watt ushered in what many scholars recognize as the greatest change, revolutionizing transportation and, thereby, the entire production of goods with his improved steam engine. As people moved to cities to fill factory jobs, factory production also changed. Workers did their jobs in assembly lines and were trained to complete only one or two steps in the manufacturing process. These advances meant that more finished goods could be manufactured with more efficiency and speed than ever before. The Industrial Revolution also changed agricultural practices. Until that time, many people practiced subsistence farming in which they produced only enough to feed themselves and pay their taxes. New technology introduced gasoline-powered farm tools such as tractors, seed drills, threshers, and combine harvesters. Farmers were encouraged to plant large fields of a single crop to maximize profits. With improved transportation and the invention of refrigeration, produce could be shipped safely all over the world. The Industrial Revolution modernized the world. With growing resources came growing societies and economies. Between 1800 and 2000, the world’s population grew sixfold, while per capita income saw a tenfold jump (Maddison, 2003). While many people’s lives were improving, the Industrial Revolution also birthed many societal problems. There were inequalities in the system. Owners amassed vast fortunes while labourers, including young children, toiled for long hours in unsafe conditions. Workers’ rights, wage protection, and safe work environments are issues that arose during this period and remain concerns today. Postindustrial Societies and the Information Age Postindustrial societies, also known as information societies, have evolved in modernized nations. One of the most valuable goods of the modern era is information. Those who have the means to produce, store, and disseminate information are leaders in this type of society. One way scholars understand the development of different types of societies (like agricultural, industrial, and postindustrial) is by examining their economies in terms of four sectors: primary, secondary, tertiary, and quaternary. Each has a different focus. The primary sector extracts and produces raw materials (like metals and crops). The secondary sector turns those raw materials into finished goods. The tertiary sector provides services: child care, health care, and money management. Finally, the quaternary sector produces ideas; these include the research that leads to new technologies, the management of information, and a society’s highest levels of education and the arts (Kenessey, 1987). Modernization theory proposes a model of quasi-natural economic development, from undeveloped economies to advanced, to explain the difference in distribution of these sectors around the globe. In underdeveloped countries, the majority of the people work in the primary sector. As economies develop, more and more people are employed in the secondary sector. In well-developed economies, such as those in Canada, the United States, Japan, and western Europe, the majority of the workforce is employed in service industries. In Canada, for example, more than 75% of the workforce is employed in the tertiary sector (Statistics Canada, 2012). The rapid increase in computer use in all aspects of daily life is a main reason for the transition to an information economy. Fewer people are needed to work in factories because computerized robots now handle many of the tasks. Other manufacturing jobs have been outsourced to less-developed countries as a result of the developing global economy. The growth of the internet has created industries that exist almost entirely online. Within industries, technology continues to change how goods are produced. For instance, the music and film industries used to produce physical products like CDs and DVDs for distribution. Now those goods are increasingly produced digitally and streamed or downloaded at a much lower physical manufacturing cost. Information and the wherewithal to use it creatively become commodities in a postindustrial economy. Capitalism Figure 18.5. Companies sell stock to raise capital that they can invest in new projects, improving the company and producing the means for further income generation. (Photo courtesy of Paul B. Toman/Wikimedia Commons) Scholars do not always agree on a single definition of capitalism. For our purposes, we will define capitalism as an economic system characterized by private ownership of property or capital (as opposed to state ownership), sale of commodities on the open market, the purchase of labour for wages, and the impetus to generate profit and thereby accumulate wealth. This is the type of economy in place in Canada today. Under capitalism, people invest capital (money or property invested in a business venture) in a business to produce a product or service that can be sold in a market to consumers. The investors in the company are generally entitled to a share of any profit made on sales after the costs of production and distribution are taken out. These investors often reinvest their profits to improve and expand the business or acquire new ones. To illustrate how this works, consider this example. Sarah, Antonio, and Chris each invest $250,000 into a start-up company offering an innovative baby product. When the company nets $1 million in profits its first year, a portion of that profit goes back to Sarah, Antonio, and Chris as a return on their investment. Sarah reinvests with the same company to fund the development of a second product line, Antonio uses his return to help another start-up in the technology sector, and Chris buys a small yacht for vacations. The goal for all parties is to maximize profits. To provide their product or service, owners hire workers, to whom they pay wages. The cost of raw materials, the retail price they charge consumers, and the amount they pay in wages are determined through the law of supply and demand and by competition. This leads to the dynamic qualities of capitalism, including its instability and tendency toward crisis. When demand exceeds supply, prices tend to rise. When supply exceeds demand, prices tend to fall. When multiple businesses market similar products and services to the same buyers, there is competition. Competition can be good for consumers because it can lead to lower prices and higher quality as businesses try to get consumers to buy from them rather than from their competitors. However, competition also leads to key problems like the general tendency for a falling rate of profit, periodic crises of investment, and stock market crashes where billions of dollars of economic value can disappear overnight. Wages tend to be set in a similar way. People who have talents, skills, education, or training that is in short supply and is needed by businesses tend to earn more than people without comparable skills. Competition in the workforce helps determine how much people will be paid. In times when many people are unemployed and jobs are scarce, people are often willing to accept less than they would when their services are in high demand. In this scenario, businesses are able to maintain or increase profits by obliging workers to accept reduced wages. When fewer people are working or people are working for lower wages, the amount of money circulating in the economy decreases, reducing the demand for commodities and services and creating a vicious cycle of economic recession or depression. To sum up, capitalism is defined by a unique set of features that distinguish it from previous economic systems such as feudalism or agrarianism, or contemporary systems such as socialism or communism: The means of production (i.e., productive property or capital) are privately owned and controlled. Labour power is purchased from workers by capitalists for a wage or salary. The goal of production is to make a profit from selling commodities in a competitive free market. Profit from the sale of commodities is appropriated by the owners of capital. Part of this profit is reinvested as capital in the business enterprise in order to expand its profitability. The competitive accumulation of capital and profit leads to capitalism’s dynamic qualities: constant expansion of markets, globalization of investment, growth and centralization of capital, boom and bust cycles, economic crises, class conflict, etc. Capitalism in Practice As capitalists began to dominate the economies of many countries during the Industrial Revolution, the rapid growth of businesses and their tremendous profitability gave some owners the capital they needed to create enormous corporations that could monopolize an entire industry. Many companies controlled all aspects of the production cycle for their industry, from the raw materials to the production to the stores in which they were sold. These companies were able to use their wealth to buy out or stifle any competition. In Canada, the predatory tactics used by these large monopolies caused the government to take action. In 1889, the government passed the Act for the Prevention and Suppression of Combinations Formed in the Restraint of Trade (precursor to the contemporary Competition Act of 1985), a law designed to break up monopolies and regulate how key industries — such as transportation, steel production, and oil and gas exploration and refining — could conduct business. Canada is considered a capitalist country. However, the Canadian government has a great deal of influence on private companies through the laws it passes and the regulations enforced by government agencies. Through taxes, regulations on wages, guidelines to protect worker safety and the environment, plus financial rules for banks and investment firms, the government exerts a certain amount of control over how all companies do business. Provincial and federal governments also own, operate, or control large parts of certain industries, such as the post office, schools, hospitals, highways and railroads, and water, sewer, and power utilities. From the building of the Canadian Pacific Railway in the 1880s to the development of the Alberta tar sands in the 1960s and 1970s, the Canadian government has played a substantial interventionist role in investing, providing incentives, and assuming ownership in the economy. Debate over the extent to which the government should be involved in the economy remains an issue of contention today. Neoliberal economists and corporate-funded think tanks like the Fraser Institute criticize such involvements, arguing that they lead to economic inefficiency and distortion in free market processes of supply and demand. Others believe intervention is necessary to protect the rights of workers and the well-being of the general population. Socialism Figure 18.6. The economies of China and Russia after World War II are examples of one form of socialism. (Photo courtesy of Wikimedia Commons) Socialism is an economic system in which there is government ownership (often referred to as “state run”) of goods and their production, with an impetus to share work and wealth equally among the members of a society. Under socialism, everything that people produce, including services, is considered a social product. Everyone who contributes to the production of a good or to providing a service is entitled to a share in any benefits that come from its sale or use. To make sure all members of society get their fair share, government must be able to control property, production, and distribution. The focus in socialism is on benefiting society, whereas capitalism seeks to benefit the individual. Socialists claim that a capitalistic economy leads to inequality, with unfair distribution of wealth and individuals who use their power at the expense of society. Socialism strives, ideally, to control the economy to avoid the problems and instabilities inherent in capitalism. Within socialism, there are diverging views on the extent to which the economy should be controlled. The communist systems of the Soviet Union, Cuba, and China under Chairman Mao Tse Tung were organized so that all but the most personal items were public property. Contemporary democratic socialism is based on the socialization or government control of essential services such as health care, education, and utilities (electrical power, telecommunications, and sewage). This is essentially a mixed economy based on a free market system and with substantial portions of the economy under private control. Farms, small shops, and businesses are privately owned, while the state might own large businesses in key sectors like energy extraction and transportation. The central component of democratic socialism, however, is the redistribution of wealth and the universal provision of services like child care, health care, and unemployment insurance through a progressive tax system. The other area on which socialists disagree is on what level society should exert its control. In communist countries like the former Soviet Union, China, Vietnam, and North Korea, the national government exerts control over the economy centrally. They had the power to tell all businesses what to produce, how much to produce, and what to charge for it. Other socialists believe control should be decentralized so it can be exerted by those most affected by the industries being controlled. An example of this would be a town collectively owning and managing the businesses on which its populace depends. Because of challenges in their economies, several of these communist countries have moved from central planning to letting market forces help determine many production and pricing decisions. Market socialism describes a subtype of socialism that adopts certain traits of capitalism, like allowing limited private ownership or consulting market demands. This could involve situations like profits generated by a company going directly to the employees of the company or being used as public funds (Gregory and Stuart, 2003). Many eastern European and some South American countries have mixed economies. Key industries are nationalized and directly controlled by the government; however, most businesses are privately owned and regulated by the government. State intervention in the economy has been a central component to the Canadian system since the founding of the country. Democratic socialist movements became prominent in Canadian politics in the 1920s. The efforts of the western agrarian movements, the labour union movement, and the social democratic parties like the CCF (the Co-operative Commonwealth Federation) and its successor, the NDP (New Democratic Party), were instrumental in implementing many of the democratic socialist features of contemporary Canada such as universal health care, old age pensions, employment insurance, and welfare. Figure 18.7. This map shows countries that have adopted a socialist economy at some point. The colours indicate the duration that socialism prevailed. (Map courtesy of Wikimedia Commons) Socialism in Practice As with capitalism, the basic ideas behind socialism go far back in history. Plato, in ancient Greece, suggested a republic in which people shared their material goods. Early Christian communities believed in common ownership, as did the systems of monasteries set up by various religious orders. Many of the leaders of the French Revolution called for the abolition of all private property, not just the estates of the aristocracy they had overthrown. Thomas More’s Utopia , published in 1516, imagined a society with little private property and mandatory labour on a communal farm. Most experimental utopian communities had the abolition of private property as a founding principle. Modern socialism really began as a reaction to the excesses of uncontrolled industrial capitalism in the 1800s and 1900s. The enormous wealth and lavish lifestyles enjoyed by owners contrasted sharply with the miserable conditions of the workers. Some of the first great sociological thinkers studied the rise of socialism. Max Weber admired some aspects of socialism, especially its rationalism and how it could help social reform, but noted that social revolution would not resolve the issues of bureaucratic control and the “iron cage of future bondage” (Greisman and Ritzer, 1981). Pierre-Joseph Proudhon (1809−1865) was an early anarchist who thought socialism could be used to create utopian communities. In his 1840 book, What Is Property? , he famously stated that “property is theft” (Proudhon, 1840). By this he meant that if an owner did not work to produce or earn the property or profit, then the owner was stealing it from those who did. Proudhon believed economies could work using a principle called mutualism , under which individuals and cooperative groups would exchange products with one another on the basis of mutually satisfactory contracts (Proudhon, 1840). By far the most important influential thinker on socialism was Karl Marx (Marx and Engels, 1848). Through his own writings and those with his collaborator, industrialist Friedrich Engels, Marx used a materialist analysis to show that throughout history, the resolution of class struggles caused changes in economies. Materialist analyses focus on changes in the economic mode of production to explain the nature and transformation of the social order. Marx saw the history of class conflict developing dialectically from slave and owner, to serf and lord, to journeyman and master, to worker and owner. The resolution of one conflict was precipitated by the emergence of another. In the final epoch of class conflict, Marx argued that the development of capitalism would lead to the creation of a level of technology and economic organization sufficient to meet the needs of everyone in society equally. Scarcity, poverty, and the unequal distribution of resources were the increasingly anachronistic products of the institution of private property. However, capitalism also created the material conditions under which the working class, brought together en masse in factories and other workplaces, would recognize their common interests in ending class exploitation (i.e., they would attain “class consciousness”). Once private property was socialized through the revolution of the working classes, Marx argued that not only would the exploitive relationships of capitalism come to an end, but classes and class conflict themselves would disappear. Making Connections: Sociology in the Real World Obama and Socialism: A Few Definitions In the 2008 U.S. presidential election, the Republican Party latched onto what is often considered a dirty word to describe then-Senator Barack Obama’s politics: socialist. It may have been because the president was campaigning by telling workers it’s good for everybody when wealth gets spread around. But whatever the reason, the label became a weapon of choice for Republicans during and after the campaign. In 2012, Republican presidential contender Rick Perry continued this battle cry. A New York Times article quotes him as telling a group of Republicans in Texas that President Obama is “hell bent on taking America towards a socialist country” (Wheaton, 2011). Meanwhile, during the first few years of his presidency, Obama worked to create universal health care coverage and pushed forth a partial takeover of the nation’s failing automotive industry. So does this make him a socialist? What does that really mean, anyway? There is more than one definition of socialism, but it generally refers to an economic or political theory that advocates for shared or governmental ownership and administration of production and distribution of goods. Often held up in counterpoint to capitalism, which encourages private ownership and production, socialism is not typically an all-or-nothing plan. For example, Canada, the United Kingdom, and France, as well as other European countries, have socialized medicine, meaning that medical services are run nationally to reach as many people as possible. These nations are, of course, still essentially capitalist countries with free-market economies. So is Obama a socialist because he wants universal health care? Or is the word a lightning rod for conservatives who associate it with a lack of personal freedom? By almost any measure, the answer is more the latter. A look at the politics of President Obama and Democrats in general shows that there is, compared to most other free-market countries, very little limitation on private ownership and production. What this is, instead, is an attempt to ensure that the United States, like all other core nations, has a safety net for its poorest and most vulnerable. Although it might be in Perry’s best interest to label this as socialism, a study of the term makes it clear that it is untrue. American voters are unlikely to find, whoever their choice of candidate may be, that socialism is on the agenda in the United States. Modernization Theory and Convergence Theory We have seen how the economies of some capitalist countries such as Canada have features that are very similar to socialism. Some industries, particularly utilities, are either owned by the government or controlled through regulations. Public programs such as welfare, Medicare, and Social Security exist to provide public funds for private needs. We have also seen how several large communist (or formerly communist) countries such as Russia, China, and Vietnam have moved from state-controlled socialism with central planning to market socialism, which allows market forces to dictate prices and wages, and for some business to be privately owned. In many formerly communist countries, these changes have led to economic growth compared to the stagnation they experienced under communism (Fidrmuc, 2002). Modernization theory proposes that there are natural stages of economic development that all societies go through from undeveloped to advanced. Implied in this theory is a normative model that takes the wealthy economies of the Northern and Western world as being “advanced” and then compares other economies to them. One form of modernization theory is convergence theory . In studying the economies of developing countries to see if they go through the same stages as previously developed nations did, sociologists have observed a pattern they call convergence. This describes the theory that societies move toward similarity over time as their economies develop. Convergence theory explains that as a country’s economy grows, its societal organization changes to become more like that of an industrialized society. Rather than staying in one job for a lifetime, people begin to move from job to job as conditions improve and opportunities arise. This means the workforce needs continual training and retraining. Workers move from rural areas to cities as they become centres of economic activity, and the government takes a larger role in providing expanded public services (Kerr et al., 1960). Supporters of the theory point to Germany, France, and Japan — countries that rapidly rebuilt their economies after World War II. They point out how, in the 1960s and 1970s, East Asian countries like Singapore, South Korea, and Taiwan converged with countries with developed economies. They are now considered developed countries themselves. Figure 18.8. Sociologists look for signs of convergence and divergence in the societies of countries that have joined the European Union. (Map courtesy of Kolja21/Wikimedia Commons) The theory is also known as the catch-up effect because the economies of poor countries that have capital invested in them will generally grow faster than countries that are already wealthy. This allows the income of poorer countries to “catch up” under the right conditions (“Catch-up Effect,” 2011). To experience this rapid growth, the economies of developing countries must to be able to attract inexpensive capital to invest in new businesses and to improve traditionally low productivity. They need access to new, international markets for buying the goods. If these characteristics are not in place, then their economies cannot catch up. This is why the economies of some countries are diverging rather than converging (Abramovitz, 1986). Another key characteristic of economic growth regards the implementation of technology. A developing country can bypass some steps of implementing technology that other nations faced earlier. Television and telephone systems are a good example. While developed countries spent significant time and money establishing elaborate system infrastructures based on metal wires or fibre-optic cables, developing countries today can go directly to cell phone and satellite transmission with much less investment. Another factor affects convergence concerning social structure. Early in their development, countries such as Brazil and Cuba had economies based on cash crops (coffee or sugarcane, for instance) grown on large plantations by unskilled workers. The elite ran the plantations and the government, with little interest in training and educating the populace for other endeavours. This retarded economic growth until the power of the wealthy plantation owners was challenged (Sokoloff and Engerman, 2000). Improved economies generally lead to wider social improvement. Society benefits from improved educational systems, allowing people more time to devote to learning and leisure. Convergence theory and modernization theory are often criticized, however, by those who point out that the widely varying degrees of development observed globally have less to do with natural stages of development and more to do with relations of economic exploitation and geopolitical power, especially those structured by the legacy of the periods of European colonization and American imperialism. The notion of economic development itself, which came into widespread usage only after the geopolitical realignments following World War II, is also widely disputed. It is based on the idea that the capitalist economies of the dominant Western and Northern countries represent the ideal end point of a quasi-natural incremental process. Many point out that modernization theory is better seen as a self-serving ideological framework that actually prevents observers from seeing the real diversity of economic systems and the actual modes of their operation on a global basis (see Chapter 10). Theoretical Perspectives on the Economy Now that we’ve developed an understanding of the history and basic components of economies, let us turn to theory. How might social scientists study these topics? What questions do they ask? What theories do they develop to add to the body of sociological knowledge? Functionalist Perspective Someone taking a functional perspective will most likely view work and the economy as a well-oiled machine, designed for maximum efficiency. The Davis-Moore thesis, for example, suggests that some social stratification is a social necessity. The need for certain highly skilled positions combined with the relative difficulty of the occupation and the length of time it takes to qualify will result in a higher reward for that job, providing a financial motivation to engage in more education and a more difficult profession (Davis and Moore, 1945). This theory can be used to explain the prestige and salaries that go to those with doctorates or medical degrees. Like any theory, this is subject to criticism. For example, the thesis fails to take into account the many people who spend years on their education only to pursue work at a lower-paying position in a nonprofit organization, or who teach high school after pursuing a PhD. It also fails to acknowledge the effect of life changes and social networks on individual opportunities. The underlying notion that jobs and rewards are allocated on the basis of merit (i.e., a meritocracy) is belied by data that show that both class and gender play significant roles in structuring inequality (see Chapter 9). The functionalist perspective would assume that the continued “health” of the economy is vital to the functioning of the society, as it ensures the systematic distribution of goods and services. For example, we need food to travel from farms (high-functioning and efficient agricultural systems) via roads (safe and effective trucking and rail routes) to urban centres (high-density areas where workers can gather). However, sometimes a dysfunction — a function with the potential to disrupt social institutions or organization (Merton, 1968) — in the economy occurs, usually because some institutions fail to adapt quickly enough to changing social conditions. This lesson has been driven home recently with the financial crisis of 2008 and the bursting of the housing bubble. Due to irresponsible (i.e., dysfunctional) lending practices and an underregulated financial market, we are currently living with the after-effects of this major dysfunction. From the functionalist view, this crisis might be regarded as an element in the cyclical nature of the internal self-regulating system of the free market economy. In functionalism, systems are said to adapt to external contingencies. Markets produce goods as they are supposed to, but eventually the market is saturated and the supply of goods exceeds the demands. Typically the market goes through phases of surplus, or excess, inflation, where the money in your pocket today buys less than it did yesterday, and recession , which occurs when there are two or more consecutive quarters of economic decline. The functionalist would say to let market forces fluctuate in a cycle through these stages. In reality, to control the risk of an economic depression (a sustained recession across several economic sectors), the Canadian government will often adjust interest rates to encourage more spending. In short, letting the natural cycle fluctuate is not a gamble most governments are willing to take. Critical Sociology For a conflict perspective theorist, the economy is not a source of stability for society. Instead, the economy reflects and reproduces economic inequality, particularly in a capitalist marketplace. A dominant critical perspective on the economy is the classical Marxist approach, which views the underlying dynamic of capitalism as defined by class struggle. The bourgeoisie (ruling class) accumulate wealth and power by exploiting the proletariat (workers), and regulating those who cannot work (the aged, the infirm) into the great mass of unemployed (Marx and Engels, 1848). From the symbolic (though probably made up) statement of Marie Antoinette, who purportedly said “Let them eat cake” when told that the peasants were starving, to the Occupy Wall Street movement, the sense of inequity is almost unchanged. Both the people fighting in the French Revolution and those blogging from Zuccotti Park in New York believe the same thing: wealth is concentrated in the hands of those who do not deserve it. As of 2012, 20% of Canadians owned 70% of Canadian wealth. The wealthiest 86 Canadians had amassed the same amount of wealth as the poorest 11.4 million combined (Macdonald, 2014). While the inequality might not be as extreme as in pre-revolutionary France, it is enough to make many believe that Canada is not the meritocracy it seems to be. Symbolic Interactionist Perspective Those working in the symbolic interaction perspective take a microanalytical view of society, focusing on the way reality is socially constructed through day-to-day interaction and how society is composed of people communicating based on a shared understanding of symbols. One important symbolic interactionist concept related to work and the economy is career inheritance . This concept means simply that children tend to enter the same or similar occupation as their parents, a correlation that has been demonstrated in research studies (Antony, 1998). For example, the children of police officers learn the norms and values that will help them succeed in law enforcement, and since they have a model career path to follow, they may find law enforcement even more attractive. Related to career inheritance is career socialization, learning the norms and values of a particular job. A symbolic interactionist might also study what contributes to job satisfaction. Melving Kohn and his fellow researchers (1990) determined that workers were most likely to be happy when they believed they controlled some part of their work, when they felt they were part of the decision-making processes associated with their work, when they have freedom from surveillance, and when they felt integral to the outcome of their work. Sunyal, Sunyal, and Yasin (2011) found that a greater sense of vulnerability to stress, the more stress experienced by a worker, and a greater amount of perceived risk consistently predicted a lower worker job satisfaction. 18.2. Work in Canada Figure 18.9. Many people attend job fairs looking for their first job or for a better one. (Photo courtesy of Daniel Ramirez/flickr) Common wisdom states that if you study hard, develop good work habits, and graduate from high school or, even better, university, then you’ll have the opportunity to land a good job. That has long been seen as the key to a successful life. And although the reality has always been more complex than suggested by the myth, the worldwide recession that began in 2008 has made it harder than ever to play by the rules and win the game. The data are grim: for example, in the United States, from December 2007 through March 2010, 8.2 million workers lost their jobs, and the unemployment rate grew to almost 10% nationally, with some states showing much higher rates (Autor, 2010). Times are very challenging for those in the workforce. For those looking to finish their schooling, often with enormous student-debt burdens, it is not just challenging — it is terrifying. So where did all the jobs go? Will any of them be coming back, and if not, what new ones will there be? How do you find and keep a good job now? These are the kinds of questions people are currently asking about the job market in Canada. Making Connections: Sociology in the Real World? Real Money, Virtual Worlds Figure 18.10. In a virtual world, living the good life still costs real money. (Photo courtesy of Juan Pablo Amo/flickr) If you are not one of the tens of millions of gamers who enjoy World of Warcraft or other online virtual world games, you might not even know what MMORPG stands for. But if you made a living playing MMORPGs, as a growing number of enterprising gamers do, then massive multiplayer online role-playing games might matter a bit more. According to an article in Forbes magazine, the online world of gaming has been yielding very real profits for entrepreneurs who are able to buy, sell, and manage online real estate, currency, and more for cash (Holland and Ewalt, 2006). If it seems strange that people would pay real money for imaginary goods, consider that for serious gamers the online world is of equal importance to the real one. These entrepreneurs can sell items because the gaming sites have introduced scarcity into the virtual worlds. The game makers have realized that MMORPGs lack tension without a level of scarcity for needed resources or highly desired items. In other words, if anyone can have a palace or a vault full of wealth, then what’s the fun? So how does it work? One of the easiest ways to make such a living is called gold farming, which involves hours of repetitive and boring play, hunting and shooting animals like dragons that carry a lot of wealth. This virtual wealth can be sold on eBay for real money: a timesaver for players who do not want to waste their playing time on boring pursuits. Players in parts of Asia engage in gold farming, playing eight hours a day or more, to sell their gold to players in western Europe or North America. From virtual prostitutes to power levellers (people who play the game logged in as you so your characters get the wealth and power), to architects, merchants, and even beggars, online players can offer to sell any service or product that others want to buy. Whether buying a magic carpet in World of Warcraft or a stainless-steel kitchen appliance in Second Life, gamers have the same desire to acquire as the rest of us — never mind that their items are virtual. Once a gamer creates the code for an item, she can sell it again and again, for real money. Finally, you can also sell yourself. According to Forbes , a University of Virginia computer science student sold his World of Warcraft character on eBay for $1,200, due to the high levels of powers and skills it had gained (Holland and Ewalt, 2006). So should you quit your day job to make a killing in online games? Probably not. Those who work hard might eke out a decent living, but for most people, grabbing up land that does not really exist or selling your body in animated action scenes is probably not the best opportunity. Still, for some, it offers the ultimate in work-from-home flexibility, even if that home is a mountain cave in a virtual world. Polarization in the Workforce The mix of jobs available in Canada began changing many years before the recession struck. Geography, race, gender, and other factors have always played a role in the reality of success. More recently, the increased outsourcing (or contracting a job or set of jobs to an outside source) of manufacturing jobs to developing nations has greatly diminished the number of high-paying, often unionized, blue-collar positions available. A similar problem has arisen in the white-collar sector, with many low-level clerical and support positions also being outsourced, as evidenced by the international technical-support call centres in Mumbai, India. The number of supervisory and managerial positions has been reduced as companies streamline their command structures and industries continue to consolidate through mergers. Even highly educated skilled workers such as computer programmers have seen their jobs vanish overseas. The automation (replacing workers with technology) of the workplace is another cause of the changes in the job market. Computers can be programmed to do many routine tasks faster and less expensively than people who used to do such tasks. Jobs like bookkeeping, clerical work, and repetitive tasks on production assembly lines all lend themselves to automation. Think about the newer automated toll passes we can install in our cars. Toll collectors are just one of the many endangered jobs that will soon cease to exist. Despite all this, the job market is actually growing in some areas, but in a very polarized fashion. Polarization means that a gap has developed in the job market, with most employment opportunities at the lowest and highest levels and few jobs for those with mid-level skills and education. At one end, there has been strong demand for low-skilled, low-paying jobs in industries like food service and retail. On the other end, some research shows that in certain fields there has been a steadily increasing demand for highly skilled and educated professionals, technologists, and managers. These high-skilled positions also tend to be highly paid (Autor, 2010). The fact that some positions are highly paid while others are not is an example of the dual labour market structure , a division of the economy into sectors with different levels of pay. The primary labour market consists of high-paying jobs in the public sector, manufacturing, telecommunications, biotechnology, and other similar sectors that require high levels of capital investment (or other restrictions) that limit the number of businesses able to enter the sector. The costs of labour are considered marginal in comparison to the total capital investment required. Jobs in the sector usually offer good benefits, security, prospects for advancement, and comparatively higher levels of unionization. The secondary labour market consists of jobs in more competitive sectors of the economy like service industries, restaurants, and commercial enterprises, where the cost of entry for businesses is relatively low. Jobs in the secondary labour market are usually poorly paid, offer few if any benefits, and have little job security, poor prospects for advancement, and minimal unionization. Wages paid to employees make up a significant portion of the cost of products or services offered to consumers, and because of the high level of competition, businesses are obliged to keep the cost of labour to a minimum to remain competitive. Hard work does not guarantee success in the dual labour market economy, because social capital — the accumulation of a network of social relationships and knowledge that will provide a platform from which to achieve financial success — in the form of connections or higher education are often required to access the high-paying jobs. Increasingly, we are realizing intelligence and hard work are not enough. If you lack knowledge of how to leverage the right names, connections, and players, you are unlikely to experience upward mobility. Particularly in the knowledge economy, which generates a new dual labour market between jobs that require high levels of education (scientists, programmers, designers, etc.) and support jobs (secretarial, data entry, technicians, etc.), social capital in the form of formal education is a condition for accessing quality jobs. The division between those who are able to access, create, utilize, and disseminate knowledge and those who cannot is often referred to as the knowledge divide . With so many jobs being outsourced or eliminated by automation, what kinds of jobs is there a demand for in Canada? While manufacturing jobs are in decline and fishing and agriculture are static, several job markets are expanding. These include resource extraction, computer and information services, professional business services, health care and social assistance, and accommodation and food services. Figure 18.11, from Employment and Social Development Canada, illustrates areas of projected growth. Figure 18.11. This chart shows the projected growth of several occupational groups. (Graph courtesy of the Employment and Social Development Canada (Labour Market Research and Forecasting Policy Research Directorate 2011a) available from The Canadian Government allows this graph to be used in whole or part for non-commercial purposes in any format ( Professional and related jobs, which include any number of positions, typically require significant education and training and tend to be lucrative career choices. Service jobs, according to Employment and Social Development Canada, can include everything from consumer service jobs such as scooping ice cream, to producer service jobs that contract out administrative or technical support, to government service jobs including teachers and bureaucrats (Labour Market Research and Forecasting Policy Research Directorate, 2011b). There is a wide variety of training needed, and therefore an equally large wage potential discrepancy. One of the largest areas of growth by industry, rather than by occupational group (as seen above), is in the health field (Labour Market Research and Forecasting Policy Research Directorate, 2011a). This growth is across occupations, from associate-level nurse’s aides to management-level assisted-living staff. As baby boomers age, they are living longer than any generation before, and the growth of this population segment requires an increase in capacity throughout our country’s elder care system, from home health care nursing to geriatric nutrition. Notably, jobs in manufacturing are in decline. This is an area where those with less education traditionally could be assured of finding steady, if low-wage, work. With these jobs disappearing, more and more workers will find themselves untrained for the types of employment that are available. Another projected trend in employment relates to the level of education and training required to gain and keep a job. As Figure 18.12 shows, growth rates are higher for those with more education. It is estimated that between 2011 and 2020, there will be 6.5 million new job openings due to economic growth or retirement, two-thirds of which will be in occupations that require post-secondary education (“PSE” in the chart) or in management positions (Labour Market Research and Forecasting Policy Research Directorate, 2011a). 70% of new jobs created through economic growth are projected to be in management or occupations that require post-secondary education. Those with a university degree may expect job growth of 21.3%, and those with a college degree or apprenticeship 34.3%. At the other end of the spectrum, jobs that require a high school diploma or equivalent are projected to grow at only 24.9%, while jobs that require less than a high school diploma will grow at 8.6%. Quite simply, without a degree, it will be more difficult to find a job. It is worth noting that these projections are based on overall growth across all occupation categories, so obviously there will be variations within different occupational areas. Seven out of the ten occupations with the highest proportion of job openings are in management and the health sector. However, once again, those who are the least educated will be the ones least able to fulfill the Canadian dream. Figure 18.12. More education generally means more jobs. (Graph courtesy of the Social Development Canada (Labour Market Research and Forecasting Policy Research Directorate, 2011a)) available from The Canadian Government allows this graph to be used in whole or part for non-commercial purposes in any format ( Women in the Workforce In the past, rising education levels in Canada were able to keep pace with the rise in the number of education-dependent jobs. Since the late 1970s, men have been enrolling in university at a lower rate than women, and graduating at a rate of almost 10% less (Wang and Parker, 2011). In 2008, 62% of undergraduate degrees and 54% of graduate degrees were granted to women (Drolet, 2011). The lack of male candidates reaching the education levels needed for skilled positions has opened opportunities for women and immigrants. Women have been entering the workforce in ever-increasing numbers for several decades. Their increasingly higher levels of education attainment than men has resulted in many women being better positioned to obtain high-paying, high-skill jobs. Between 1991 and 2011, the percentage of employed women between the ages of 25 and 34 with a university degree increased from 19% to 40%, whereas among employed men aged 25 to 34 the percentage increased from 17% to 27%. It is interesting to note however that at least 20% of all women with a university degree were still employed in the same three occupations as they were in 1991: registered nurses, elementary school and kindergarten teachers, and secondary school teachers. The top three occupations for university-educated men (11% of this group) were computer programmers and interactive media developers, financial auditors and accountants, and secondary school teachers (Uppal and LaRochelle-Côté, 2014). While women are getting more and better jobs and their wages are rising more quickly than men’s wages are, Statistics Canada data show that they are still earning only 76% of what men are for the same positions. However when the wages of young women aged 25 to 29 are compared to young men in the same age cohort, the women now earn 90% of young men’s hourly wage (Statistics Canada, 2011). Immigration and the Workforce Simply put, people will move from where there are few or no jobs to places where there are jobs, unless something prevents them from doing so. The process of moving to a country is called immigration. Canada has long been a destination for workers of all skill levels. While the rate decreased somewhat during the economic slowdown of 2008, immigrants, both legal and illegal, continue to be a major part of the Canadian workforce. In 2006, before the recession arrived, immigrants made up 19.9% of the workforce, up from 19 percent in 1996 (Kustec, 2012). The economic downturn affected them disproportionately. In 2008, employment rates were at the peak for both native-born Canadians (84.1%) and immigrants (77.4%). In 2009, these figures dropped to 82.2% and 74.9% respectively, meaning that the gap in employment rates increased to 7.3 percentage points from 6.7. The gap was greater between native-born and very recent immigrants (18.6 percentage points in 2009, compared with a gap of 17.5 points in 2008) (Yssaad, 2012). Interestingly, in the United States, this trend was reversed.  The unemployment rate decreased for immigrant workers and increased for native workers (Kochhar, 2010). This no doubt did not help to reduce tensions in that country about levels of immigration, particularly illegal immigration. Figure 18.13. Landings of permanent residents intending to work by skill level, 1980-2011 (Graph courtesy of Citizenship &amp; Immigration Canada (Kustec, 2012)). This graph is a reproduction of an official work that is published by the Government of Canada and that has not been produced in affiliation with, or with the endorsement of the Government of Canada. This graph may be used in part or whole for non-commercial purposes without further permissions. Recent political debate about the Temporary Foreign Worker Program has been fuelled by conversations about low-skilled service industry jobs being taken by low-earning foreign workers (Mas, 2014). It should be emphasized that a substantial portion of working-age immigrants (i.e., not temporary workers) landing in Canada are highly educated and highly skilled (Figure 18.13). They play a significant role in filling skilled positions that open up through both job creation and retirement. About half of the landed immigrants identify an occupational skill, 80 to 90% of which fall within the higher skill level classifications. Of the other 50% of landed immigrants who intend to work but do not indicate a specific occupational skill, most have recently completed school and are new to the labour market, or have landed under the family class or as refugees — classes which are not coded by occupation (Kustec, 2012). Poverty in Canada When people lose their jobs during a recession or in a changing job market, it takes longer to find a new one, if they can find one at all. If they do, it is often at a much lower wage or not full time. This can force people into poverty. In Canada, we tend to have what is called relative poverty, defined as being unable to live the lifestyle of the average person in your country. This must be contrasted with the absolute poverty that can be found in underdeveloped countries, defined as being barely able, or unable, to afford basic necessities such as food (Byrns, 2011). We cannot even rely on unemployment statistics to provide a clear picture of total unemployment in Canada. First, unemployment statistics do not take into account underemployment , a state in which people accept lower-paying, lower-status jobs than their education and experience qualifies them to perform. Second, unemployment statistics only count those: who are actively looking for work who have not earned income from a job in the past four weeks who are ready, willing, and able to work The unemployment statistics provided by Statistics Canada are rarely accurate, because many of the unemployed become discouraged and stop looking for work. Not only that, but these statistics undercount the youngest and oldest workers, the chronically unemployed (e.g., homeless), and seasonal and migrant workers. A certain amount of unemployment is a direct result of the relative inflexibility of the labour market, considered structural unemployment , which describes when there is a societal level of disjuncture between people seeking jobs and the available jobs. This mismatch can be geographic (they are hiring in Alberta, but the highest rates of unemployment are in Newfoundland and Labrador), technological (skilled workers are replaced by machines, as in the auto industry), or can result from any sudden change in the types of jobs people are seeking versus the types of companies that are hiring. Because of the high standard of living in Canada, many people are working at full-time jobs but are still poor by the standards of relative poverty. They are the working poor. Canada has a higher percentage of working poor than many other developed countries (Brady, Fullerton, and Cross, 2010). In terms of employment, Statistics Canada defines the working poor as those who worked for pay at least for at least 910 hours during the year, and yet remain below the poverty line according to the Market Basket Measure (i.e., they lack the disposable income to purchase a specified “basket” of basic goods and services). Many of the facts about the working poor are as expected: those who work only part time are more likely to be classified as working poor than those with full-time employment; higher levels of education lead to less likelihood of being among the working poor; and those with children under 18 are four times more likely than those without children to fall into this category. In 2011, 6.4% of Canadians of all ages lived in households classified as working poor (Employment and Social Development Canada, 2011). Figure 18.14. A higher percentage of the people living in poverty in Canada and the United States have jobs compared to other developed nations. Figure 18.15. Poverty rates for children: 1976 to 2008. [Long Description] (Graph courtesy of the Canadian Centre for Policy Alternatives (Yalnizyan, 2010)) used with a CC-BY-NC-ND 3.0 Unported license ( Figure 18.16. Poverty rates for seniors: 1976 to 2008. (Graph courtesy of the Canadian Centre for Policy Alternatives (Yalnizyan, 2010)) used with a CC-BY-NC-ND 3.0 Unported license ( Most developed countries such as Canada protect their citizens from absolute poverty by providing different levels of social services such as employment insurance, welfare, health care, and so on. They may also provide job training and retraining so that people can re-enter the job market. In the past, the elderly were particularly vulnerable to falling into poverty after they stopped working; however, the Canada and Quebec Pension Plans, the Old Age Security program, and the Guaranteed Income Supplement are credited with successfully reducing old age poverty. A major concern in Canada is the number of young people growing up in poverty, although these numbers have been declining as well. About 606,000 children younger than 18 lived in low-income families in 2008. The proportion of children in low-income families was 9% in 2008, half the 1996 peak of 18% (Statistics Canada, 2011). Growing up poor can cut off access to the education and services people need to move out of poverty and into stable employment. As we saw, more education was often a key to stability, and those raised in poverty are the ones least able to find well-paying work, perpetuating a cycle. With the shift to neoliberal economic policies, there has been greater debate about how much support local, provincial, and federal governments should give to help the unemployed and underemployed. Often the issue is presented as one in which the interests of “taxpayers” are opposed to the “welfare state.” It is interesting to note that in social democratic countries like Norway, Finland, and Sweden, there is much greater acceptance of higher tax rates when these are used to provide universal health care, education, child care, and other forms of social support than there is in Canada. Nevertheless, the decisions made on these issues have a profound effect on working in Canada. Key Terms alienation: The condition in which an individual is isolated from their society, work, or the sense of self and common humanity. automation: Workers being replaced by technology. bartering: When people exchange one form of goods or services for another. capitalism: An economic system based on private ownership of property or capital, competitive markets, wage labour, and the impetus to produce profit and accumulate private wealth. career inheritance: When children tend to enter the same or similar occupation as their parents. commodities: Goods produced for sale on the market. convergence theory: A sociological theory to explain how and why societies move toward similarity over time as their economies develop. depression: A sustained recession across several economic sectors. dual labour market: The division of the economy into high-wage and low-wage sectors. economy: The social institution through which a society’s resources (goods and services) are managed. goods: Physical objects we find, grow, or make to meet our needs and those of others. knowledge divide: The division between those who are able to access, create, utilize, and disseminate knowledge and those who cannot. market socialism: A subtype of socialism that adopts certain traits of capitalism, like allowing limited private ownership or consulting market demand. mercantilism: An economic policy based on national policies of accumulating silver and gold by controlling markets with colonies and other countries through taxes and customs charges. modernization theory: A theory of economic development that proposes that there are natural stages of economic development that all societies go through from undeveloped to advanced. money: An object that a society agrees to assign a value to so it can be exchanged as payment. mutualism: A form of socialism under which individuals and cooperative groups exchange products with one another on the basis of mutually satisfactory contracts. outsourcing: When jobs are contracted to an outside source, often in another country. polarization: When the differences between low-end and high-end jobs becomes greater and the number of people in the middle levels decreases. recession: When there are two or more consecutive quarters of economic decline. services: Activities that benefit people, such as health care, education, and entertainment. social capital: The accumulation of a network of social relationships and knowledge that will provide a platform from which to achieve financial success. socialism: An economic system in which there is government ownership (often referred to as “state run”) of goods and their production, with an impetus to share work and wealth equally among the members of a society. structural unemployment: When there is a societal level of disjuncture between people seeking jobs and the jobs that are available. subsistence farming: When farmers grow only enough to feed themselves and their families. underemployment: A state in which a person accepts a lower-paying, lower-status job than their education and experience qualifies them to perform. usufruct: The distribution of resources according to need. Section Summary 18.1. Economic Systems Economy refers to the social institution through which a society’s resources (goods and services) are managed. The Agricultural Revolution led to development of the first economies that were based on trading goods. Mechanization of the manufacturing process led to the Industrial Revolution and gave rise to two major competing economic systems. Under capitalism, private owners invest their capital and that of others to produce goods and services they can sell in an open market. Prices and wages are set by supply and demand and competition. Under socialism, the means of production is commonly owned, and the economy is controlled centrally by government. Several countries’ economies exhibit a mix of both systems. Convergence theory seeks to explain the correlation between a country’s level of development and changes in its economic structure. 18.2. Work in Canada The job market in Canada is meant to be a meritocracy that creates social stratifications based on individual achievement. Economic forces, such as outsourcing and automation, are polarizing the workforce, with most job opportunities being either low-level, low-paying manual jobs or high-level, high-paying jobs based on abstract skills. Women’s role in the workforce has increased, although they have not yet achieved full equality. Immigrants play an important role in the Canadian labour market. The changing economy has forced more people into poverty even if they are working. Welfare, old age pensions, and other social programs exist to protect people from the worst effects of poverty. Short Answer 18.1. Economic Systems Explain the difference between state socialism with central planning and market socialism. In what ways can capitalistic and socialistic economies converge? Describe the impact a rapidly growing economy can have on families. How do you think the Canadian economy will change as we move closer to a technology-driven service economy? 18.2. Work in Canada As polarization occurs in the Canadian job market, this will affect other social institutions. For example, if mid-level education does not lead to employment, we could see polarization in educational levels as well. Use the sociological imagination to consider what social institutions may be impacted, and how. Do you believe we have a true meritocracy in Canada? Why or why not? Further Research 18.1. Economic Systems Green jobs have the potential to improve not only your prospects of getting a good job, but the environment as well. Learn more about the green revolution in jobs : 18.2. Work in Canada The role of women in the workplace is constantly changing: The Employment Projections Program of Employment and Social Development Canada looks at a ten-year projection for jobs and employment. See some employment trends for the next decade : Global poverty is tracked by the globalissues.org website. See recent analyses and statistics about poverty : References 18.1. Economic Systems Abramovitz, Moses. (1986). Catching up, forging ahead and falling behind. Journal of Economic History, 46(2):385–406. Retrieved February 6, 2012, from Antony, James. (1998). Exploring the factors that influence men and women to form medical career aspirations. Journal of College Student Development, 39:417–426. Bond, Eric, Sheena Gingerich, Oliver Archer-Antonsen, Liam Purcell, and Elizabeth Macklem. (2003). The industrial revolution — Innovations . Retrieved February 6, 2012, from Bookchin, Murray. (1982). The ecology of freedom: The emergence and dissolution of hierarchy. Palo Alto CA: Cheshire Books. Boxall, Michael. (2006, February 9). Just don’t call it funny money. The Tyee. Retrieved July 25, 2014, from Davis, Kingsley and Wilbert Moore. (1945). Some principles of stratification. American Sociological Review, 10:242–249. Diamond, J. and P. Bellwood. (2003, April 25). Farmers and their languages: The first expansions. Science, April 25: 597-603. The Economist. (2011). Economics A-Z terms beginning with C: Catch-up Effect. The Economist.com . Retrieved February 5, 2012, from Fidrmuc, Jan. (2002). Economic reform, democracy and growth during post-communist transition. [PDF] European Journal of Political Economy, 19(30):583–604. Retrieved February 6, 2012, from Goldsborough, Reid. (2010). A case for the world’s oldest coin: Lydian Lion. World’s Oldest Coin – First Coins [Website]. Retrieved February 6, 2012, from ). Gregory, Paul R. and Robert C. Stuart. (2003). Comparing Economic Systems in the Twenty-First Century . Boston, MA: South-Western College Publishing. Greisman, Harvey C. and George Ritzer. (1981). Max Weber, critical theory, and the administered world. Qualitative Sociology, 4(1):34–55. Retrieved February 6, 2012, from  Horne, Charles F. (1915). The code of Hammurabi : Introduction . Yale University. Retrieved July 11, 2016, from Kenessey, Zoltan. (1987). The primary, secondary, tertiary and quaternary sectors of the economy. The Review of Income and Wealth, 33(4):359–386. Kerr, Clark, John T. Dunlap, Frederick H. Harbison, and Charles A. Myers. (1960). Industrialism and industrial man . Cambridge, MA: Harvard University Press. Kohn, Melvin, Atsushi Naoi, Carrie Schoenbach, Carmi Schooler, and Kazimierz Slomczynski. (1990). Position in the class structure and psychological functioning in the United States, Japan, and Poland. American Journal of Sociology, 95:964–1008. Macdonald, David. (2014, April). Outrageous fortune: Documenting Canada’s wealth gap. [PDF] Canadian Centre for Policy Alternatives.  Retrieved July 25, 2014, from Maddison, Angus. (2003). The world economy: Historical statistics . Paris: Development Centre, OECD. Retrieved February 6, 2012, from  Marx, Karl and Friedrich Engels. (1998). The communist manifesto . New York: Penguin. (Original work published 1848) Marx, Karl and Friedrich Engels. (1988). Economic and philosophic manuscripts of 1844 and the communist manifesto. (Translated by M. Milligan). New York: Prometheus Books. (Original work published 1844) Mauss, Marcel. (1990). The gift: The form and reason for exchange in archaic societies , London: Routledge. (Original work published 1922) Merton, Robert. (1968). Social theory and social structure . New York: Free Press. Proudhon, Pierre-Joseph. (2010). Property is theft! A Pierre-Joseph Proudhon anthology . Iain McKay (Ed.). Retrieved February 15, 2012, from  (Original work published 1840) Schwermer, Heidemarie. (2007). Gib und Nimm . Retrieved January 22, 2012, from  Schwermer, Heidemarie. (2011). Living without money . Retrieved January 22, 2012, from Sokoloff, Kenneth L. and Stanley L. Engerman. (2000). History lessons: Institutions, factor endowments, and paths of development in the New World. Journal of Economic Perspectives, 14(3)3:217–232. Statistics Canada. (2012, November). Canada year book 2012. Statistics Canada [PDF] Catalogue no. 11-402-XPE.  Retrieved July 25, 2012, from Sunyal, Ayda, Onur Sunyal and Fatma Yasin. (2011). A comparison of workers employed in hazardous jobs in terms of job satisfaction, perceived job risk and stress: Turkish jean sandblasting workers, dock workers, factory workers and miners. Social Indicators Research, 102:265–273. Wheaton, Sarah. (2011, September 15). Perry repeats socialist charge against Obama policies. New York Times. Retrieved January 30, 2012 from 18.2. Work in Canada Autor, David. (2010, April). The polarization of job opportunities in the U.S. labor market implications for employment and earnings. MIT Department of Economics and National Bureau of Economic Research . Retrieved February 15, 2012, from  Brady, David, Andrew Fullerton, and Jennifer Moren Cross. (2010). More than just nickels and dimes: A cross-national analysis of working poverty in affluent democracies. [PDF] Social Problems, 57:559–585. Retrieved July 12, 2016, from Drolet, Marie. (2011). Why has the gender wage gap narrowed? [PDF] Ottawa: Statistics Canada. Retrieved July 25, 2014, from Employment and Social Development Canada. (2011). Financial security – Low income incidence . Indicators of well-being in Canada. Ottawa: Employment and Social Development Canada. Retrieved July 25, 2014, from Holland, Laurence H.M. and David M. Ewalt. (2006, August 7). Making real money in virtual worlds. Forbes . Retrieved January 30, 2012, from Kochhar, Rokesh. (2010, October 29). After the great recession: Foreign born gain jobs; Native born lose jobs. Pew Hispanic Center. Retrieved January 29, 2012, from Kustec, Stan. (2012,  June). The role of migrant labour supply in the Canadian labour market. [PDF] Ottawa: Citizenship and Immigration Canada. Retrieved July 25, 2014, from Labour Market Research and Forecasting Policy Research Directorate.  (2011a). Canadian occupational projection system 2011 projections: Job openings 2011-2020. Employment and social development Canada .  Ottawa. Retrieved July 25, 2014, from Labour Market Research and Forecasting Policy Research Directorate. (2011b.) Industrial outlook – 2011-2020. Employment and social development Canada . Ottawa. Retrieved July 25, 2014, from Marx, Karl. (1977). Economic and philosophical manuscripts . In David McLellan (Ed.) , Karl Marx: Selected writings (pp. 75–112). Oxford: Oxford University Press.  (Original work published 1932) Mas, Susana. (2014, June 20). Temporary foreign worker overhaul imposes limits, hikes inspections: Cap on low-wage temporary workers to be phased in over 2 years. CBC News . Retrieved July 25, 2014, from Statistics Canada. (2011). Women in Canada: A gender based statistical report. [PDF] Ottawa: Statistics Canada. Retrieved July 25, 2014, from Uppal, Sharanjit and Sébastien LaRochelle-Côté. (2014, April). Changes in the occupational profile of young men and women in Canada. [PDF] Statistics Canada Catalogue no. 75‑006‑X. Retrieved July 25, 2014, from Wang, Wendy and Kim Parker. (2011,August 17). Women see value and benefit of College; Men lag behind on both fronts. Pew Social and Demographic Trends . Retrieved January 30, 2012, from Yalnizyan, Armine. (2010, August). The problem of poverty post-recession. [PDF] Ottawa: Canadian Centre for Policy Alternatives.  Retrieved July 25, 2014, from Yssaad, Lahouaria. (2012, December). The immigrant labour force analysis series: The Canadian immigrant labour market. [PDF] Statistics Canada Catalogue no. 71-606-X. Retrieved July 25, 2014, from   Solutions to Section Quiz 1 B, | 2 C, | 3 C, | 4 D, | 5 C, | 6 A, | 7 B, | 8 A, | 9 C, | 10 A, | 11 C, [Return to Quiz] Figure 18.5 The Toronto Stock Exchange by Paul B Toman ( used under CC BY SA 3.0 ( Long Descriptions Figure 18.15 long description: Poverty Rates for Children (Under 18) Canada, 1976 to 2008 Year Percentage 1976 13.5 1978 12.5 1980 12 1982 14 1984 16.1 1986 14 1988 12.1 1990 14 1992 15.1 1994 16.1 1996 18.2 1998 15.8 2000 14 2002 12.3 2004 13.1 2006 11.5 2008 9.1 [Return to Figure 18.15] 19 Chapter 19. The Sociology of the Body: Health and Medicine Figure 19.1. Vaccinations can slow or halt the spread of disease, but some families refuse them. (Photo courtesy of USACE Europe District/flickr) \n",
      "-----------\n",
      "18.1. Economic Systems Understand types of economic systems and their historical development.\n",
      "Describe capitalism and socialism both in theory and in practice.\n",
      "Discussion how functionalists, critical sociologists, and symbolic interactionists view the economy and work.\n",
      "18.2. Work in Canada Describe the current Canadian workforce and the trend of polarization.\n",
      "Explain how women and immigrants have impacted the modern Canadian workforce.\n",
      "Understand the basic elements of poverty in Canada today.\n",
      "--------------------------\n",
      "Human language is the most complex behaviour on the planet and, at least as far as we know, in the universe. Language involves both the ability to comprehend spoken and written words and to create communication in real time when we speak or write. Most languages are oral, generated through speaking. Speaking involves a variety of complex cognitive, social, and biological processes including operation of the vocal cords, and the coordination of breath with movements of the throat, mouth, and tongue. Other languages are sign languages, in which the communication is expressed by movements of the hands. The most common sign language is American Sign Language (ASL), commonly used in many countries across the world and adapted for use in varying countries. The other main sign language used in Canada is la Langue des Signes Québécoise (LSQ); there is also a regional dialect, Maritimes Sign Language (MSL). Although language is often used for the transmission of information (“turn right at the next light and then go straight,” “Place tab A into slot B”), this is only its most mundane function. Language also allows us to access existing knowledge, to draw conclusions, to set and accomplish goals, and to understand and communicate complex social relationships. Language is fundamental to our ability to think, and without it we would be nowhere near as intelligent as we are. Language can be conceptualized in terms of sounds, meaning, and the environmental factors that help us understand it. Phonemes are the elementary sounds of our language, morphemes are the smallest units of meaning in a language, syntax is the set of grammatical rules that control how words are put together, and contextual information is the elements of communication that are not part of the content of language but that help us understand its meaning. The Components of Language A phoneme is the smallest unit of sound that makes a meaningful difference in a language . The word “bit” has three phonemes, /b/, /i/, and /t/ (in transcription, phonemes are placed between slashes), and the word “pit” also has three: /p/, /i/, and /t/. In spoken languages, phonemes are produced by the positions and movements of the vocal tract, including our lips, teeth, tongue, vocal cords, and throat, whereas in sign languages phonemes are defined by the shapes and movement of the hands. There are hundreds of unique phonemes that can be made by human speakers, but most languages only use a small subset of the possibilities. English contains about 45 phonemes, whereas other languages have as few as 15 and others more than 60. The Hawaiian language contains only about a dozen phonemes, including five vowels (a, e, i, o, and u) and seven consonants (h, k, l, m, n, p, and w). In addition to using a different set of phonemes, because the phoneme is actually a category of sounds that are treated alike within the language, speakers of different languages are able to hear the difference only between some phonemes but not others. This is known as the categorical perception of speech sounds . English speakers can differentiate the /r/ phoneme from the /l/ phoneme, and thus “rake” and “lake” are heard as different words. In Japanese, however, /r/ and /l/ are the same phoneme, and thus speakers of that language cannot tell the difference between the word “rake” and the word “lake.” Try saying the words “cool” and “keep” out loud. Can you hear the difference between the two /k/ sounds? To English speakers they both sound the same, but to speakers of Arabic these represent two different phonemes (Figure 10.9, “Speech Sounds and Adults”). Infants are born able to understand all phonemes, but they lose their ability to do so as they get older; by 10 months of age a child’s ability to recognize phonemes becomes very similar to that of the adult speakers of the native language. Phonemes that were initially differentiated come to be treated as equivalent (Werker &amp; Tees, 2002). Figure 10.9 Speech Sounds and Adults. When adults hear speech sounds that gradually change from one phoneme to another, they do not hear the continuous change; rather, they hear one sound until they suddenly begin hearing the other. In this case, the change is from /ba/ to /pa/. Whereas phonemes are the smallest units of sound in language, a morpheme is a string of one or more phonemes that makes up the smallest units of meaning in a language . Some morphemes, such as one-letter words like “I” and “a,” are also phonemes, but most morphemes are made up of combinations of phonemes. Some morphemes are prefixes and suffixes used to modify other words. For example, the syllable “re-” as in “rewrite” or “repay” means “to do again,” and the suffix “-est” as in “happiest” or “coolest” means “to the maximum.” Syntax is the set of rules of a language by which we construct sentences . Each language has a different syntax. The syntax of the English language requires that each sentence have a noun and a verb, each of which may be modified by adjectives and adverbs. Some syntaxes make use of the order in which words appear, while others do not. In English, “The man bites the dog” is different from “The dog bites the man.” In German, however, only the article endings before the noun matter. “Der Hund beisst den Mann” means “The dog bites the man” but so does “Den Mann beisst der Hund.” Words do not possess fixed meanings but change their interpretation as a function of the context in which they are spoken. We use contextual information — the information surrounding language —to help us interpret it. Examples of contextual information include the knowledge that we have and that we know that other people have, and nonverbal expressions such as facial expressions, postures, gestures, and tone of voice. Misunderstandings can easily arise if people aren’t attentive to contextual information or if some of it is missing, such as it may be in newspaper headlines or in text messages. Examples in Which Syntax Is Correct but the Interpretation Can Be Ambiguous Grandmother of Eight Makes Hole in One Milk Drinkers Turn to Powder Farmer Bill Dies in House Old School Pillars Are Replaced by Alumni Two Convicts Evade Noose, Jury Hung Include Your Children When Baking Cookies The Biology and Development of Language Anyone who has tried to master a second language as an adult knows the difficulty of language learning. And yet children learn languages easily and naturally. Children who are not exposed to language early in their lives will likely never learn one. Case studies, including Victor the “Wild Child,” who was abandoned as a baby in France and not discovered until he was 12, and Genie, a child whose parents kept her locked in a closet from 18 months until 13 years of age, are (fortunately) two of the only known examples of these deprived children. Both of these children made some progress in socialization after they were rescued, but neither of them ever developed language (Rymer, 1993). This is also why it is important to determine quickly if a child is deaf and to begin immediately to communicate in sign language. Deaf children who are not exposed to sign language during their early years will likely never learn it (Mayberry, Lock, &amp; Kazmi, 2002). Research Focus: When Can We Best Learn Language? Testing the Critical Period Hypothesis For many years psychologists assumed that there was a critical period ( a time in which learning can easily occur ) for language learning, lasting between infancy and puberty, and after which language learning was more difficult or impossible (Lenneberg, 1967; Penfield &amp; Roberts, 1959). But later research provided a different interpretation. An important study by Jacqueline Johnson and Elissa Newport (1989) using Chinese and Korean speakers who had learned English as a second language provided the first insight. The participants were all adults who had immigrated to the United States between three and 39 years of age and who were tested on their English skills by being asked to detect grammatical errors in sentences. Johnson and Newport found that the participants who had begun learning English before they were seven years old learned it as well as native English speakers but that the ability to learn English dropped off gradually for the participants who had started later. Newport and Johnson also found a correlation between the age of acquisition and the variance in the ultimate learning of the language. While early learners were almost all successful in acquiring their language to a high degree of proficiency, later learners showed much greater individual variation. Johnson and Newport’s finding that children who immigrated before they were seven years old learned English fluently seemed consistent with the idea of a critical period in language learning. But their finding of a gradual decrease in proficiency for those who immigrated between eight and 39 years of age was not — rather, it suggested that there might not be a single critical period of language learning that ended at puberty, as early theorists had expected, but that language learning at later ages is simply better when it occurs earlier. This idea was reinforced in research by Hakuta, Bialystok, and Wiley (2003), who examined census records of language learning in millions of Chinese and Spanish immigrants. The census form asks respondents to describe their own English ability using one of five categories: not at all, not well, well, very well, and speak only English. The results of this research dealt another blow to the idea of the critical period, because it showed that regardless of what year was used as a cutoff point for the end of the critical period, there was no evidence for any discontinuity in language-learning potential. Rather, the results (Figure 10.10, “English Proficiency in Native Chinese Speakers”) showed that the degree of success in second-language acquisition declined steadily throughout the respondent’s life span. The difficulty of learning language as one gets older is probably due to the fact that, with age, the brain loses its plasticity — that is, its ability to develop new neural connections . Figure 10.10 English Proficiency in Native Chinese Speakers. Hakuta, Bialystok, and Wiley (2003) found no evidence for critical periods in language learning. Regardless of level of education, self-reported second-language skills decreased consistently across age of immigration. For the 90% of people who are right-handed, language is stored and controlled by the left cerebral cortex, although for some left-handers this pattern is reversed. These differences can easily be seen in the results of neuroimaging studies that show that listening to and producing language creates greater activity in the left hemisphere than in the right. Broca’s area , an area in front of the left hemisphere near the motor cortex , is responsible for language production (Figure 10.11, “Drawing of Brain Showing Broca’s and Wernicke’s Areas”). This area was first localized in the 1860s by the French physician Paul Broca, who studied patients with lesions to various parts of the brain. Wernicke’s area , an area of the brain next to the auditory cortex , is responsible for language comprehension. Figure 10.11 Drawing of Brain Showing Broca’s and Wernicke’s Areas. Evidence for the importance of Broca’s and Wernicke’s areas in language is seen in patients who experience aphasia , a condition in which language functions are severely impaired . People with Broca’s aphasia have difficulty producing speech, whereas people with damage to Wernicke’s area can produce speech, but what they say makes no sense and they have trouble understanding language. Learning Language Language learning begins even before birth, because the fetus can hear muffled versions of speaking from outside the womb. Moon, Cooper, and Fifer (1993) found that infants only two days old sucked harder on a pacifier when they heard their mothers’ native language being spoken than when they heard a foreign language, even when strangers were speaking the languages. Babies are also aware of the patterns of their native language, showing surprise when they hear speech that has a different patterns of phonemes than those they are used to (Saffran, Aslin, &amp; Newport, 2004). During the first year or so after birth, and long before they speak their first words, infants are already learning language. One aspect of this learning is practice in producing speech. By the time they are six to eight weeks old, babies start making vowel sounds (ooohh, aaahh, goo) as well as a variety of cries and squeals to help them practice. At about seven months, infants begin babbling , engaging in intentional vocalizations that lack specific meaning . Children babble as practice in creating specific sounds, and by the time they are one year old, the babbling uses primarily the sounds of the language that they are learning (de Boysson-Bardies, Sagart, &amp; Durand, 1984). These vocalizations have a conversational tone that sounds meaningful even though it isn’t. Babbling also helps children understand the social, communicative function of language (Figure 10.12, “Practising Language”). Children who are exposed to sign language babble in sign by making hand movements that represent real language (Petitto &amp; Marentette, 1991). Figure 10.12 Practising Language. Babies often engage in vocal exchanges to help them practise language. At the same time that infants are practising their speaking skills by babbling, they are also learning to better understand sounds and eventually the words of language. One of the first words that children understand is their own name, usually by about six months, followed by commonly used words like “bottle,” “mama,” and “doggie” by 10 to 12 months (Mandel, Jusczyk, &amp; Pisoni, 1995). The infant usually produces his or her first words at about one year of age. It is at this point that the child first understands that words are more than sounds — they refer to particular objects and ideas. By the time children are two years old, they have a vocabulary of several hundred words, and by kindergarten their vocabularies have increased to several thousand words. By Grade 5, most children know about 50,000 words and by the time they are in university, about 200,000. The early utterances of children contain many errors, for instance, confusing /b/ and /d/, or /c/ and /z/. And the words that children create are often simplified, in part because they are not yet able to make the more complex sounds of the real language (Dobrich &amp; Scarborough, 1992). Children may say “keekee” for kitty, “nana” for banana, and “vesketti” for spaghetti in part because it is easier. Often these early words are accompanied by gestures that may also be easier to produce than the words themselves. Children’s pronunciations become increasingly accurate between one and three years, but some problems may persist until school age. Most of a child’s first words are nouns, and early sentences may include only the noun. “Ma” may mean “more milk please” and “da” may mean “look, there’s Fido.” Eventually the length of the utterances increases to two words (“mo ma” or “da bark”), and these primitive sentences begin to follow the appropriate syntax of the native language. Because language involves the active categorization of sounds and words into higher level units, children make some mistakes in interpreting what words mean and how to use them. In particular, they often make overextensions of concepts, which means they use a given word in a broader context than appropriate . A child might at first call all adult men “daddy” or all animals “doggie.” Children also use contextual information, particularly the cues that parents provide, to help them learn language. Infants are frequently more attuned to the tone of voice of the person speaking than to the content of the words themselves, and are aware of the target of speech. Werker, Pegg, and McLeod (1994) found that infants listened longer to a woman who was speaking to a baby than to a woman who was speaking to another adult. Children learn that people are usually referring to things that they are looking at when they are speaking (Baldwin, 1993), and that that the speaker’s emotional expressions are related to the content of their speech. Children also use their knowledge of syntax to help them figure out what words mean. If a child hears an adult point to a strange object and say, “this is a dirb,” they will infer that a “dirb” is a thing, but if they hear them say, “this is a one of those dirb things” they will infer that it refers to the colour or other characteristic of the object. And if they hear the word “dirbing,” they will infer that “dirbing” is something that we do (Waxman, 1990). How Children Learn Language: Theories of Language Acquisition Psychological theories of language learning differ in terms of the importance they place on nature versus nurture. Yet it is clear that both matter. Children are not born knowing language; they learn to speak by hearing what happens around them. On the other hand, human brains, unlike those of any other animal, are prewired in a way that leads them, almost effortlessly, to learn language. Perhaps the most straightforward explanation of language development is that it occurs through principles of learning, including association, reinforcement, and the observation of others (Skinner, 1965). There must be at least some truth to the idea that language is learned, because children learn the language that they hear spoken around them rather than some other language. Also supporting this idea is the gradual improvement of language skills with time. It seems that children modify their language through imitation, reinforcement, and shaping, as would be predicted by learning theories. But language cannot be entirely learned. For one, children learn words too fast for them to be learned through reinforcement. Between the ages of 18 months and five years, children learn up to 10 new words every day (Anglin, 1993). More importantly, language is more generative than it is imitative. Generativity refers to the fact that speakers of a language can compose sentences to represent new ideas that they have never before been exposed to . Language is not a predefined set of ideas and sentences that we choose when we need them, but rather a system of rules and procedures that allows us to create an infinite number of statements, thoughts, and ideas, including those that have never previously occurred. When a child says that she “swimmed” in the pool, for instance, she is showing generativity. No adult speaker of English would ever say “swimmed,” yet it is easily generated from the normal system of producing language. Other evidence that refutes the idea that all language is learned through experience comes from the observation that children may learn languages better than they ever hear them. Deaf children whose parents do not speak ASL very well nevertheless are able to learn it perfectly on their own, and may even make up their own language if they need to (Goldin-Meadow &amp; Mylander, 1998). A group of deaf children in a school in Nicaragua, whose teachers could not sign, invented a way to communicate through made-up signs (Senghas, Senghas, &amp; Pyers, 2005). The development of this new Nicaraguan Sign Language has continued and changed as new generations of students have come to the school and started using the language. Although the original system was not a real language, it is becoming closer and closer every year, showing the development of a new language in modern times. The linguist Noam Chomsky is a believer in the nature approach to language, arguing that human brains contain a language acquisition device that includes a universal grammar that underlies all human language (Chomsky, 1965, 1972). According to this approach, each of the many languages spoken around the world (there are between 6,000 and 8,000) is an individual example of the same underlying set of procedures that are hardwired into human brains. Chomsky’s account proposes that children are born with a knowledge of general rules of syntax that determine how sentences are constructed. Chomsky differentiates between the deep structure of an idea — how the idea is represented in the fundamental universal grammar that is common to all languages , and the surface structure of the idea — how it is expressed in any one language . Once we hear or express a thought in surface structure, we generally forget exactly how it happened. At the end of a lecture, you will remember a lot of the deep structure (i.e., the ideas expressed by the instructor), but you cannot reproduce the surface structure (the exact words that the instructor used to communicate the ideas). Although there is general agreement among psychologists that babies are genetically programmed to learn language, there is still debate about Chomsky’s idea that there is a universal grammar that can account for all language learning. Evans and Levinson (2009) surveyed the world’s languages and found that none of the presumed underlying features of the language acquisition device were entirely universal. In their search they found languages that did not have noun or verb phrases, that did not have tenses (e.g., past, present, future), and even some that did not have nouns or verbs at all, even though a basic assumption of a universal grammar is that all languages should share these features. Bilingualism and Cognitive Development Bilingualism ( the ability to speak two languages ) is becoming more and more frequent in the modern world. Nearly one-half of the world’s population, including 17% of Canadian citizens, grows up bilingual. In Canada, education is under provincial jurisdiction; however, the federal government has been a strong supporter of establishing Canada as a bilingual country and has helped pioneer the French immersion programs in the public education systems throughout the country. In contrast, many U.S. states have passed laws outlawing bilingual education in schools based on the idea that students will have a stronger identity with the school, the culture, and the government if they speak only English, and in part based on the idea that speaking two languages may interfere with cognitive development. A variety of minority language immersion programs are now offered across the country depending on need and interest. In British Columbia, for instance, the city of Vancouver  established a new bilingual Mandarin Chinese-English immersion program in 2002 at the elementary school level in order accommodate Vancouver’s both historic and present strong ties to the Chinese-speaking world. Similar programs have been developed for both Hindi and Punjabi to serve the large South Asian cultural community in the city of Surrey. By default, most schools in British Columbia teach in English, with French immersion options available. In both English and French schools, one can study and take government exams in Japanese, Punjabi, Mandarin Chinese, French, Spanish, and German at the secondary level. Some early psychological research showed that, when compared with monolingual children, bilingual children performed more slowly when processing language, and their verbal scores were lower. But these tests were frequently given in English, even when this was not the child’s first language, and the children tested were often of lower socioeconomic status than the monolingual children (Andrews, 1982). More current research that has controlled for these factors has found that, although bilingual children may, in some cases, learn language somewhat slower than do monolingual children (Oller &amp; Pearson, 2002), bilingual and monolingual children do not significantly differ in the final depth of language learning, nor do they generally confuse the two languages (Nicoladis &amp; Genesee, 1997). In fact, participants who speak two languages have been found to have better cognitive functioning, cognitive flexibility, and analytic skills in comparison to monolinguals (Bialystok, 2009). Research (Figure 10.13, “Gray Matter in Bilinguals”) has also found that learning a second language produces changes in the area of the brain in the left hemisphere that is involved in language, such that this area is denser and contains more neurons (Mechelli et al., 2004). Furthermore, the increased density is stronger in those individuals who are most proficient in their second language and who learned the second language earlier. Thus, rather than slowing language development, learning a second language seems to increase cognitive abilities. Figure 10.13 Gray Matter in Bilinguals. Andrea Mechelli and her colleagues (2004) found that children who were bilingual had increased gray matter density (i.e., more neurons) in cortical areas related to language in comparison to monolinguals (panel a), that gray matter density correlated positively with second language proficiency (panel b) and that gray matter density correlated negatively with the age at which the second language was learned (panel c). Can Animals Learn Language? Nonhuman animals have a wide variety of systems of communication. Some species communicate using scents; others use visual displays, such as baring the teeth, puffing up the fur, or flapping the wings; and still others use vocal sounds. Male songbirds, such as canaries and finches, sing songs to attract mates and to protect territory, and chimpanzees use a combination of facial expressions, sounds, and actions, such as slapping the ground, to convey aggression (de Waal, 1989). Honeybees use a waggle dance to direct other bees to the location of food sources (von Frisch, 1956). The language of vervet monkeys is relatively advanced in the sense that they use specific sounds to communicate specific meanings. Vervets make different calls to signify that they have seen either a leopard, a snake, or a hawk (Seyfarth &amp; Cheney, 1997). Despite their wide abilities to communicate, efforts to teach animals to use language have had only limited success. One of the early efforts was made by Catherine and Keith Hayes, who raised a chimpanzee named Viki in their home along with their own children. But Viki learned little and could never speak (Hayes &amp; Hayes, 1952). Researchers speculated that Viki’s difficulties might have been in part because she could not create the words in her vocal cords, and so subsequent attempts were made to teach primates to speak using sign language or boards on which they can point to symbols. Allen and Beatrix Gardner worked for many years to teach a chimpanzee named Washoe to sign using ASL. Washoe, who lived to be 42 years old, could label up to 250 different objects and make simple requests and comments, such as “please tickle” and “me sorry” (Fouts, 1997). Washoe’s adopted daughter Loulis, who was never exposed to human signers, learned more than 70 signs simply by watching her mother sign. The most proficient nonhuman language speaker is Kanzi, a bonobo who lives at the Language Learning Center at Georgia State University (Savage-Rumbaugh &amp; Lewin, 1994). As you can see in “Video Clip: Language Recognition in Bonobos,” Kanzi has a propensity for language that is in many ways similar to humans. He learned faster when he was younger than when he got older, he learns by observation, and he can use symbols to comment on social interactions, rather than simply for food treats. Kanzi can also create elementary syntax and understand relatively complex commands. Kanzi can make tools and can even play the video game Pac-Man. The bonobo Kanzi is the most proficient known nonhuman language speaker. Watch: “Kanzi and Novel Sentences” [YouTube] : And yet even Kanzi does not have a true language in the same way that humans do. Human babies learn words faster and faster as they get older, but Kanzi does not. Each new word he learns is almost as difficult as the one before. Kanzi usually requires many trials to learn a new sign, whereas human babies can speak words after only one exposure. Kanzi’s language is focused primarily on food and pleasure and only rarely on social relationships. Although he can combine words, he generates few new phrases and cannot master syntactic rules beyond the level of about a two-year-old human child (Greenfield &amp; Savage-Rumbaugh, 1991). In sum, although many animals communicate, none of them has a true language. With some exceptions, the information that can be communicated in nonhuman species is limited primarily to displays of liking or disliking, and related to basic motivations of aggression and mating. Humans also use this more primitive type of communication, in the form of nonverbal behaviours such as eye contact, touch, hand signs, and interpersonal distance, to communicate their like or dislike for others, but they (unlike animals) also supplant this more primitive communication with language. Although other animal brains share similarities to ours, only the human brain is complex enough to create language. What is perhaps most remarkable is that although language never appears in nonhumans, language is universal in humans. All humans, unless they have a profound brain abnormality or are completely isolated from other humans, learn language. Language and Perception To this point in the chapter we have considered intelligence and language as if they are separate concepts. But what if language influences our thinking? The idea that language and its structures influence and limit human thought is called linguistic relativity . The most frequently cited example of this possibility was proposed by Benjamin Whorf (1897-1941), a linguist who was particularly interested in Aboriginal languages. Whorf argued that the Inuit people of Canada had many words for snow, whereas English speakers have only one, and that this difference influenced how the different cultures perceived snow. Whorf argued that the Inuit perceived and categorized snow in finer details than English speakers possibly could, because the English language constrained perception. Although the idea of linguistic relativism seemed reasonable, research has suggested that language has less influence on thinking than might be expected. For one, in terms of perceptions of snow, although it is true that the Inuit do make more distinctions among types of snow than English speakers do, the latter also make some distinctions (think powder, slush, whiteout, and so forth). And it is also possible that thinking about snow may influence language, rather than the other way around. In a more direct test of the possibility that language influences thinking, Eleanor Rosch (1973) compared people from the Dani culture of New Guinea, who have only two terms for colour (dark and bright), with English speakers who use many more terms. Rosch hypothesized that if language constrains perception and categorization, then the Dani should have a harder time distinguishing colours than English speakers would. But her research found that when the Dani were asked to categorize colours using new categories, they did so in almost the same way that English speakers did. Similar results were found by Frank, Everett, Fedorenko, and Gibson (2008), who showed that the Amazonian tribe known as the Pirahã, who have no linguistic method for expressing exact quantities (not even the number one), were nevertheless able to perform matches with large numbers without problem. Although these data led researchers to conclude that the language we use to describe colour and number does not influence our underlying understanding of the underlying sensation, another more recent study has questioned this assumption. Roberson, Davies, and Davidoff (2000) conducted another study with Dani participants and found that, at least for some colours, the names that they used to describe colours did influence their perceptions of the colours. Other researchers continue to test the possibility that our language influences our perceptions, and perhaps even our thoughts (Levinson, 1998), and yet the evidence for this possibility is, as of now, mixed. Key Takeaways Language involves both the ability to comprehend spoken and written words and to speak and write. Some languages are sign languages, in which the communication is expressed by movements of the hands. Phonemes are the elementary sounds of our language, morphemes are the smallest units of meaningful language, syntax is the grammatical rules that control how words are put together, and contextual information is the elements of communication that help us understand its meaning. Recent research suggests that there is not a single critical period of language learning, but that language learning is simply better when it occurs earlier. Broca’s area is responsible for language production. Wernicke’s area is responsible for language comprehension. Language learning begins even before birth. An infant usually produces his or her first words at about one year of age. One explanation of language development is that it occurs through principles of learning, including association, reinforcement, and the observation of others. Noam Chomsky argues that human brains contain a language acquisition module that includes a universal grammar that underlies all human language. Chomsky differentiates between the deep structure and the surface structure of an idea. Although other animals communicate and may be able to express ideas, only the human brain is complex enough to create real language. Our language may have some influence on our thinking, but it does not affect our underlying understanding of concepts. What languages do you speak? Did you ever try to learn a new one? What problems did you have when you did this? Would you consider trying to learn a new language? Some animals, such as Kanzi, display at least some language. Do you think that this means that they are intelligent? References Andrews, I. (1982). Bilinguals out of focus: A critical discussion. International Review of Applied Linguistics in Language Teaching, 20 (4), 297–305. Anglin, J. M. (1993). Vocabulary development: A morphological analysis. Monographs of the Society for Research in Child Development, 58 (10), v–165. Baldwin, D. A. (1993). Early referential understanding: Infants’ ability to recognize referential acts for what they are. Developmental Psychology, 29 (5), 832–843. Bialystok, E. (2009). Bilingualism: The good, the bad, and the indifferent. Bilingualism: Language and Cognition, 12 (1), 3–11. Chomsky, N. (1965). Aspects of the theory of syntax . Cambridge, MA: MIT Press. Chomsky, N. (1972). Language and mind (Extended ed.). New York, NY: Harcourt, Brace &amp; Jovanovich. de Boysson-Bardies, B., Sagart, L., &amp; Durand, C. (1984). Discernible differences in the babbling of infants according to target language. Journal of Child Language, 11 (1), 1–15. de Waal, F. (1989). Peacemaking among primates . Cambridge, MA: Harvard University Press. Dobrich, W., &amp; Scarborough, H. S. (1992). Phonological characteristics of words young children try to say. Journal of Child Language, 19 (3), 597–616. Evans, N., &amp; Levinson, S. C. (2009). The myth of language universals: Language diversity and its importance for cognitive science. Behavioral and Brain Sciences, 32 (5), 429–448. Fouts, R. (1997). Next of kin: What chimpanzees have taught me about who we are . New York, NY: William Morrow. Frank, M. C., Everett, D. L., Fedorenko, E., &amp; Gibson, E. (2008). Number as a cognitive technology: Evidence from Pirahã language and cognition. Cognition, 108 (3), 819–824. Goldin-Meadow, S., &amp; Mylander, C. (1998). Spontaneous sign systems created by deaf children in two cultures. Nature, 391 (6664), 279–281. Greenfield, P. M., &amp; Savage-Rumbaugh, E. S. (1991). Imitation, grammatical development, and the invention of protogrammar by an ape. In N. A. Krasnegor, D. M. Rumbaugh, R. L. Schiefelbusch, &amp; M. Studdert-Kennedy (Eds.), Biological and behavioral determinants of language development (pp. 235–258). Hillsdale, NJ: Lawrence Erlbaum Associates. Hakuta, K., Bialystok, E., &amp; Wiley, E. (2003). Critical evidence: A test of the critical-period hypothesis for second-language acquisition. Psychological Science, 14 (1), 31–38. Hayes, K. J., and Hayes, C. (1952). Imitation in a home-raised chimpanzee. Journal of Comparative and Physiological Psychology, 45, 450–459. Johnson, J. S., &amp; Newport, E. L. (1989). Critical period effects in second language learning: The influence of maturational state on the acquisition of English as a second language. Cognitive Psychology, 21 (1), 60–99. Lenneberg, E. (1967). Biological foundations of language . New York, NY: John Wiley &amp; Sons. Levinson, S. C. (1998). Studying spatial conceptualization across cultures: Anthropology and cognitive science. Ethos, 26 (1), 7–24. Mandel, D. R., Jusczyk, P. W., &amp; Pisoni, D. B. (1995). Infants’ recognition of the sound patterns of their own names. Psychological Science, 6 (5), 314–317. Mayberry, R. I., Lock, E., &amp; Kazmi, H. (2002). Development: Linguistic ability and early language exposure. Nature, 417 (6884), 38. Mechelli, A., Crinion, J. T., Noppeney, U., O’Doherty, J., Ashburner, J., Frackowiak, R. S., &amp; Price C. J. (2004). Structural plasticity in the bilingual brain: Proficiency in a second language and age at acquisition affect grey-matter density. Nature, 431 , 757. Moon, C., Cooper, R. P., &amp; Fifer, W. P. (1993). Two-day-olds prefer their native language. Infant Behavior &amp; Development, 16 (4), 495–500. Nicoladis, E., &amp; Genesee, F. (1997). Language development in preschool bilingual children. Journal of Speech-Language Pathology and Audiology, 21 (4), 258–270. Oller, D. K., &amp; Pearson, B. Z. (2002). Assessing the effects of bilingualism: A background. In D. K. Oller &amp; R. E. Eilers (Eds.), Language and literacy in bilingual children (pp. 3–21). Tonawanda, NY: Multilingual Matters. Penfield, W., &amp; Roberts, L. (1959). Speech and brain mechanisms . Princeton, NJ: Princeton University Press. Petitto, L. A., &amp; Marentette, P. F. (1991). Babbling in the manual mode: Evidence for the ontogeny of language. Science, 251 (5000), 1493–1496. Roberson, D., Davies, I., &amp; Davidoff, J. (2000). Color categories are not universal: Replications and new evidence from a stone-age culture. Journal of Experimental Psychology: General, 129 (3), 369–398. Rosch, E. H. (1973). Natural categories. Cognitive Psychology, 4 (3), 328–350. Rymer, R. (1993). Genie: An abused child’s flight from silence . New York, NY: HarperCollins. Saffran, J. R., Aslin, R. N., &amp; Newport, E. L. (2004). Statistical learning by 8-month-old infants . New York, NY: Psychology Press. Savage-Rumbaugh, S., &amp; Lewin, R. (1994). Kanzi: The ape at the brink of the human mind . Hoboken, NJ: John Wiley &amp; Sons. Senghas, R. J., Senghas, A., &amp; Pyers, J. E. (2005). The emergence of Nicaraguan Sign Language: Questions of development, acquisition, and evolution. In S. T. Parker, J. Langer, &amp; C. Milbrath (Eds.), Biology and knowledge revisited: From neurogenesis to psychogenesis (pp. 287–306). Mahwah, NJ: Lawrence Erlbaum Associates. Seyfarth, R. M., &amp; Cheney, D. L. (1997). Behavioral mechanisms underlying vocal communication in nonhuman primates. Animal Learning &amp; Behavior, 25 (3), 249–267. Skinner, B. F. (1965). Science and human behavior. New York, NY: Free Press. von Frisch, K. (1956). Bees: Their vision, chemical senses, and language . Ithaca, NY: Cornell University Press. Waxman, S. R. (1990). Linguistic biases and the establishment of conceptual hierarchies: Evidence from preschool children. Cognitive Development, 5 (2), 123–150. Werker, J. F., &amp; Tees, R. C. (2002). Cross-language speech perception: Evidence for perceptual reorganization during the first year of life. Infant Behavior &amp; Development, 25 (1), 121–133. Werker, J. F., Pegg, J. E., &amp; McLeod, P. J. (1994). A cross-language investigation of infant preference for infant-directed communication. Infant Behavior &amp; Development, 17 (3), 323–333. Wood, C. C. (1976). Discriminability, response bias, and phoneme categories in discrimination of voice onset time. Journal of the Acoustical Society of America , 60(6), 1381–1389. Figure 10.9: Adapted from Wood, 1976. Figure 10.10: Adapted from Hakuta, Bialystok, &amp; Wiley, 2003. Figure 10.12: “ on the phone to mama ” by Lars Plougmann ( is licensed under CC BY-SA 2.0 license ( Figure 10.13: Adapted from Mechelli, et al., 2004. 56 10.4 Chapter Summary Intelligence — the ability to think, to learn from experience, to solve problems, and to adapt to new situations — is more strongly related than any other individual difference variable to successful educational, occupational, economic, and social outcomes. The French psychologist Alfred Binet and his colleague Henri Simon developed the first intelligence test in the early 1900s. Charles Spearman called the construct that the different abilities and skills measured on intelligence tests have in common the general intelligence factor, or simply “g.” There is also evidence for specific intelligences (s), measures of specific skills in narrow domains. Robert Sternberg has proposed a triarchic (three-part) theory of intelligence, and Howard Gardner has proposed that there are eight different specific intelligences. Good intelligence tests both are reliable and have construct validity. Intelligence tests are the most accurate of all psychological tests. IQ tests are standardized, which allows calculation of mental age and the intelligence quotient (IQ), The Wechsler Adult lntelligence Scale (WAIS) is the most widely used intelligence test for adults. Other intelligence tests include aptitude tests such as the Graduate Record Examination (GRE), and structured tests used for personnel selection. People with higher IQs have somewhat larger brains, which operate more efficiently and faster than the brains of the less intelligent. Although intelligence is not located in a specific part of the brain, it is more prevalent in some brain areas than others. Intelligence has both genetic and environmental causes, and between 40% and 80% of the variability in IQ is heritable. Social and economic deprivation, including poverty, can adversely affect IQ, and intelligence is improved by education. Emotional intelligence refers to the ability to identify, assess, manage, and control one’s emotions. However, tests of emotional intelligence are often unreliable, and emotional intelligence may be a part of a skill that can be applied in some specific work situations. About 3% of the population score above an IQ of 130 (the threshold for giftedness), and about the same percentage score below an IQ of 70 (the threshold for intellectual disability). Males are about 20% more common in these extremes than are women. Women and men show overall equal intelligence, but there are sex differences on some types of tasks. There are also differences in which members of different racial and ethnic groups cluster along the IQ line. The causes of these differences are not completely known. These differences have at times led to malicious, misguided, and discriminatory attempts to try to correct for them, such as eugenics. Language involves both the ability to comprehend spoken and written words and to create communication in real time when we speak or write. Language can be conceptualized in terms of sounds (phonemes), meaning (morphemes and syntax), and the environmental factors that help us understand it (contextual information). Language is best learned during the critical period between three and seven years of age. Broca’s area, an area of the brain in front of the left hemisphere near the motor cortex, is responsible for language production, and Wernicke’s area, an area of the brain next to the auditory cortex, is responsible for language comprehension. Children learn language quickly and naturally, progressing through stages of babbling, first words, first sentences, and then a rapid increase in vocabulary. Children often make overextensions of concepts. Some theories of language learning are based on principles of learning. Noam Chomsky argues that human brains contain a language acquisition device that includes a universal grammar that underlies all human language and that allows generativity. Chomsky differentiates between the deep structure and the surface structure of an idea. Bilingualism is becoming more and more frequent in the modern world. Bilingual children may show more cognitive function and flexibility than monolingual children do. Nonhuman animals have a wide variety of systems of communication. But efforts to teach animals to use human language have had only limited success. Although many animals communicate, none of them has a true language. XI Chapter 11. Emotions and Motivations 57 11. Emotions and Motivations Grace under Pressure On June 27, 2014, 13-year-old Gavin England saved his grandfather from drowning when their prawning boat took on water and sank off the Saanich Peninsula on Vancouver Island (CTV, 2014). Gavin’s grandfather Vern was not a strong swimmer, and though both were wearing life jackets, they would not have survived for long in the cold Pacific ocean waters 300 meters from shore. Gavin recounted the event, explaining how he suffered sharp cuts to his bare feet when climbing the embankment where he had dragged his grandfather. He attributed his ability to overcome the pain of the cuts to adrenalin. Upon finding an old truck with keys in the ignition, and despite the high emotions he was experiencing, he then had the wherewithal to learn to drive on the spot and make it up a three-kilometer hill to get help. Gavin explained that his knowledge of driving a dirt bike served him well: “I knew that clutch in meant drive.” Vern described the young boy as “tenacious” and calm throughout the event. He was giving his grandfather words of encouragement as he pulled him to shore. Stories such as Gavin’s are rare and unpredictable. We hope we will act with the same clear-headed tenacity in emergency situations, but the heroic response is not assured. Gavin’s ability to abate panic, and recognize and regulate his emotions was central to his actions in this emergency situation. The topic of this chapter is affect , defined as the experience of feeling or emotion . Affect is an essential part of the study of psychology because it plays such an important role in everyday life. As we will see, affect guides behaviour, helps us make decisions, and has a major impact on our mental and physical health. The two fundamental components of affect are emotions and motivation . Both of these words have the same underlying Latin root, meaning “to move.” In contrast to cognitive processes that are calm, collected, and frequently rational, emotions and motivations involve arousal , or our experiences of the bodily responses created by the sympathetic division of the autonomic nervous system (ANS) . Because they involve arousal, emotions and motivations are “hot” — they “charge,” “drive,” or “move” our behaviour. When we experience emotions or strong motivations, we feel the experiences. When we become aroused, the sympathetic nervous system provides us with energy to respond to our environment. The liver puts extra sugar into the bloodstream, the heart pumps more blood, our pupils dilate to help us see better, respiration increases, and we begin to perspire to cool the body. The stress hormones epinephrine and norepinephrine are released. We experience these responses as arousal. American pilot Captain”Sully” Sullenberger  (Figure 11.1, “Captain Sullenberger and His Plane on the Hudson River”) was 915 metres up in the air when the sudden loss of power in his airplane put his life, as well as the lives of 150 passengers and crew members, in his hands. Both of the engines on flight 1539 had shut down, and his options for a safe landing were limited. Sully kept flying the plane and alerted the control tower to the situation: “This is Cactus 1539…hit birds. We lost thrust in both engines. We’re turning back toward La Guardia.” When the tower gave him the compass setting and runway for a possible landing, Sullenberger’s extensive experience allowed him to give a calm response: “I’m not sure if we can make any runway…Anything in New Jersey?” Captain Sullenberger was not just any pilot in a crisis, but a former U.S. Air Force fighter pilot with 40 years of flight experience. He had served both as a flight instructor and the safety chairman for the Airline Pilots Association. Training had quickened his mental processes in assessing the threat, allowing him to maintain what tower operators later called an “eerie calm.” He knew the capabilities of his plane. When the tower suggested a runway in New Jersey, Sullenberger calmly replied: “We’re unable. We may end up in the Hudson.” Figure 11.1 Captain Sullenberger and His Plane on the Hudson River. Imagine that you are on a plane that you know is going to crash. What emotions would you experience, and how would you respond to them? Would the rush of fear cause you to panic, or could you control your emotions like Captain Sullenberger did, as he calmly calculated the heading, position, thrust, and elevation of the plane, and then landed it on the Hudson River? The last communication from Captain Sullenberger to the tower advised of the eventual outcome: “We’re going to be in the Hudson.” He calmly set the plane down on the water. Passengers reported that the landing was like landing on a rough runway. The crew kept the passengers calm as women, children, and then the rest of the passengers were evacuated onto the rescue boats that had quickly arrived. Captain Sullenberger then calmly walked the aisle of the plane to be sure that everyone was out before joining the 150 other rescued survivors (Levin, 2009; National Transportation Safety Board, 2009). Some called it “grace under pressure,” and others called it the “miracle on the Hudson.” But psychologists see it as the ultimate in emotion regulation — the ability to control and productively use one’s emotions. An emotion is a mental and physiological feeling state that directs our attention and guides our behaviour . Whether it is the thrill of a roller-coaster ride that elicits an unexpected scream, the flush of embarrassment that follows a public mistake, or the horror of a potential plane crash that creates an exceptionally brilliant response in a pilot, emotions move our actions. Emotions normally serve an adaptive role: We care for infants because of the love we feel for them, we avoid making a left turn onto a crowded highway because we fear that a speeding truck may hit us, and we are particularly nice to Mandy because we are feeling guilty that we did not go to her party. But emotions may also be destructive, such as when a frustrating experience leads us to lash out at others who do not deserve it. The Surrey School District in British Columbia has incorporated “emotional regulation” into the curriculum (Wells, 2013). In six schools, educators are piloting a program that helps teachers look for what may be stressing children, making them unable to  pay attention, lethargic, hyperactive, or out of control. The children may be impacted by too much noise in the classroom, too little sleep, or too much junk food in their lunch. The teachers help the children recognize what they need to do to make themselves calm and productive in class. The program ultimately places the motivation for behavioural control within the hands of the children. Motivations are closely related to emotions. A motivation is a driving force that initiates and directs behaviour . Some motivations are biological, such as the motivation for food, water, and sex. But there are a variety of other personal and social motivations that can influence behaviour, including the motivations for social approval and acceptance, the motivation to achieve, and the motivation to take, or to avoid taking, risks (Morsella, Bargh, &amp; Gollwitzer, 2009). In each case we follow our motivations because they are rewarding. As predicted by basic theories of operant learning, motivations lead us to engage in particular behaviours because doing so makes us feel good. Motivations are often considered in psychology in terms of drives , which are internal states that are activated when the physiological characteristics of the body are out of balance, and goals , which are desired end states that we strive to attain. Motivation can thus be conceptualized as a series of behavioural responses that lead us to attempt to reduce drives and to attain goals by comparing our current state with a desired end state (Lawrence, Carver, &amp; Scheier, 2002). Like a thermostat on an air conditioner, the body tries to maintain homeostasis , the natural state of the body’s systems, with goals, drives, and arousal in balance. When a drive or goal is aroused—for instance, when we are hungry—the thermostat turns on and we start to behave in a way that attempts to reduce the drive or meet the goal (in this case to seek food). As the body works toward the desired end state, the thermostat continues to check whether or not the end state has been reached. Eventually, the need or goal is satisfied (we eat), and the relevant behaviours are turned off. The body’s thermostat continues to check for homeostasis and is always ready to react to future needs. In addition to more basic motivations such as hunger, a variety of other personal and social motivations can also be conceptualized in terms of drives or goals. When the goal of studying for an exam is hindered because we take a day off from our schoolwork, we may work harder on our studying on the next day to move us toward our goal. When we are dieting, we may be more likely to have a big binge on a day when the scale says that we have met our prior day’s goals. And when we are lonely, the motivation to be around other people is aroused and we try to socialize. In many, if not most cases, our emotions and motivations operate out of our conscious awareness to guide our behaviour (Freud, 1922; Hassin, Bargh, &amp; Zimerman, 2009; Williams, Bargh, Nocera, &amp; Gray, 2009). We begin this chapter by considering the role of affect on behaviour, discussing the most important psychological theories of emotions. Then we will consider how emotions influence our mental and physical health. We will discuss how the experience of long-term stress causes illness, and then turn to research on positive thinking and what has been learned about the beneficial health effects of more positive emotions. Finally, we will review some of the most important human motivations, including the behaviours of eating and sex. The importance of this chapter is not only in helping you gain an understanding the principles of affect but also in helping you discover the important roles that affect plays in our everyday lives, and particularly in our mental and physical health. The study of the interface between affect and physical health — that principle that “everything that is physiological is also psychological” — is a key focus of the branch of psychology known as health psychology . The importance of this topic has made health psychology one of the fastest growing fields in psychology. References CTV. (2014). Heroic act (video broadcast). Toronto, ON: CTV National News . Retrieved July 24, 2014, from Freud, S. (1922). The unconscious. The Journal of Nervous and Mental Disease, 56 (3), 291. Hassin, R. R., Bargh, J. A., &amp; Zimerman, S. (2009). Automatic and flexible: The case of nonconscious goal pursuit. Social Cognition, 27 (1), 20–36. Lawrence, J. W., Carver, C. S., &amp; Scheier, M. F. (2002). Velocity toward goal attainment in immediate experience as a determinant of affect. Journal of Applied Social Psychology, 32 (4), 788–802. Levin, A. (2009, June 9). Experience averts tragedy in Hudson landing . USA Today . Retrieved from  Morsella, E., Bargh, J. A., &amp; Gollwitzer, P. M. (2009). Oxford handbook of human action . New York, NY: Oxford University Press. National Transportation Safety Board. (2009, June 9). Excerpts of Flight 1549 cockpit communications . USA Today . Retrieved from  Wells, K. (2013). Self-regulation technique helps students focus in class: Teachers try new approach to improving students’ behaviour. CBC News Posted: Nov 30, 2013 Retrieved 2014 from  Williams, L. E., Bargh, J. A., Nocera, C. C., &amp; Gray, J. R. (2009). The unconscious regulation of emotion: Nonconscious reappraisal goals modulate emotional reactivity. Emotion, 9 (6), 847–854. Figure 11.1: Sully Sullenberger by Ingrid Taylar ( used under CC BY 2.0 license ( Plane crash into Hudson River by Greg L., ( used under CC BY 2.0 license ( 58 11.1 The Experience of Emotion \n",
      "-----------\n",
      "Review the components and structure of language.\n",
      "Explain the biological underpinnings of language.\n",
      "Outline the theories of language development.\n",
      "--------------------------\n",
      "The term stress as it relates to the human condition first emerged in scientific literature in the 1930s, but it did not enter the popular vernacular until the 1970s (Lyon, 2012). Today, we often use the term loosely in describing a variety of unpleasant feeling states; for example, we often say we are stressed out when we feel frustrated, angry, conflicted, overwhelmed, or fatigued. Despite the widespread use of the term, stress is a fairly vague concept that is difficult to define with precision. Researchers have had a difficult time agreeing on an acceptable definition of stress. Some have conceptualized stress as a demanding or threatening event or situation (e.g., a high-stress job, overcrowding, and long commutes to work). Such conceptualizations are known as stimulus-based definitions because they characterize stress as a stimulus that causes certain reactions. Stimulus-based definitions of stress are problematic, however, because they fail to recognize that people differ in how they view and react to challenging life events and situations. For example, a conscientious student who has studied diligently all semester would likely experience less stress during final exams week than would a less responsible, unprepared student. Others have conceptualized stress in ways that emphasize the physiological responses that occur when faced with demanding or threatening situations (e.g., increased arousal). These conceptualizations are referred to as response-based definitions because they describe stress as a response to environmental conditions. For example, the endocrinologist Hans Selye , a famous stress researcher, once defined stress as the “response of the body to any demand, whether it is caused by, or results in, pleasant or unpleasant conditions” (Selye, 1976, p. 74). Selye’s definition of stress is response-based in that it conceptualizes stress chiefly in terms of the body’s physiological reaction to any demand that is placed on it. Neither stimulus-based nor response-based definitions provide a complete definition of stress. Many of the physiological reactions that occur when faced with demanding situations (e.g., accelerated heart rate) can also occur in response to things that most people would not consider to be genuinely stressful, such as receiving unanticipated good news: an unexpected promotion or raise. A useful way to conceptualize stress is to view it as a process whereby an individual perceives and responds to events that he appraises as overwhelming or threatening to his well-being (Lazarus &amp; Folkman, 1984). A critical element of this definition is that it emphasizes the importance of how we appraise—that is, judge—demanding or threatening events (often referred to as stressors ); these appraisals, in turn, influence our reactions to such events. Two kinds of appraisals of a stressor are especially important in this regard: primary and secondary appraisals. A primary appraisal involves judgment about the degree of potential harm or threat to well-being that a stressor might entail. A stressor would likely be appraised as a threat if one anticipates that it could lead to some kind of harm, loss, or other negative consequence; conversely, a stressor would likely be appraised as a challenge if one believes that it carries the potential for gain or personal growth. For example, an employee who is promoted to a leadership position would likely perceive the promotion as a much greater threat if she believed the promotion would lead to excessive work demands than if she viewed it as an opportunity to gain new skills and grow professionally. Similarly, a college student on the cusp of graduation may face the change as a threat or a challenge. Graduating from college and entering the workforce can be viewed as either a threat (loss of financial support) or a challenge (opportunity for independence and growth). (credit: Timothy Zanker) The perception of a threat triggers a secondary appraisal : judgment of the options available to cope with a stressor, as well as perceptions of how effective such options will be (Lyon, 2012). As you may recall from what you learned about self-efficacy, an individual’s belief in his ability to complete a task is important (Bandura, 1994). A threat tends to be viewed as less catastrophic if one believes something can be done about it (Lazarus &amp; Folkman, 1984). Imagine that two middle-aged women, Robin and Maria, perform breast self-examinations one morning and each woman notices a lump on the lower region of her left breast. Although both women view the breast lump as a potential threat (primary appraisal), their secondary appraisals differ considerably. In considering the breast lump, some of the thoughts racing through Robin’s mind are, “Oh my God, I could have breast cancer! What if the cancer has spread to the rest of my body and I cannot recover? What if I have to go through chemotherapy? I’ve heard that experience is awful! What if I have to quit my job? My husband and I won’t have enough money to pay the mortgage. Oh, this is just horrible…I can’t deal with it!” On the other hand, Maria thinks, “Hmm, this may not be good. Although most times these things turn out to be benign, I need to have it checked out. If it turns out to be breast cancer, there are doctors who can take care of it because the medical technology today is quite advanced. I’ll have a lot of different options, and I’ll be just fine.” Clearly, Robin and Maria have different outlooks on what might turn out to be a very serious situation: Robin seems to think that little could be done about it, whereas Maria believes that, worst case scenario, a number of options that are likely to be effective would be available. As such, Robin would clearly experience greater stress than would Maria. When encountering a stressor, a person judges its potential threat (primary appraisal) and then determines if effective options are available to manage the situation. Stress is likely to result if a stressor is perceived as extremely threatening or threatening with few or no effective coping options available. To be sure, some stressors are inherently more stressful than others in that they are more threatening and leave less potential for variation in cognitive appraisals (e.g., objective threats to one’s health or safety). Nevertheless, appraisal will still play a role in augmenting or diminishing our reactions to such events (Everly &amp; Lating, 2002). If a person appraises an event as harmful and believes that the demands imposed by the event exceed the available resources to manage or adapt to it, the person will subjectively experience a state of stress. In contrast, if one does not appraise the same event as harmful or threatening, she is unlikely to experience stress. According to this definition, environmental events trigger stress reactions by the way they are interpreted and the meanings they are assigned. In short, stress is largely in the eye of the beholder: it’s not so much what happens to you as it is how you respond (Selye, 1976). Good Stress? Although stress carries a negative connotation, at times it may be of some benefit. Stress can motivate us to do things in our best interests, such as study for exams, visit the doctor regularly, exercise, and perform to the best of our ability at work. Indeed, Selye (1974) pointed out that not all stress is harmful. He argued that stress can sometimes be a positive, motivating force that can improve the quality of our lives. This kind of stress, which Selye called eustress (from the Greek eu = “good”), is a good kind of stress associated with positive feelings, optimal health, and performance. A moderate amount of stress can be beneficial in challenging situations. For example, athletes may be motivated and energized by pregame stress, and students may experience similar beneficial stress before a major exam. Indeed, research shows that moderate stress can enhance both immediate and delayed recall of educational material. Male participants in one study who memorized a scientific text passage showed improved memory of the passage immediately after exposure to a mild stressor as well as one day following exposure to the stressor (Hupbach &amp; Fieman, 2012). Increasing one’s level of stress will cause performance to change in a predictable way. As stress increases, so do performance and general well-being (eustress); when stress levels reach an optimal level (the highest point of the curve), performance reaches its peak. A person at this stress level is colloquially at the top of his game, meaning he feels fully energized, focused, and can work with minimal effort and maximum efficiency. But when stress exceeds this optimal level, it is no longer a positive force—it becomes excessive and debilitating, or what Selye termed distress (from the Latin dis = “bad”). People who reach this level of stress feel burned out; they are fatigued, exhausted, and their performance begins to decline. If the stress remains excessive, health may begin to erode as well (Everly &amp; Lating, 2002). As the stress level increases from low to moderate, so does performance (eustress). At the optimal level (the peak of the curve), performance has reached its peak. If stress exceeds the optimal level, it will reach the distress region, where it will become excessive and debilitating, and performance will decline (Everly &amp; Lating, 2002). The Prevalence of Stress Stress is everywhere and, it has been on the rise over the last several years. Each of us is acquainted with stress—some are more familiar than others. In many ways, stress feels like a load you just can’t carry—a feeling you experience when, for example, you have to drive somewhere in a crippling blizzard, when you wake up late the morning of an important job interview, when you run out of money before the next pay period, and before taking an important exam for which you realize you are not fully prepared. Nearly half of U.S. adults indicated that their stress levels have increased over the last five years (Neelakantan, 2013). Stress is an experience that evokes a variety of responses, including those that are physiological (e.g., accelerated heart rate, headaches, or gastrointestinal problems), cognitive (e.g., difficulty concentrating or making decisions), and behavioral (e.g., drinking alcohol, smoking, or taking actions directed at eliminating the cause of the stress). Although stress can be positive at times, it can have deleterious health implications, contributing to the onset and progression of a variety of physical illnesses and diseases (Cohen &amp; Herbert, 1996). The scientific study of how stress and other psychological factors impact health falls within the realm of health psychology , a subfield of psychology devoted to understanding the importance of psychological influences on health, illness, and how people respond when they become ill (Taylor, 1999). Health psychology emerged as a discipline in the 1970s, a time during which there was increasing awareness of the role behavioral and lifestyle factors play in the development of illnesses and diseases (Straub, 2007). In addition to studying the connection between stress and illness, health psychologists investigate issues such as why people make certain lifestyle choices (e.g., smoking or eating unhealthy food despite knowing the potential adverse health implications of such behaviors). Health psychologists also design and investigate the effectiveness of interventions aimed at changing unhealthy behaviors. Perhaps one of the more fundamental tasks of health psychologists is to identify which groups of people are especially at risk for negative health outcomes, based on psychological or behavioral factors. For example, measuring differences in stress levels among demographic groups and how these levels change over time can help identify populations who may have an increased risk for illness or disease. The results of three national surveys in which several thousand individuals from different demographic groups completed a brief stress questionnaire; the surveys were administered in 1983, 2006, and 2009 (Cohen &amp; Janicki-Deverts, 2012). All three surveys demonstrated higher stress in women than in men. Unemployed individuals reported high levels of stress in all three surveys, as did those with less education and income; retired persons reported the lowest stress levels. However, from 2006 to 2009 the greatest increase in stress levels occurred among men, Whites, people aged 45–64, college graduates, and those with full-time employment. One interpretation of these findings is that concerns surrounding the 2008–2009 economic downturn (e.g., threat of or actual job loss and substantial loss of retirement savings) may have been especially stressful to White, college-educated, employed men with limited time remaining in their working careers. The charts above, adapted from Cohen &amp; Janicki-Deverts (2012), depict the mean stress level scores among different demographic groups during the years 1983, 2006, and 2009. Across categories of sex, age, race, education level, employment status, and income, stress levels generally show a marked increase over this quarter-century time span. Early Contributions to the Study of Stress As previously stated, scientific interest in stress goes back nearly a century. One of the early pioneers in the study of stress was Walter Cannon , an eminent American physiologist at Harvard Medical School. In the early part of the 20th century, Cannon was the first to identify the body’s physiological reactions to stress. Harvard physiologist Walter Cannon first articulated and named the fight-or-flight response, the nervous system’s sympathetic response to a significant stressor. Cannon and the Fight-or-Flight Response Imagine that you are hiking in the beautiful mountains of Colorado on a warm and sunny spring day. At one point during your hike, a large, frightening-looking black bear appears from behind a stand of trees and sits about 50 yards from you. The bear notices you, sits up, and begins to lumber in your direction. In addition to thinking, “This is definitely not good,” a constellation of physiological reactions begins to take place inside you. Prompted by a deluge of epinephrine (adrenaline) and norepinephrine (noradrenaline) from your adrenal glands, your pupils begin to dilate. Your heart starts to pound and speeds up, you begin to breathe heavily and perspire, you get butterflies in your stomach, and your muscles become tense, preparing you to take some kind of direct action. Cannon proposed that this reaction, which he called the fight-or-flight response , occurs when a person experiences very strong emotions—especially those associated with a perceived threat (Cannon, 1932). During the fight-or-flight response, the body is rapidly aroused by activation of both the sympathetic nervous system and the endocrine system. This arousal helps prepare the person to either fight or flee from a perceived threat. Fight or flight is a physiological response to a stressor. According to Cannon, the fight-or-flight response is a built-in mechanism that assists in maintaining homeostasis—an internal environment in which physiological variables such as blood pressure, respiration, digestion, and temperature are stabilized at levels optimal for survival. Thus, Cannon viewed the fight-or-flight response as adaptive because it enables us to adjust internally and externally to changes in our surroundings, which is helpful in species survival. Selye and the General Adaptation Syndrome Another important early contributor to the stress field was Hans Selye , mentioned earlier. He would eventually become one of the world’s foremost experts in the study of stress. As a young assistant in the biochemistry department at McGill University in the 1930s, Selye was engaged in research involving sex hormones in rats. Although he was unable to find an answer for what he was initially researching, he incidentally discovered that when exposed to prolonged negative stimulation (stressors)—such as extreme cold, surgical injury, excessive muscular exercise, and shock—the rats showed signs of adrenal enlargement, thymus and lymph node shrinkage, and stomach ulceration. Selye realized that these responses were triggered by a coordinated series of physiological reactions that unfold over time during continued exposure to a stressor. These physiological reactions were nonspecific, which means that regardless of the type of stressor, the same pattern of reactions would occur. What Selye discovered was the general adaptation syndrome , the body’s nonspecific physiological response to stress. Hans Selye specialized in research about stress. In 2009, his native Hungary honored his work with this stamp, released in conjunction with the 2nd annual World Conference on Stress. The general adaptation syndrome, consists of three stages: (1) alarm reaction, (2) stage of resistance, and (3) stage of exhaustion (Selye, 1936; 1976). Alarm reaction describes the body’s immediate reaction upon facing a threatening situation or emergency, and it is roughly analogous to the fight-or-flight response described by Cannon. During an alarm reaction, you are alerted to a stressor, and your body alarms you with a cascade of physiological reactions that provide you with the energy to manage the situation. A person who wakes up in the middle of the night to discover her house is on fire, for example, is experiencing an alarm reaction. The three stages of Selye’s general adaptation syndrome are shown in this graph. Prolonged stress ultimately results in exhaustion. If exposure to a stressor is prolonged, the organism will enter the stage of resistance . During this stage, the initial shock of alarm reaction has worn off and the body has adapted to the stressor. Nevertheless, the body also remains on alert and is prepared to respond as it did during the alarm reaction, although with less intensity. For example, suppose a child who went missing is still missing 72 hours later. Although the parents would obviously remain extremely disturbed, the magnitude of physiological reactions would likely have diminished over the 72 intervening hours due to some adaptation to this event. If exposure to a stressor continues over a longer period of time, the stage of exhaustion ensues. At this stage, the person is no longer able to adapt to the stressor: the body’s ability to resist becomes depleted as physical wear takes its toll on the body’s tissues and organs. As a result, illness, disease, and other permanent damage to the body—even death—may occur. If a missing child still remained missing after three months, the long-term stress associated with this situation may cause a parent to literally faint with exhaustion at some point or even to develop a serious and irreversible illness. In short, Selye’s general adaptation syndrome suggests that stressors tax the body via a three-phase process—an initial jolt, subsequent readjustment, and a later depletion of all physical resources—that ultimately lays the groundwork for serious health problems and even death. It should be pointed out, however, that this model is a response-based conceptualization of stress, focusing exclusively on the body’s physical responses while largely ignoring psychological factors such as appraisal and interpretation of threats. Nevertheless, Selye’s model has had an enormous impact on the field of stress because it offers a general explanation for how stress can lead to physical damage and, thus, disease. As we shall discuss later, prolonged or repeated stress has been implicated in development of a number of disorders such as hypertension and coronary artery disease. The Physiological Basis of Stress What goes on inside our bodies when we experience stress? The physiological mechanisms of stress are extremely complex, but they generally involve the work of two systems—the sympathetic nervous system and the hypothalamic-pituitary-adrenal (HPA) axis . When a person first perceives something as stressful (Selye’s alarm reaction), the sympathetic nervous system triggers arousal via the release of adrenaline from the adrenal glands. Release of these hormones activates the fight-or-flight responses to stress, such as accelerated heart rate and respiration. At the same time, the HPA axis, which is primarily endocrine in nature, becomes especially active, although it works much more slowly than the sympathetic nervous system. In response to stress, the hypothalamus (one of the limbic structures in the brain) releases corticotrophin-releasing factor, a hormone that causes the pituitary gland to release adrenocorticotropic hormone (ACTH). The ACTH then activates the adrenal glands to secrete a number of hormones into the bloodstream; an important one is cortisol, which can affect virtually every organ within the body. Cortisol is commonly known as a stress hormone and helps provide that boost of energy when we first encounter a stressor, preparing us to run away or fight. However, sustained elevated levels of cortisol weaken the immune system. This diagram shows the functioning of the hypothalamic-pituitary-adrenal (HPA) axis. The hypothalamus activates the pituitary gland, which in turn activates the adrenal glands, increasing their secretion of cortisol. In short bursts, this process can have some favorable effects, such as providing extra energy, improving immune system functioning temporarily, and decreasing pain sensitivity. However, extended release of cortisol—as would happen with prolonged or chronic stress—often comes at a high price. High levels of cortisol have been shown to produce a number of harmful effects. For example, increases in cortisol can significantly weaken our immune system (Glaser &amp; Kiecolt-Glaser, 2005), and high levels are frequently observed among depressed individuals (Geoffroy, Hertzman, Li, &amp; Power, 2013). In summary, a stressful event causes a variety of physiological reactions that activate the adrenal glands, which in turn release epinephrine, norepinephrine, and cortisol. These hormones affect a number of bodily processes in ways that prepare the stressed person to take direct action, but also in ways that may heighten the potential for illness. When stress is extreme or chronic, it can have profoundly negative consequences. For example, stress often contributes to the development of certain psychological disorders, including post-traumatic stress disorder, major depressive disorder, and other serious psychiatric conditions. Additionally, we noted earlier that stress is linked to the development and progression of a variety of physical illnesses and diseases. For example, researchers in one study found that people injured during the September 11, 2001, World Trade Center disaster or who developed post-traumatic stress symptoms afterward later suffered significantly elevated rates of heart disease (Jordan, Miller-Archie, Cone, Morabia, &amp; Stellman, 2011). Another investigation yielded that self-reported stress symptoms among aging and retired Finnish food industry workers were associated with morbidity 11 years later. This study also predicted the onset of musculoskeletal, nervous system, and endocrine and metabolic disorders (Salonen, Arola, Nygård, &amp; Huhtala, 2008). Another study reported that male South Korean manufacturing employees who reported high levels of work-related stress were more likely to catch the common cold over the next several months than were those employees who reported lower work-related stress levels (Park et al., 2011). Later, you will explore the mechanisms through which stress can produce physical illness and disease. Test Your Understanding Summary Stress is a process whereby an individual perceives and responds to events appraised as overwhelming or threatening to one’s well-being. The scientific study of how stress and emotional factors impact health and well-being is called health psychology, a field devoted to studying the general impact of psychological factors on health. The body’s primary physiological response during stress, the fight-or-flight response, was first identified in the early 20th century by Walter Cannon. The fight-or-flight response involves the coordinated activity of both the sympathetic nervous system and the hypothalamic-pituitary-adrenal (HPA) axis. Hans Selye, a noted endocrinologist, referred to these physiological reactions to stress as part of general adaptation syndrome, which occurs in three stages: alarm reaction (fight-or-flight reactions begin), resistance (the body begins to adapt to continuing stress), and exhaustion (adaptive energy is depleted, and stress begins to take a physical toll). Personal Application Question Glossary 82 Stressors \n",
      "-----------\n",
      "Differentiate between stimulus-based and response-based definitions of stress\n",
      "Define stress as a process\n",
      "Differentiate between good stress and bad stress\n",
      "Describe the early contributions of Walter Cannon and Hans Selye to the stress research field\n",
      "Understand the physiological basis of stress and describe the general adaptation syndrome\n",
      "--------------------------\n",
      "To this point, we have seen, among other things, that human beings have complex and well-developed self-concepts and that they generally attempt to view themselves positively. These more cognitive and affective aspects of ourselves do not, of course, occur in a vacuum. They are heavily influenced by the social forces that surround us. We have alluded to some of these forces already; for example, in our review of self-verification theory, we saw how feedback from others can affect our self-concept and esteem. We also looked at ways that our sociocultural backgrounds can affect the content of our self-concept. In this section, we will consider in more detail these and other social aspects of the self by exploring the many ways that the social situation influences our self-concept and esteem. The self is not created in isolation; we are not born with perceptions of ourselves as shy, interested in jazz, or charitable to others, for example. Rather, such beliefs are determined by our observations of and interactions with others. Are you rich or poor? Beautiful or ugly? Smart or not? Good or bad at playing video games? And how do you know? These questions can be answered only by looking at those around us. The self has meaning only within the social context, and it is not wrong to say that the social situation defines our self-concept and our self-esteem. We rely on others to provide a “social reality”—to help us determine what to think, feel, and do (Hardin &amp; Higgins, 1996). But what forms do these social influences take? It is to this question that we will now turn. The Looking-Glass Self: Our Sense of Self is Influenced by Others’ Views of Us The concept of the looking-glass self states that part of how we see ourselves comes from our perception of how others see us (Cooley, 1902). We might feel that we have a great sense of humor, for example, because others have told us, and often laugh (apparently sincerely) at our jokes. Many studies have supported a basic prediction derived from the notion of the looking-glass self, namely that our self-concepts are often quite similar to the views that others have of us (Beer, Watson, &amp; McDade-Montez, 2013). This may be particularly so with people from our own families and culture. Perkins, Wiley, and Deaux (2014), for example, found that, in the United States, how members of ethnic minority groups believed other members of the same culture perceived them significantly correlated with their self-esteem scores. In contrast, their perceived appraisal of European Americans toward them was only weakly related to their self-esteem. This evidence is merely correlational, though, so we cannot be sure which way the influence is working. Maybe we develop our self-concept quite independently of others, and they then base their views of us on how we see ourselves. The work of Mark Baldwin and colleagues has been particularly important in demonstrating that how we think we are being perceived by others really can affect how we see ourselves. For example, Baldwin and Holmes (1987) conducted two experiments to test the hypothesis that our self-concepts derive partly from the way we imagine that we would be perceived by significant others. In the first study, 40 women were instructed to visualize the faces of either two acquaintances or two older members of their own family. Later they were asked to rate their perceived enjoyableness of a piece of fiction with sexual content, and they typically responded in keeping with the responses they perceived the people they had visualized would have had. This effect was more pronounced when they sat in front of a mirror (remember the earlier discussion of self-awareness theory). In the second study, 60 men were exposed to a situation involving failure, and their self-evaluations to this setback were then measured. As with the women’s study, the men’s self-evaluations matched those they perceived that the people they were asked to visualize would have made, particularly when they were more self-aware. At least some of the time, then, we end up evaluating ourselves as we imagine others would. Of course, it can work both ways, too. Over time, the people around us may come to accept the self-concept that we present to others (Yeung &amp; Martin, 2003). Sometimes, the influence of other people’s appraisals of ourselves on our self-concept may be so strong that we end up internalizing them. For example, we are often labeled in particular ways by others, perhaps informally in terms of our ethnic background, or more formally in terms of a physical or psychological diagnosis. The labeling bias occurs when we are labeled, and others’ views and expectations of us are affected by that labeling (Fox &amp; Stinnett, 1996). For example, if a teacher knows that a child has been diagnosed with a particular psychological disorder, that teacher may have different expectations and explanations of the child’s behavior than he or she would if not aware of that label. Where things get really interesting for our present discussion is when those expectations start to become self-fulfilling prophecies, and our self-concept and even our behavior start to align with them. For example, when children are labeled in special education contexts, these labels can then impact their self-esteem (Taylor, Hume, &amp; Welsh, 2010). If we are repeatedly labeled and evaluated by others, then self-labeling may occur, which happens when we adopt others’ labels explicitly into our self-concept . The effects of this self-labeling on our self-esteem appear to depend very much on the nature of the labels. Labels used in relation to diagnosis of psychological disorders can be detrimental to people whom then internalize them. For example, Moses (2009) found that adolescents who self-labeled according to diagnoses they had received were found to have higher levels of self-stigma in their self-concepts compared with those who described their challenges in non-pathological terms. In these types of situation, those who self-label may come to experience internalized prejudice, which occurs when individuals turn prejudice directed toward them by others onto themselves. Internalized prejudice has been found to predict more negative self-concept and poorer psychological adjustment in members of various groups, including sexual minorities (Carter, 2012) and racial minorities (Szymanski &amp; Obiri, 2011). In other cases, labels used by wider society to describe people negatively can be positively reclaimed by those being labeled. Galinsky and colleagues (2013) explored this use of self-labeling by members of oppressed groups to reclaim derogatory terms, including “queer” and “bitch,” used by dominant groups. After self-labeling, minority group members evaluated these terms less negatively, reported feeling more powerful, and were also perceived by observers as more powerful. Overall, these results indicate that individuals who incorporate a formerly negative label into their self-concept in order to reclaim it can sometimes undermine the stigma attached to the label. Social Comparison Theory: Our Sense of Self Is Influenced by Comparisons with Others Self-concept and self-esteem are also heavily influenced by the process of social comparison (Buunk &amp; Gibbons, 2007; Van Lange, 2008). Social comparison occurs when we learn about our abilities and skills, about the appropriateness and validity of our opinions, and about our relative social status by comparing our own attitudes, beliefs, and behaviors with those of others . These comparisons can be with people who we know and interact with, with those whom we read about or see on TV, or with anyone else we view as important. However, the most meaningful comparisons we make tend to be with those we see as similar to ourselves (Festinger, 1954). Social comparison occurs primarily on dimensions on which there are no correct answers or objective benchmarks and thus on which we can rely only on the beliefs of others for information. Answers to questions such as “What should I wear to the interview?” or “What kind of music should I have at my wedding?” are frequently determined at least in part by using the behavior of others as a basis of comparison. We also use social comparison to help us determine our skills or abilities—how good we are at performing a task or doing a job, for example. When students ask their teacher for the class average on an exam, they are also seeking to use social comparison to evaluate their performance. Research Focus Affiliation and Social Comparison The extent to which individuals use social comparison to determine their evaluations of events was demonstrated in a set of classic research studies conducted by Stanley Schachter (1959). Schachter’s experiments tested the hypothesis that people who were feeling anxious would prefer to affiliate with others rather than be alone because having others around would reduce their anxiety. Female college students at the University of Minnesota volunteered to participate in one of his experiments for extra credit in their introductory psychology class. They arrived at the experimental room to find a scientist dressed in a white lab coat, standing in front of a large array of electrical machinery. The scientist introduced himself as Dr. Zilstein of the Department of Neurology and Psychiatry, and he told the women that they would be serving as participants in an experiment concerning the effects of electrical shock. Dr. Zilstein stressed how important it was to learn about the effects of shocks, since electroshock therapy was being used more and more commonly and because the number of accidents due to electricity was also increasing! At this point, the experimental manipulation occurred. One half of the participants (those in the high-anxiety condition ) were told that the shocks would be “painful” and “intense,” although they were assured that they could do no permanent damage. The other half of the participants (those in the low-anxiety condition ) were also told that they would be receiving shocks but that they would in no way be painful—rather, the shocks were said to be mild and to resemble a “tickle” or a “tingle.” Of course, the respondents were randomly assigned to conditions to assure that the women in the two conditions were, on average, equivalent except for the experimental manipulation. Each of the women was then told that before the experiment could continue the experimenter would have to prepare the equipment and that they would have to wait until he was finished. He asked them if they would prefer to wait alone or with others. The outcome of Schachter’s research was clear: while only 33% of the women who were expecting mild shocks preferred to wait with others, 63% of the women expecting to get painful shocks wanted to wait with others. This was a statistically significant difference, and Schachter concluded that the women chose to affiliate with each other in order to reduce their anxiety about the upcoming shocks. In further studies, Schachter found that the research participants who were under stress did not want to wait with just any other people. They preferred to wait with other people who were expecting to undergo the same severe shocks that they were rather than with people who were supposedly just waiting to see their professor. Schachter concluded that this was not just because being around other people might reduce our anxiety but because we also use others who are in the same situation as we are to help us determine how to feel about things. As Schachter (1959) put it, “Misery doesn’t just love any kind of company, it loves only miserable company” (p. 24). In this case, the participants were expecting to determine from the other participants how afraid they should be of the upcoming shocks. In short, and as predicted by the idea of social comparison, the women in Schachter’s studies relied on each other to help them understand what was happening to them and to find out how they should feel and respond to their social situations. Again, the power of the social situation—in this case, in determining our beliefs and attitudes—is apparent. Although Schachter’s studies were conducted in relatively artificial lab settings, similar effects have been found in field studies in more naturally occurring settings. For instance, Kulik, Mahler, and Moore (1996) found that hospital patients who were awaiting surgery preferred to talk to other individuals who were expecting to have similar procedures rather than to patients who were having different procedures, so that they could share information about what they might expect to experience. Furthermore, Kulik and his colleagues found that sharing information was helpful: people who were able to share more information had shorter hospital stays. Upward and Downward Comparisons Influence Our Self-Esteem Although we use social comparison in part to develop our self-concept—that is, to form accurate conclusions about our attitudes, abilities, and opinions—social comparison has perhaps an even bigger impact on our self-esteem. When we are able to compare ourselves favorably with others, we feel good about ourselves, but when the outcome of comparison suggests that others are better or better off than we are, then our self-esteem is likely to suffer. This is one reason why good students who attend high schools in which the other students are only average may suddenly find their self-esteem threatened when they move on to colleges and universities in which they are no longer better than the other students (Marsh, Kong, &amp; Hau, 2000). Perhaps you’ve had the experience yourself of the changes in self-esteem that occur when you have moved into a new year in school, got a new job, or changed your circle of friends. In these cases, you may have felt much better about yourself or much worse, depending on the nature of the change. You can see that in these cases the actual characteristics of the individual person have not changed at all; only the social situation and the comparison with others have changed. Because many people naturally want to have positive self-esteem, they frequently attempt to compare themselves positively with others. Downward social comparison occurs when we attempt to create a positive image of ourselves through favorable comparisons with others who are worse off than we are. In one study Morse and Gergen (1970) had students apply for a job, and they also presented the students with another individual who was supposedly applying for the same job. When the other candidate was made to appear to be less qualified for the job, the downward comparison with the less-qualified applicant made the students feel better about their own qualifications. As a result, the students reported higher self-esteem than they did when the other applicant was seen as a highly competent job candidate. Research has also found that people who are suffering from serious diseases prefer to compare their condition with other individuals whose current condition and likely prognosis is worse than their own (Buunk, Gibbons, &amp; Visser, 2002). These comparisons make them feel more hopeful about their own possible outcomes. More frequent use of downward than upward social comparison with similar others has been been shown to be a commonly used coping strategy for preserving self-esteem in the face of a wide variety of challenging life situations, including experiences of physical decline, rheumatoid arthritis, AIDS, occupational burnout, eating disorders, unemployment, educational difficulties, and intellectual disabilities (Buunk, Gibbons, &amp; Buunk, 1997). Although downward comparison provides us with positive feelings, upward social comparison , which occurs when we compare ourselves with others who are better off than we are , is also common (Blanton, Buunk, Gibbons, &amp; Kuyper, 1999; Vrugt &amp; Koenis, 2002). Upward comparison may lower our self-esteem by reminding us that we are not as well off as others. The power of upward social comparison to decrease self-esteem has been documented in many domains (Buunk, Gibbons, &amp; Buunk, 1997). Thinking back to our case study at the beginning of this chapter, this power can sometimes be strongly felt when looking at social networking sites. Imagine someone who has had a bad day, or is generally unhappy with how life is going, then logs onto Facebook to see that most of his or her friends have posted very positive status updates about how happy they are, how well they are doing, or the wonderful vacations they are having. What would your prediction be about how that person would feel? Would that person take pleasure from knowing that the friends were happy, or would the friends’ happiness make the person feel worse? The research on upward social comparisons to similar others would suggest the latter, and this has been demonstrated empirically. Feinstein and colleagues (2013) investigated whether a tendency to make upward social comparisons on Facebook led to increased symptoms of depression over a three-week period. Sure enough, making more upward comparisons predicted increased rumination, which in turn was linked to increased depressive symptoms. Despite these negative effects of upward comparisons, they can sometimes be useful because they provide information that can help us do better, help us imagine ourselves as part of the group of successful people that we want to be like (Collins, 2000), and give us hope (Snyder, Cheavens, &amp; Sympson, 1997). The power of upward social comparison can also be harnessed for social good. When people are made aware that others are already engaging in particular prosocial behaviors, they often follow suit, partly because an upward social comparison is triggered. This has been shown in relation to sustainable environmental practices, for example, with upward social comparisons helping to facilitate energy-saving behaviors in factory workers (Siero, Bakker, Dekker, &amp; van den Berg, 1996) and hotel guests (Goldstein, Cialdini, &amp; Griskevicius, 2008).  As with downward comparisons, the effects of looking upward on our self-esteem tend to be more pronounced when we are comparing ourselves to similar others. If, for example, you have ever performed badly at a sport, the chances are that your esteem was more threatened when you compared yourselves to your teammates as opposed to the top professional athletes in that sport. The outcomes of upward and downward social comparisons can have a substantial impact on our feelings, on our attempts to do better, and even on whether or not we want to continue performing an activity. When we compare positively with others and we feel that we are meeting our goals and living up to the expectations set by ourselves and others, we feel good about ourselves, enjoy the activity, and work harder at it. When we compare negatively with others, however, we are more likely to feel poorly about ourselves and enjoy the activity less, and we may even stop performing it entirely. When social comparisons come up poorly for us, we may experience depression or anxiety, and these discrepancies are important determinants of our self-esteem (Higgins, Loeb, &amp; Moretti, 1995; Strauman &amp; Higgins, 1988). Although everyone makes social comparisons, both upward and downward, there are some sources of differences in how often we do so and which type we tend to favor. As downward social comparisons generally increase and upward ones generally decrease self-esteem, and the pursuit of high self-esteem, as we have seen, is more prominent in Western as opposed to Eastern cultures, then it should come as no surprise that there are cultural differences here. White and Lehman (2005), for example, found that Asian Canadians made more upward social comparisons than did European Canadians, particularly following failures and when the opportunity to self-improve was made salient. These findings, the authors suggest, indicate that the Asian Canadians were using social comparisons more as a vehicle for self-improvement than self-enhancement. There are also some age-related trends in social comparison. In general, older adults tend to make more downward comparisons than do younger adults, which is part of the reason why their self-esteem is typically higher (Helgeson &amp; Mickelson, 2000). Older adults also use more downward social comparisons to cope with feelings of regret than do younger adults, and these comparisons are often more effective for them (Bauer, Wrosch, &amp; Jobin, 2008). In addition to these cultural and age differences in social comparison processes, there are also individual differences. People who score higher on a measure of social comparison orientation have been found to experience more positive affect following downward social comparisons and more negative affect following upward ones (Buunk, Zurriaga, Peiró, Nauta, &amp; Gosalvez, 2005). Social Identity Theory: Our Sense of Self Is Influenced by the Groups We Belong To In our discussion of social comparisons, we have seen that who we compare ourselves to can affect how we feel about ourselves, for better or worse. Another social influence on our self-esteem is through our group memberships. For example, we can gain self-esteem by perceiving ourselves as members of important and valued groups that make us feel good about ourselves. Social identity theory asserts that we draw part of our sense of identity and self-esteem from the social groups that we belong to (Hogg, 2003; Oakes, Haslam, &amp; Turner, 1994; Tajfel, 1981). Normally, group memberships result in positive feelings, which occur because we perceive our own groups and thus ourselves in a positive light. If you are an Arsenal F.C. fan, or if you are an Australian, or if you are a Muslim, for example, then your membership in the group becomes part of what you are, and the membership often makes you feel good about yourself. The list that follows presents a measure of the strength of social identity with a group of university students. If you complete the measure for your own school, university, or college, the research evidence would suggest that you would agree mostly with the statements that indicate that you identify with the group. Figure 3.10 A Measure of Social Identity This 10-item scale is used to measure identification with students at the University of Maryland, but it could be modified to assess identification with any group. The items marked with an R are reversed (so that low numbers become high numbers and vice versa) before the average of the scale is computed. The scale was originally reported by Luhtanen and Crocker (1992). For each of the following items, please indicate your response on a scale from 1 (strongly disagree) to 7 (strongly agree) by writing a number in the blank next to the question. ___ I identify with the group of University of Maryland students. ___ I am glad to belong to the group of University of Maryland students. ___ I make excuses for belonging to the group of University of Maryland students. ___ I consider the group of University of Maryland students to be important. ___ I feel held back by the group of University of Maryland students. (R) ___ I criticize the group of University of Maryland students. (R) ___ I see myself as belonging to the group of University of Maryland students. ___ I try to hide belonging to the group of University of Maryland students. (R) ___ I feel strong ties with the group of University of Maryland students. ___ I am annoyed to say that I am a member of the group of University of Maryland students. (R) Kay Deaux and her colleagues (Deaux, Reid, Mizrahi, &amp; Ethier, 1995) asked U.S. college students to list the groups that they identified with. As you can see in Table 3.1 ,”Varieties of Social Identities,” the students reported belonging to a wide variety of groups and claimed that many of these groups provided them with social identities. The categories that they listed included ethnic and religious groups (e.g., Asian, Jewish), political affiliations (e.g., conservative, Democrat), occupations and hobbies (e.g., gardener, tennis player), personal relationships (e.g., husband, girlfriend), and marginalized groups (e.g., gay, homeless). You can see that these identities were likely to provide a lot of positive feelings for the individuals. Table 3.1 Varieties of Social Identities Relationships Vocation/avocation Political affiliation Stigma Ethnicity/religion Widow Divorced person Woman Man Lover Friend Girlfriend Boyfriend Homemaker Head of household Teenager Child Wife Husband Son Daughter Sister Brother Grandmother Grandfather Uncle Aunt Mother/Father Intellectual Bookworm Military veteran Student Collector Musician Gardener Teacher Supervisor Secretary Scientist Psychologist Salesperson Business person Athlete Feminist Political independent Democrat Republican Old person Fat person Deaf person Person with AIDS Lesbian Gay Smoker Alcoholic Welfare recipient Unemployed person Homeless person Retired person New Yorker American Hispanic Asian American African American Jewish Christian Catholic Southerner This table represents some of the many social identities reported by a sample of college students. Data are from Deaux and colleagues (1995). Which of our many identities is most accessible for us will vary from day to day as a function of the particular situation we are in (Yakushko, Davidson, &amp; Williams, 2009). Seeing our national flag outside a government office may remind of us our national identity, whereas walking past our local soccer stadium may remind us of our identification with our team. Identity can also be heightened when it is threatened by conflict with another group—such as during an important sports game with a rival team. We each have multiple social identities, and which of our identities we draw our self-esteem from at a given time will depend on the situation we are in, as well as the social goals we have. Figure 3.11 Social identity refers to the positive emotions we experience as a member of an important social group. In particular, we use occasions when our social groups are successful in meeting their goals to fuel our self-worth. Robert Cialdini and his colleagues (Cialdini et al., 1976) studied the idea that we can sometimes enhance our self-esteem by basking in the reflected glory of our ingroups, which occurs when we use and advertise our ingroups’ positive achievements to boost our self-esteem . To test this idea, they observed the clothes and clothing accessories that students at different U.S. universities wore to classes on Mondays. They found that when the university’s football team had won its game on Saturday, students were likely to emphasize their university membership by wearing clothing, such as sweatshirts and hats with the symbols of the university on them. However, they were significantly less likely to wear university clothing on the Mondays that followed a football loss. Furthermore, in a study in which students from a university were asked to describe a victory by their university team, they frequently used the term “we,” whereas when asked to describe a game in which their school lost, they used the term “we” significantly less frequently. Emphasizing that “we’re a good school” and “we beat them” evidently provided a social identity for these students, allowing them to feel good about themselves. When people in our ingroups perform well, social identity theory suggests that we tend to make intergroup social comparisons, and by seeing our group as doing better than other groups, we come to feel better about ourselves. However, this is not generally what happens when we make intragroup comparisons—those between ourselves and other ingroup members. In this case it is often not advantageous to bask in the glory of others in our ingroups, because in some cases the other person’s successes may create an upward comparison and thus more negative emotions. Self-evaluation maintenance theory (Tesser, 1988) asserts that our self-esteem can be threatened when someone else outperforms us, particularly if that person is close to us and the performance domain is central to our self-concept. This theory leads to the interesting implication that these threats will often occur in the context of our family relationships, and they have been shown to be an integral part of both family functioning in general (Tesser, 1980) and marital relationships in particular (Beach et al., 1996). When threats occur, the theory states that we will typically try to rebuild our self-esteem using one of three main strategies. The first is distancing, where we redefine ourselves as less close to the person in question. For example, if a close friend keeps beating you at tennis, you may, over time, seek out another playing partner to protect your bruised ego. Interestingly, people who are more narcissistic are more likely to use this tactic than people who are lower in these characteristics (Nicholls &amp; Stukas, 2011). The second option is to redefine how important the trait or skill really is to your self-concept. For instance, you may decide that tennis ability just isn’t that important a part of who you are, and choose to take up another hobby instead. The third strategy is try to improve on the ability in question. In the current example, this would mean practicing more often or hiring a coach to improve your tennis game. Notice the clear parallels between these strategies that occur in response to threats to our self-esteem posed by the behavior of others, and those that are triggered by feelings of self-discrepancy, discussed earlier in this chapter. In both cases, we seek to rebuild our self-esteem by redefining the aspect of ourself that has been diminished. Self-Presentation: Our Sense of Self Is Influenced by the Audiences We Have It is interesting to note that each of the social influences on our sense of self that we have discussed can be harnessed as a way of protecting our self-esteem. The final influence we will explore can also be used strategically to elevate not only our own esteem, but the esteem we have in the eyes of others. Positive self-esteem occurs not only when we do well in our own eyes but also when we feel that we are positively perceived by the other people we care about. Figure 3.12 Being seen positively by others helps us to feel positive about ourselves. Because it is so important to be seen as competent and productive members of society, people naturally attempt to present themselves to others in a positive light. We attempt to convince others that we are good and worthy people by appearing attractive, strong, intelligent, and likable and by saying positive things to others (Jones &amp; Pittman, 1982; Schlenker, 2003). The tendency to present a positive self-image to others, with the goal of increasing our social status , is known as self-presentation , and it is a basic and natural part of everyday life. A big question in relation to self-presentation is the extent to which it is an honest versus more strategic, potentially dishonest enterprise. The sociologist Erving Goffman (1959) developed an influential theory of self-presentation and described it as a mainly honest process, where people need to present the parts of themselves required by the social role that they are playing in a given situation. If everyone plays their part according to accepted social scripts and conventions, then the social situation will run smoothly and the participants will avoid embarrassment. Seen in this way, self-presentation is a transparent process, where we are trying to play the part required of us, and we trust that others are doing the same. Other theorists, though, have viewed self-presentation as a more strategic endeavor, which may involve not always portraying ourselves in genuine ways (e.g., Jones &amp; Pittman, 1982). As is often the case with two seemingly opposing perspectives, it is quite likely that both are true in certain situations, depending on the social goals of the actors. Different self-presentation strategies may be used to create different emotions in other people, and the use of these strategies may be evolutionarily selected because they are successful (Toma, Hancock, &amp; Ellison, 2008). Edward Jones and Thane Pittman (1982) described five self-presentation strategies, each of which is expected to create a resulting emotion in the other person: The goal of ingratiation is to create liking by using flattery or charm. The goal of intimidation is to create fear by showing that you can be aggressive. The goal of exemplification is to create guilt by showing that you are a better person than the other. The goal of supplication is to create pity by indicating to others that you are helpless and needy. The goal of self-promotion is to create respect by persuading others that you are competent. Figure 3.13 Attempts to impress and intimidate others to gain status are not unique to humans. No matter who is using it, self-presentation can easily be overdone, and when it is, it backfires. People who overuse the ingratiation technique and who are seen as obviously and strategically trying to get others to like them are often disliked because of this. Have you ever had a slick salesperson obviously try to ingratiate him- or herself with you just so you will buy a particular product, and you end up not liking the person and making a hasty retreat from the premises? People who overuse the exemplification or self-promotion strategies by boasting or bragging, particularly if that boasting does not appear to reflect their true characteristics, may end up being perceived as arrogant and even self-deluded (Wosinska, Dabul, Whetstone-Dion, &amp; Cialdini, 1996). Using intimidation can also often backfire; acting more modestly may be more effective. Again, the point is clear: we may want to self-promote with the goal of getting others to like us, but we must also be careful to consider the point of view of the other person. Being aware of these strategies is not only useful for better understanding how to use them responsibly ourselves, it can also help us to understand that other people’s behaviors may often reflect their self-presentational concerns. This can, in turn, facilitate better empathy for others, particularly when they are exhibiting challenging behaviors (Friedlander &amp; Schwartz, 1985). For instance, perhaps someone’s verbally aggressive behavior toward you is more about that person being afraid rather than about his or her desire to do you harm. Now that we have explored some of the commonly used self-presentation tactics, let’s look at how they manifest in specific social behaviors. One concrete way to self-promote is to display our positive physical characteristics. A reason that many of us spend money on improving our physical appearance is the desire to look good to others so that they will like us. We can also earn status by collecting expensive possessions such as fancy cars and big houses and by trying to associate with high-status others. Additionally, we may attempt to dominate or intimidate others in social interactions. People who talk more and louder and those who initiate more social interactions are afforded higher status. A businessman who greets others with a strong handshake and a smile, and people who speak out strongly for their opinions in group discussions may be attempting to do so as well. In some cases, people may even resort to aggressive behavior, such as bullying, in attempts to improve their status (Baumeister, Smart, &amp; Boden, 1996). Self-promotion can also be pursued in our online social behaviors. For example, a study in Taiwan conducted by Wang and Stefanone (2013) used survey methodology to investigate the relationship between personality traits, self-presentation and the use of check-ins on Facebook. Interestingly, narcissism was found to predict scores on a measure of exhibitionistic, self-promoting use of Facebook check-ins, which included items like “I check in so people know that I am with friends,” and “I expect friends to like or leave comments on my check-in status on Facebook.” Other studies have also found associations between narcissistic traits and self-promotional activity on Facebook. Mehdizadeh (2010), for example, found that narcissistic personality scores were positively correlated with the amount of daily logins on Facebook and the duration of each login. Furthermore, narcissistic traits were related to increased use of self-promotional material in the main photo, view photos, status updates, and notes sections of people’s Facebook pages. Analysis of the content and language used in Facebook postings has also revealed that they are sometimes used by individuals to self-promote. Bazarova, Taft, Choi, and Cosley (2013) explored self-presentation through language styles used in status updates, wall posts, and private messages from 79 participants. The use of positive emotion words was correlated with self-reported self-presentation concern in status updates. This is consistent with the idea that people share positive experiences with Facebook friends partly as a self-enhancement strategy. Online self-presentation doesn’t seem to be limited to Facebook usage. There is also evidence that self-promotional concerns are often a part of blogging behaviors, too. Mazur and Kozarian (2010), for example, analyzed the content of adolescents’ blog entries and concluded that a careful concern for self-presentation was more central to their blogging behavior than direct interaction with others. This often seems to apply to micro-blogging sites like Twitter. Marwick and Boyd (2011) found that self-presentational strategies were a consistent part of celebrity tweeting, often deployed by celebrities to maintain their popularity and image. You might not be surprised to hear that men and women use different approaches to self-presentation. Men are more likely to present themselves in an assertive way, by speaking and interrupting others, by visually focusing on the other person when they are speaking, and by leaning their bodies into the conversation. Women, on the other hand, are more likely to be modest; they tend to create status by laughing and smiling, and by reacting more positively to the statements of others (Dovidio, Brown, Heltman, Ellyson, &amp; Keation, 1988). These gender differences are probably in large part socially determined as a result of the different reinforcements that men and women receive for using particular self-presentational strategies. For example, self-promoting by speaking out and acting assertively can be more effective for men than it is for women, in part because cross-culturally consistent stereotypes tend to depict assertiveness as more desirable in men than in women. These stereotypes can have very important consequences in the real world. For instance, one of the reasons for the “glass ceiling” existing in some occupations (where women experience discrimination in reaching top positions in organizations) may be attributable to the more negative reactions that their assertive behaviors, necessary for career advancement, receive than those of their male colleagues  (Eagly &amp; Carli, 2007). There are also some cultural differences in the extent to which people use self-presentation strategies in social contexts. For instance, when considering job interviews, Konig, Haftseinsson, Jansen, &amp; Stadelmann (2011) found that individuals from Iceland and Switzerland used less self-presentational behavior than people from the United States. Differences in self-presentation have also been found in job interviews involving individuals from Ghana, Turkey, Norway, and Germany, with the former two groups showing higher impression management scores than the latter two (Bye et al., 2011). So far we have been talking about self-presentation as it operates in particular situations in the short-term. However, we also engage in longer-term self-presentational projects, where we seek to build particular reputations with particular audiences. Emler &amp; Reicher (1995) describe the unique capacity humans have to know one another by repute and argue that, accordingly, we are often engaged in a process of reputation management , which is a form of long-term self-presentation, where individuals seek to build and sustain specific reputations with important audiences . According to this perspective, our behaviors in current social situations may not only be to serve our self-presentational goals in that moment, but also be based on a consideration of their longer-term repercussions for our reputations. As many politicians, for example, know only too well, a poor decision from their past can come back to haunt them when their reputation is being assessed during a campaign. The concept of reputation management can be used to help explain a wide variety of social and antisocial behaviors, including corporate branding (Smith, Smith, &amp; Wang, 2010), sociomoral debate (Emler, Tarry, &amp; St. James, 2007), and teenage criminal activity (Lopez-Romero &amp; Romero, 2011). In the last example, it is argued that a lot of teenage antisocial behavior results from a desire to build a reputation for toughness and rebelliousness with like-minded peer audiences (Emler &amp; Reicher, 1995). Similarly, antisocial and self-destructive online actions, like people posting to Facebook their involvement in illegal acts during riots, or individuals engaging in life-threatening activities in Internet crazes like Neknominate, may make more sense if they are considered partly as stemming from a desire to project a particular reputation to specific audiences. Perhaps the perceived social kudos from doing these things outweighs the obvious personal risks in the individuals’ minds at the time. People often project distinct reputations to different social audiences. For example, adolescents who engage in antisocial activity to build reputations for rebelliousness among their peers will often seek to construct very different reputations when their parents are the audience (Emler &amp; Reicher, 1995). The desire to compartmentalize our reputations and audiences can even spill over into our online behaviors. Wiederhold (2012) found that, with some adolescents’ Facebook friends numbering in the hundreds or thousands, increasing numbers are moving to Twitter in order to reach a more selective audience. One critical trigger for this has been that their parents are now often friends with them on Facebook, creating a need for young people to find a new space where they can build reputations that may not always be parent-friendly (Wiederhold, 2012). Although the desire to present the self favorably is a natural part of everyday life, both person and situation factors influence the extent to which we do it. For one, we are more likely to self-present in some situations than in others. When we are applying for a job or meeting with others whom we need to impress, we naturally become more attuned to the social aspects of the self, and our self-presentation increases. There are also individual differences. Some people are naturally better at self-presentation—they enjoy doing it and are good at it—whereas others find self-presentation less desirable or more difficult. An important individual-difference variable known as self-monitoring has been shown in many studies to have a major impact on self-presentation. Self-monitoring refers to the tendency to be both motivated and capable of regulating our behavior to meet the demands of social situations (Gangestad &amp; Snyder, 2000). High self-monitors are particularly good at reading the emotions of others and therefore are better at fitting into social situations—they agree with statements such as “In different situations and with different people, I often act like very different persons,” and “I guess I put on a show to impress or entertain people.” Low self-monitors, on the other hand, generally act on their own attitudes, even when the social situation suggests that they should behave otherwise. Low self-monitors are more likely to agree with statements such as “At parties and social gatherings, I do not attempt to do or say things that others will like,” and “I can only argue for ideas that I already believe.” In short, high self-monitors use self-presentation to try to get other people to like them by behaving in ways that the others find desirable, whereas low self-monitors tend to follow their internal convictions more than the demands of the social situation. In one experiment that showed the importance of self-monitoring, Cheng and Chartrand (2003) had college students interact individually with another student (actually an experimental confederate) whom they thought they would be working with on an upcoming task. While they were interacting, the confederate subtly touched her own face several times, and the researchers recorded the extent to which the student participant mimicked the confederate by also touching his or her own face. The situational variable was the status of the confederate. Before the meeting began, and according to random assignment to conditions, the students were told either that they would be the leader and that the other person would be the worker on the upcoming task, or vice versa. The person variable was self-monitoring, and each participant was classified as either high or low on self-monitoring on the basis of his or her responses to the self-monitoring scale. As you can see in Figure 3.14, “Self-Monitoring and Behavioral Mimicry,” Cheng and Chartrand found an interaction effect: the students who had been classified as high self-monitors were more likely to mimic the behavior of the confederate when she was described as being the leader than when she was described as being the worker, indicating that they were “tuned in” to the social situation and modified their behavior to appear more positively. Although the low self-monitors did mimic the other person, they did not mimic her more when the other was high, versus low, status. This finding is consistent with the idea that the high self-monitors were particularly aware of the other person’s status and attempted to self-present more positively to the high-status leader. The low self-monitors, on the other hand—because they feel less need to impress overall—did not pay much attention to the other person’s status. Figure 3.14: Self-Monitoring and Behavioral Mimicry High self-monitors imitated more when the person they were interacting with was of higher (versus lower) status. Low self-monitors were not sensitive to the status of the other. Data are from Cheng and Chartrand (2003). This differential sensitivity to social dynamics between high and low self-monitors suggests that their self-esteem will be affected by different factors. For people who are high in self-monitoring, their self-esteem may be positively impacted when they perceive that their behavior matches the social demands of the situation, and negatively affected when they feel that it does not. In contrast, low self-monitors may experience self-esteem boosts when they see themselves behaving consistently with their internal standards, and feel less self-worth when they feel they are not living up to them (Ickes, Holloway, Stinson, &amp; Hoodenpyle, 2006). Key Takeaways Our self-concepts are affected by others’ appraisals, as demonstrated by concepts including the looking-glass self and self-labeling. The self-concept and self-esteem are also often strongly influenced by social comparison. For example, we use social comparison to determine the accuracy and appropriateness of our thoughts, feelings, and behavior. When we are able to compare ourselves favorably with others through downward social comparison, we feel good about ourselves. Upward social comparison with others who are better off than we are leads to negative emotions. Social identity refers to the positive emotions that we experience as a member of an important social group. Normally, our group memberships result in positive feelings, which occur because we perceive our own groups, and thus ourselves, in a positive light. Which of our many category identities is most accessible for us will vary from day to day as a function of the particular situation we are in. In the face of others’ behaviors, we may enhance our self-esteem by “basking in the reflected glory” of our ingroups or of other people we know. If other people’s actions threaten our sense of self according to self-evaluation maintenance theory, we may engage in a variety of strategies aimed at redefining our self-concept and rebuilding our self-esteem. The tendency to present a positive self-image to others, with the goal of increasing our social status, is known as self-presentation, and it is a basic and natural part of everyday life. Different self-presentation strategies may be used to create different emotions in other people. We often use self-presentation in the longer term, seeking to build and sustain particular reputations with specific social audiences. The individual-difference variable of self-monitoring relates to the ability and desire to self-present. References Baldwin, M. W., &amp; Holmes, J. O. (1987). Salient private audiences and awareness of the self. Journal of Personality and Social Psychology, 52, 1087-1098. Baumeister, R. F., Smart, L., &amp; Boden, J. M. (1996). Relation of threatened egotism to violence and aggression: The dark side of high self-esteem. Psychological Review , 103 (1), 5-33. doi:10.1037/0033-295X.103.1.5 Bauer, I., Wrosch, C., &amp; Jobin, J. (2008). I’m better off than most other people: The role of social comparisons for coping with regret in young adulthood and old age. Psychology And Aging , 23 (4), 800-811. doi:10.1037/a0014180 Bazarova, N. N., Taft, J. G., Choi, Y., &amp; Cosley, D. (2013). Managing impressions and relationships on Facebook: Self-presentational and relational concerns revealed through the analysis of language style. Journal Of Language And Social Psychology , 32 (2), 121-141. doi:10.1177/0261927X12456384 Beach, S. H., Tesser, A., Mendolia, M., Anderson, P., Crelia, R., Whitaker, D., &amp; Fincham, F. D. (1996). Self-evaluation maintenance in marriage: Toward a performance ecology of the marital relationship. Journal of Family Psychology , 10 (4), 379-396. doi:10.1037/0893-3200.10.4.379 Beer, A., Watson, D., &amp; McDade-Montez, E. (2013). Self–other agreement and assumed similarity in neuroticism, extraversion, and trait affect: Distinguishing the effects of form and content. Assessment , 20 (6), 723-737. doi:10.1177/1073191113500521 Blanton, H., Buunk, B. P., Gibbons, F. X., &amp; Kuyper, H. (1999). When better-than-others compare upward: Choice of comparison and comparative evaluation as independent predictors of academic performance. Journal of Personality and Social Psychology, 76 (3), 420–430. Buunk, A. P., &amp; Gibbons, F. X. (2007). Social comparison: The end of a theory and the emergence of a field. Organizational Behavior and Human Decision Processes, 102 (1), 3–21. Buunk, B. P., Gibbons, F. X., &amp; Buunk, A. P. (1997). Health, coping and well-being: Perspectives from social comparison theory. Psychology Press. Buunk, A. P., Gibbons, F. X., &amp; Visser, A. (2002). The relevance of social comparison processes for prevention and health care. Patient Education and Counseling, 47, 1–3. Buunk, B. P., Zurriaga, R., Peiró, J. M., Nauta, A., &amp; Gosalvez, I. (2005). Social comparisons at work as related to a cooperative social climate and to individual differences in social comparison orientation. Applied Psychology: An International Review , 54 (1), 61-80. doi:10.1111/j.1464-0597.2005.00196.x Bye, H., Sandal, G., van de Vijver, F. R., Sam, D., Çakar, N., &amp; Franke, G. (2011). Personal values and intended self‐presentation during job interviews: A cross‐cultural comparison. Applied Psychology: An International Review , 60 (1), 160-182. doi:10.1111/j.1464-0597.2010.00432.x Carter, L. (2012). Locus of control, internalized heterosexism, experiences of prejudice, and the psychological adjustment of lesbian, gay, and bisexual individuals. Dissertation Abstracts International , 73. Cheng, C., &amp; Chartrand, T. L. (2003). Self-Monitoring Without Awareness: Using Mimicry as a Nonconscious Affiliation Strategy. Journal Of Personality And Social Psychology , 85 (6), 1170-1179. doi:10.1037/0022-3514.85.6.1170 Cialdini, R. B., Borden, R. J., Thorne, A., Walker, M. R., Freeman, S., &amp; Sloan, L. R. (1976). Basking in reflected glory: Three (football) field studies. Journal of Personality and Social Psychology, 34 , 366–374. Collins, R. L. (2000). Among the better ones: Upward assimilation in social comparison. In J. Suls &amp; L. Wheeler (Eds.), Handbook of social comparison (pp. 159–172). New York, NY: Kulwer Academic/Plenum. Cooley, C. H. (1902). Human nature and social order. New York: Scribner’s. Deaux, K., Reid, A., Mizrahi, K., &amp; Ethier, K. A. (1995). Parameters of social identity. Journal of Personality and Social Psychology, 68 (2), 280–291. Dovidio, J. F., Brown, C. E., Heltman, K., Ellyson, S. L., &amp; Keating, C. F. (1988). Power displays between women and men in discussions of gender-linked tasks: A multichannel study. Journal Of Personality And Social Psychology , 55 (4), 580-587. doi:10.1037/0022-3514.55.4.580 Eagly, A. H., &amp; Carli, L. L. (2007). Through the labyrinth: The truth about how women become leaders . Boston, MA, US: Harvard Business School Press. Emler, N. &amp; Reicher, S. (1995). Adolescence and delinquency: The collective management of reputation. Malden Blackwell Publishing. Emler, N., Tarry, H. &amp; St. James, A. (2007). Postconventional moral reasoning and reputation. Journal of Research in Personality, 41, 76-89. Feinstein, B. A., Hershenberg, R., Bhatia, V., Latack, J. A., Meuwly, N., &amp; Davila, J. (2013). Negative social comparison on Facebook and depressive symptoms: Rumination as a mechanism. Psychology Of Popular Media Culture , 2 (3), 161-170. doi:10.1037/a003311 Festinger, L. U. (1954). A theory of social comparison processes. Human Relations, 7, 117-140. doi: 10.1177/001872675400700202 Fox, J. D., &amp; Stinnett, T. A. (1996). The effects of labeling bias on prognostic outlook for children as a function of diagnostic label and profession. Psychology In The Schools , 33 (2), 143-152. Friedlander, M. L., &amp; Schwartz, G. S. (1985). Toward a theory of strategic self-presentation in counseling and psychotherapy. Journal of Counseling Psychology, 32(4), 483-501. doi: 10.10370022-0167.32.4.483 Galinsky, A. D., Wang, C. S., Whitson, J. A., Anicich, E. M., Hugenberg, K., &amp; Bodenhausen, G. V. (2013). The reappropriation of stigmatizing labels: The reciprocal relationship between power and self-labeling. Psychological Science , 24 (10), 2020-2029. doi:10.1177/0956797613482943 Gangestad, S. W., &amp; Snyder, M. (2000). Self-monitoring: Appraisal and reappraisal. Psychological Bulletin , 126 (4), 530-555. doi:10.1037/0033-2909.126.4.530 Goffman, E. (1959). The presentation of self in everyday life. Oxford, England: Doubleday. Goldstein, N. J., Cialdini, R. B., &amp; Griskevicius, V. (2008). A room with a viewpoint: Using social norms to motivate environmental conservation in hotels. Journal of Consumer Research, 35(3), 472-482. Hardin, C., &amp; Higgins, T. (1996). Shared reality: How social verification makes the subjective objective. In R. M. Sorrentino &amp; E. T. Higgins (Eds.), Handbook of motivation and cognition: Foundations of social behavior (Vol. 3, pp. 28–84). New York, NY: Guilford Press. Helgeson, V. S., &amp; Mickelson, K. (2000). Coping with chronic illness among the elderly: Maintaining self-esteem. In S. B. Manuck, R. Jennings, B. S. Rabin, &amp; A. Baum (Eds.), Behavior, health, and aging. Mahwah, NJ: Erlbaum. Higgins, E. T., Loeb, I., &amp; Moretti, M. (Eds.). (1995). Self-discrepancies and developmental shifts in vulnerability: Life transitions in the regulatory significance of others . Rochester, NY: University of Rochester Press. Hogg, M. A. (2003). Social identity. In M. R. Leary, J. P. Tangney, M. R. E. Leary, &amp; J. P. E. Tangney (Eds.), Handbook of self and identity (pp. 462–479). New York, NY: Guilford Press. Ickes, W., Holloway, R., Stinson, L. L., &amp; Hoodenpyle, T. (2006). Self-Monitoring in Social Interaction: The Centrality of Self-Affect. Journal Of Personality , 74 (3), 659-684. doi:10.1111/j.1467-6494.2006.00388.x Jones, E. E., &amp; Pittman, T. S. (1982). Toward a general theory of strategic self presentation. In J. Suls (Ed.), Psychological perspectives on the self. Hillsdale, NJ:Erlbaum König, C. J., Hafsteinsson, L. G., Jansen, A., &amp; Stadelmann, E. H. (2011). Applicants’ self‐presentational behavior across cultures: Less self‐presentation in Switzerland and Iceland than in the United States. International Journal Of Selection And Assessment , 19 (4), 331-339. Kulik, J. A., Mahler, H. I. M., &amp; Moore, P. J. (1996). Social comparison and affiliation under threat: Effects on recovery from major surgery. Journal of Personality and Social Psychology, 71 (5), 967–979. López-Romero, L., &amp; Romero, E. (2011). Reputation management of adolescents in relation to antisocial behavior. The Journal of Genetic Psychology: Research And Theory On Human Development , 172 (4), 440-446. doi:10.1080/00221325.2010.549156 Luhtanen, R., &amp; Crocker, J. (1992). A collective self-esteem scale: Self-evaluation of one’s social identity. Personality and Social Psychology Bulletin, 18 , 302–318. Marsh, H. W., Kong, C.-K., &amp; Hau, K-T. (2000). Longitudinal multilevel models of the big-fish-little-pond effect on academic self-concept: Counterbalancing contrast and reflected-glory effects in Hong Kong schools. Journal of Personality and Social Psychology, 78, 337–349. Marwick, A. E., &amp; Boyd, D. (2011). I tweet honestly, I tweet passionately: Twitter users, context collapse, and the imagined audience. New Media &amp; Society , 13 (1), 114-133. doi:10.1177/1461444810365313 Mazur, E., &amp; Kozarian, L. (2010). Self-presentation and interaction in blogs of adolescents and young emerging adults. Journal Of Adolescent Research , 25 (1), 124-144. doi:10.1177/0743558409350498 Mehdizadeh, S. (2010). Self-presentation 2.0: Narcissism and self-esteem on Facebook. Cyberpsychology, Behavior, And Social Networking , 13 (4), 357-364. doi:10.1089/cyber.2009.0257 Morse, S., &amp; Gergen, K. (1970). Social comparison, self-consistency, and the concept of self. Journal of Personality and Social Psychology, 16 (1), 148–156. Moses, T.  (2009). Self-labeling and its effects among adolescents diagnosed with mental disorders. Social Science and Medicine, 68(3), 570-578. Nicholls, E., &amp; Stukas, A. A. (2011). Narcissism and the self-evaluation maintenance model: Effects of social comparison threats on relationship closeness. The Journal of Social Psychology , 151 (2), 201-212. doi:10.1080/00224540903510852 Oakes, P. J., Haslam, S. A., &amp; Turner, J. C. (1994). Sterotyping and social reality . Oxford, England: Blackwell. Perkins, K., Wiley, S., &amp; Deaux, K. (2014). Through which looking glass? Distinct sources of public regard and self-esteem among first- and second-generation immigrants of color. Cultural Diversity And Ethnic Minority Psychology , 20 (2), 213-219. doi:10.1037/a0035435 Schachter, S. (1959). The psychology of affiliation . Stanford, CA: Stanford University Press. Schlenker, B. R. (2003). Self-presentation. In M. R. Leary, J. P. Tangney, M. R. E. Leary, &amp; J. P. E. Tangney (Eds.), Handbook of self and identity (pp. 492–518). New York, NY: Guilford Press. Siero, F. W., Bakker, A. B., Dekker, G. B., &amp; van den Berg, M. T. (1996). Changing organizational energy consumption behavior through comparative feedback. Journal of Environmental Psychology, 16, 235-246. Smith, K., Smith, M., &amp; Wang, K. (2010). Does brand management of corporate reputation translate into higher market value?. Journal of Strategic Marketing , 18 (3), 201-221. doi:10.1080/09652540903537030 Snyder, C., Cheavens, J., &amp; Sympson, S. (1997). Hope: An individual motive for social commerce. Group Dynamics: Theory, Research, and Practice, 1 , 107–118. Strauman, T. J., &amp; Higgins, E. T. (1988). Self-discrepancies as predictors of vulnerability to distinct syndromes of chronic emotional distress. Journal of Personality, 56 (4), 685–707. Szymanski, D. M., &amp; Obiri, O. (2011). Do religious coping styles moderate or mediate the external and internalized racism-distress links? The Counseling Psychologist , 39 (3), 438-462. doi:10.1177/0011000010378895 Tajfel, H. (1981). Human groups and social categories: Studies in social psychology . Cambridge, England: Cambridge University Press. Taylor, L.M., Hume, I.R., and Welsh, N. (2010) Labelling and Self-esteem: The impact of using specific versus generic labels. Educational Psychology, 1, 1-12 Tesser, A. (1980) Self–esteem maintenance in family dynamics. Journal of Personality and Social Psychology 1980, 39(1), Tesser, A. (1988). Toward a self-evaluation maintenance model of social behavior. Advances in Experimental Social Psychology, 21 , 181–227. Toma, C. L., Hancock, J. T., &amp; Ellison, N. B. (2008). Separating fact from fiction: An examination of deceptive self-presentation in online dating profiles. Personality And Social Psychology Bulletin , 34 (8), 1023-1036. doi:10.1177/0146167208318067 Van Lange, P. A. M. (2008). Social comparison is basic to social psychology. American Journal of Psychology, 121 (1), 169–172. Vrugt, A., &amp; Koenis, S. (2002). Perceived self-efficacy, personal goals, social comparison, and scientific productivity. Applied Psychology: An International Review, 51 (4), 593–607. Wang, S., &amp; Stefanone, M. A. (2013). Showing off? Human mobility and the interplay of traits, self-disclosure, and Facebook check-ins. Social Science Computer Review , 31 (4), 437-457. White, K., &amp; Lehman, D. R. (2005). Culture and social comparison seeking: The role of self-motives. Personality and Social Psychology Bulletin, 31 , 232-242. Wiederhold, B. K. (2012). As parents invade Faceboo, teens tweet more. Cyberpsychology, Behavior, and Social Networking, 15(8), 385-386. Wosinska, W., Dabul, A. J., Whetstone-Dion, R., &amp; Cialdini, R. B. (1996). Self-presentational responses to success in the organization: The costs and benefits of modesty. Basic And Applied Social Psychology , 18 (2), 229-242. doi:10.1207/s15324834basp1802_8 Yakushko, O., Davidson, M., &amp; Williams, E.N. (2009). Identity Salience Model: A paradigm for integrating multiple identities in clinical practice. Psychotherapy:  Theory, Research, Practice, Training 46, 180-192. doi: 10.1037/a0016080 Yeung, K., &amp; Martin, J. (2003). The Looking Glass Self: An empirical test and elaboration. Social Forces , 81 (3), 843-879. doi:10.1353/sof.2003.0048 “ Students rushing renovated Kinnick Stadium ” by Foxhunt king is licensed under a CC BY-SA 3.0 licence. “ Ralph Lauren getting in his orange 997 GT3 RS ” by Damian Morys is licensed under a CC BY 2.0 licence. “ Helping the homeless ” by Ed Yourdon is licensed under a CC BY-SA 2.0 licence. “ Angry Old Lion 50D ” by koorosh B is licensed under a CC BY 2.0 licence. “ Brazilian Federal Highway Police ” by Fabio Pozzebom is licensed under a CC BY 3.0 BR licence. “ Mad dog ” by U.S. Air Force Photo by Josh Plueger is licensed under a CC0 1.0 licence. “ angry man 1 ” by Chris Gallagher is licensed under a CC BY-ND 2.0 licence. 13 3.4 Thinking Like a Social Psychologist about the Self Social psychologists think about the self in the same way that they think about any other social phenomenon—in terms of affect, behavior, and cognition, and in terms of the person-situation interaction. Our focus in this chapter has been on the cognitive, affective, and social aspects of the self and on the remarkable extent to which the self is created by the social situation in which we find ourselves. Take a moment and use this new knowledge about how social psychologists think about the self to consider your own self. Think carefully (and as fairly as you can) about how you think and feel about yourself. What constructs did you list when you tried the Twenty Statements Test in section 10, “ The Cognitive Self: The Self-Concept” ? Which of your physical characteristics were most accessible for you? And what about your social identities and your traits? Do you now have a better insight into the characteristics that are most important to you? Now consider the complexity and consistency of your self-concept. Do you think it would be better if it was more complex or consistent? Do you think you should seek out more dimensions to round it out? Or perhaps you feel that you already have a healthy and complex self-concept. In any case, you might want to keep this concept in mind as you think about yourself in the future. Self-esteem is one of the most important aspects of the self. Do you feel that you have relatively high or low self-esteem? What about other people you know? Does their level of self-esteem influence how you relate to them? And how do the aspects of your own self help (or potentially harm) your relations with others? And what about your relations with the social groups you belong to? Do you derive a lot of your self-esteem from your group memberships? Which groups provide you with social identities, and are there group memberships that may potentially not provide you with high social identity? When and how do you use self-presentation and reputation management in your daily life? Finally, take a moment and consider your online behavior. How do you think it both reflects, and influences how you see yourself? In sum, the self is the fundamental part of human psychology and will form the basis of all our analyses of social behavior. We have already seen this in previous topics, and will continue to see it going forward. 14 3.5 Chapter Summary The many and varied thoughts that we have about ourselves are stored in the variety of self-schemas that make up the cognitive part of the self—the self-concept. The self-concept is the most complex of all our schemas because it includes all of the images, desires, beliefs, feelings, and hopes that we have for and about ourselves. The self-concept can be measured by simply asking people to list the things that come to mind when they think about themselves or by using other techniques such as asking people to remember information related to the self. Research has found that some people have more complex and consistent selves than others do, and that having a variety of self-schemas is useful because the various aspects of the self help to improve our responses to the events that we experience. The self-concept can vary in its current accessibility. When the self-concept is highly accessible and therefore becomes the focus of our attention, the outcome is known as self-awareness or self-consciousness. Private self-consciousness occurs when we are introspective about our inner thoughts and feelings, whereas public self-consciousness occurs when we focus on our public image. It is important to be aware of variation in the accessibility of the aspects of the self-concept because the changes in our thoughts about the self have an important influence on our behavior. Increased self-awareness, for instance, can lead to increased perceptions of self-discrepancy, which occurs when we see our current self as not matching our ideal self. Self-esteem refers to the positive (high self-esteem) or negative (low self-esteem) evaluations that we make of ourselves. When we feel that we are viewed positively and held in esteem by others, we say that we have high social status. Having high social status creates positive self-esteem. The desire to see ourselves positively leads us to seek out, process, and remember information in a way that allows us to see ourselves even more positively. However, although the desire to self-enhance is a powerful motive, it is not the same in all cultures, and increases in self-esteem do not necessarily make us better or more effective people. An effective life involves an appropriate balance between the feeling and the cognitive parts of the self: we must always consider not only the positivity of our self-views but also the accuracy of our self-characterizations and the strength of our relationships with others. Although we learn about ourselves in part by examining our own behaviors, the self-concept and self-esteem are also determined through our interactions with others. The looking-glass self reflects how others’ views of us feed into the way we see ourselves. Social comparison occurs when we learn about our abilities and skills, about the appropriateness and validity of our opinions, and about our relative social status by comparing our own attitudes, beliefs, and behaviors with those of others. We use downward social comparison to create a positive image of ourselves through favorable comparisons with others who are worse off than we are. Through upward social comparison, we compare ourselves with others who are better off than we are. In some cases, we can bask in the reflected glory of others that we care about, but in other cases, upward comparison makes us feel inadequate. An important aspect of the self-concept that is derived from our social experiences is our social identity , which is turn is derived from our membership in social groups and our attachments to those groups. The tendency to attempt to present a positive image to others and thereby attempt to increase our social status is known as self-presentation, and it is a basic and natural part of everyday life. In the longer term, our concern to present ourselves in particular ways can become a more ongoing reputation management project, and we may end up building different reputations with different audiences. Some people are high self-monitors, more able and willing to self-present than are other people, and will shift their behavior across situations and audiences more often than low self-monitors, who try to act more consistently with their internal values. IV Chapter 4. Attitudes, Behavior, and Persuasion Chapter \n",
      "-----------\n",
      "Describe the concept of the looking-glass self and how it affects our self-concept.\n",
      "Explore the impact of the labeling bias, self-labeling, and internalized prejudice on people’s self-concepts, particularly in those from marginalized social groups.\n",
      "Define social comparison, and summarize how people use it to define their self-concepts and self-esteem.\n",
      "Give examples of the use of upward and downward social comparison and their influences on social cognition and affect.\n",
      "Explain the concept of social identity and why it is important to human behavior.\n",
      "Describe how self-evaluation maintenance theory helps to explain how we react when other people’s behaviors threaten our sense of self.\n",
      "Describe the concept of self-presentation and the various strategies we use to portray ourselves to others.\n",
      "Outline the concept of reputation management and how it relates to self-presentation.\n",
      "Discuss the individual-difference variable of self-monitoring and how it relates to the ability and desire to self-present.\n",
      "--------------------------\n",
      "Scientific research is a critical tool for successfully navigating our complex world. Without it, we would be forced to rely solely on intuition, other people’s authority, and blind luck. While many of us feel confident in our abilities to decipher and interact with the world around us, history is filled with examples of how very wrong we can be when we fail to recognize the need for evidence in supporting claims. At various times in history, we would have been certain that the sun revolved around a flat earth, that the earth’s continents did not move, and that mental illness was caused by possession. It is through systematic scientific research that we divest ourselves of our preconceived notions and superstitions and gain an objective understanding of ourselves and our world. Some of our ancestors, across the world and over the centuries, believed that trephination—the practice of making a hole in the skull, as shown here—allowed evil spirits to leave the body, thus curing mental illness and other disorders. (credit: “taiproject”/Flickr) The goal of all scientists is to better understand the world around them. Psychologists focus their attention on understanding behavior, as well as the cognitive (mental) and physiological (body) processes that underlie behavior. In contrast to other methods that people use to understand the behavior of others, such as intuition and personal experience, the hallmark of scientific research is that there is evidence to support a claim. Scientific knowledge is empirical : It is grounded in objective, tangible evidence that can be observed time and time again, regardless of who is observing. While behavior is observable, the mind is not. If someone is crying, we can see behavior. However, the reason for the behavior is more difficult to determine. Is the person crying due to being sad, in pain, or happy? Sometimes we can learn the reason for someone’s behavior by simply asking a question, like “Why are you crying?” However, there are situations in which an individual is either uncomfortable or unwilling to answer the question honestly, or is incapable of answering. For example, infants would not be able to explain why they are crying. In such circumstances, the psychologist must be creative in finding ways to better understand behavior. This chapter explores how scientific knowledge is generated, and how important that knowledge is in forming decisions in our personal lives and in the public domain. Use of Research Information Trying to determine which theories are and are not accepted by the scientific community can be difficult, especially in an area of research as broad as psychology. More than ever before, we have an incredible amount of information at our fingertips, and a simple internet search on any given research topic might result in a number of contradictory studies. In these cases, we are witnessing the scientific community going through the process of reaching a consensus, and it could be quite some time before a consensus emerges. For example, the hypothesized link between exposure to media violence and subsequent aggression has been debated in the scientific community for roughly 60 years. Even today, we will find detractors, but a consensus is building. Several professional organizations view media violence exposure as a risk factor for actual violence, including the American Medical Association, the American Psychiatric Association, and the American Psychological Association (American Academy of Pediatrics, American Academy of Child &amp; Adolescent Psychiatry, American Psychological Association, American Medical Association, American Academy of Family Physicians, American Psychiatric Association, 2000). In the meantime, we should strive to think critically about the information we encounter by exercising a degree of healthy skepticism. When someone makes a claim, we should examine the claim from a number of different perspectives: what is the expertise of the person making the claim, what might they gain if the claim is valid, does the claim seem justified given the evidence, and what do other researchers think of the claim? This is especially important when we consider how much information in advertising campaigns and on the internet claims to be based on “scientific evidence” when in actuality it is a belief or perspective of just a few individuals trying to sell a product or draw attention to their perspectives. We should be informed consumers of the information made available to us because decisions based on this information have significant consequences. One such consequence can be seen in politics and public policy. Imagine that you have been elected as the governor of your state. One of your responsibilities is to manage the state budget and determine how to best spend your constituents’ tax dollars. As the new governor, you need to decide whether to continue funding the D.A.R.E. (Drug Abuse Resistance Education) program in public schools. This program typically involves police officers coming into the classroom to educate students about the dangers of becoming involved with alcohol and other drugs. According to the D.A.R.E. website (www.dare.org), this program has been very popular since its inception in 1983, and it is currently operating in 75% of school districts in the United States and in more than 40 countries worldwide. Sounds like an easy decision, right? However, on closer review, you discover that the vast majority of research into this program consistently suggests that participation has little, if any, effect on whether or not someone uses alcohol or other drugs (Clayton, Cattarello, &amp; Johnstone, 1996; Ennett, Tobler, Ringwalt, &amp; Flewelling, 1994; Lynam et al., 1999; Ringwalt, Ennett, &amp; Holt, 1991). If you are committed to being a good steward of taxpayer money, will you fund this particular program, or will you try to find other programs that research has consistently demonstrated to be effective? The D.A.R.E. program continues to be popular in schools around the world despite research suggesting that it is ineffective. Watch this news report to learn more about some of the controversial issues surrounding the D.A.R.E. program: Science Scene: Does D.A.R.E. Work? A YouTube element has been excluded from this version of the text. You can view it online here: Ultimately, it is not just politicians who can benefit from using research in guiding their decisions. We all might look to research from time to time when making decisions in our lives. Imagine you just found out that a close friend has breast cancer or that one of your young relatives has recently been diagnosed with autism. In either case, you want to know which treatment options are most successful with the fewest side effects. How would you find that out? You would probably talk with your doctor and personally review the research that has been done on various treatment options—always with a critical eye to ensure that you are as informed as possible. In the end, research is what makes the difference between facts and opinions. Facts are observable realities, and opinions are personal judgments, conclusions, or attitudes that may or may not be accurate. In the scientific community, facts can be established only using evidence collected through empirical research. The Process of Scientific Research Scientific knowledge is advanced through a process known as the scientific method . Basically, ideas (in the form of theories and hypotheses) are tested against the real world (in the form of empirical observations), and those empirical observations lead to more ideas that are tested against the real world, and so on. In this sense, the scientific process is circular. The types of reasoning within the circle are called deductive and inductive. In deductive reasoning , ideas are tested against the empirical world; in inductive reasoning , empirical observations lead to new ideas. These processes are inseparable, like inhaling and exhaling, but different research approaches place different emphasis on the deductive and inductive aspects. Psychological research relies on both inductive and deductive reasoning. In the scientific context, deductive reasoning begins with a generalization—one hypothesis—that is then used to reach logical conclusions about the real world. If the hypothesis is correct, then the logical conclusions reached through deductive reasoning should also be correct. A deductive reasoning argument might go something like this: All living things require energy to survive (this would be your hypothesis). Ducks are living things. Therefore, ducks require energy to survive (logical conclusion). In this example, the hypothesis is correct; therefore, the conclusion is correct as well. Sometimes, however, an incorrect hypothesis may lead to a logical but incorrect conclusion. Consider this argument: all ducks are born with the ability to see. Quackers is a duck. Therefore, Quackers was born with the ability to see. Scientists use deductive reasoning to empirically test their hypotheses. Returning to the example of the ducks, researchers might design a study to test the hypothesis that if all living things require energy to survive, then ducks will be found to require energy to survive. Deductive reasoning starts with a generalization that is tested against real-world observations; however, inductive reasoning moves in the opposite direction. Inductive reasoning uses empirical observations to construct broad generalizations. Unlike deductive reasoning, conclusions drawn from inductive reasoning may or may not be correct, regardless of the observations on which they are based. For instance, you may notice that your favorite fruits—apples, bananas, and oranges—all grow on trees; therefore, you assume that all fruit must grow on trees. This would be an example of inductive reasoning, and, clearly, the existence of strawberries, blueberries, and kiwi demonstrate that this generalization is not correct despite it being based on a number of direct observations. Scientists use inductive reasoning to formulate theories, which in turn generate hypotheses that are tested with deductive reasoning. In the end, science involves both deductive and inductive processes. For example, case studies, which you will read about in the next section, are heavily weighted on the side of empirical observations. Thus, case studies are closely associated with inductive processes as researchers gather massive amounts of observations and seek interesting patterns (new ideas) in the data. Experimental research, on the other hand, puts great emphasis on deductive reasoning. Play this “Deal Me In” interactive card game to practice using inductive reasoning. We’ve stated that theories and hypotheses are ideas, but what sort of ideas are they, exactly? A theory is a well-developed set of ideas that propose an explanation for observed phenomena. Theories are repeatedly checked against the world, but they tend to be too complex to be tested all at once; instead, researchers create hypotheses to test specific aspects of a theory. A hypothesis is a testable prediction about how the world will behave if our idea is correct, and it is often worded as an if-then statement (e.g., if I study all night, I will get a passing grade on the test). The hypothesis is extremely important because it bridges the gap between the realm of ideas and the real world. As specific hypotheses are tested, theories are modified and refined to reflect and incorporate the result of these tests. The scientific method of research includes proposing hypotheses, conducting research, and creating or modifying theories based on results. [Scientific Method image description] To see how this process works, let’s consider a specific theory and a hypothesis that might be generated from that theory. As you’ll learn in a later chapter, the James-Lange theory of emotion asserts that emotional experience relies on the physiological arousal associated with the emotional state. If you walked out of your home and discovered a very aggressive snake waiting on your doorstep, your heart would begin to race and your stomach churn. According to the James-Lange theory, these physiological changes would result in your feeling of fear. A hypothesis that could be derived from this theory might be that a person who is unaware of the physiological arousal that the sight of the snake elicits will not feel fear. A scientific hypothesis is also falsifiable , or capable of being shown to be incorrect. Recall from the introductory chapter that Sigmund Freud had lots of interesting ideas to explain various human behaviors. However, a major criticism of Freud’s theories is that many of his ideas are not falsifiable; for example, it is impossible to imagine empirical observations that would disprove the existence of the id, the ego, and the superego—the three elements of personality described in Freud’s theories. Despite this, Freud’s theories are widely taught in introductory psychology texts because of their historical significance for personality psychology and psychotherapy, and these remain the root of all modern forms of therapy. Many of the specifics of (a) Freud’s theories, such as (b) his division of the mind into id, ego, and superego, have fallen out of favor in recent decades because they are not falsifiable. In broader strokes, his views set the stage for much of psychological thinking today, such as the unconscious nature of the majority of psychological processes. In contrast, the James-Lange theory does generate falsifiable hypotheses, such as the one described above. Some individuals who suffer significant injuries to their spinal columns are unable to feel the bodily changes that often accompany emotional experiences. Therefore, we could test the hypothesis by determining how emotional experiences differ between individuals who have the ability to detect these changes in their physiological arousal and those who do not. In fact, this research has been conducted and while the emotional experiences of people deprived of an awareness of their physiological arousal may be less intense, they still experience emotion (Chwalisz, Diener, &amp; Gallagher, 1988). Scientific research’s dependence on falsifiability allows for great confidence in the information that it produces. Typically, by the time information is accepted by the scientific community, it has been tested repeatedly. Visit this website to apply the scientific method and practice its steps by using them to solve a murder mystery, determine why a student is in trouble, and design an experiment to test house paint. Summary Scientists are engaged in explaining and understanding how the world around them works, and they are able to do so by coming up with theories that generate hypotheses that are testable and falsifiable. Theories that stand up to their tests are retained and refined, while those that do not are discarded or modified. In this way, research enables scientists to separate fact from simple opinion. Having good information generated from research aids in making wise decisions both in public policy and in our personal lives. Personal Application Questions Glossary Image Descriptions Scientific Method image description: A diagram showing the cycle of the scientific method: Theory. Use the theory to form a hypothesis. Hypothesis. Design a study to test the hypothesis. Research. Perform the research. Observation. Create or modify the theory and start over again. [Return to Scientific Method image] “ Science Scene: Does D.A.R.E. Work? ” by The Daily Texan . Standard YouTube License. 7 Approaches to Research \n",
      "-----------\n",
      "Explain how scientific research addresses questions about behavior\n",
      "Discuss how scientific research guides public policy\n",
      "Appreciate how scientific research can be important in making personal decisions\n",
      "--------------------------\n",
      "In this section, we look at how to write an APA-style empirical research report , an article that presents the results of one or more new studies. Recall that the standard sections of an empirical research report provide a kind of outline. Here we consider each of these sections in detail, including what information it contains, how that information is formatted and organized, and tips for writing each section. At the end of this section is a sample APA-style research report that illustrates many of these principles. Sections of a Research Report Title Page and Abstract An APA-style research report begins with a title page . The title is centred in the upper half of the page, with each important word capitalized. The title should clearly and concisely (in about 12 words or fewer) communicate the primary variables and research questions. This sometimes requires a main title followed by a subtitle that elaborates on the main title, in which case the main title and subtitle are separated by a colon. Here are some titles from recent issues of professional journals published by the American Psychological Association. Sex Differences in Coping Styles and Implications for Depressed Mood Effects of Aging and Divided Attention on Memory for Items and Their Contexts Computer-Assisted Cognitive Behavioural Therapy for Child Anxiety: Results of a Randomized Clinical Trial Virtual Driving and Risk Taking: Do Racing Games Increase Risk-Taking Cognitions, Affect, and Behaviour? Below the title are the authors’ names and, on the next line, their institutional affiliation—the university or other institution where the authors worked when they conducted the research. As we have already seen, the authors are listed in an order that reflects their contribution to the research. When multiple authors have made equal contributions to the research, they often list their names alphabetically or in a randomly determined order. It’s Soooo Cute! How Informal Should an Article Title Be? In some areas of psychology, the titles of many empirical research reports are informal in a way that is perhaps best described as “cute.” They usually take the form of a play on words or a well-known expression that relates to the topic under study. Here are some examples from recent issues of the Journal Psychological Science . “Smells Like Clean Spirit: Nonconscious Effects of Scent on Cognition and Behavior” “Time Crawls: The Temporal Resolution of Infants’ Visual Attention” “Scent of a Woman: Men’s Testosterone Responses to Olfactory Ovulation Cues” “Apocalypse Soon?: Dire Messages Reduce Belief in Global Warming by Contradicting Just-World Beliefs” “Serial vs. Parallel Processing: Sometimes They Look Like Tweedledum and Tweedledee but They Can (and Should) Be Distinguished” “How Do I Love Thee? Let Me Count the Words: The Social Effects of Expressive Writing” Individual researchers differ quite a bit in their preference for such titles. Some use them regularly, while others never use them. What might be some of the pros and cons of using cute article titles? For articles that are being submitted for publication, the title page also includes an author note that lists the authors’ full institutional affiliations, any acknowledgments the authors wish to make to agencies that funded the research or to colleagues who commented on it, and contact information for the authors. For student papers that are not being submitted for publication—including theses—author notes are generally not necessary. The abstract is a summary of the study. It is the second page of the manuscript and is headed with the word Abstract . The first line is not indented. The abstract presents the research question, a summary of the method, the basic results, and the most important conclusions. Because the abstract is usually limited to about 200 words, it can be a challenge to write a good one. Introduction The introduction begins on the third page of the manuscript. The heading at the top of this page is the full title of the manuscript, with each important word capitalized as on the title page. The introduction includes three distinct subsections, although these are typically not identified by separate headings. The opening introduces the research question and explains why it is interesting, the literature review discusses relevant previous research, and the closing restates the research question and comments on the method used to answer it. The Opening The opening , which is usually a paragraph or two in length, introduces the research question and explains why it is interesting. To capture the reader’s attention, researcher Daryl Bem recommends starting with general observations about the topic under study, expressed in ordinary language (not technical jargon)—observations that are about people and their behaviour (not about researchers or their research; Bem, 2003 ). Concrete examples are often very useful here. According to Bem, this would be a poor way to begin a research report: Festinger’s theory of cognitive dissonance received a great deal of attention during the latter part of the 20th century (p. 191) The following would be much better: The individual who holds two beliefs that are inconsistent with one another may feel uncomfortable. For example, the person who knows that he or she enjoys smoking but believes it to be unhealthy may experience discomfort arising from the inconsistency or disharmony between these two thoughts or cognitions. This feeling of discomfort was called cognitive dissonance by social psychologist Leon Festinger (1957), who suggested that individuals will be motivated to remove this dissonance in whatever way they can (p. 191). After capturing the reader’s attention, the opening should go on to introduce the research question and explain why it is interesting. Will the answer fill a gap in the literature? Will it provide a test of an important theory? Does it have practical implications? Giving readers a clear sense of what the research is about and why they should care about it will motivate them to continue reading the literature review—and will help them make sense of it. Breaking the Rules Researcher Larry Jacoby reported several studies showing that a word that people see or hear repeatedly can seem more familiar even when they do not recall the repetitions—and that this tendency is especially pronounced among older adults. He opened his article with the following humourous anecdote: A friend whose mother is suffering symptoms of Alzheimer’s disease (AD) tells the story of taking her mother to visit a nursing home, preliminary to her mother’s moving there. During an orientation meeting at the nursing home, the rules and regulations were explained, one of which regarded the dining room. The dining room was described as similar to a fine restaurant except that tipping was not required. The absence of tipping was a central theme in the orientation lecture, mentioned frequently to emphasize the quality of care along with the advantages of having paid in advance. At the end of the meeting, the friend’s mother was asked whether she had any questions. She replied that she only had one question: “Should I tip?” (Jacoby, 1999, p. 3) Although both humour and personal anecdotes are generally discouraged in APA-style writing, this example is a highly effective way to start because it both engages the reader and provides an excellent real-world example of the topic under study. The Literature Review Immediately after the opening comes the literature review , which describes relevant previous research on the topic and can be anywhere from several paragraphs to several pages in length. However, the literature review is not simply a list of past studies. Instead, it constitutes a kind of argument for why the research question is worth addressing. By the end of the literature review, readers should be convinced that the research question makes sense and that the present study is a logical next step in the ongoing research process. Like any effective argument, the literature review must have some kind of structure. For example, it might begin by describing a phenomenon in a general way along with several studies that demonstrate it, then describing two or more competing theories of the phenomenon, and finally presenting a hypothesis to test one or more of the theories. Or it might describe one phenomenon, then describe another phenomenon that seems inconsistent with the first one, then propose a theory that resolves the inconsistency, and finally present a hypothesis to test that theory. In applied research, it might describe a phenomenon or theory, then describe how that phenomenon or theory applies to some important real-world situation, and finally suggest a way to test whether it does, in fact, apply to that situation. Looking at the literature review in this way emphasizes a few things. First, it is extremely important to start with an outline of the main points that you want to make, organized in the order that you want to make them. The basic structure of your argument, then, should be apparent from the outline itself. Second, it is important to emphasize the structure of your argument in your writing. One way to do this is to begin the literature review by summarizing your argument even before you begin to make it. “In this article, I will describe two apparently contradictory phenomena, present a new theory that has the potential to resolve the apparent contradiction, and finally present a novel hypothesis to test the theory.” Another way is to open each paragraph with a sentence that summarizes the main point of the paragraph and links it to the preceding points. These opening sentences provide the “transitions” that many beginning researchers have difficulty with. Instead of beginning a paragraph by launching into a description of a previous study, such as “Williams (2004) found that…,” it is better to start by indicating something about why you are describing this particular study. Here are some simple examples: Another example of this phenomenon comes from the work of Williams (2004). Williams (2004) offers one explanation of this phenomenon. An alternative perspective has been provided by Williams (2004). We used a method based on the one used by Williams (2004). Finally, remember that your goal is to construct an argument for why your research question is interesting and worth addressing—not necessarily why your favourite answer to it is correct. In other words, your literature review must be balanced. If you want to emphasize the generality of a phenomenon, then of course you should discuss various studies that have demonstrated it. However, if there are other studies that have failed to demonstrate it, you should discuss them too. Or if you are proposing a new theory, then of course you should discuss findings that are consistent with that theory. However, if there are other findings that are inconsistent with it, again, you should discuss them too. It is acceptable to argue that the balance of the research supports the existence of a phenomenon or is consistent with a theory (and that is usually the best that researchers in psychology can hope for), but it is not acceptable to ignore contradictory evidence. Besides, a large part of what makes a research question interesting is uncertainty about its answer. The Closing The closing of the introduction—typically the final paragraph or two—usually includes two important elements. The first is a clear statement of the main research question or hypothesis. This statement tends to be more formal and precise than in the opening and is often expressed in terms of operational definitions of the key variables. The second is a brief overview of the method and some comment on its appropriateness. Here, for example, is how Darley and Latané (1968) concluded the introduction to their classic article on the bystander effect: These considerations lead to the hypothesis that the more bystanders to an emergency, the less likely, or the more slowly, any one bystander will intervene to provide aid. To test this proposition it would be necessary to create a situation in which a realistic “emergency” could plausibly occur. Each subject should also be blocked from communicating with others to prevent his getting information about their behaviour during the emergency. Finally, the experimental situation should allow for the assessment of the speed and frequency of the subjects’ reaction to the emergency. The experiment reported below attempted to fulfill these conditions. (p. 378) Thus the introduction leads smoothly into the next major section of the article—the method section. Method The method section is where you describe how you conducted your study. An important principle for writing a method section is that it should be clear and detailed enough that other researchers could replicate the study by following your “recipe.” This means that it must describe all the important elements of the study—basic demographic characteristics of the participants, how they were recruited, whether they were randomly assigned, how the variables were manipulated or measured, how counterbalancing was accomplished, and so on. At the same time, it should avoid irrelevant details such as the fact that the study was conducted in Classroom 37B of the Industrial Technology Building or that the questionnaire was double-sided and completed using pencils. The method section begins immediately after the introduction ends with the heading “Method” (not “Methods”) centred on the page. Immediately after this is the subheading “Participants,” left justified and in italics. The participants subsection indicates how many participants there were, the number of women and men, some indication of their age, other demographics that may be relevant to the study, and how they were recruited, including any incentives given for participation. Figure 11.1 Three Ways of Organizing an APA-Style Method [Long Description] After the participants section, the structure can vary a bit. Figure 11.1 shows three common approaches. In the first, the participants section is followed by a design and procedure subsection, which describes the rest of the method. This works well for methods that are relatively simple and can be described adequately in a few paragraphs. In the second approach, the participants section is followed by separate design and procedure subsections. This works well when both the design and the procedure are relatively complicated and each requires multiple paragraphs. What is the difference between design and procedure? The design of a study is its overall structure. What were the independent and dependent variables? Was the independent variable manipulated, and if so, was it manipulated between or within subjects? How were the variables operationally defined? The procedure is how the study was carried out. It often works well to describe the procedure in terms of what the participants did rather than what the researchers did. For example, the participants gave their informed consent, read a set of instructions, completed a block of four practice trials, completed a block of 20 test trials, completed two questionnaires, and were debriefed and excused. In the third basic way to organize a method section, the participants subsection is followed by a materials subsection before the design and procedure subsections. This works well when there are complicated materials to describe. This might mean multiple questionnaires, written vignettes that participants read and respond to, perceptual stimuli, and so on. The heading of this subsection can be modified to reflect its content. Instead of “Materials,” it can be “Questionnaires,” “Stimuli,” and so on. Results The results section is where you present the main results of the study, including the results of the statistical analyses. Although it does not include the raw data—individual participants’ responses or scores—researchers should save their raw data and make them available to other researchers who request them. Several journals now encourage the open sharing of raw data online. Although there are no standard subsections, it is still important for the results section to be logically organized. Typically it begins with certain preliminary issues. One is whether any participants or responses were excluded from the analyses and why. The rationale for excluding data should be described clearly so that other researchers can decide whether it is appropriate. A second preliminary issue is how multiple responses were combined to produce the primary variables in the analyses. For example, if participants rated the attractiveness of 20 stimulus people, you might have to explain that you began by computing the mean attractiveness rating for each participant. Or if they recalled as many items as they could from study list of 20 words, did you count the number correctly recalled, compute the percentage correctly recalled, or perhaps compute the number correct minus the number incorrect? A third preliminary issue is the reliability of the measures. This is where you would present test-retest correlations, Cronbach’s α, or other statistics to show that the measures are consistent across time and across items. A final preliminary issue is whether the manipulation was successful. This is where you would report the results of any manipulation checks. The results section should then tackle the primary research questions, one at a time. Again, there should be a clear organization. One approach would be to answer the most general questions and then proceed to answer more specific ones. Another would be to answer the main question first and then to answer secondary ones. Regardless, Bem (2003) suggests the following basic structure for discussing each new result: Remind the reader of the research question. Give the answer to the research question in words. Present the relevant statistics. Qualify the answer if necessary. Summarize the result. Notice that only Step 3 necessarily involves numbers. The rest of the steps involve presenting the research question and the answer to it in words. In fact, the basic results should be clear even to a reader who skips over the numbers. Discussion The discussion is the last major section of the research report. Discussions usually consist of some combination of the following elements: Summary of the research Theoretical implications Practical implications Limitations Suggestions for future research The discussion typically begins with a summary of the study that provides a clear answer to the research question. In a short report with a single study, this might require no more than a sentence. In a longer report with multiple studies, it might require a paragraph or even two. The summary is often followed by a discussion of the theoretical implications of the research. Do the results provide support for any existing theories? If not, how can they be explained? Although you do not have to provide a definitive explanation or detailed theory for your results, you at least need to outline one or more possible explanations. In applied research—and often in basic research—there is also some discussion of the practical implications of the research. How can the results be used, and by whom, to accomplish some real-world goal? The theoretical and practical implications are often followed by a discussion of the study’s limitations. Perhaps there are problems with its internal or external validity. Perhaps the manipulation was not very effective or the measures not very reliable. Perhaps there is some evidence that participants did not fully understand their task or that they were suspicious of the intent of the researchers. Now is the time to discuss these issues and how they might have affected the results. But do not overdo it. All studies have limitations, and most readers will understand that a different sample or different measures might have produced different results. Unless there is good reason to think they would have, however, there is no reason to mention these routine issues. Instead, pick two or three limitations that seem like they could have influenced the results, explain how they could have influenced the results, and suggest ways to deal with them. Most discussions end with some suggestions for future research. If the study did not satisfactorily answer the original research question, what will it take to do so? What new research questions has the study raised? This part of the discussion, however, is not just a list of new questions. It is a discussion of two or three of the most important unresolved issues. This means identifying and clarifying each question, suggesting some alternative answers, and even suggesting ways they could be studied. Finally, some researchers are quite good at ending their articles with a sweeping or thought-provoking conclusion. Darley and Latané (1968) , for example, ended their article on the bystander effect by discussing the idea that whether people help others may depend more on the situation than on their personalities. Their final sentence is, “If people understand the situational forces that can make them hesitate to intervene, they may better overcome them” (p. 383). However, this kind of ending can be difficult to pull off. It can sound overreaching or just banal and end up detracting from the overall impact of the article. It is often better simply to end when you have made your final point (although you should avoid ending on a limitation). References The references section begins on a new page with the heading “References” centred at the top of the page. All references cited in the text are then listed in the format presented earlier. They are listed alphabetically by the last name of the first author. If two sources have the same first author, they are listed alphabetically by the last name of the second author. If all the authors are the same, then they are listed chronologically by the year of publication. Everything in the reference list is double-spaced both within and between references. Appendices, Tables, and Figures Appendices, tables, and figures come after the references. An appendix is appropriate for supplemental material that would interrupt the flow of the research report if it were presented within any of the major sections. An appendix could be used to present lists of stimulus words, questionnaire items, detailed descriptions of special equipment or unusual statistical analyses, or references to the studies that are included in a meta-analysis. Each appendix begins on a new page. If there is only one, the heading is “Appendix,” centred at the top of the page. If there is more than one, the headings are “Appendix A,” “Appendix B,” and so on, and they appear in the order they were first mentioned in the text of the report. After any appendices come tables and then figures. Tables and figures are both used to present results. Figures can also be used to illustrate theories (e.g., in the form of a flowchart), display stimuli, outline procedures, and present many other kinds of information. Each table and figure appears on its own page. Tables are numbered in the order that they are first mentioned in the text (“Table 1,” “Table 2,” and so on). Figures are numbered the same way (“Figure 1,” “Figure 2,” and so on). A brief explanatory title, with the important words capitalized, appears above each table. Each figure is given a brief explanatory caption, where (aside from proper nouns or names) only the first word of each sentence is capitalized. More details on preparing APA-style tables and figures are presented later in the book. Sample APA-Style Research Report Figures 11.2, 11.3, 11.4, and 11.5 show some sample pages from an APA-style empirical research report originally written by undergraduate student Tomoe Suyama at California State University, Fresno. The main purpose of these figures is to illustrate the basic organization and formatting of an APA-style empirical research report, although many high-level and low-level style conventions can be seen here too. Figure 11.2 Title Page and Abstract. This student paper does not include the author note on the title page. The abstract appears on its own page. Figure 11.3 Introduction and Method. Note that the introduction is headed with the full title, and the method section begins immediately after the introduction ends. Figure 11.4 Results and Discussion. The discussion begins immediately after the results section ends. Figure 11.5 References and Figure. If there were appendices or tables, they would come before the figure. Key Takeaways An APA-style empirical research report consists of several standard sections. The main ones are the abstract, introduction, method, results, discussion, and references. The introduction consists of an opening that presents the research question, a literature review that describes previous research on the topic, and a closing that restates the research question and comments on the method. The literature review constitutes an argument for why the current study is worth doing. The method section describes the method in enough detail that another researcher could replicate the study. At a minimum, it consists of a participants subsection and a design and procedure subsection. The results section describes the results in an organized fashion. Each primary result is presented in terms of statistical results but also explained in words. The discussion typically summarizes the study, discusses theoretical and practical implications and limitations of the study, and offers suggestions for further research. Long Descriptions Figure 11.1 long description: Table showing three ways of organizing an APA-style method section. In the simple method, there are two subheadings: “Participants” (which might begin “The participants were…”) and “Design and procedure” (which might begin “There were three conditions…”). In the typical method, there are three subheadings: “Participants” (“The participants were…”), “Design” (“There were three conditions…”), and “Procedure” (“Participants viewed each stimulus on the computer screen…”). In the complex method, there are four subheadings: “Participants” (“The participants were…”), “Materials” (“The stimuli were…”), “Design” (“There were three conditions…”), and “Procedure” (“Participants viewed each stimulus on the computer screen…”). [Return to Figure 11.1] Bem, D. J. (2003). Writing the empirical journal article. In J. M. Darley, M. P. Zanna, &amp; H. R. Roediger III (Eds.), The compleat academic: A practical guide for the beginning social scientist (2nd ed.). Washington, DC: American Psychological Association. Darley, J. M., &amp; Latané, B. (1968). Bystander intervention in emergencies: Diffusion of responsibility. Journal of Personality and Social Psychology, 4 , 377–383. Bem, D. J. (2003). Writing the empirical journal article. In J. M. Darley, M. P. Zanna, &amp; H. R. Roediger III (Eds.), The compleat academic: A practical guide for the beginning social scientist (2nd ed.). Washington, DC: American Psychological Association. Darley, J. M., &amp; Latané, B. (1968). Bystander intervention in emergencies: Diffusion of responsibility. Journal of Personality and Social Psychology, 4 , 377–383. 35 Other Presentation Formats \n",
      "-----------\n",
      "Identify the major sections of an APA-style research report and the basic contents of each section.\n",
      "Plan and write an effective APA-style research report.\n",
      "--------------------------\n",
      "Figure 11.1 T Longboat, the Canadian runner Standing (HS85-10-18314) by Canadian Copyright Collection, Picturing Canada Project, British Library is in the public domain . 140 11.2 Environment and Colonialism Figure 11.2 The Sinixt people of the Arrow Lakes controlled salmon fisheries along the Columbia River system, including this site at Fort Colville in what is now Washington State. Epidemics, ranching, mining, industrial fisheries, and hydroelectric projects reduced their numbers to such an extent that in 1956 they were declared “extinct” by Ottawa, much to the chagrin of the Sinixt still living in BC. One of the more subtle features of colonialism is the way in which it creates environments that favour newcomers over natives. NASA defines terraforming — a staple of many science-fiction movies — as “the process of transforming a hostile environment into one suitable for human life.” Mars Team Online, accessed February 1, 2016, . But what kind of “human life”? If it’s European human life, extensive grazing lands will be required for their dairy animals and meat herds, and even larger territories will be required for grain production and a variety of edible and non-edible crops that include tobacco and cotton, among others. European societies effectively terraformed North America to make it more amenable to their familiar and preferred food sources. By doing so, the kinds of animals and plants on which innumerable generations of Aboriginal peoples survived were reduced, removed, or eliminated. Bison herds, salal berries, camas roots, and many other resources were chased off, burned away, or ploughed under to make way for beef cattle, strawberries, and potatoes. This occurred in small plots across New France and British North America before 1867, and in the post-Confederation years, the wholesale transformation of the Prairie West under the plough is one of the most rapid and enormous examples of environmental colonialism in history. Accomplishing this required a reorganization of the land itself (into lots), the addition of modern-era infrastructure (roads, rails, airports), and the development of energy sources to keep this new economic order moving. From the mid-century to the present, hydroelectricity projects have had the greatest impact on indigenous populations. The Columbia and Peace River projects in British Columbia, Churchill Falls in Labrador, and the James Bay dams in northern Quebec have flooded more than a million hectares of land. There have been cases (BC’s Columbia Valley system, for example) where Euro-Canadians have been displaced, but these are the exceptions that prove the rule. Mostly “native land” has been terraformed so as to be unusable for anything other than the production of electricity. Figure 11.3 By 1900 bison herds were virtually extinct, and their rangeland was being converted to wheat fields. Sometimes these changes have been less immediate but no less disastrous for Aboriginal economies and communities. The commercial salmon fishery in Georgia Strait (aka: the Salish Sea) in the early part of the 20th century plundered the sockeye and spring runs so aggressively that fewer and fewer spawning fish made it into the Interior along the Fraser and Thompson River systems. Communities that relied on these resources, and which had fewer fallback alternatives, suffered from an industrialized fishery hundreds of miles away. However, the situation could be worse: it is thought that the Sacramento River in California was the largest salmon spawning ground on the west coast of North America in the 19 th century, but today, the native fish are as good as extinct. The loss of resources like salmon or bison is often used as a reason to relocate native communities. Having terraformed Canada to suit the needs of the Euro-Canadian food and economic cultures, Canadian administrators were tasked with finding spaces where alienated native people could be huddled together with alternative resources or services delivered from “the south.” Thus, relocations and their consequent economic marginalization became common themes in Aboriginal history in the 20th century. Environmental historian Sean Kheraj (York University) describes how one mammal species bounced back in a Europeanized environment. An interactive or media element has been excluded from this version of the text. You can view it online here: Key Points Aboriginal people experienced the arrival Euro-Canadian agriculture and other industries as a process that alienated land and food resources, as well as traditional spaces with more complex meanings. European food cultures have been historically incompatible with Aboriginal food resources. The mega-projects of the 20th century displaced permanently large numbers of Aboriginal peoples by utterly destroying their landscapes. Figure 11.2 PaulKane-BushCamp-ROM by Captmondo is in the public domain . Figure 11.3 Herd of buffaloes in the National Park, Banff North West Territories, Canada Photo B (HS85-10-11286) by “Picturing Canada Project” of the British Library is in the public domain . 141 11.3 Natives by the Numbers Figure 11.4 This is a strange pastiche from a pre-Photoshop era. What “The Evening of his Race” conveys, however, is the belief of many non-Aboriginals that First Nations’ days were numbered. In the 19th century, Karl Marx predicted the withering away of the state, and John A. Macdonald and his contemporaries predicted the withering away of Aboriginal peoples. Many non-Aboriginal people anticipated that it would be a matter of only a few generations until the First Nations of Canada ceased to be. Some Native people would sacrifice their status and be assimilated into the mainstream of Canadian society, but the bulk would simply perish. Viewed in this light, it is necessary to understand the initiatives like the treaties, reserves, and the industrial schools as temporary measures that would not be needed for long. Why invest heavily in an educational system that won’t be necessary in 20 years? From where did this expectation of a vanishing population arise? Although the mid-19th century saw an improved understanding of infectious diseases, it didn’t do much to stop their spread. Germ theory was just beginning to gain a toehold, and the prevention and cure of some illnesses was coming within reach. The Euro-Canadian population would experience enormous benefits from this revolution in medical science, but Aboriginal peoples did not. Indeed, the non-Aboriginals tasked with the guardianship role envisioned by Ottawa were often misguided in their understanding of how health sciences operated. Missionaries in the mid- and late-19th century debated the health advantages of intermarriage between Aboriginal peoples and non-Natives. According to one historian, the Moravian Church in Labrador during the 1860s “began to sanction intermarriage on the grounds that European blood, with its resistance to Western diseases, might protect the Inuit from extinction.” Lynne D. Fitzhugh, The Labradorians : Voices from the Land of Cain (St. John’s, NF: Breakwater, 1999), 250-251. It certainly didn’t make much difference elsewhere. Exotic diseases were still having a severe impact on Aboriginal populations, even where there had been decades of intermarriage. Smallpox was by no means done at the end of the 19th century; as recently as 1862-1863, the last great smallpox epidemic burned through British Columbian Aboriginal populations, claiming upwards of 20,000 lives. The Haida, to take one specific case, numbered in excess of 8,400 in 1840 and barely 1,600 in 1881; the Heiltsuk, to take another, were reckoned to total more than 2,000 in 1835 and only 204 in 1890. The loss of access to resources that occurred around the same time on the West Coast and the plains, in particular as settler societies arrived, reduced Aboriginal peoples’ access to traditional foods, and thus poverty’s grip intensified and Aboriginal people became malnourished. This cycle was repeated for much of the next century: vulnerability led to death; deaths led to dispossession; dispossession created greater vulnerability; and so on. An Overview Canadians’ understanding of Aboriginal population numbers is somewhat akin to looking through the wrong end of the telescope. Resettlement of the Prairies and British Columbia occurred when native numbers were already slashed. However, historians disagree over the pre-contact demography of Canada. Only a few years ago, scholars spoke with confidence of a probable 100,000 Aboriginals in what became Canada, but now moderate estimates suggests that there were three to five times that number in the Pacific Northwest alone. By 1867, however, the total number of First Nations was about 125,000, including roughly 10,000 Métis in the West and 2,000 Inuit in the North. These numbers were not stable. Aboriginal demographics worsened up until the 1920s. Population numbers bottomed out — reached their nadir — in most communities sometime between the 1890s and the interwar era, and then began a slow but steady recovery. From 113,724 in 1921, the total more than doubled by 1951 and surpassed half a million in 1971. Statistics Canada, Historical Statistics of Canada , 2nd ed., ed. F. H. Leacy (Ottawa, ON: Statistics Canada, 1983), A154-184. The 1996 Royal Commission on Aboriginal Peoples used a more restrictive definition of Aboriginal but, even so, it observed population increases of 42% from 1961 to 1971, 57% from 1971 to 1981, and nearly 47% from 1981 to 1991. Lance W. Roberts, Rodney A. Clifton, Barry Ferguson, Karen Kampen, and Simon Langlois, eds. Recent Social Trends in Canada, 1960-2000 (Montreal and Kingston: McGill-Queen’s University Press, 2005), 32. This 20th century turn-around was fuelled by high fertility rates and came in the face of terrible health conditions. Even at the end of the 20th century, by which time the fertility transition saw overall Canadian fertility drop to below 2.1 births per woman (which is to say, below replacement levels), it was comfortably in the 3.0 range on reserves. In the 1960s, the Aboriginal crude birth rate stood at 47 per 1,000 population, falling to 28 per 1,000 by 1980, and rebounding a little to 29.5 in 1991. Juhee Suwal and Frank Trovato, “Canadian Aboriginal Fertility,” Canadian Studies in Population 25, no. 1 (1998): 75. Aboriginal fertility rates have resisted global and Canadian trends toward smaller families in part because of socio-economic factors: educational attainment — for mothers in particular — is a strong predictor of life-time fertility and, generally, Aboriginal females have had fewer opportunities in this respect than non-Aboriginal women. Poverty, artificial and racist barriers to secondary education, and cultural disinclinations to stay in school (partly a product of the dismal record of residential schools) contributed to higher fertility throughout the 20th century and into the new millennium. Having more babies, however, is only part of the equation. While there were additions (few of which, incidentally, came from immigration — unlike in a newcomer society), there were also significant subtractions. Poverty and malnutrition, along with overcrowding on reserves, poor state-provided housing, and cramped living conditions among children in residential schools were ideal circumstances for the spread of epidemic tuberculosis (TB) . Well-established within Aboriginal communities in the East by 1800, TB spread to the West Coast in the early 19th century, the Plains during the railway boom, the sub-Arctic in the early 20th century, and the Arctic soon thereafter. Mortality rates were at record levels. Tuberculosis is more conventionally known as a disease associated with rapid urbanization, tenement housing, and slums, but its toll in industrializing Europe was surpassed by rural, isolated Aboriginal communities. Fully 700 per 100,000 population died in First Nations communities in the 1930s and 1940s and, even though this ranks as one of the worst rates recorded, it is utterly eclipsed by the 8,000 per 100,000 mortality recorded in residential schools. \"TB and Aboriginal People,\" Canadian Public Health Association, accessed February 11, 2016, . By the 1950s, the TB epidemic among Inuit had affected a third of the population, many of whom were sent south for treatment (that included surgical draining of the lungs and the removal of ribs). It was not until advances in antibiotics and specifically the development of streptomycin in the mid-1950s that mortality rates fell among Aboriginal peoples (the rest of Canadian society already had experienced enough socio-economic improvements to reduce its mortality rates). Removal and resettlement confounds any effort at a continuous demography of Aboriginal peoples. Although the First Nations that signed (“took”) treaties had the expectation that the Canadians would provide medicine and would exercise a “guardian”-like role, the colonial authorities proved incapable of settling on a consistent definition of aboriginal . Repeated efforts on the part of Canada to reduce its obligations produced fluid categories and a shell-and-pea approach to counting people in Aboriginal communities. Doing so left Aboriginal peoples exposed to health crises and, from the demographer’s perspective, continues to vex any understanding of the population history of Aboriginal peoples. Status and non-Status categories make matters slippery enough, but Métis self-identification compounds things considerably. From a fraction of the total in the pre-WWII period, Métis, as a share of the Aboriginal total, have leapt to 32%. Statistics Canada, Aboriginal Peoples in Canada: First Nations People, Metis and Inuit, National Household Survey, 2011, Catalogue no. 99-011-X2011001 (Ottawa: Minister of Industry, 2013): 6. Changes to the legal definition of Status and the reinstatement of Aboriginal women and their children as Status Indians beginning in 1985 gave a major boost to Aboriginal numbers and demonstrates: a) the arbitrariness of this census category, b) the way it was used by government to give the false impression of declining numbers, and c) a sense of how badly undercounted Aboriginal populations may have been in the 100 years after the Indian Act . Other significant changes include growth in urban Aboriginal numbers. Winnipeg’s Aboriginal population, to take one example, quadrupled from 1985 to 2010, rising to 10% of the city’s total population. Indigenous and Northern Affairs Canada, “Fact Sheet - Urban Aboriginal Population in Canada,” accessed February 11, 2016, . In the cities as well as in rural areas, this population continues to be young: roughly one-quarter of the Aboriginal population is under 15 years of age, which reflects the high fertility rates that have pulled Aboriginal numbers up from the 1920s nadir levels. It also reflects the high rates of morbidity and lower life expectancies of Aboriginal people. In 1975 Aboriginal males had a projected life expectancy of 59.2 years, whereas Canadian males generally were at 70.3 years. The gap closed significantly by 2000 to 69.5 and 76.0 years respectively, but the distribution of elders is still starkly different: non-Aboriginals over 75 years of age constitute close to 6% of the non-Aboriginal population, whereas Aboriginal elders constitute less than 1% of their population. Métis Populations The significant Métis presence in the West was almost overwhelmed after the defeat of the Northwest Rebellion in 1885. Just as the Canadianization of Red River squeezed the Métis out of southern Manitoba and into the Saskatchewan River Valleys, the hanging of Riel was followed with further movement to the north and west. The Métis diaspora retained roots in what would become the province of Saskatchewan, although greater and greater numbers moved into Alberta. In 1900 Treaty 8 provided land grants to Métis in the north, but poverty obliged many to sacrifice those gains to make some ready cash. At this time, the Métis occupied an administrative and legal space that was neither as good nor as bad as that of First Nations. They had little in the way of Treaty rights, but they were not as heavily administered as Reserve bands. Racial discrimination was an increasing concern as the category of “half-breed” — once almost a neutral descriptor — became a term of contempt. The ongoing Métis relationship with the Catholic Church and allies in Quebec, however, was both fortuitous and a strategy for survival in the emergent Canadian nation. Openness to supporters and reinforcements in fact brought changes to the Métis in the 20th century. In prairie communities where the presence of Métis francophones and the clergy attracted Québecois settlers, the Métis’ Canadien traditions and French identity became of greater importance; however, in those areas where connections with the Cree were stronger, an Aboriginal identity became more apparent. These were only two of several emergent divisions across Métis communities in the West. The “New Nation” struggled with definitions that made it simultaneously more and less inclusive. Was being “Métis” a category into which anyone of mixed ancestry might fit or was it a hybridized culture that was more than the sum of its Plains Native and Franco-Canadien parts? Beginning in the 1930s, Métis organizations emerged and gained traction politically. Although membership inevitably included individuals who had Indian Status, most Métis do not. For this reason, many Métis have not viewed organizations like the Native Indian Brotherhood bodies as sufficiently representative of Métis interests. Nevertheless, inclusion in Section 35 of the Constitution Act of 1982 as “Aboriginal” peoples with legally entrenched rights has presented an opportunity. There are now more than 400,000 Canadians who identify as Métis. The Return of the Native Bulked up Métis numbers are only part of the current picture. In the 10 years after 1996, the number of Canadians who identify themselves as Aboriginal in the census expanded from slightly under 800,000 to 1,172,790. What happened after 1996? The changes that Bill C-31 (1985) introduced with respect to Status took a while to process, but led inexorably to “identity mobility.” Lisa Monchalin, The Colonial Problem: An Indigenous Perspective on Crime and Punishment in Canada (Toronto, ON: University of Toronto Press, 2016), 8-9. This was coupled with a growing emphasis on Aboriginal community recovery, enthusiasm for reviving languages, and greater public awareness of First Nations issues. Although the law and colonialism had dissuaded Aboriginals from claiming this identity in the past, the circumstances had changed. The resumption of the mandatory long-form census in 2016 will likely reveal a continuing growth curve, although possibly less dramatic. The reappearance of Aboriginal numbers at the millennium may well have been a one-shot increase, although fertility rates remain outstanding. Key Points Aboriginal populations were declining severely until they reached their nadir in the years between 1890 and 1930. Depopulation, which was accelerating in the late 19th century and made worse by TB in the early 20th, impacted Aboriginal peoples’ view of colonization and Canada’s view of Native people. Accessing reliable numbers of Aboriginal populations after Confederation is complicated by categories like Status and non-Status , relocation projects, and differing understandings of who qualified as “Métis.” Population recovery in the 20th century has been aggressive, even though it has had to counter high mortality rates and low life expectancy rates. Aboriginal numbers in urban areas increased in the late 20th century as more First Nations, Inuit, and Métis people moved into cities and as those urban populations themselves experienced natural increase (that is, births over deaths). Figure 11.4 The evening of his race (HS85-10-27674) by “Picturing Canada Project” of the British Library is in the public domain . 142 11.4 Aboriginal – Newcomer Relations before Confederation Jennifer Pettit, Department of Humanities, Mount Royal University Relations between the Crown and Indigenous peoples in what is now Canada began hundreds of years ago and have been affected by both internal and external forces. These interactions have changed over time and continue to evolve today. While there were periods in which some have deemed the association a partnership, more often it has been exchanges that were largely characterized by myopic policies and actions by the British, and later Canadian federal government; a lack of consultation; and an absence of consent by Indigenous peoples — in short, Canada is built on colonialist foundations. Some, such as the recent Truth and Reconciliation Commission , have even described the government’s policies for Indigenous peoples as cultural genocide . Canada, Truth and Reconciliation Commission, “Honouring the Truth, Reconciling for the Future: Summary of the Final Report of the Truth and Reconciliation Commission of Canada,” last modified July 23, 2015, . In the words of historian Susan Neylan: …most Canadians have trouble regarding themselves as living in an Aboriginal nation or seeing how historical legacies have relevance for contemporary identities. However, scholars of Aboriginal History are well aware of how Canada was founded upon acts of resettlement and dispossession. The erasure of its original inhabitants and their histories is the byproduct of a persistent “settler myth” that views Aboriginal peoples as obstacles to, or in the least, passive players in the “real” history of non-Indigenous peoples, who are presumed to have dealt peacefully and benevolently with those Aboriginal societies. Susan Neylan, “Colonialism and Resettling British Columbia: Canadian Aboriginal Historiography, 1992–2012,” History Compass 11, no. 10 (2013): 833. This section and the three that follow trace the history of these dealings of the British and Canadian government with Indigenous peoples from just prior to Confederation up until and including more recent events such as political activism, land claims, confrontations such as Oka, and new movements such as Idle No More. Economic and Military Allies Historians such as J. R. Miller have described early interactions between Aboriginal peoples and non-Indigenous newcomers as an “era of cooperation” in which reciprocal relationships existed. See works such as J. R. Miller, Skyscrapers Hide the Heavens: A History of Indian-White Relations in Canada, 3rd ed. (Toronto: University of Toronto Press, 2000). These contacts began hundreds of years ago when Europeans began to travel to North America in search of resources such as fish and timber. Soon they discovered that furs, in particular beaver, was a profitable commodity. While the extent to which Indigenous groups became involved in the fur trade varied, many willingly and readily became “partners in furs,” since they too saw various benefits to being involved in the trade. See Daniel Francis and Toby Morantz, Partners in Fur: A History of the Fur Trade in Eastern James Bay, 1600-1870 (Montreal and Kingston: McGill-Queen’s University Press, 1983) and Robin Fisher, Contact &amp; Conflict: Indian-European Relations in British Columbia, 1774-1890 , 2nd ed. (Vancouver: University of British Columbia Press, 1992). However, in these early years, the British and French clashed over control of the trade and other events external to North America. Before long, Indigenous peoples were drawn into  various battles and were also encouraging the British and French to join with them as allies in their own conflicts. Cognizant of the value and importance of military alliances with Indigenous peoples, in 1755, the British government established the British Indian Department, which was divided into two parts: a Northern Department under Sir William Johnson (1715-1774) who was named Superintendent of Indian Affairs, and a second department that was to manage affairs with Indigenous peoples farther south. Both departments were under the jurisdiction of the Commander of the British Forces in North America. Shortly after the creation of the Indian Department, the Seven Years’ War broke out in which rivals Britain and France fought for control not only of what would become the country of Canada, but beyond on a global scale. The main goal of the Indian Department during these battles was to ensure that various Indigenous groups were allies, or at the very least remained neutral. In the end, the British would gain control of Canada from the French, and Indigenous peoples would officially fall under British imperial authority. The Royal Proclamation In 1763 shortly after the end of the Seven Years’ War, the British passed the Royal Proclamation that set aside a large territory west of the British-American Thirteen Colonies and that more importantly, also recognized inherent Indigenous land tenure rights or Aboriginal title to the land. The Proclamation set out a fiduciary or protector relationship in which the Crown would act as a trustee who would supposedly act in the best interests of Indigenous peoples, overseeing the policy that Aboriginal title could be extinguished only by treaty with the Crown. The Royal Proclamation also promised that Indigenous peoples would “not be molested or disturbed.” Alongside these changes, the Indian Department grew in size and complexity, in part, because of the failure of the Royal Proclamation to keep colonists off Indigenous lands, but primarily due to a series of other battles including the American Revolutionary War (1775-1783). Thus, the main goal of the British government remained to maintain Indigenous peoples as allies. The “Indian Problem” and Early Government and Church Solutions The end of the War of 1812 (1812-1815) initiated a new era of relations with Indigenous peoples. As the threat of future North American wars retreated, increasingly, Indigenous peoples were seen as a “problem.” See Noel Dyck, What is the Indian “Problem”: Tutelage and Resistance in Canadian Indian Administration (St. John’s, NF: Institute of Social and Economic Studies, 1991). This situation was exacerbated by the decline of the fur trade in some areas, growing demand for Indigenous land by settlers, and increasing costs of supplying presents to First Nations groups to ensure their loyalty. With costs rising and returns dwindling, the British government sought a new direction for their interactions with Indigenous peoples. Thus, in 1829 under Major General H.C. Darling, Superintendent of Indians, a new plan was proposed that would supposedly address the “Indian problem.” Darling proposed a plan to “civilize” Indigenous peoples by assimilating them into Euro-Canadian society. This plan would shape Canadian Indian administration thinking for many years. Whether or not this plan was assimilation or genocide has been debated, although assimilation did become a justification in Canada for colonialism. The plan to civilize and protect Indigenous peoples resulted in significant changes to the Indian Department in 1830, including moving control of the Department from the military to the civil arm of government. This new “civilization” plan sought to turn Indigenous peoples into self-sufficient Christian farmers who would integrate into settler society and no longer be a costly expense for the government. See Jennifer Pettit, “'To Christianize and Civilize': Native Industrial Schools in Canada” (PhD dissertation, University of Calgary, 1997). To keep up with the economic, technological, and social changes in the Canada, Indigenous peoples were to be converted to Christianity; taught to practice a trade (usually farming); and educated on how to live, act, and dress as Euro-Canadians. As a result, model farming communities such as the one at the Coldwater Narrows reserve near Lake Simcoe were built. In addition, treaties moved from a model of largely peace and friendship to treaties whose goal was land cession in which First Nations peoples would be placed on reserves. The government argued that this was for the protection of Indigenous peoples until they could assimilate or until they disappeared completely (what many at the time saw as an inevitability). It also, of course, helped clear the path for non-Indigenous settlement. Figure 11.5 The Mohawk Institute and Farm at Brantford, 1917. Government officials felt it would be best to begin “civilizing” at an early age, which would take place in schools in which children would be removed from the influences of their parents. While day schools existed, there was not yet a manual labour or industrial school system in place in which students would receive basic academic instruction and also be taught a trade. Soon, the first of these industrial schools, the Mohawk Institute , opened in Brantford, Ontario in the 1830s under the auspices of the New England Company. See Jennifer Pettit, “From Longhouse to Schoolhouse: The Mohawk Institute 1834-1970” (MA thesis, University of Western Ontario, 1993). While there would be an initial outlay to construct and maintain the schools, these costs were borne largely by the churches, and it was assumed that assimilation would happen quickly. Some officials such as Lieutenant-Governor Sir Francis Bond Head (1793-1875), however, argued in the mid-1830s that any attempts to assimilate Indigenous peoples were folly and that the Indigenous peoples of what is now Ontario should be gathered up and moved to Manitoulin Island. Bond Head’s plan failed to gain support, and the government forged ahead with Darling’s civilization plan instead. From the 1830s to the 1850s, the British government also undertook a number of investigations into Aboriginal affairs in the newly created united Province of Canada. As was the case up to this point, these inquiries were made without any consultation with Indigenous peoples. One of the earliest of these studies, the Bagot Commission, reported in 1844, argued that changes needed to be made to a number of areas including the management of Indigenous land. A number of Acts followed, including the Gradual Civilization Act (1857), which promoted voluntary enfranchisement and the gradual dissolution of reserve lands. Another significant change took place in 1860, when the British government transferred the control of Indian affairs to the Province of Canada. Key Points Pre-Conquest relations between Aboriginal nations and newcomers (principally French and British) could be described as military and economic alliances and collaborations. Beginning with the Royal Proclamation in 1763, Aboriginal title was recognized by the British regime at a time when military alliances with powerful indigenous communities were sought after. Military circumstances changed after 1815 and so too did the Euro-Canadian perspective on Aboriginal peoples. The phase that followed focused on assimilating Aboriginal peoples into the economic and cultural norms of Euro-Canadians. This process was known as “civilizing.” Figure 11.5 Mohawk Institute farm in Brantford, [Ont.] (Online MIKAN no.3309629) by John Boyd / Library and Archives Canada is in the public domain . 143 11.5 Aboriginal-Newcomer Relations since Confederation Jennifer Pettit, Department of Humanities, Mount Royal University Figure 11.6 A Mi’kmaq delegation waiting to meet with Governor General Marquess of Lorne in 1878. Additional attention to Canadian policy for Indigenous peoples came about as the result of Canadian Confederation in 1867. Section 91, Subsection 24 of the British North America Act made the federal government responsible for all matters related to Indigenous peoples, and made First Nations peoples into wards of the Federal Government. The portfolio of Indian Affairs was placed under the guidance of the Secretary of State and, despite some early failures, much of the earlier legislation and policies were maintained including the civilization plan, treaties, and the reserve system. Additionally, some new legislation was passed including the Enfranchisement Act (1869), which made enfranchisement compulsory in some cases (such as when an Indigenous woman married a non-Indigenous man), promoted individual land ownership, and granted the government the power to impose an elective band council system of governance. As had been the case in the past, these changes were made largely to benefit non-Indigenous society without consultation with First Nations peoples. The government was concerned with the territorial growth of Canada; acquiring land from the Hudson’s Bay Company in the West; creating the new provinces of Manitoba, British Columbia and Prince Edward Island; and creating an Indian Lands Branch in the new Department of the Interior in 1873. “Christianize and Civilize” The most significant piece of legislation in this period was the passage of the Indian Act of 1876. See John Leslie, The Historical Development of the Indian Act (Ottawa, ON: Treaties and Historical Research Centre, 1978). Consisting of 100 sections, the Indian Act consolidated earlier legislation and addressed a wide variety of areas concerning lands, status, and governance. At the core of the Act was the reinforcement of the policy of aggressive assimilation and colonization. This Act , among other things, defined who was and was not an “Indian” according to the government, described band election procedures, defined a band and reserve , and discussed the management of resources including timber and band monies. Invasive and paternalistic, the Indian Act ignored the diversity among Indigenous groups in Canada, and treated Indigenous peoples as children who required management. Made into wards of the state, Indigenous peoples were no longer autonomous according to the government. As was the case in the past, central to the Indian Act and new policies was the plan to separate Indigenous peoples from their land through a system of treaty-making and reserves, and increased farming instruction and schools for Indigenous children. This plan was particularly important in Western Canada to clear the way for settlers who were central to Prime Minister John A. Macdonald’s National Policy, one part of which was the settlement of the West through immigration (see Section 3.3 ). However, first, the government had to extinguish Indigenous title through a series of treaties signed in the early and mid-1870s. Given the changes brought about by the numbered treaties and the expanding importance of the Indian Affairs portfolio, in 1880, the Indian Branch of the Department of the Interior was turned into a separate department called the Department of Indian Affairs, although the Minister of the Interior continued to act as Superintendent-General of Indian Affairs and oversaw the new department. There would be much to focus on, including strengthening the civilization program through the promotion of farming instruction and schools. Key Points In 1867, the Dominion of Canada  inherited Britain’s responsibility for maintaining relations and honouring agreements made with Aboriginal peoples. Between the years 1867 and 1900, the policy of “civilization” continued, to which was added a greater focus on Christianization. The Indian Act (1876) took a “pan-Indian” view of Native peoples and created categories and processes that were both artificial and bureaucratic, which provided the means for aggressive colonization and displacement. Figure 11.6 Micmac Indians Waiting to Receive Lord Lorne, Halifax (Online MIKAN no.2839092) by Library and Archives Canada, Acc. No. 1984-45-1 is in the public domain . 144 11.6 Living with Treaties Keith Smith, Departments of History and First Nations Studies, Vancouver Island University Not unlike communities in Europe or elsewhere, the Indigenous peoples of North America confirmed access to resource sites, facilitated trade, resolved conflicts, settled alliances, and navigated the mass of other relations with their neighbours by negotiating agreements. When European newcomers found their way into Indigenous territories, they realized it was in their interest, and often necessary for their survival, to learn Indigenous treaty protocols and to fit themselves into Indigenous commercial networks. After these initial encounters, over time, treaty making changed in intent and content, but whether for military alliance, access to land and resources, or for some other reason, all of those involved understood that only agreements of this sort could protect the often divergent strategic, cultural, and economic interests of the treaty partners. On treaty making in Canada across time see J. R. Miller, Compact, Contract, Covenant: Aboriginal Treaty-Making in Canada (Toronto: University of Toronto Press, 2009). The significance of treaty making to the newcomers is evident in Britain’s Royal Proclamation (1763) that, in part, committed it and then Canada to gain the consent of Indigenous Nations before settling in their territories. This commitment led to several treaties on Canada’s West Coast, and in what became Ontario and southern Manitoba prior to 1867. Soon after Confederation, the treaty process continued with the negotiation of the so-called “numbered treaties,” the first seven of which were concluded between 1871 and 1877 and covered the southern region between Lake Superior and the Rocky Mountains. For its part, Canada was primarily concerned with the acquisition of land and the fulfillment of its promise to British Columbia for a transcontinental railway. First Nations, on the other hand, were generally interested in protecting their territories and resources from incursion, while at the same time ensuring their cultural survival and independence. For them, these treaties were peace treaties. As Piikani (Peigan) elder Cecile Many Guns (aka: Grassy Water) confirmed almost a century after the treaties, the intent was that there would be “no more fighting between anyone, everybody will be friends…. Everybody will be in peace.” Interview with Mrs. Cecile Many Guns conducted by Dila Provost and Albert Yellowhorn Sr., n.d. University of Regina, oURspace , From the perspective of the newcomers, the transfer of land stood above all other policy considerations, and the numbered treaties were presented as successful mechanisms by both politicians of the day and many later historians. However, it is becoming increasingly recognized that rather than representing everything that was agreed to, the written treaties are much more reflective of Canada’s goals and Euro-Canadian interpretations of treaty-making, and much less representative of the objectives of First Nations and of Indigenous understandings of treaty processes. Many of the arrangements that were presented and agreed to orally during treaty negotiations are absent or minimized in the text of the numbered treaties. Sarah Carter, Aboriginal People and Colonizers of Western Canada to 1900 (Toronto, ON: University of Toronto Press, 1999), 118-127. The actual meaning of these treaties remains in dispute among historians and in the courts. Reserves As a central provision of the numbered treaties , and where there were no treaties as Federal Government policy initiatives, isolated enclaves called Indian reserves were created to accommodate Indigenous people. The reserve system, as it developed in the mid to late 19th century, was meant as a temporary measure only, providing closed sites where missionaries and agents of the state could indoctrinate Indigenous populations in the economic, political, religious, and social conduct acceptable to settler Canada. Reserves offered residents refuge of sort from the various forms of discrimination they faced in the outside world, but to policy makers and church officials, they were laboratories of reform where residents could be observed and judged and where “Indian-ness” could be instructed, legislated, or coerced out of Indigenous people. Keith Smith, Liberalism, Surveillance, and Resistance: Indigenous Communities in Western Canada, 1877-1927 (Edmonton, AB: University of Athabasca Press, 2009), 50. On these fragments of ancestral territories, Indigenous residents held the right to occupancy only. Ownership and title remained in the hands of Canada. Figure 11.7 Medals were issued to Aboriginal signatories of the numbered treaties. This 1873 example was given to Muskeekee Eyineer, one of the Manitoban signatories to Treaty 3. Since non-Indigenous lawmakers took for themselves, even in treaty areas, absolute authority to decide who would own land, reserve size depended largely on local settler demand. Even in areas covered by the numbered treaties, reserve size was calculated differentially on the basis of between 160 and 640 acres per family of five, while in British Columbia, for example, 10 acres per family was established as the standard. These inequities, and the smaller average reserve land base in Canada compared to the United States, were recognized and challenged by Indigenous political movements such as the Allied Tribes of British Columbia during the First World War and Interwar period, but they have largely remained to the present day. Ibid., 132; Robert White-Harvey, “Reservation Geography and Restoration of Native Self-Government,” The Dalhousie Law Journal 17, no. 2 (1994): 588-589; Statement of the Allied Indian Tribes of British Columbia for the Government of British Columbia (Vancouver: Cowan &amp; Brookhouse, 1919) in LAC, RG 10, vol. 3821, file 59335, part 4A. Regardless of the original size of reserves, even these small tracts remaining to Indigenous people were often under threat. While the Federal Government restricted the ability of reserve communities to manage the lands they lived on, Canadian officials were more than willing to alienate reserve lands themselves to meet settler demands for mineral, forest, or agricultural lands; for the construction of transportation routes or military sites; or for a myriad of other purposes. While often, though not always, Indigenous agreement of a sort was sought, this consent was regularly acquired under circumstances that were at best questionable. Additionally, the sale of reserve lands was consistently presented as being in the long-term interests of the reserve communities, although it was railway and corporate executives and other members of the settler elite — including senior Department of Indian Affairs (DIA) and other public officials — who gained possession of the alienated reserve lands during the late 19th and early 20th centuries. Robert Cail, Land, Man and the Law: The Disposal of Crown Lands in British Columbia, 1871-1913 (Vancouver, BC: University of British Columbia Press, 1974), 14; Peggy Martin-McGuire, First Nation Land Surrenders on the Prairies, 1896-1911 (Ottawa, ON: Indian Claims Commission, 1998), 15-16, 42, 493-494, and 497-498. Some of these land sales continue to be the subject of land claims and court challenges. The contradictions here are apparent. While Canada presented its policies as beneficial to Indigenous peoples, and while it maintained that its goal was to remake reserve residents into farmers, the best agricultural land was the first to be removed from First Nations’ control. Even the right to use modern farming equipment and to participate in training programs, farm organizations, and wheat pools like their non-Native neighbours were curbed by Canadian officials. Further, amendments were made to the Indian Act soon after its creation, and more strictly applied after the mid-1880s, whereby reserve residents were required to secure a permit before selling or giving away any goods located or produced on reserves or by reserve residents. While some, like Cree elder John Tootoosis (1899-1989), recognized the positive aspects of the permit system as a means to protect First Nations vendors and consumers, he nonetheless saw it as a “loaded gun” that was, in the end, turned against those it was ostensibly designed to protect. Certainly, there was ongoing resistance to all of this from Indigenous communities, but for the most part, the protests were disregarded in Ottawa. Sarah Carter, Lost Harvests: Prairie Indian Reserve Farmers and Government Policy (Montreal and Kingston: McGill-Queen’s University Press, 1990), 253-258 and 156-158; Smith, Liberalism, Surveillance and Resistance , 99-103; Jean Goodwill and Norma Sluman, John Tootoosis (Winnipeg, MB: Pemmican Publications, 1984), 123-125. Restricting Movement and Cultural Practices Most Canadians are secure in their right to move about freely and practice whatever form of spirituality they choose, but in the late 19th and early 20th centuries, Canadian and church authorities went to some lengths to restrict both for those they defined as Indians . The kinds of activities allowed on ever-shrinking reserves were increasingly limited, restrictions were placed on movement, and cultural practices among reserve residents were policed and penalized. The suppression of liberty among Indigenous peoples was central to Canada’s Indian policy. The Pass System The confinement of Indigenous peoples to reserves was set in motion through the application of a matrix of laws, regulations, and policies meant to “elevate” reserve residents while advancing the interests of non-Indigenous settlers. In much of Canada, movement was limited through the vagrancy provisions of the Criminal Code or the restrictions against trespass in the Indian Act . However, in the region that became the prairie provinces, the most notorious and comprehensive element of the restrictive matrix was implemented through a Federal Government policy known as the pass system . Under this initiative, a reserve resident was required to first secure a written pass from their Indian agent if they wanted to visit family or friends in a nearby village; check on their children at a residential school; participate in a celebration or attend a cultural event in a neighbouring community; leave their reserve to hunt, fish, and collect resources; find paid employment; travel to urban centres; or leave the reserve for any other reason. This section on the pass system is drawn from Smith, Liberalism, Surveillance and Resistance , 60-77. According to Assiniboine Chief Dan Kennedy of the Carry the Kettle First Nation in Saskatchewan, “[t]he Indian reserve was a veritable concentration camp.” Dan Kennedy, Recollections of an Assiniboine Chief , ed. James R. Stevens (Toronto, ON: McClelland and Stewart, 1972), 87. Official correspondence from the decade before 1885 reveals that procedures were already in place and that there was a will at all levels of the D.I.A., the North-West Mounted Police, and political hierarchies, including Prime Minister John A. Macdonald himself, to restrict Indigenous movement in the West. The Northwest Resistance of 1885 provided the justification for the application of a comprehensive pass system in the Prairie West, regardless of whether individuals or their communities were part of the resistance. All of those involved in the implementation of the pass system understood that it had no basis in Canadian law. It was never included in the Indian Act or any other piece of Canadian legislation, which naturally put senior police officials in a difficult position. The regulations were at odds with settlers who relied on Indigenous labour and trade (and so opposed the restrictions), but high-ranking policemen also feared that they would be humiliated once Indigenous people recognized the pass system lacked a legal foundation and then chose not to comply with the policy. Generally, the NWMP/RNWMP/RCMP leadership preferred compliance by persuasion rather than by force, although individual officers were at times even more zealous than Indian agents, and chose to apply force when they felt it was necessary. Indigenous people naturally resisted their confinement to reserves and seem to have made little distinction between being persuaded to remain on, or return to, their reserves and being escorted back by a contingent of mounted policemen. They tended to choose to comply with the policy, or openly defy it, according their own judgment of the specific situation. There is textual evidence that passes continued to be issued until after World War I, and oral evidence that the pass system remained in operation into the mid-1930s at least. Even though Canada never had the capacity to forcibly restrict all off-reserve movement, the will of both the police and the D.I.A. to do what they could in this regard — regardless of the lack of legal foundation — is evident, even if some in the upper echelons of the police were sometimes uncomfortable. Cultural Restriction Figure 11.8 State and church combined to end Aboriginal cultural practices. Ceremonies were targeted, as were burial and mourning practices. By 1907 memorial poles were combined with headstones at Kitwanga as new forms are adopted and older ones persist. Not only were Indigenous people restricted in their right to move about freely, even in their traditional territories, but also spiritual practices that were fundamental to personal and community identity and well-being — and that had been practiced since time immemorial — were targeted for suppression. State and church officials alike were intolerant of these practices, which they regarded as alien and immoral. Canadian and religious authorities also recognized that spiritual systems were integral components of the cultural, political, economic, and social structures of Indigenous communities. To transform one, the others had to be reconfigured as well. Katherine Pettipas, Severing the Ties that Bind: Government Repression of Indigenous Religious Ceremonies on the Prairies (Winnipeg, MB: University of Manitoba Press, 1994), 3-4. Figure 11.9 Potlatching continued at Alert Bay (aka: ‘yalis) until an RCMP crackdown in 1921. While there is evidence of this cultural repression across the country, the ceremonies of West Coast peoples known collectively as the potlatch received particular attention from politicians, missionaries, and government officials. The term potlatch refers to a complex of strictly regulated ceremonies that continue to be of critical significance to the Kwakwaka’wakw, Nuu-chah-nulth, Coast Salish, Haida, Tlingit, Tsimshian, Heiltsuk, and other peoples of the North West Coast of North America. The potlatch is the central institution that binds each of these societies together. Potlatches can be held to confirm leadership, alliances, or access to land and resources. Names (and, thus, status) can be given or passed down, debts repaid, dishonour erased, marriages performed, births announced, or the loss of loved ones memorialized. Potlatches provide a forum for history to be transmitted and verified, and gifts are given to witnesses who are obliged to remember and confirm what they have experienced. In addition to handling and healing earthly concerns, potlatches also have important spiritual components. John Lutz, Makuk: A New History of Aboriginal-White Relations (Vancouver, BC: University of British Columbia Press, 2008), 58. Many in late 19th and early 20th century settler society who were fortunate enough to witness potlatch ceremonies first hand, or who benefited materially by providing supplies, supported their continuation. On the other hand, Indian agents who saw families working for months to meet the expense of a potlatch denounced the institution as “foolish, wasteful, and demoralizing.” It seemed to them that these ceremonies were held solely to give away material goods, a concept that was directly opposite to settler goals of capitalist accumulation and private property, and which simultaneously challenged settler understandings of what constituted “wealth.” Robin Fisher, Contact and Conflict: Indian-European Relations in British Columbia, 1774-1890, 2nd ed. (Vancouver, BC: University of British Columbia Press, 1992), 206-207; Jean Barman, The West Beyond the West: A History of British Columbia (Toronto, ON: University of Toronto Press, 1991), 160. Missionaries, for their part, tended to see potlatches simply as a manifestation of evil. Thomas Crosby (1840-1914), who worked as a Methodist lay missionary to Coast Salish peoples of southern Vancouver Island and the lower Fraser Valley, from 1863 to the 1890s, said of potlatches, “Of the many evils of heathenism, with the exception of witchcraft, the potlatch is the worst, and one of the most difficult to root out.” Thomas Crosby, Among the An-Ko-me-nums or Flathead Tribes of Indians of the Pacific Coast (Toronto, ON: William Briggs, 1907), 106. Figure 9.10 Plains peoples like the Niitsitapi struggled to preserve ceremonies like the sun dance in the face of Canadian efforts to eradicate Aboriginal culture. In 1884, the Indian Act was amended to include a ban on the potlatch along with the expressly spiritual dances associated with plains ceremonial practices. Unlike the pass system, the prohibition against these institutions and practices was backed up by the force of law that became ever more strict and comprehensive over time. Despite the legislative prohibitions, many communities felt they had no alternative but to continue to hold potlatches and dances, even if they went to considerable effort to make them more portable and keep them out of the view of missionaries and Indian agents. Even with these precautions, there was a wave of prosecutions and subsequent incarcerations soon after World War I. It wasn’t until 1951 that the prohibitions against Indigenous ceremonies were finally dropped from the Indian Act . Some of the masks and other spiritual objects confiscated during the period of the ban have since been returned to their owners, but many others remain in the hands of museums and private collectors. Key Points Treaties evolved as instruments for negotiating accommodation between Aboriginal peoples and the newcomer society. By the late 19th century, the newcomers saw treaties as a means to acquire resources and manage Aboriginal populations. The final versions of the numbered treaties do not always or honestly reflect what was agreed (or understood to have taken place) in the treaty-making processes. Reserves were accepted by Aboriginal peoples as lands that were protected against intrusion; the Canadians carved out reserves as contained spaces in which assimilative efforts could be conducted more efficiently. Reserve size and resources were determined more by settler needs than Aboriginal requirements or expectations. Federal policies like the pass system and prohibitions against the potlatch and the sun dance were bureaucratic tools used to extinguish Aboriginal culture while restricting basic freedoms of movement and belief. Figure 11.7 Indian Chiefs 1873 Medal, Presented to commemorate Treaty Number 3 (Queen Victoria) (Online MIKAN no.2851194) by Library and Archives Canada, Acc. No. 1970-27-8M is in the public domain . Figure 11.8 Totem pole with modern tombstone (Online MIKAN no.3349323) by Library and Archives Canada is in the public domain . Figure 11.9 In P49 – Indian Potlach Alert Bay B.C. by City of Vancouver Archives AM54-S4-: In P49 is in the public domain . Figure 11.10 Sun Dance, Blackfeet Indians (Online MIKAN no.3368318) by Trueman / Library and Archives Canada / C-014106 is in the public domain . 145 11.7 From Agricultural Training to Residential School Jennifer Pettit, Department of Humanities, Mount Royal University Figure 11.11 The Numbered Treaties cover all of the Prairie West, the western North, most of northern Ontario, and a quarter of British Columbia. By the time the numbered treaties and the reserve system were created, Indigenous peoples in what is now Western Canada faced dire conditions. Many communities were ravaged by diseases such as smallpox, and devastated by the whisky trade. The bison, on which they relied, was almost extinct. See James Daschuk, Clearing the Plains: Disease, Politics of Starvation, and the Loss of Aboriginal Life (Regina, SK: University of Regina Press, 2013). The Canadian government once again decided that the solution was model farms to accompany a policy of peasant farming through which Indigenous families were to receive “2 acres and a cow” — and through which they were not encouraged to utilize any labour-saving machinery. The government felt this would ensure Indigenous peoples would be converted to sedentary farmers, but would not be so successful that they would compete with the new settlers moving west. Not surprisingly, the plan failed. Government bureaucrats at the time blamed the supposed “lazy” nature of First Nations peoples. Historian Sarah Carter has since proven that Indigenous peoples were interested in farming, but that the government’s policies and practices undermined reserve agriculture. See Sarah Carter, Lost Harvests: Prairie Indian Reserve Farmers and Government Policy (Montreal, QC: McGill-Queen’s University Press, 1990). More important to the government was a new system of schools for Indigenous children. Though they had weak results in the early schools in central Canada, the Federal Government was optimistic that expanding schools into the Prairies made sense, hopeful that the Indigenous peoples there could also be “civilized and Christianized.” See J. R. Miller, Shingwauk’s Vision: A History of Native Residential Schools (Toronto, ON: University of Toronto Press, 1996) and John Milloy, A National Crime: The Canadian Government and the Residential School System, 1879 to 1986 (Winnipeg, MB: University of Manitoba Press, 1999). Starving and destitute, some Indigenous peoples also hoped the schools would teach their children the skills necessary to adapt to changing conditions and, ideally, to learn a trade that would make them self-supporting. What remained to be determined though was what kind of education system would best serve the Indigenous peoples living in the West. To help answer that question in 1879, the government enlisted Nicholas Flood Davin (1840-1901), a Regina newspaper editor and the M.P. for Assiniboia West, to study the American system of industrial schools for Indigenous peoples. Notably, as was the pattern in government dealings with Indigenous peoples, Davin did not consult First Nations. He concluded that industrial schools in which children learned a trade and which were similar to those in the United States would be appropriate and useful in the West, despite disappointing results in similar schools in Central Canada. Davin also suggested that the Canadian government forge alliances with the churches to manage the schools. Canada, Report on Industrial Schools for Indians and Half-Breeds by Nicholas Flood Davin. 14 March, 1879. Library and Archives Canada, Record Group 10, Vol. 6001, File 1-1-1. These “industrial” schools were costly, however, and as a result, a parallel system of day and boarding schools was also created. Boarding schools were similar to the industrial schools, but were typically smaller with a much reduced focus on trades instruction. The first of the industrial schools — the Qu’Appelle Industrial School and the Battleford Industrial School located in the future province of Saskatchewan, and the St. Joseph’s School (also known as the High River or Dunbow school) southwest of Calgary — opened in the 1880s. These schools would lay the groundwork for a system of schools that would eventually spread across the Prairies and into British Columbia and the North. Figure 11.12 The Fort Qu’Appelle Indian Industrial School was one of the first to open. Seen here ca.1885 with teepees and carts outside the fence. By the time the last school closed in 1996, over 130 would have operated and over 150,000 Indigenous children would have been forced to attend what would ultimately be deemed tools of cultural genocide. Canada, Truth and Reconciliation Commission, \"Honouring the Truth, Reconciling for the Future: Summary of the Final Report of the Truth and Reconciliation Commission of Canada,\" last modified July 23, 2015, Indigenous children were taken from their homes, separated from their communities and families, and were forbidden to speak their languages or practice their culture. Students were poorly fed; subjected to medical experiments; forced to undertake manual labour; and were subjected to physical, sexual, and mental or spiritual abuse. Ian Mosby, “Administering Colonial Science: Nutrition Research and Human Biomedical Experimentation in Aboriginal Communities and Residential Schools, 1942-1952,” Histoire sociale/Social History 46, no. 91 (2013): 615-642. The legacy of this appalling treatment is still being felt in Indigenous communities today. Canada, Royal Commission on Aboriginal Peoples. Report of the Royal Commission on Aboriginal Peoples. Vol. 5: Renewal: A Twenty-Year Commitment. In For Seven Generations: An Information Legacy of the Royal Commission on Aboriginal Peoples [CD-ROM] (Ottawa: Libraxus, 1997.) To ensure the schools “succeeded,” the government enacted a number of measures including compulsory attendance in 1894 (and reinforced in further legislation in 1920). However, the parents of Indigenous students were not passive participants in the plans of church and state to “civilize” their children, and many did whatever they could to prevent their children from attending these schools and to demonstrate their displeasure. Parents were angered that their children were being abused and that they were taken so far away from the reserves. Parents were also upset that students were alienated from their culture, were forced to work long hours, were not properly cared for, and could not find employment after graduation. This opposition took place, however, in a power relationship in which Aboriginal peoples were unable to bring about real change. Thus, their opposition had only a limited effect. What did sway the administrators was rising costs. Figure 11.13 St. Joseph’s (Cariboo) Indian Residential School was established in 1891 as one of the several schools run by the Catholic Church in BC. Originally thought to be a quick and relatively inexpensive way to deal with what administrators deemed the “Indian Problem,” the schools had evolved into a costly and complicated system that was not producing significant results. As a consequence, Duncan Campbell Scott (1862-1947), who was appointed to the position of Superintendent of Indian Education in 1909, changed the professed goal of schools for Indigenous peoples from integration to segregation (in the words of Scott: “for civilized life in his own environment”). In 1923 officials merged the industrial and boarding schools to create a new category of schools known as “residential schools.” Brian Titley, A Narrow Vision: Duncan Campbell Scott and the Administration of Indian Affairs in Canada (Vancouver, BC: University of British Columbia Press, 1986). Scott, though, still very much believed in a policy in which Indigenous peoples should be obliterated as a distinct community. In 1920 he made this now famous statement: “I want to get rid of the Indian problem. I do not think as a matter of fact, that the country ought to continuously protect a class of people who are able to stand alone.… Our objective is to continue until there is not a single Indian in Canada that has not been absorbed into the body politic and there is no Indian question….” Duncan Campbell Scott, Deputy Superintendent General of Indian affairs, testimony before the Special Committee of the House of Commons examining the Indian Act amendments of 1920, Library and Archives Canada, Record Group 10, vol. 6810, file 470-2-3, volume 7, pp. 55 (L-3) and 63 (N-3). Key Points Setting Aboriginal people down the path to become European-style agriculturalists was underfunded and purposely organized to ensure they did not compete with European newcomers on the Prairies. Canadian-organized schools appealed to Aboriginal people because they held out the hope of skills and opportunities that would help their people escape poverty. The industrial schools were augmented by boarding schools in which industrial skills were minimized, the clergy were heavily involved, and costs were managed by obliging the children/pupils to do maintenance work. Compulsory attendance was legislated in 1894, enabling the abduction of children from their parents by the local Canadian authorities. By 1909 the objectives of the schools had changed again from integration to segregation and the combination of industrial and boarding schools to produce residential schools. Superintendant Duncan Campbell Scott believed that Aboriginal peoples could never occupy an equitable position in Canadian society and was satisfied to use the schools to build a marginalized people. Figure 11.11 Numbered-Treaties-Map by Yug / STyx / Themightyquill is used under a CC-BY-SA-3.0 license. Figure 11.12 Distant view of Fort Qu’Appelle Indian Industrial School with tents, [Red River] carts and teepees outside the fence, Lebret, Saskatchewan, [May 1885?] (Online MIKAN no.3194883) by O.B. Buell / Library and Archives Canada / PA-182246 in the public domain . Figure 11.13 [Panorama of Cariboo Indian Residential School, William’s Lake, British Columbia, 1949].(Online MIKAN no.4674075) by Canada. Dept. of Indian and Northern Affairs / Library and Archives Canada / e011080297_s1 in the public domain . 146 11.8 WWI to 1970 Jennifer Pettit, Department of Humanities, Mount Royal University At the same time these events were transpiring, over 4,000 Indigenous people fought in World War I (see Section 6.12 ). Canada, Aboriginal Affairs and Northern Development Canada, “Aboriginal Contributions During the First World War,” last modified October 24, 2014, . They returned, not to significant progress for First Nations, but to a country in which some of their lands had been taken without their permission and in which they were still not entitled to vote. While the Canadian economy was strong in the 1920s, by the 1930s the Great Depression hit and the Department of Indian Affairs was reduced to a branch of the Department of Mines and Resources. When WWII broke out, Indigenous peoples once again volunteered in significant numbers. This time, however, they returned to a Canada with a burgeoning concern for the conditions facing First Nations. As a result, in 1946 Parliament created a Special Joint Committee of the Senate and the House of Commons to undertake a study of the Indian Act . Unlike earlier commissions, the Joint Committee also sought feedback and consultation with Indigenous associations such as the North American Indian Brotherhood and the Indian Association of Alberta. When they reported in 1948, the Committee recommended a number of changes, including allowing Indigenous peoples to vote in federal elections; creating a treaty claims commission; enacting self-government; giving title of reserve lands to Indigenous peoples; and encouraging integration rather than assimilation. In the end, the federal government ignored many of these recommendations. There were, however, some changes made to the Indian Act in 1951, including lifting the ban on Indigenous dances and ceremonies, permitting Indigenous groups to pursue land claims, and increasing the powers of chiefs and band councils. However, it would not be until the 1960s that significant changes in the relationship between the federal government and Canada’s First Nations would begin to transpire. “Citizens Plus” — the 1960s The Hawthorn Report The decade of the 1960s saw significant changes begin to take place. The right to vote in federal elections was extended to Indigenous peoples in 1960, and in 1961 the compulsory enfranchisement provisions were dropped from the Indian Act . A stand-alone Department of Indian Affairs was created in 1966. Another significant event was the Hawthorn-Tremblay Report entitled A Survey of the Contemporary Indians of Canada: Economic, Political, Educational Needs and Policies . Based on a series of cross-Canada consultations, the 1966-1967 Hawthorn Report concluded that Canada’s First Nations were marginalized and disadvantaged due to misguided government policies like the residential school system (which the Report recommended closing). Hawthorn argued that Indigenous peoples needed to be treated as “Citizens Plus” and provided with the resources required for self-determination. As a result of this report, the Canadian government decided to take policies in an entirely new direction, which were outlined in the White Paper of 1969. The White Paper and the Red Paper In the White Paper, the stated goal of Prime Minister Pierre Trudeau and Jean Chrétien, Minister for Indian Affairs, was to achieve greater equality for Canada’s First Nations. The White Paper called for an end to Indian status, the closure of the Department of Indian Affairs, the dismantling of the Indian Act , the conversion of reserve lands to private property, and immediate integration. While the federal government believed this to be desirable, Indigenous groups across Canada were outraged, and argued that forced assimilation was not the means to achieve equity and that the White Paper had not addressed their concerns. They responded with a document called Citizens Plus, which became known as the Red Paper . In the Red Paper, Indigenous peoples stressed the importance of land and upholding the promises made in the treaties, and called for political organization. In response, the government withdrew the White Paper in 1970. Over 200 years has passed since the passage of the Royal Proclamation of 1763, and yet the deeply flawed Indian Act still remains in effect today. Altough there has been some progress, such as the entrenchment of Aboriginal and treaty rights in the 1982 Constitution and the 2008 Federal Government apology for residential schools, much remains to be done. The fight for this recognition has unfolded in a number of ways: peaceful movements like Idle No More ; violent clashes such as the events at Oka; issues such as land claims reconsidered in the courts; and consultations that were part of studies, such as the 1996 Royal Commission and the more recent Truth and Reconciliation Commission (discussed in Sections 11.9 and 11.11 ). Key Points Aboriginal leaders were finally able to secure Ottawa’s interest in their complaints shortly after the Second World War. Recommendations arising from the 1948 Special Joint Committee were acted on incrementally, first by ending the ban on the sun dance and potlatch, removing the sanctions against legal claims against Canada, and devolving authority to band leadership. Winning the franchise in 1960 was followed by the Hawthorn Report of 1966-1967, which adopted the approach of “Citizens Plus.” Motivated to act, the Trudeau administration in 1969 issued the White Paper, which was instantly rejected by Aboriginal leaders as assimilative. They responded with the Red Paper. Issues that were identified decades earlier remained off the table and continue to be avoided by Canadian governments. 147 11.9 The Aqueduct and Colonialism Adele Perry, Department of History, University of Manitoba Located at the forks of two major rivers and prone to flooding, the city of Winnipeg often seems awash in water, but an adequate supply of clean drinking water has been a continual problem for the city from its earliest days as the Red River Settlement to its incorporation as a city in 1874 to the present day. In his classic Winnipeg: A Social History of Urban Growth, 1874-1914 (1977), Alan Artibise explains how in the last decades of the 19th century, Winnipeg experimented with private companies and public water supply operations. They filtered river water and dug artesian wells, but  still had to deal with problems like “hard” water (with a high mineral content), inadequate supply, and, more pressingly, annual outbreaks of typhoid. 1904 was especially bad: 1,276 people, or a little over 5% of 67,300 Winnipeggers, were diagnosed with typhoid. By 1913 the ambitious settler city had decided to address its enduring problems with the water supply by building an aqueduct to transport water from Shoal Lake. Located about 150 kilometers east, Shoal Lake straddles the borders of Ontario and Manitoba, and is within Anishinaabe territory, which is covered by the provisions and promises of Treaty 3, signed in 1873. Supporters of the Shoal Lake Aqueduct were well aware of just how expensive and ambitious the plan was, and argued that the estimated cost of $13.5 million would be well worth it to secure Winnipeg’s human and economic growth. Figure 11.14 A spider’s web of infrastructure radiates outward from Winnipeg, claiming territory and water. Greater Winnipeg Water District Map, 1918. What this plan might mean for the Anishinaabe communities at Shoal Lake rarely entered into the conversations about what the Aqueduct could do for the mainly settler city of Winnipeg. In 1914 the Federal Government used its enormous powers under the Indian Act , first passed in 1876, to sell approximately 3,000 acres of land belonging to Shoal Lake 40 Reserve to the Greater Winnipeg Water District (GWWD) for the sum of $1,500. In an effort to separate “dark” water from the more palatable water destined for the city, the GWWD then built a canal and a dyke, which effectively made the community of Shoal Lake 40 an artificial island. Shoal Lake water first flowed in Winnipeg’s water mains in 1919, less than half a year after the armistice of the Great War and a few months before a General Strike would rock the prairie city. The project carried an enormous price tag: it cost $17 million at the time, which translates to about $229,861,702 in 2016 terms. The Shoal Lake Aqueduct project involved the building of a railroad, telephone lines, and tunnelling under multiple rivers, and employed as many as 2,000 men at one time — all during the labour shortages of World War 1. The Aqueduct has served the city of Winnipeg well and continues to supply the city with its drinking water. It did not take long for Winnipeggers to begin celebrating the Aqueduct as a triumph of engineering and public-minded policy. It would take much, much longer and an enormous amount of activism and advocacy from Indigenous communities for awareness to grow with respect to what the Aqueduct cost the Anishinaabe communities of Shoal Lake. Surrounded by Winnipeg’s water supply, Shoal Lake 40 nevertheless lacks a reliable source of fresh water, and the community has been on a boil water advisory since 1998. (They are not alone: as of the summer of 2015, there were about 175 drinking water advisories in Reserves across Canada.) Also, the approximately 250 people of Shoal Lake 40 lack a year-round way of coming and going from the community, and as a result, have poor waste removal, emergency services, and postal services. During the winter, they use an ice road across water, but for a few weeks every fall and spring, they face the danger of travel across thinning and uncertain ice. The fact that the community of Shoal Lake 40’s poor water supply and any chances for ameliorating it can be tied directly to the Aqueduct that secured Winnipeg’s water supply tells us a lot about the history of colonialism in modern Canada. The relative prosperity of non-Indigenous people in 20th century Canada has come at the expense — sometimes general and sometimes very specific — of Indigenous people. Alongside the histories of World War 1, the Winnipeg General Strike, and the provision of municipal services in Winnipeg and across Canada, we also need to analyze the histories of Indigenous dispossession that undergirded the stories of settler vision, conflict, and triumph. Key Points The ability to undertake large engineering projects in the 20th century recasts colonial relations between Canada and Aboriginal communities like Shoal Lake 40; the issue is not simply the taking of Aboriginal land, but any other resource that is needed by the colonial society. As is the case at Shoal Lake 40, this is very much to the detriment of the colonized people. Figure 11.14 Map Showing Location of Aqueduct (1918) by Wyman Laliberte / Courtesy of University of Manitoba : Archives &amp; Special Collections is used under a CC-BY-2.0 license. 148 11.10 Canada and the Colonized, 1970-2002 The White Paper and the Red Paper demonstrated how far out of sync Ottawa was with respect to the Aboriginal leadership across Canada. It was, however, a moment in Canadian history that catalyzed First Nations groups into new political action. When one looks at the period between the Great War and the late 1960s, it might seem that Aboriginal peoples mustered very little opposition to colonialism. Although resistance was widespread, and small victories were won at the immediate, on-reserve level, the systemic obstacles to Aboriginal protest were too significant to be bypassed. Aboriginal people who held Status could not vote until 1960, so that avenue was closed. Moreover, although band leadership was typically elected, it was often at the mercy of the local Department of Indian Affairs Agent, whose interests were very frequently at odds with those of the bands. In the 1920s there were two telling developments. Section 141 of the Indian Act forbade bands from hiring lawyers to pursue entitlements or damages owed by the federal government; raising funds to do so was itself a criminal offence. In a stroke, Ottawa had criminalized legal action in support of Aboriginal rights. Almost simultaneously, the RCMP was directed to be more aggressive in suppressing Aboriginal cultural events: one outcome of Dan Cranmer’s potlatch in 1921 at Alert Bay was the arrest of more than 40 participants, and the conviction and imprisonment of roughly half their number. (Another outcome was the confiscation and subsequent loss of several generations’ artistic creations, sacred items, and cherished family possessions.) Starting in the 1930s, Aboriginal people from Coast to Coast found themselves being relocated. In Nova Scotia in 1942, for example, 20 settlements were consolidated into 2 to ease administrative and assimilationist processes, entirely in the face of Mi’kmaq opposition. Housing and services were inadequate for the growing populations, and by the 1950s, the provincial government in Halifax lost interest in trying to fix the mess the Federal Government had created. At mid-century, a similar situation emerged on the Labrador Coast. Davis Inlet (aka: Utshimassit) was attractive to coastal traders from the late 18th century on because of its deep natural moorage. At around 1870, the Hudson’s Bay Company offered Aboriginal traders access to inoculation against smallpox and a variety of trade goods, but the site had no profound, traditional meaning to the Innu who visited it only when it served their purposes. Missionary work in the region was intermittent at best until the 1950s. At that time, growing interest and commerce in the region led to an outbreak of alcohol abuse. The missionaries stayed aloof from families and households in which drinking was routine and/or problematic; the Innu who suffered from alcoholism also steered clear of the church and held themselves separate from non-drinkers as well. This phenomenon exposed fissures within the Innu population that — when they were relocated wholesale north to “New Davis Inlet” — became part of a new dysfunctional and divided normalcy. Moving from tents into Euro-style housing appeared — to observers outside the community — to indicate permanence and settlement, but it concealed deep social problems that were to manifest in violence, several kinds of abuse, and horrendous suicide rates. Lynne D. Fitzhugh, The Labradorians: Voices from the Land of Cain (St. John’s, NF: Breakwater, 1999), 261-263. Like so many other Aboriginal peoples, the Mi’kmaq at Shubenacadie and Eskasoni and the Innu at New Davis Inlet were impoverished by relocation and the structural unemployment that was sustained by anti-Aboriginal racism. Also, they were fearful of further decapitation of community leadership by governments that didn’t seem reluctant to incarcerate troublemakers. First Nations facing these conditions and others struggled to find strategies and tactics suitable for the modern era of colonialism. In 1951 Ottawa lifted the barriers to raising funds for legal challenges, sanctions against the potlatch and other ceremonies were dropped, and steps were taken toward enfranchisement. A new era in Aboriginal-Newcomer relations was about to begin. Figure 11.15 In 1953, at the start of the Cold War, Inuit communities were relocated from Inukjuak to Resolute Bay (left arrow) and Grise Fiord (right) to act as “human flagpoles” for Canadian sovereignty in the high Arctic. New Organizations Political organizations had been struggling for years, but the White Paper gave them new life, as did 1960s organizations like the American Indian Movement (AIM) and the civil rights movement in the United States. Harold Cardinal (1945-2005) gave voice to Aboriginal concerns at the time in his 1969 book The Unjust Society , which took its title from Prime Minister Pierre Trudeau’s 1968 campaign slogan of a “just society.” The Union of BC Indian Chiefs (UBCIC) and the National Indian Brotherhood (NIB) were established the same year as a further response to the White Paper crisis. The NIB grew out of a foundation established by the Federation of Saskatchewan Indians and the National Indian Council, and its creation also included a divorce from the leading Métis organization. The movement faced challenges from the outset as First Nations with treaty rights pulled in one direction and those without pursued solutions under Aboriginal rights. The leadership of George Manuel (1921-89) was critical in the early years of the NIB. A Secwepemc leader from Neskonlith on the South Thompson River, Manuel emerged as a capable spokesperson and a theorist. His conception of the Fourth World , a category of largely small and colonized Indigenous populations around the globe, resonated with those advocating for Aboriginal rights, informed the thinking of Aboriginal organizations in Canada generally, and contributed to the establishment of the World Council of Indigenous Peoples, which Manuel led in the mid-1970s. Manuel was able to secure federal funding for research into a variety of native claims and set the movement on a solid financial footing for the first time. J. R. Miller, Skyscrapers Hide the Heavens: A History of Indian-White Relations in Canada , revised edition (Toronto, ON: University of Toronto Press, 1991), 231-233. See also \"George Manuel,\" accessed January 9, 2016, . The thrust of the NIB’s efforts and those of its successor, the Assembly of First Nations (AFN) , was to obtain progressively greater and greater degrees of self-governance for Aboriginal communities. Social work and child welfare were priorities, although it was in education that the greatest victories were won. As the role of the Department of Indian Affairs and Northern Development (DIAND) was progressively reduced, band offices took up a larger share of local responsibility. The AFN — established in 1978 — played a key role along with the UBCIC in securing recognition for Aboriginal rights in Section 35 of the Constitution Act, 1982. New Legal Precedents The first court case to significantly change the landscape of Aboriginal-Canadian relations came in 1973. The Nisga’a First Nation of northwestern British Columbia successfully demonstrated that title to their land had never been extinguished. The Calder Case worked its way through the BC court system and reached the Supreme Court of Canada. Although the Court agreed that Aboriginal title existed before Confederation, it was split on whether title persisted after 1871. The British Columbia government took this as a signal that they owed nothing to the Nisga’a (nor, if it came to that, to any other First Nations with which post-1871 administrations had failed to negotiate a treaty or purchase of land); Ottawa, however, took the view that the Calder decision demanded the start of a new treaty negotiation process. The entrenchment of Aboriginal rights in the Constitution Act gave further weight to this position and, with the election of a new NDP government in BC in 1990, Victoria joined in the process of seeking a new generation of treaties. In 1998 the Nisga’a Final Agreement was reached. By that time, 13 other post-1973 treaties had been negotiated. At roughly the same time that the Nisga’a brought forward their initial claim, the Cree and Inuit of Northern Quebec sought a legal solution for their own situations. The expansion of Quebec into the Ungava Peninsula in 1911 was meant to be followed by a round of treaty negotiations, which never took place. Despite Aboriginal protests, the Provincial Government’s aggressive mid-century hydroelectricity development program around James Bay uprooted and displaced First Nations. Late in 1973, the provincial courts made it clear that the province’s obligation to negotiate a treaty had not disappeared and, in the year that followed, an agreement was reached with the Grand Assembly of the Cree and the Northern Quebec Inuit Association. Although this was an “Agreement,” it was a “Treaty” in every other respect and is regarded as the first in 50 years. Using the courts to get provinces and Ottawa to the bargaining table was rapidly becoming an accepted process. Courtroom challenges and precedents were slowly won, and every time a significant watershed was crossed, it happened at the Supreme Court of Canada. In 1990 — the same year British Columbia joined in the treaty-making process — a precedent was set by the case of Regina v Sparrow. Five years earlier, Ronald Sparrow, a fisherman and member of the Musqueam (aka: Xwméthkwiyem or xʷməθkʷəy̓əm) First Nation, was caught using a drift net that exceeded the dimensions permitted by the Fisheries Act. Sparrow admitted the offence but challenged the charge, citing A boriginal rights provided under Section 35(1) of the Constitution Act (1982). The case was initially lost, but successive appeals were made, all the way to the Supreme Court of Canada where Justices reached a unanimous decision that supported Sparrow’s position. Specifically, any activity or “right” that existed before 1982 that had not been explicitly and specifically extinguished was recognized as continuing unabated. This was the first significant test of Aboriginal rights, and it was an important win for First Nations. In the case of Delgamuukw v British Columbia , the Gitksan-Wet’suwet’en First Nations decided against the slow federal treaty negotiation process (in which British Columbia’s Provincial Government had initially refused to participate) and sought a resolution through the legal system. At first this went very badly for the plaintiffs: in 1991 Chief Justice Allan McEachern (1926-2008) ruled — contrary to Calder — that Aboriginal rights existed only because, and so long as, the colonial power said they did. Moreover, he ruled that oral tradition did not constitute a viable source of evidence. Also, McEachern’s tone was condescending to such an extent that it swung public support toward the Gitksan-Wet’suwet’en side. The Supreme Court of Canada decided in 1998 that McEachern was wrong in both regards. On the topic of oral history, the court stated: Notwithstanding the challenges created by the use of oral histories as proof of historical facts, the laws of evidence must be adapted in order that this type of evidence can be accommodated and placed on an equal footing with the types of historical evidence that courts are familiar with, which largely consists of historical documents. Delgamuukw v. British Columbia, [1997] 3 S.C.R. 1010 at para. 84. File No.: 23799. As regards Aboriginal title , Delgamuukw was definitive that (a) it existed, and (b) it was exclusive. That is, a province and/or Ottawa could not lay claim to land within traditional territories without extinguishing title first through treaty negotiations. This decision was further reinforced in Haida Nation v British Columbia in 2004 and as recently as 2014 in the case of Tsilhqot’in Nation v British Columbia , both of which involved provincial forest policies and grants. In the case of Haida , a dispute over corporate access to forest resources on Haida Gwaii (aka: the Queen Charlotte Islands), Crown rights to grant access, and Haida Aboriginal rights to harvest red cedar began in 1961. More than 40 years later, it was decided by the British Columbia Court of Appeals that the Crown has a duty to conduct meaningful negotiations with First Nations over the use of resources in unceded territories and to accommodate their interests. Tsilhqot’in strengthened this position in 2014 in a dispute over licenses to log forests on unceded traditional territory. Once again, appeals took the case from the provincial level to Ottawa and the Supreme Court and, once again, the highest court in the country decided against the Provincial and Federal Governments. The Court concurred with earlier decisions that Aboriginal title exists and, almost ironically, turned the Indian Act back on the governments, stating that a fiduciary responsibility exists between the Crown and Indigenous people. In short, governments cannot hand over to third parties resources that are unceded, since doing so would be to cheat the First Nation in question out of their inherent value. The implications of Tsilhqot’in Nation is still being worked out but, on the face of it, it prohibits resource extraction on any unceded territories without the permission of the relevant First Nation(s). (It is worth noting at this point that the approach taken by settler society has been to identify, catalogue, pursue, extract, and profit from individual and specific “resources” or commodities; Aboriginal societies, in contrast, generally perceive their lands more holistically, not as a vault full of riches from which one may selectively make withdrawals.) The fact that so many of the key legal precedents come out of British Columbia speaks to its distinctive (although not unique) experience of treaties. Apart from the dozen or so Douglas Treaties signed by Governor James Douglas in the colonial era, and the part of Treaty 8 that spills over from Alberta into the British Columbian Peace District, there were no attempts to extinguish title with the vast majority of First Nations in the province. On the East Coast, as well, the treaty system developed very differently. Treaties were never signed with the Aboriginal peoples of Newfoundland and Labrador. The Mi’kmaq of Newfoundland are politically related to their cousins on the Maritime mainland but not in terms of treaty. The situation for the Innu and Inuit of Labrador is similar. They have had full Canadian citizenship for about a century now, which includes voting rights, and they never have  been covered by the Indian Act ; thus, notions of Status and non-Status are irrelevant to them. Moreover, they never have been wards of the state. This means that they have escaped some of the worst effects of colonialism but, at the same time, they were rendered invisible to the D.I.A. What the Innu call Nitassinan has been viewed by outsiders as so bereft of human occupancy and culture that the region has been repeatedly pounded by NATO aircraft on training missions. Lynne D. Fitzhugh, The Labradorians: Voices from the Land of Cain (St. John’s, NF: Breakwater, 1999), 376-377. A different story unfolded in the North West Territories (NWT) beginning in the late 1970s. Ottawa engaged the Inuit Tapirisat of Canada (now called Inuit Tapiriit Kanatami) in negotiations over claims to the eastern third of the NWT (what was, at the time, called the District of Keewatin). The idea of a separate, autonomous Inuit administrative unit gained ground and, in 1982, a referendum of residents of the whole Territory showed overwhelming support for the idea. It took another decade to complete the land claims negotiation process (the Nunavut Land Claims Agreement Act, 1992 ), and that was followed by legislation that created the new Nunavut Territory . The government in Iqaluit represents a population that is more than 80% Inuit, and Inuktitut is the Territory’s first official language. Reforming the Indian Act The White Paper failed at the first hurdle, and the Red Paper set a new agenda for change. Nevertheless, legislative change was  slow in coming. The Penner Report in 1983 recommended to Ottawa a form of autonomy that represented to most Aboriginal leaders an advance on what had gone before it, but the government changed, and Prime Minister Brian Mulroney’s administration took a different approach. Informed by a neo-conservative fear of fiscal mismanagement and public dependency, the Mulroney government first looked for ways to reduce spending on band issues. Offering up a kind of municipal-level of self-government, the Tories hoped to dismantle the bureaucracy of guardianship that had existed for a century. To many native leaders, this looked like White Paper 2.0, and they pointed to the implicit shift in dependence from Ottawa to the provinces (to which municipalities are subservient); only a small number of bands perceived it as an opportunity to seize upon. The overall effect of the first year of Conservative government was a sudden increase in rancour and bad press. The Mulroney administration looked elsewhere to secure change. Efforts were made in 1985 to reform some of the most egregiously discriminatory elements of the Indian Act. The most noteworthy of these changes pertains to Status and Aboriginal women. Before Bill C-31, the Indian Act specified that Aboriginal women who married non-Aboriginal men lost Status. What’s more, children of that marriage also lost any claim to Status. Aboriginal men who married non-Aboriginal women, however, were not similarly impacted. Since bands were (and are) funded based on the number of Status members on their lands, an incentive exists to prevent non-Status members from residing on-reserve and making demands on band services. Loss of Status meant that Aboriginal women and their children got the right to vote, which was offset by their potential loss of community. The 1985 reforms restored Status to Aboriginal women and children from whom it had hitherto been stripped. It was celebrated at the time as a significant step forward for Aboriginal women’s rights and, symbolically at least, it was. However, the amended law simply carried forward into the next generation the prospect of losing Status through marriage to non-Aboriginals. In that respect, it was more of a temporary amnesty rather than a wholesale elimination of a discriminatory law. The ways in which the new laws impose a “two generation cut-off” is described nicely in Thomas King, The Inconvenient Indian: A Curious Account of Native People in North America (Toronto, ON: Anchor Canada, 2012), 167-169. Extra-Legal Protests Several factors contributed to the rise of protest tactics among Aboriginal leaders. One was the American Indian Movement (AIM) that appeared in the late 1960s in the United States. Sometimes described as Red Power (in a nod to the Afro-American Black Power movement), AIM inevitably reached across the border to Canadian First Nations with shared grievances against colonialist forces. Beginning in 1970, AIM-style demonstrations appeared in Canada including road blockades, the occupation of government offices, and attempts to seize lands that had either been unilaterally cut out of reserves or never covered by treaty. The frequency of protests increased through the decade, many of which became high profile confrontations. In the North West Territories, Dene mobilized to block the proposed Mackenzie Valley Pipeline . A Royal Commission from 1974 to 1977, chaired by Justice Thomas Berger (b. 1933), accepted much of the Dene case and called for extensive land settlement agreements before the pipeline project could proceed. Effectively, this established a moratorium on a major infrastructural development, a significant win for Aboriginal activists. Similar confrontations took place in northern Quebec over the James Bay hydroelectric development program, a process that hardened Innu and Cree sentiment against Péquiste separatism. Figure 11.16 Members of the Mohawk First Nation at the barricades, Kanesatake, 1990. The temper of events cooled in the 1980s, but when it returned, it had changed in tone. The town of Oka , a village to the northwest of Montreal, in 1989 approved the expansion of a private golf course into land claimed by the Mohawk of Kanesatake, and which contained a Mohawk graveyard. The band’s response included a blockade of access to the proposed construction site in July 1990, which engendered the Oka Crisis. Beginning with a party of 30 armed Mohawk band members, a teargas attack by the Sûreté du Québec led to a firefight in which one Sûreté member was killed. The ranks of the Oka protesters grew almost overnight to nearly 100 and then to 600. Another Mohawk community at nearby Kahnawake supported the standoff by blockading access to the Mercier Bridge. RCMP reinforcements were sent to Oka in support of the Sûreté, which were soon augmented by members of the Canadian Armed Forces’ Royal 22nd Régiment (the Van Doos). Seventy-eight days after the confrontation began, the Mohawk forces at Oka stood down. Although the golf course expansion was cancelled, none of the outstanding land claims issues were addressed. Similar events unfolded at the other end of the country near Gustafsen Lake in central British Columbia in the summer of 1995. Secwepemc spiritual leaders had established an annual sun dance  on rangeland claimed by a local rancher, and which was within the traditional and unceded lands of the Secwepemc. Despite initial cooperation between the parties involved, goodwill evaporated in the winter of 1995, leading to a confrontation between Indigenous and non-Indigenous allies against the RCMP. As at Oka, gunfire was exchanged, although there were no fatalities. The RCMP mobilized enormous resources, including helicopters, armoured personnel carriers, and several hundred tactical squad members. In September, the Aboriginal side dismantled its position and left Gustafsen Lake. As at Oka, arrests of protesters followed, and 15 people received sentences of 6 months to 8  years. Gustafsen Lake was still simmering when another protest flared at Ipperwash Provincial Park at the south end of Lake Huron, where a stretch of shoreline that contained an Anishinaabeg burial site was expropriated from Kettle Point 44 Reserve under the War Measures Act during WWII. Ottawa promised to return the land at the end of the war but did not follow through. In 1994 members of the Kettle Point band initiated a round of occupations and protests to remind authorities that this issue had not been resolved. In September 1995, a group of protesters set up a camp in the park for a more formal and sustained protest. At the outset, the Ontario Provincial Police attempted to achieve a negotiated outcome so as not to repeat the mistakes of Oka, or to echo events concurrently underway in British Columbia. This strategy was replaced by riot police with shields, batons, and helmets. On September 6, the two sides confronted one another in the park, and events quickly spiralled out of control. Gunfire occurred (participants disagree as to whether shots were fired both ways), and Dudley George (1957-1995) was struck three times by a police sniper. Attempts to get George to a hospital were blocked by the OPP, and the man bled out. The sniper, Sergeant Ken Deane, was subsequently tried and found guilty of criminal negligence. The role of the Ontario Provincial Government, led by Conservative Premier Mike Harris (b. 1945), was resolutely opposed to the Anishinaabe protest. Harris was quoted by his Attorney-General as saying “I want the fucking Indians out of the park.” Ontario, Report of the Ipperwash Inquiry , Vol.1 (Ontario: Government of Ontario, 2007), 363. Figure 11.17 The Kettle Point 44 Reserve was appropriated by Ottawa during WWII and never returned. Four years after Ipperwash, confrontation over resources on the East Coast captured the headlines. The Burnt Church Crisis of 1999-2002 bears similarities with Sparrow in that it proved a test of Aboriginal rights over resource gathering. In this instance, the Burnt Church First Nation, a Mi’kmaq community at the mouth of the Miramichi River in northeastern New Brunswick exercised what they understood to be their right to harvest reasonable amounts of maritime resources, regardless of Department of Fisheries ideas of seasonality. Their attempt to trap lobster “out of season” resulted in confrontations with non-Aboriginals (mostly commercial lobster trappers) who attacked Mi’kmaq equipment and, reportedly, thousands of lobster traps. The conflict expanded into a community-wide civil war with attacks launched by both sides against property and individuals. By 2002 the Department of Fisheries itself was attacking Mi’kmaq boats as the region descended into near-lawlessness. Agreements were reached in the same year that permitted the Mi’kmaq to fish for subsistence and not for commerce, regardless of “seasons.” Aboriginal people continue to pursue redress, compensation, and rights through legal avenues and protest. Democratic processes are limited in their ability to achieve results because First Nations constitute relatively small and mostly isolated populations with limited ability to secure change through the ballot box. Even at the local level, bands are not always united on the best strategy to pursue and so do not always speak with one voice in formal negotiations. From a historical perspective, attempts to win advances using extra-parliamentary means speaks to the fact that Aboriginal peoples have a working relationship with the Crown and an adversarial relationship with Canada. Key Points Legal challenges to Canada’s approach to Treaty obligations were essentially illegal until the 1950s, which significantly dampened Aboriginal people’s recourse. Resettlement and dispossession of traditional lands accelerated in the 20th century. Once legal organization was permitted, new Aboriginal organizations like the UBCIC and the NIB were established to advance First Nations’ concerns. Following effective lobbying, Aboriginal rights were enshrined in the Constitution. Legal precedents tended to favour Aboriginal claimants beginning in the 1970s with Calder , R. v Sparrow , and Delgamuukw. These cases served to clarify the extent of Aboriginal title and rights, particularly in the absence of treaties. The benchmarks for Status were changed in 1985 in a move that remedied the situation of many Aboriginal women and their children. The failure of Parliament to address outstanding issues and the costs and slowness of pursuing legal remedies encouraged some Aboriginal leaders to make use of more confrontational strategies beginning in the 1980s, especially where the issues were immediate. Examples include Oka, Gustafsen Lake, Ipperwash, and Burnt Church. Figure 11.15 Can high arctic relocation by University of Manitoba : Archives &amp; Special Collections is used under a CC-BY-SA-3.0 license. Figure 11.16 Mohawks watching Oka crisis news on barricades (Online MIKAN no.3602895) by Benoît Aquin / Library and Archives Canada / e has nil restrictions on use. Figure 11.17 [Kettle Point Reserve no. 44. Plan showing the Kettle Point and Stony Point Indian Reserves, Ont.] [cartographic material] (Online MIKAN no. 3694469) by Library and Archives Canada is in the public domain . 149 11.11 Residential Schools Figure 11.18 Study period at the Roman Catholic Indian Residential School, at Fort Resolution, NWT, n.d. The goals of the Residential School system (described in Section 11.5 ) were explicitly assimilationist. The program existed precisely to replace Aboriginal economic practices with those of the mainstream colonial economy, substitute English and French for indigenous languages, erase indigenous belief systems with some kind of Christianity, and interrupt the transmission of social practices (including fundamental familial relationships) by capturing children and keeping them away from their parents, siblings, and other relations. This needs to be underlined: there was nothing accidental about the way the residential schools turned out; these were clearly stated goals and tactics. In the 1960s and 1970s, as plans advanced to end the program, the consequences of a century of residential schools were everywhere visible. Traumatized children became traumatized adults. Social workers drawn from the colonizing society were sent to reserves — often with RCMP and other police supports — to “rescue” children from dysfunctional environments in which colonialism itself was heavily implicated. In the decade after 1955, as a study by Christopher Walmsley points out, “Aboriginal children in the care of the Province of British Columbia jumped from less than 1% to 34.2%, and this pattern was repeated in other parts of Canada during the same time.” Christopher Walmsley, Protecting Aboriginal Children (Vancouver, BC: University of British Columbia Press, 2005), 2. Just as residential schools were being closed, the Federal Government’s monopoly over the management of Aboriginal communities on-reserve began to fray, and provincial responsibilities increased: The principal response of provincial child welfare authorities during the 1960s was the apprehension and removal of Aboriginal children from their families and communities. Known as the “ sixties scoop ,” social workers explained their actions by arguing that they were in the best interests of the children. Ibid., 13-15. Citing poverty, health concerns, and even malnutrition, the secular authorities perpetuated the alienation of children from their communities that had begun by missionaries and residential schools. Aboriginal children in care were placed with non-Aboriginal families, and some were exported to the United States. In almost every case, the link between child and ancestral culture was severed. Whether in care or in residential schools, the same outcomes prevailed: practices — especially, but not exclusively, those censured by the anti-potlatch and sun dance laws — were inadequately passed from one generation to the next; the skills taught at woefully underfunded schools prepared students for 19th century field labour but not 20th century factories or offices, let alone professions. Substance abuse on reserves, particularly alcohol, was extensive as generations self-medicated to deal with everything from a personal sense of diminished self-worth to cultural alienation to systemic poverty and — from generation to generation — to the loss of children. Whereas the reserve system and pass system were designed to keep Aboriginal people physically in check, the residential school system and the intervention of colonialist social workers and police authorities were intended to keep them culturally in check. The enormous educational, social, and moral failures of the residential school system are now widely known. The system contained a single ineluctable contradiction: it proceeded from an explicitly racist assumption that indigenous cultures were inferior and proceeded to strip away those features with an eye to assimilating native people into “mainstream” society, but neglected to address the inherent racist and discriminatory perspectives of Euro-Canadians who would not hire, marry, work with, drink with, study with, lend money to, extend the franchise to, or vote for Aboriginal people, regardless of whether they were “schooled” or not. “Assimilation” was entirely about change, and not about inclusion. It could hardly be otherwise under the circumstances. At the peak in the 1930s, there were roughly 80 residential schools in Canada. They were in seven of the nine provinces; there were none in New Brunswick and Prince Edward Island, nor were in the Dominion (later, the province) of Newfoundland. Most of the schools were located far from urban centres. As institutions go, the large brick or stone structures were universally imposing. At Kamloops (Tk’emlúps), for example, the Indian Residential School, opened in 1893, was the largest brick structure in the Thompson Valleys and, indeed, between the Lower Mainland and the CPR hotels of the Rocky Mountain national parks. An entire brickworks was established to enable its construction. On Kuper Island, at Alert Bay, and in town after town across the Prairies, two- and three-storey buildings were erected to enable the warehousing and transformation of generations of Native children. The involvement of the nation’s Christian churches from the outset was viewed by officials as a good way to transmit Euro-Canadian cultural values, morals, and discipline. It was, as well, cheap, because missionary groups would effectively work for free. Over half of the schools were run by the Catholic Church, most of the rest by the Anglicans, and the remainder by the United Church and the Presbyterians. Conditions varied from place to place, but few were adequately funded; by the second quarter of the 20th century, child labour was an essential component of the residential school business model. Through most of their history, the general practice at residential schools was to provide only half-day schooling; the rest of the day was dedicated to labour in the fields and workshops, and mopping the floors to keep the children busy and reduce operating costs. The schooling the students received was light on the humanities, lighter still on sciences and math, and heavy on religion and theology. Generally speaking, girls were taught domestic skills like cooking and sewing, while boys were taught basic agricultural skills and some crafts. Children were housed in dormitory rooms. Rows of beds allowed for little privacy. Boys and girls were separated and kept separate: stories abound of brothers and sisters who were allowed no contact despite being kept in the same building. Showers and baths were spartan. Meals were Dickensian, and children suffered from malnutrition. Complaints of cold facilities are sustained by a terrible record of mortalities from illnesses, including tuberculosis (which claimed as many as 60% of the student population). Every residential school has its own sad little graveyard, and some of them aren’t that little. As Mary-Ellen Kelm has pointed out, some schools kept their mortality statistics low by shipping fatally ill children home to their families, which consequently inflated mortality rates on reserves. Kelm also has noted that the transformation of Aboriginal diets to Euro-Canadian foods was part of an attempt to colonize not only the mind but the Aboriginal body as well. Mary-Ellen Kelm, Colonizing Bodies: Aboriginal Health and Healing in British Columbia, 1900-50 (Vancouver, BC: University of British Columbia Press, 1998). Doing so could be lethal: only recently, it has become known that nutritional experiments conducted on children under Ottawa’s auspices resulted in deaths. If the colonizing society wasn’t intervening in education or abducting children from what authorities judged as poor environments, it was managing some of the health crises in which it was — once again — complicit. “Indian hospitals,” separate from non-Aboriginal facilities, were established to deal with the specific illnesses (mostly tuberculosis) that afflicted Aboriginal populations. On the whole, these Indian hospitals functioned as another element in the government’s management of Aboriginal lives. Sainty Morris In the mid-1940s, perhaps a little later, Sainty Morris — still a very young child — contracted tuberculosis from his older brother, with whom he shared a bed in his parents’ home on the reserve near Duncan on Vancouver Island. Soon thereafter, he was sent by medical authorities to the Nanaimo Indian Hospital, more than 60 km north. He passed along this account — from which I quote at some length — to a historian of healthcare Laurie Meijer Drees. One would have to have a very flinty heart indeed to read this and not be moved; more than that, however, it serves to show the severe disempowerment of Aboriginal people and the complicity of far more than a handful of officials and professionals in the business of controlling Aboriginal children. In the hospital the food was good. At the time we were used to our native ice cream [made from berries and fish grease whipped together…] and other food that we were raise[d] on. At that time, my family had little money, and we lived mainly off the land and the beaches. When I was in hospital, I wished I had clams, duck, and all that food from home that I could not have. The nurses when I first got in there were funny. They were mean and there was one nurse who used the strap on us. I remember a particular time. It was when I first got to the hospital. They had what you called a rest period. It was set for an hour in the morning and an hour in the afternoon. I was new there and could not force myself to sleep so I picked myself up a book, a comic book. As I was lying there reading, I remember how suddenly the book was smashed out of my hand. I got strapped! The nurse took my comic book away and strapped my hand with leather. On the other hand, there was another nurse who was very friendly. […]I thought she was a very wonderful friend as opposed to the other one. I wasn’t the only one that was strapped. She strapped a lot of other children. I was there off and on for, I can’t remember, years, months, days. I was in there for a year and a half when they sent me to Kuper Island Indian Residential School. After being there for a while, I was sent back to the Nanaimo Indian Hospital. […]One day the head nurse came to see me, and she told me I was going home. I was so happy! She said, “We are going to measure you for clothing and are ordering your clothes from Vancouver. Then you are going home.” A few weeks later, the nurses came and brought me to change into my new clothes. I got a bath and changed clothes, and then I asked if I could visit my friends and relatives [in the hospital]. I was allowed to visit, and they said, “We’ll find you when the nurse is ready.” Miss Fletcher finally showed up, and we got into her car and starting heading south, towards where my family lived. We started going towards Chemainus [a town between Nanaimo and Duncan]. I thought we were going to a store there, but when we got to the wharf, she told me to get out. I thought, “What is going on?” She told me, “You are going to Kuper Island Residential School.” I told her, “No, they told me I was going home.” That’s when the nurse told me, “No, I’ve got strict orders not to leave you until you get onto that boat.” So I got onto the boat, and they brought me there…. Figure 11.19 Kuper Island Residential School. This school was another awful place. They [the hospital staff] didn’t tell my parents they were shipping me to Kuper Island! My parents didn’t know where I was! My … sister-in-law, Therese [another TB case at the Indian Hospital], she phoned my parents to ask how I was doing, and that’s when it turned out they didn’t know where I was. I finally wrote a letter to let them know I was at the school. When I asked the principal why they sent me to Kuper Island, he said that I was here for a rest. Some rest that was. I tell you, I did not know why they did that! As soon as I got there, they had me scrubbing things on my hands and knees and washing everything by hand. After I finished one place, I had to wax. I had to do every room in that school, both the boy and girl sides. The other kids were in school, and I went to class part of the time. One day they told me to go to the top dormitory and to wash the outside of the building and to be careful not to fall down. There was no rope, no safety, and if there was a streak I would have to go back and clean it. Eventually I got sick again, and I was sent back to the hospital in Nanaimo. Sainty Morris, interviewed in Laurie Meijer Drees, Healing Histories: Stories from Canada’s Indian Hospitals (Edmonton, AB: University of Alberta Press, 2013), xviii-xxx. Whether First Nations leaders found the concept of the industrial and then residential schools helpful to their people or not, the reality fell very far short. Parents often resisted sending their children away, and it was one of the functions of the RCMP and units like the BC Provincial Police to assist the clergy with annual roundups of students. It wasn’t until the late 1950s that the educational curriculum improved, nor was it until then that children were allowed to visit with family over the holidays. The record suggests that a great many parents discovered that their child had died at school only when the summer holidays began. These are the elements of the systemic weaknesses and shortcomings of the residential schools. Underfunding alone would have produced many of these negative outcomes. Tales of physical and sexual abuse operate at a different level. The principle Christian denominations were viewed by Euro-Canadian society as moral guardians; as a result, Canadians found it difficult to accept tales of abuse. Evidence began to accumulate and patterns began to emerge in the 1970s and 1980s. In 1990 the leader of the Assembly of Manitoba Chiefs, Phil Fontaine (b. 1944), publicly disclosed the sexual abuse he suffered as a child in residential schools, along with his reckoning that every boy in his class was similarly mistreated. This disclosure led to others and, in 1991, a Royal Commission on Aboriginal Peoples was convened. Seven years later, the Minister of Indian Affairs issued a formal apology to victims of sexual abuse in the schools, and a multi-million dollar fund for healing was established. While this process uncovered some very grim tales, it did not speak to the psychological, physical (in addition to sexual), and emotional abuse experienced routinely in the schools. Priests and nuns alike, as well as secular workers at the schools, were named, some charged, and some  convicted of a wide range of sadistic practices. One survivor of St. Anne’s Residential School at Fort Albany, ON went on record to describe the kind of abuse meted out by one nun: I remember being in the dining room having a meal. I got sick and threw up on the floor. Sister Mary Immaculate [Anna Wesley] slapped me many times and made me eat my own vomit. So I did, I ate all of it. And then I threw up again … Sister Mary Immaculate slapped me and told me again to eat my vomit. … I was sick for a few days after that. Jesse Staniforth, “Cover up of residential school crimes a national shame,” thestar.com , August 25, 2015, accessed January 31, 2016, . Beginning in the 1950s, Aboriginal children were permitted to attend public schools for the first time, and as day-students. Family connections were rebuilt, but the residential schools remained in place for most of the youngest First Nations children in the country. In 1969 the D.I.A. took over the operation of the schools from the churches, which coincided with the Red Paper and the rise of Aboriginal political organizations. However, this is not to say that there was unanimity among First Nations as to what should happen next. Gradually, the responsibility for the schools’ operations shifted to local band councils. By 1986 all of the schools were in the hands of Aboriginal managers, and many had been closed down entirely. It is reckoned that 150,000 children passed through the system from the end of the 19th century to the mid-1980s. Some of the structures are still standing: St. Eugene near Cranbrook has been converted into a luxury resort/casino and now generates revenue for the Ktunaxa First Nation; the Kamloops Indian Residential School houses offices and a museum for the highly entrepreneurial Tk’emlúps te Secwepemc. Other schools are no more: the Penelakut/Kuper Island school was demolished in the 1980s, as was St. Michael’s at Alert Bay very recently — in both cases, the prohibitive costs of repair and rehabilitation were a factor, as was an unwillingness to tolerate the gloomy presence of the buildings any longer. In 1988 Ottawa issued the first of two official apologies for the residential school experiment. Lawsuits followed and, by 2005, Ottawa had accepted a measure of culpability and set aside $1.8 billion in a compensation fund for survivors of residential schools. In 2008 Prime Minister Stephen Harper issued a fulsome apology in the House of Commons; in an unprecedented move, the leaders of Canada’s various Aboriginal political organizations attended. Although the apology was a landmark in that it involved culpability and knowledge that children placed in the care of the state were harmed, it did not accept liability. While some Aboriginal people were pleased with the apology, for many it was insufficient. When Stephen Harper announced to the G-20 in 2009 that Canada has “no history of colonialism,” questions were asked with respect to the sincerity and intelligence of his apology. Aspects of the apology and the political movements arising from it are considered in the next section. Key Points The residential schools were a project devised to replace aboriginal culture with a version of Euro-Canadian, Christian culture, and part of a larger concerted effort to interrupt the reproduction of cultural traditions in Aboriginal communities. Education and training did little to prepare Aboriginal pupils for the Canadian economy. The 80 residential schools located in every territory and province other than New Brunswick, PEI, and Newfoundland were operated by Christian clergy. Conditions were very poor, resulting in malnutrition, vulnerability to disease, and high levels of mortality. There were extraordinarily high levels of physical, psychological, and sexual abuse in the schools, principally by the clergy. The schools began closing in the 1980s; all have now been closed, demolished, or repurposed. Figure 11.18 Période d’étude au pensionnat indien catholique de [Fort] Resolution, T. N.-O. (Online MIKAN no.4063309) by Canada, Minister of the Interior, Library and Archives Canada / PA-042133 is in the public domain . Figure 11.19 Kuper Island Indian Residential School (Online MIKAN no.4820442) by Canada. Dept. of Interior / Library and Archives Canada / e011156551-v8 ; e011156551_s1-v8 is in the public domain . 150 11.12 Idle No More Mary-Ellen Kelm, Department of History, Simon Fraser University Figure 11.20 Idle No More marchers in Ottawa, 2013. On June 11, 2008, Prime Minister Stephen Harper rose in Canada’s House of Commons to give an official apology for residential schooling. He called the treatment of Aboriginal children in the schools “a sad chapter in our history,” for which “the Government of Canada sincerely apologizes.” Stephen Harper, “Statement of Apology to Former Students of Indian Residential Schools,” House of Commons, Ottawa, June, 11, 2008, accessed April 27, 2016, Mr. Harper and the other party leaders expressed palpable remorse for the past injustices of Canadian policy, and leaders representing First Nations, Métis, Inuit peoples, women, and urban Aboriginal people gravely responded to the apology from the floor of the House. For many Canadians, this promised to be a turning point in our relations with Aboriginal peoples. Until the 1990s when stories of abuse in the schools hit the media and the courts, most Canadians had never heard of the schools. Now the Prime Minister of Canada was admitting that a government policy had been wrong and that the attitudes that inspired the policy have “no place in Canada.” More importantly, he promised a new relationship between Aboriginal peoples and Canadians, one of shared history, renewed understanding, and new respect for all cultures, traditions, and communities. Ibid. Two processes were meant to bring this new relationship about. First there was compensation for those who attended the residential schools. Second, the Truth and Reconciliation Commission ( TRC ) was tasked with documenting the full history of the schools. Restorative justice scholars gave the Harper apology high marks. Sheryl Lightfoot, “Settler-State Apologies to Indigenous Peoples: A Normative Framework and Comparative Assessment,” Journal of the Native American and Indigenous Studies Association 2, no. 1 (2015): 33. However, the apology was not a turning point. Its major failing was that it situated all the wrongs of government policy in the past. It did not commit the Canadian Government in any concrete way to changing its actions towards First Nations, Inuit, and Métis peoples in the present. This was a significant mistake because a changed relationship with Canada was what Aboriginal people wanted. Beverley Jacobs, “Response to Canada’s Apology to Residential School Survivors,” Canadian Woman Studies 26, no. 3/4 (2008): 223; Sheryl Lightfoot, “Settler-State Apologies to Indigenous Peoples: A Normative Framework and Comparative Assessment,” Journal of the Native American and Indigenous Studies Association 2, no. 1 (2015): 33. By 2008, Aboriginal people in Canada had already begun to shift the conversation between themselves and Canadians in really fundamental ways. In the 20th century, Aboriginal people demanded government recognition of their rights and title to the land. As a new generation of Aboriginal leaders arose, they increasingly sought resurgence — of their own cultures and communities — rather than recognition. They wanted a new relationship with Canada, the kind of relationship of sharing and mutual respect that their ancestors had expected when they signed treaties. Figure 11.21 The Jericho Diamond Mine pit in Nunavut, n.d. The trouble was that Aboriginal people have not shared equally in Canadian wealth. In some parts of Canada, Aboriginal people have poverty rates that are three times those of other Canadians. Shauna MacKinnon, “The Harper ‘Apology’: Residential Schools and Bill C-10” (Winnipeg: Canadian Centre for Policy Alternatives, Manitoba Office, January 24, 2012); Aboriginal Children in Care Working Group, Aboriginal Children in Care: Report to Canada’s Premiers (Ottawa: Council of the Federation Secretariat, 2015): 45. July 2015: 45. Less money is spent on reserve schools and Aboriginal children are ten times more likely to end up in foster care. Don Drummond and Ellen Rosenbluth, “The Debate on First Nations Education Funding: Mind the Gap,” Working Paper, Queen’s University Policy Studies (Kingston: Queen’s University, December 2013); Aboriginal Children in Care Working Group, “Aboriginal Children in Care,” 7. So while Mr. Harper was apologizing for the damage done to Aboriginal children and families by residential schools, the legacies of residential schooling continued unabated. Aboriginal Children in Care Working Group, Aboriginal Children in Care , 6. The Cree community of Attawapiskat has become emblematic of Canada’s dysfunctional relationship with Aboriginal people. An isolated community on the shores of James Bay, Attawapiskat made the news repeatedly in the early 2000s. Its only school was condemned as a health hazard, and student Shannen Koostachin took her demands for a new school to Ottawa in 2007. Four years later, Chief Theresa Spence (b. 1963) declared a state of emergency over inadequate housing. What made the situation worse was that the multinational corporation DeBeers was just 80 km away making a steady profit mining diamonds from Cree lands. The agreement DeBeers signed with Attawapiskat to share the mine’s benefits did not include infrastructure, such as schools and houses, because that was, they argued, the responsibility of the Canadian government. Kelly Crichton, Producer, 8th Fire: Canada, Aboriginal Peoples and the Way Forward, Documentary Series, Canadian Broadcasting Corporation, 2012, accessed April 27, 2016, . On December 11, 2012, Spence announced that she would go on a hunger strike to protest unfulfilled treaties. The Kino-nda-niimi Collective, The Winter We Danced: Voices from the Past, the Future, and the Idle No More Movement (Winnipeg, MB: ARP Books, 2014), 391. When Spence announced her hunger strike, she joined an already growing wave of protest and resurgence among Aboriginal people. The protest centred on government Bill C-45, a 457-page omnibus bill that loosened legal restrictions inhibiting investment in Canadian resources. The changes that C-45 introduced to the Indian Act , for example, made it easier to lease or surrender reserve land by removing the democratic requirement for a community-wide vote. First Nations were not consulted on any of these changes. Within a month of C-45’s first reading, on 10 November 2012, four Aboriginal women in Saskatoon — Sylvia McAdam, Nina Wilson, Jessica Gordon, and Sheelah McLean — conducted a teach-in on the bill, which they publicized under the name Idle No More . Ibid., 390. For the next six months, Idle No More exemplified Aboriginal resurgence. Social media was a major force in Idle No More: by May 2013, there had been over 1.2 million Twitter mentions of the #Idlenomore hashtag. The social media profile of Idle No More underscores an important feature of the movement: it was diverse and dispersed in its power and its leadership — not linked to any mainstream Aboriginal organization. Idle No More acknowledged the importance of women in Aboriginal communities, and they often took the stage at events. To honour her leadership, the movement rallied behind Chief Spence in her hunger strike. To emphasize the social media component is, however, to miss the incredible live experience of the movement. Hundreds attended teach-ins across the country to learn more about bill C-45, and how it violated treaty rights. Thousands marched on Parliament Hill on January 10, 2013 and participated in coordinated days of action across the country. The Harper apology in 2008 and the subsequent findings of the TRC, released in 2015, have given Canadians ample reason to reflect on their failed relationship with Aboriginal people. Yet Aboriginal people ask not that Canadians focus on the past, but on the present and the future. TRC Chair, Chief Justice Murray Sinclair, has said that Canada will fail to uphold the spirit of the 2008 apology unless it commits to involving Aboriginal people in decisions about their lands and resources. APTN National News, “PM Harper Has Failed to Live up to Promise of 2008 Residential School Apology: TRC,” June, 2, 2015, accessed April 27, 2016, . This too was Idle No More’s demand as the movement expressed renewed pride among Aboriginal peoples for their grassroots leadership and traditional methods of peaceful social change. Key Points The intent of Harper’s 2008 apology was to bring an end to the saga of the residential schools, but it provided little in the way of a plan for moving forward. Compensation and a Royal Commission on Truth and Reconciliation followed. Aboriginal peoples sought two things in particular: a resurgence, rebuilding of their cultures and communities, along with an equitable share of Canadian prosperity. Substandard housing conditions, water supplies, and school facilities on reserves became a focus. Changes to the Indian Act introduced in 2012 promised to further weaken Aboriginal control over reserve and traditional lands — a prospect that spurred the Idle No More movement. One result of these developments has been a shift in discourse among Aboriginal peoples and among Canadians generally. Figure 11.20 Idle No More 2013 Ottawa 1 by Michelle Caron ( Moxy ) is used under a CC-BY-SA-3.0 license. Figure 11.21 Jericho Diamond Mine pit Nunavut Canada by Tomchurchill is in the public domain . 151 11.13 Summary Figure 11.22 Members of the Alkali Lake Braves hockey team in Vancouver, 1932. A few years later liquor became available to the Esketemc and an alcoholism epidemic was underway. The band’s collective recovery began in the 1970s and has become legendary, although recovery from cultural genocide, abuses in schools, and on-reserve poverty continues to be a work in progress. The thrust of Canadian policy as regards Aboriginal people was, from 1867 on, assimilation. John A. Macdonald said that “the great aim of our legislation has been to do away with the tribal system and assimilate the Indian people in all respects with the inhabitants of the Dominion, as speedily as they are fit for the change.” Quoted in J.R. Miller, Skyscrapers Hide the Heavens: A History of Indian-White Relations in Canada , revised edition (Toronto, ON: University of Toronto Press, 1991), 189. There were several obstacles to this project, one of which was the racism deeply embedded in Canadian society and laws that implied that Indians would never be “fit” for inclusion. Another obstacle was the resistance mounted by Aboriginal peoples to assimilationist institutions and laws. To be sure, Canadian efforts on this front were also clumsy and largely ineffectual. Decades of promoting the benefits of relinquishing Indian Status and joining Canadian society resulted in only 250 Aboriginal people taking up the offer of enfranchisement by 1920. Despite the menacing look of the laws against the potlatch and the sun dance, they were feebly enforced (with a few notable exceptions), as was the pass system. ibid., 190-194. Residential schools were much more efficient at crippling family relations and damaging childhoods than they were at producing new “Canadians” ready to join the mainstream economy. Leaving the business of education in the hands of parsimonious missionary religious orders meant that the absence of traditional cultural practices would not be replaced with an education of comparable value. Aboriginal parents and communities who had hoped for relevant training to prepare their children for a world with narrower resources and newly established economic structures would be disappointed. Children themselves resisted the sham of industrial and residential schools by running away, committing acts of vandalism and arson, and by being uncooperative. The circumstances faced by Aboriginal peoples after 1867 varied by place and over time. The Métis diaspora — or at least some of it — was, culturally speaking, in a better position to integrate into the emergent Canadian systems of land ownership, commerce, and knowledge. But at the same time, the Métis lacked any kind of homeland comparable to the reserves that provided First Nations with a base of operations. However, these reserves offered little in the way of guaranteed community prosperity. This was especially the case among relocated communities in the sub-Arctic and Arctic,  Nova Scotia, the Kootenays, and along the Great Lakes (to name only a few locations where people were shunted about to make way for efficiencies, the military, hydroelectricity, and mines). Nothing flags poor conditions on reserves and across the North as much as the ubiquity of tuberculosis in Aboriginal communities — TB is a symptom of poverty, inadequate housing, and poor diets. Colonial-era changes in traditional food supplies were coupled to immediate and general environmental degradation to produce conditions that favoured tuberculosis. The fact that Aboriginal populations recovered in impressive numbers in the face of these grim environmental circumstances begs the question: What would the demographic curve look like if Aboriginal peoples from the 1920s to the 1980s had enjoyed better housing, water, food, schools, and incomes, and less TB? Dealing with TB required the further bureaucratization and institutionalization of Aboriginal life. “Indian hospitals” joined a long list of systems that measured, monitored, rationalized, and individualized Native people. At the same time, these modernist institutions — schools, courts, prisons, hospitals, and Indian Affairs — had to identify “Indian-ness” to fulfill their task of expunging it. Treating all Aboriginal people as one was a kind of pan-Indian approach that, along the way, made it possible for First Nations, Inuit, and Métis to find common ground and to build the foundations of a response. Whatever the shortcomings of the colonialist experience, Aboriginal leaders could nonetheless play the role of magpies, keeping their eyes sharp for the few shiny opportunities that became available. They found useful tools for building up band offices, commercial enterprises, and social programs. The Tk’emlúps te Secwepemc (formerly the Kamloops Indian Band) exemplifies the ways in which First Nations people exploited Canadian assimilationist policies to fashion an effective hybrid culture of entrepreneurship based on principles of band ownership. Several of the Niitsitapi bands enjoy significant advantages arising from their oil-rich reserve lands. The Wei Wai Kum and We Wai Kai of Campbell River and Cape Mudge have utilized other models of economic advancement through commercial development and aboriginal tourism . Each of these experiments began in earnest in the 1980s, and each has leveraged economic success to build cultural and linguistic recovery. It is trite to say that not every experiment has met with victory and that many have faced criticism from within and without individual bands; of course, that is the case. Failure, regrouping, and further trial and error is in the nature of experimentation. It would be even more trite to suggest that the success of a few bands negates the fact that most Aboriginal people continue to live in poverty. A disproportionate number are incarcerated, and violence, abuse, suicide, and homicide are a reality of Aboriginal lives much more so than for non-Aboriginals. Racism has not gone away; it remains a lived experience. One consequence of events since 1970, however, has been the emergence of a cadre of Aboriginal leaders — many of them highly educated and quite a few of them women — whose prominence in government, the arts, media, and commerce are impossible to miss. It is not the business of history to suggest where this may go, nor are historians especially concerned with where we are right now. However, an exploration of the experience of Aboriginal peoples in the past points to themes — the continuing exploration of the relevance of treaties and mutual sovereignty, the necessity of dialogue, the many acts of resistance mounted by native people against colonialism, and the persistence of dramatic inequalities in a country that ostensibly places a high value on humanism — that have contributed to the energy and success of both Idle No More and the Truth and Reconciliation Commission. The current context of that story — the post-Cold War, post-colonial, and postmodern world — is examined in the next chapter. Figure 11.23 Jody Wilson-Raybould (b. 1971) is a Kwakwaka-wakw politician from Comox who was elected in the riding of Vancouver Granville in 2015. She is currently the Federal Minister of Justice — the first Aboriginal person to hold that position. Key Terms Aboriginal rights: Defined in two ways: 1) as an abstract set of inherent and collective rights available on principle only to Aboriginal peoples, which may include land, resource and treaty rights; 2) also or alternately, cultural rights associated with traditional or customary practices that are thought to predate European contact. The latter are protected in the Constitution Act, 1982 . Aboriginal tourism: Usually associated with cultural displays and/or performances, sometimes with Aboriginal lifestyle experiences. The sector was very small in the 1990s, but since has become an annual multi-million dollar industry. Assembly of First Nations (AFN): The successor to the National Indian Brotherhood (NIB); the AFN, a national advocacy organization that represents Aboriginal peoples, was established in 1982. band offices: The administrative centre of a First Nation band; a unit of government within the First Nation; applies principally to populations covered by the Indian Act (that is, Status Indians). The band council is the decision-making assembly in the band office. Burnt Church Crisis: Between 1999 and 2002, a confrontation between the Burnt Church First Nation (a Mi’kmaq community in New Brunswick) and non-Aboriginal fishers and the Federal Department of Fisheries. Calder Case: Supreme Court case (Calder v British Columbia) in 1973 that decided that Aboriginal title existed prior to colonization and persisted after 1871. Criminal Code : Properly, an Act respecting the criminal law ; the Criminal Code is a regularly amended body of legislation pertaining to criminal — as opposed to civil or statute — law. cultural genocide: Premeditated and systematic attempts to eliminate a culture while not necessarily exterminating the population. Delgamuukw v British Columbia: 1997 landmark decision in the Supreme Court of Canada; established a test for the existence of Aboriginal title, extended title beyond evidence of past use to include custodianship of territory, and thus includes a cultural relationship — rather than simply an economic relationship — with the land. Department of Indian Affairs and Northern Development: Created in 1966, a successor administrative unit to the Department of Indian Affairs (D.I.A.). Department of Indian Affairs (DIA): Established in 1888 to administer the Federal Government’s responsibilities as regards First Nations; was housed for many years under the office of the Minister of the Interior (who was also responsible for settling the West with immigrants). Douglas Treaties: Negotiated by Governor James Douglas of Vancouver Island in the colonial era and concluded with 14 First Nations in the colony in the early 1850s; apart from Treaty No.8 in the Peace District, the only treaties in British Columbia before the late 20th century. Fourth World: A category of mostly small and colonized indigenous populations around the globe; juxtaposed with First (northwestern European and North American), Second (Soviet bloc of developed nations), and Third (developing) Worlds; formalized with the establishment of the World Council of Indigenous Peoples led by George Manuel in the mid-1970s. Idle No More: A peaceful protest and awareness-raising movement launched in 2012 by a group of Aboriginal and allies; catalyzed by Federal Government legislation that threatened Treaty rights. Mohawk Institute: First industrial school for Aboriginal people, principally Mohawk; taught basic academic instruction and trades; based in Brantford, Ontario; opened in the 1830s under the auspices of the New England Company. nadir: The opposite of zenith; it is the trough, and in demographic terms, it means the point at which a falling population bottoms out and from which it recovers. In the case of First Nations populations, they continued to fall until the 1920s at which point they began a steady recovery. National Indian Brotherhood (NIB): Established in 1967-1968 and propelled into action by the appearance of the White Paper (1969). See also Assembly of First Nations. numbered treaties: Treaties struck between Canada and Aboriginal peoples from 1871 (Treaty 1) to 1921 (Treaty 11), covering a territory that stretches from Ontario’s eastern boundary in the North West to British Columbia, incorporating the whole of the Peace River Valley and the Mackenzie River drainage basin. Areas not covered by numbered treaties include southern Ontario (including the Rainy River area and Thunder Bay-Nippissing corridor), most of British Columbia, most of the Yukon and North West Territories, and all of Quebec, the Maritimes, and Newfoundland-Labrador. Oka Crisis: In 1990 armed Mohawk band members from Kanesatake blockaded access to the proposed construction site of a golf course in Oka; the arrival of Canadian Armed Forces troops was followed by disruptions of traffic through reserve lands to the south by Mohawk band members from Kahnawake. pass system: Aboriginal reserve residents were required to secure a pass from their Indian agent in order to leave the reserve. Penner Report: Recommended to Ottawa in 1983 that Aboriginal peoples constitute a distinct order of government and ought to be recognized as such. post-colonial, post-colonialism: The range of experiences and perspectives that look beyond the paradigm of colonial society and colonialism; associated with the late 20th century. potlatch: Refers to ceremonies associated with First Nations cultures on the Pacific Northwest Coast. Red Paper: Also called Citizens Plus ; prepared by Harold Cardinal and the Indian Association of Alberta in 1970, the Red Paper was a response to Ottawa’s 1969 White Paper (aka: The Statement of the Government of Canada on Indian Policy, 1969 ); called for preservation of Treaty rights and recognition of Aboriginal rights. Red Power: A continent-wide movement led by Aboriginal peoples in the late 1960s and through the 1970s to place Aboriginal issues on the political agenda. Royal Proclamation: 1763; Britain’s first constitution for post-Conquest Canada; recognized inherent Indigenous land tenure rights or Aboriginal title to the land, making it impossible for any authority or individual other than the Crown to alienate Aboriginal title; provoked objections among the American colonists because it interfered with their plans for westward expansion; sometimes called the Indian Magna Carta . Section 35: Of the Constitution Act, 1982 ; recognizes and affirms Aboriginal rights. sixties scoop: The apprehension and removal of Aboriginal children from their families and communities by provincial child welfare authorities during the 1960s. Truth and Reconciliation Commission (TRC): A commission tasked in 2008 with documenting the full history of the residential schools; report presented in 2015. tuberculosis (TB): An epidemic associated with rapid urbanization, tenement housing, slums, and poverty; spread rapidly in the post-Confederation period, becoming epidemic among Aboriginal populations; tuberculosis sanatoria were established and operating across Canada until the 1960s, by which time antibiotics (especially Streptomycin) had severely reduced the incidence and morbidity associated with TB. Union of BC Indian Chiefs (UBCIC): Established in 1969 in response to the Federal Government’s White Paper; replaced rival coastal and interior groups. vagrancy: The state of being without work or employment, homelessness, and (often) transience; associated with poverty and begging. Vagrancy was treated as a crime and was listed in the Criminal Code until 1972. The 21st century has seen the return of anti-vagrancy laws with different names. wheat pools: Typically cooperatives made up of grain growers who combined (pooled) their output — and risk — to reduce competition and overheads while securing the best price; replaced temporarily by the Canadian Wheat Board in 1935; competed against private grain elevators in the post-war era. White Paper: Also known as The Statement of the Government of Canada on Indian Policy, 1969 ; proposed the dismantling of the Indian Act , an effective end to Indian Status, and the conversion of reserve land to private property; introduced by the Liberal government of Pierre Trudeau and led by the Minister of Justice, Jean Chrétien; met with strident opposition from Aboriginal leaders, part of which took the form of the Red Paper. Suggested Readings Girard, Michel F. “The Oka Crisis from an Environmental Perspective, 1870-1990.” In Consuming Canada: Readings in Environmental History, edited by Chad Gaffield and Pam Gaffield, 298-315. Toronto, ON: Copp Clark, 1995. Kenny, James and Bill Parenteau. “‘Each year the Indians flexed their muscles a little more’: The Maliseet Defence of Aboriginal Fishing Rights on the St. John River, 1945–1990.” Canadian Historical Review 95, no. 2 (2014): 187-216. Knickerbocker, Madeline Rose. “’namała, Su Na chii k’chige, ʔems taʔaw: Indigenous-Academic Collaborative Histories.” Histoire sociale/Social history 48, no. 96 (2015): 294-302. Lutz, John. “After the Fur Trade: The Aboriginal Labouring Class of British Columbia, 1849-1890.” Journal of the Canadian Historical Association 3 (1992): 69-93. Lux, Maureen K. “Care for the ‘Racially Careless’: Indian Hospitals in the Canadian West, 1920–1950s.” Canadian Historical Review 9 1, no. 3 (2010): 407-434. Neimi-Bohun, Melanie. “Colonial Categories and Familial Responses to Treaty and Metis Scrip Policy: The ‘Edmonton and District Stragglers,’ 1870–88.” Canadian Historical Review 90, no. 1 (2009): 71-98. Neylan, Susan. “Colonialism and Resettling British Columbia: Canadian Aboriginal Historiography, 1992–2012.” History Compass 11, no. 10 (2013): 833-844. Rueck, Daniel. “Commons, Enclosure, and Resistance in Kahnawáke Mohawk Territory, 1850–1900.” Canadian Historical Review 95, no. 3 (2014): 352-381. Figure 11.22 CVA 99-4112 – Indian Hockey Team [from] Alkali Lake by Stewart Thompson / City of Vancouver Archives (AM1535-: CVA 99-4112) is in the public domain . Figure 11.23 Jody Wilson-Raybould by Erich Saide is used under a CC-BY-SA-3.0 license. XIII Chapter 12. Canada at the End of History 152 12.1 Introduction Figure 12.1 The National Film Board came under heavy fire in the early 1990s when it produced a 3-part series, The Valour and the Horror , on what it claimed were less-than-noble moments in Canada’s WWII record. The CBC aired the series and was excoriated by politicians and veterans alike. Just as 1914-1918 marks a watershed in the history of the modern world, so does 1989-1991. The end of the Cold War signalled to some a turning point in international affairs and, thus, the end of the “short 20th century.” Francis Fukuyama (b. 1952), an American political economist, argued in his 1992 book The End of History and the Last Man that the centuries-long struggle between competing ideologies was essentially settled and that liberal democracies with market economies had won. It wasn’t that “history” itself was over but that the idea of history as an unfolding of alternative models of social and economic relations was done. This constitutes a response to Karl Marx — the 19th century political economist — who predicted, instead, the inevitable triumph of the industrial proletariat, the elimination of national governments and states, and the emergence of global (though not Soviet) communism. One could debate endlessly whether Fukuyama was on target, premature, or a decade late. His work nevertheless underscored the fact that the world had reached a watershed in the early 1990s. The growth of the nation state since the 18th century — as an idea and a phenomenon — had dominated thinking about history for two centuries. The Western perspective was severely linear and, after the mid-19th century, evolutionary as well. Nations developed from antiquity through feudalism, absolutism, capitalism, and sometimes communism, to something new. Each nation moved along this course at its own speed because its economic needs favoured one system over the last. This view was at the heart of Marxist theory but also the models of most other Western thinkers, journalists, and — importantly — historians. For example, the Whig historians of the 19th and early 20th century argued that the history of humanity was a constant movement forward — progress — toward a better and better society. However, the Whigs were no Marxists; they were small-l liberals who believed that greater freedoms — from feudalism or monarchism, for example — led to greater happiness and a better nation state. For the most part, the business of writing history has been bound up with the question of how nations form and operate. This has been done in the service of the idea of a Fukuyama-esque history , the unfolding of a nation’s story from beginning to end (or more cheerily) to a continuously brighter and better future. If History (with a capital “H”) existed to serve (and serve up) the national story of progress, it was deeply rooted in modernity. The modern age, with its emphasis on social and technological progress, was both the environment of the state and a measure of its success. Democracy, a wider distribution of wealth and opportunity, and the latest infrastructural fashions were the means and ends simultaneously. The blueprints of modernity, as we have seen nearly two centuries ago, would inevitably require revision. At the end of the Cold War, the balance of global power changed dramatically. International bipolarism was over, and when the stand-off between the two superpowers evaporated, the necessity and perhaps the possibility of mutually assured destruction (MAD) also went out the door, even though more nations had joined the “nuclear club.” The urgency felt by successive governments in Canada to deliver the “good life” so to make communism look less appealing was effectively gone as well. Beyond foreign affairs and domestic policies, however, the “end of history” also suggested the end of the meta-narrative. In this new postmodern era, the saga of the nation had outlived its purpose. History — that assembling of stories about the past that offer insights into the affairs of humans then and now — could shift its focus away from what the popular historian Pierre Berton (1920-2004) called “the national dream.” Berton’s history of the CPR, The National Dream , was first published in 1970 and was followed the next year by The Last Spike. Both describe the project and the politicians and capitalists behind it in heroic, nation-building terms. These are, in all likelihood, the best selling Canadian history books ever. A great popularizer of history, Berton was also a champion of the nationalist school. The spotlight could now fall on stories that had either been viewed as unimportant or irrelevant to the main event, or to histories that actually countered modernity’s forward march. The most visible facet of that postmodernist trend in the writing of history has been post-colonialism. At one stage in the history of Canada — for something like 200 years — colonization (biological settlement and populating) and colonialism (the intentional suppression of Indigenous peoples) were regarded approvingly as two of the foremost elements of the Canadian project. Through that lens, “Aboriginal history” was almost an oxymoron, a contradiction in terms. Post-colonialism made room for histories of First Nations that provided other perspectives and, from time to time, spoke with Aboriginal voices. This chapter engages with several of these ideas. What was Canada like in the first decade or so at the “end of history”? In what ways was the postmodern made manifest in domestic, social, economic, and international affairs? How had our world and historic view changed? Could Canada continue to hide from its colonialist past in a post-colonial world? Canada’s emerging international and domestic preoccupations are explored, including the fringe political movements of the day. As the meta-narrative of Canadian history began to fray, it became possible to look with some detachment at the ways in which national identity and alternative identities were constructed in the 20th century, which included challenges to the “normal” that were increasingly launched in the 1980s, 1990s, and the new millennium. If the histories that sustained the national project were no longer vitally necessary or particularly welcome in the academy, what replaced them? As the postmodern world fractured storylines into increasingly specialized fragments, historians began to question whether a national history was even possible. This chapter explores some aspects of the newer historical interests, including two considerations of digital histories. History Wars The idea that historical method has responded to this changed world is also engaged in this chapter. If the focus of historical research is no longer the political history of the state, it moves from the parliamentary archives into different places and employs different tools while asking different questions. History itself changes along with the society that has emerged at history’s end. The writing of history proceeds unevenly for many and diverse reasons. In the 1960s and 1970s, there was a sudden explosion of excellent social and political history for three reasons. First, as a response to the baby boom and a national Cold War-era commitment to further education (which, notably, replaced an earlier ideology of exclusivity), there were vastly more university and college campuses and seats available to a rising generation. Second, that cohort was itself more diverse than any other in Canadian post-secondary education to that time, and it brought to the seminar table its own concerns about society and the stories we tell. Third, out of that hothouse came a generation of scholars — larger than any before it — with a shared cultural experience and language that enabled the transformation of historical studies. The benefits have been a rich legacy of investigations into the society and culture of Canada with the chief liability being a bottleneck of Cold War-era academics whose views continue to dominate as successive generations of historians strive to be heard. By way of an example, we can look at histories of the West. Valerie Korinek, an authority on Prairie and queer history, offers some insight into where Canadian history has failed to go, and calls for Western historians in particular to pay attention to the late 20th century: This was a time of considerable transformation for the Prairie West (some might argue Western ascendancy, albeit uneven) as it reconfigured from a primarily rural to an urban place, as it became an economic powerhouse, and as demographic shifts made it an increasing social and political force within the country. This transformation needs to be explored and assessed historically. Regretfully, Western historians have failed to participate in enumerating and evaluating these substantive historical changes in the second half of the twentieth century…. Valerie Korinek, “A Queer-eye View of the Prairies: Reorienting Western Canadian Histories,” in The West and Beyond: New Perspectives on an Imagined Region , eds. Alvin Finkel, Sarah Carter, and Peter Fortna (Edmonton, AB: Athabasca University Press, 2010), 281. It is not fair to say that Western Canadian historians are stuck in the past (insert winking emoji here), but the truth is that contemporary or even post-centennial histories are rare. What Korinek identifies is, in part, the challenge of contemporary history . How old do events have to be before they slip from one side of the ledger (made up of Politics, Economics, Sociology, etc.) over to the other side (where we find History)? There’s no ironclad rule on this front. The 20th century historian Kenneth McNaught (1918-1997) is said to have claimed that everything after World War One constituted “current events.” To someone born in 1918, that might make some sense but, as all historians come to realize, that boundary is always in motion. The historians who came of age in the late 1960s — mostly born in the 1940s — might be excused for feeling uncomfortable with histories of life after 1939, although that has not held back everyone. Alvin Finkel’s Our Lives: Canada after 1945 and Doug Owram’s Born at the Right Time: A History of the Baby Boom Generation show baby boomers successfully tackling the mid-century as an historical environment. However, as Korinek points out, older discourses persist, narratives become embedded within narratives, and we risk becoming unaware of the changes that history might reveal to us. In Canadian History: Pre-Confederation, I describe the current state of historical writing, including the conflict between generations of historians that took place in the 1990s. The so-called History Wars pitted the older nationalist historians against the rising generation of scholars who argued there was no longer one meta-narrative of the Canadian experience. Building a national identity out of a shared historic experience was the task set before modern historians; deconstructing those stories to show how they implicitly privileged certain groups and perspectives was the challenge taken up by newcomers to the field. The nationalist historians went down swinging. There is no universally accepted collective noun for historians, but the phrase, \"an argumentation of historians\" is sometimes preferred. While their leading figures — Jack Granatstein among them — remained productive but increasingly marginalized from the innovative work in the discipline, their advocates did not completely surrender the battlefield. Efforts to recast Canadian history as something comfortably familiar were undertaken in the last decade by conservatives who regard the Pearson years and its “pennant” as the point in time when Canada drifted from its moorings. For example, a cohort of British, imperialist, and fans of military history sought to restore a common curriculum of nation-serving historical studies in the schools and universities. They failed… mostly. While English-Canadian historical research turns its back on nationalist histories, nationalist views are increasingly embedded in the teaching of French-Canadian history in Quebec. “The History Wars,” writes University of Guelph historian Mark Sholdice, “are really not about history, but rather politics.” Mark Sholdice, “The History Wars in Canada,” Toronto Review of Books , May 5, 2013, accessed January 27, 2016, . The great English historiographer E. H. Carr wrote: “The facts speak only when the historian calls on them”; the historian “decides to which facts to give the floor….” E. H. Carr, What is History? 2nd ed. (Markham, ON: Penguin Canada, 1987), 11. We make those decisions based on, among other things, the politics around us and the politics we live, be that green, feminist, conservative, separatist, religious, or nationalist. It isn’t that political history is at an end; rather, the net we cast to capture political change must necessarily be larger. \n",
      "-----------\n",
      "Assess the transformations of Aboriginal peoples’ resource bases since 1867.\n",
      "Survey the main demographic changes in Aboriginal societies in the 20th century.\n",
      "Describe the main contours of Aboriginal-Newcomer relations since 1867.\n",
      "Identify the main features of the Treaties between Canada and Aboriginal peoples, and the issues they have created.\n",
      "Account for attempts to change Aboriginal economies through schools and farming.\n",
      "Outline Aboriginal peoples’ response to Canadian colonialism since WWII, and assess its effects.\n",
      "Describe and explain the changed political relationship between Aboriginal people and the Canadian state since the 1990s.\n",
      "--------------------------\n",
      "We have seen that, over the course of their lives, most individuals are able to develop secure attachments; reason cognitively, socially, and morally; and create families and find appropriate careers. Eventually, however, as people enter into their 60s and beyond, the aging process leads to faster changes in our physical, cognitive, and social capabilities and needs, and life begins to come to its natural conclusion, resulting in the final life stage, beginning in the 60s , known as late adulthood . Despite the fact that the body and mind are slowing, most older adults nevertheless maintain an active lifestyle, remain as happy as they were when younger — or are happier — and increasingly value their social connections with family and friends (Angner, Ray, Saag, &amp; Allison, 2009). Kennedy, Mather, and Carstensen (2004) found that people’s memories of their lives became more positive with age, and Myers and Diener (1996) found that older adults tended to speak more positively about events in their lives, particularly their relationships with friends and family, than did younger adults. Cognitive Changes During Aging The changes associated with aging do not affect everyone in the same way, and they do not necessarily interfere with a healthy life. Former Beatles drummer Ringo Starr celebrated his 70th birthday in 2010 by playing at Radio City Music Hall, and Rolling Stones singer Mick Jagger (who once supposedly said, “I’d rather be dead than singing ‘Satisfaction’ at 45”) continues to perform even as he turned 70 in 2013. The golfer Tom Watson almost won the 2010 British Open golf tournament at the age of 59, playing against competitors in their 20s and 30s. And people such as the financier Warren Buffett; Jim Pattison, a prominent Vancouver philanthropist; Hazel McCallion, mayor of Mississauga in Ontario for over 35 years; and actress Betty White, all in their 80s or 90s, all enjoy highly productive and energetic lives. Researchers are beginning to better understand the factors that allow some people to age better than others. For one, research has found that the people who are best able to adjust well to changing situations early in life are also able to better adjust later in life (Rubin, 2007; Sroufe, Collins, Egeland, &amp; Carlson, 2009). Perceptions also matter. People who believe that the elderly are sick, vulnerable, and grumpy often act according to such beliefs (Nemmers, 2005), and Levy, Slade, Kunkel, and Kasl (2002) found that the elderly who had more positive perceptions about aging also lived longer. Research on the influence of cultural values and beliefs on aging attitudes has been dominated by comparisons between Eastern/Asian versus Western cultures. This belief is inspired by the idea that Asian societies are influenced by Confucian values of filial piety and the practice of ancestor worship, which are thought to promote positive views of aging and high esteem for older adults (Davis, 1983; Ho, 1994; Sher, 1984). Western societies, in contrast, were thought to be youth-oriented and to hold more negative views about the aging process and the elderly (Palmore, 1975). Empirical evidence for the proposed East-West differences is scarce. Although some studies have found support for the notion that aging attitudes are more positive in Asian as compared to Western cultures (Levy &amp; Langer, 1994; Tan, Zhang, &amp; Fan, 2004), others report effects in the opposite direction (Giles et al., 2000; Harwood et al., 2001; Sharps, Price-Sharps, &amp; Hanson, 1998; Zhou, 2007), or fail to find any marked cultural differences (Boduroglu, Yoon, Luo, &amp; Park, 2006; Ryan, Jin, Anas, &amp; Luh, 2004). Whereas it was once believed that almost all older adults suffered from a generalized memory loss, research now indicates that healthy older adults actually experience only some particular types of memory deficits, while other types of memory remain relatively intact or may even improve with age. Older adults do seem to process information more slowly — it may take them longer to evaluate information and to understand language, and it takes them longer, on average, than it does younger people, to recall a word that they know, even though they are perfectly able to recognize the word once they see it (Burke, Shafto, Craik, &amp; Salthouse, 2008). Older adults also have more difficulty inhibiting and controlling their attention (Persad, Abeles, Zacks, &amp; Denburg, 2002), making them, for example, more likely to talk about topics that are not relevant to the topic at hand when conversing (Pushkar et al., 2000). But slower processing and less accurate executive control do not always mean worse memory, or even worse intelligence. Perhaps the elderly are slower in part because they simply have more knowledge. Indeed, older adults have more crystallized intelligence — that is, general knowledge about the world, as reflected in semantic knowledge, vocabulary, and language . As a result, adults generally outperform younger people on measures of history, geography, and even on crossword puzzles, where this information is useful (Salthouse, 2004). It is this superior knowledge combined with a slower and more complete processing style, along with a more sophisticated understanding of the workings of the world around them, that gives the elderly the advantage of wisdom over the advantages of fluid intelligence — the ability to think and acquire information quickly and abstractly — which favour the young (Baltes, Staudinger, &amp; Lindenberger, 1999; Scheibe, Kunzmann, &amp; Baltes, 2009). The differential changes in crystallized versus fluid intelligence help explain why the elderly do not necessarily show poorer performance on tasks that also require experience (i.e., crystallized intelligence), although they show poorer memory overall. A young chess player may think more quickly, for instance, but a more experienced chess player has more knowledge to draw on. Older adults are also more effective at understanding the nuances of social interactions than younger adults are, in part because they have more experience in relationships (Blanchard-Fields, Mienaltowski, &amp; Seay, 2007). Dementia and Alzheimer’s Disease Some older adults suffer from biologically based cognitive impairments in which the brain is so adversely affected by aging that it becomes very difficult for the person to continue to function effectively. Dementia is defined as a progressive neurological disease that includes loss of cognitive abilities significant enough to interfere with everyday behaviours , and Alzheimer’s disease is a form of dementia that, over a period of years, leads to a loss of emotions, cognitions, and physical functioning, and that is ultimately fatal . Dementia and Alzheimer’s disease are most likely to be observed in individuals who are 65 and older, and the likelihood of developing Alzheimer’s doubles about every five years after age 65. After age 85, the risk reaches nearly 8% per year (Hebert et al., 1995). Dementia and Alzheimer’s disease both produce a gradual decline in functioning of the brain cells that produce the neurotransmitter acetylcholine. Without this neurotransmitter, the neurons are unable to communicate, leaving the brain less and less functional, as shown in Figure 7.10. Figure 7.10 Brains. A healthy brain (left) versus a brain with advanced Alzheimer’s disease (right). Dementia and Alzheimer’s are in part heritable, but there is increasing evidence that the environment also plays a role. And current research is helping us understand the things that older adults can do to help them slow down or prevent the negative cognitive outcomes of aging, including dementia and Alzheimer’s (Pushkar, Bukowski, Schwartzman, Stack, &amp; White, 2007). Older adults who continue to keep their minds active by engaging in cognitive activities, such as reading, playing musical instruments, attending lectures, or doing crossword puzzles, who maintain social interactions with others, and who keep themselves physically fit have a greater chance of maintaining their mental acuity than those who do not (Cherkas et al., 2008; Verghese et al., 2003). In short, although physical illnesses may occur to anyone, the more people keep their brains active and the more they maintain a healthy and active lifestyle, the more healthy their brains will remain (Ertel, Glymour, &amp; Berkman, 2008). Social Changes During Aging: Retiring Effectively Because of increased life expectancy in the 21st century, elderly people can expect to spend approximately a quarter of their lives in retirement. Leaving one’s career is a major life change and can be a time when people experience anxiety, depression, and other negative changes in the self-concept and in self-identity. On the other hand, retirement may also serve as an opportunity for a positive transition from work and career roles to stronger family and community member roles, and the latter may have a variety of positive outcomes for the individual. Retirement may be a relief for people who have worked in boring or physically demanding jobs, particularly if they have other outlets for stimulation and expressing self-identity. Psychologist Mo Wang (2007) observed the well-being of 2,060 people between the ages of 51 and 61 over an eight-year period and made the following recommendations to make the retirement phase a positive one: Continue to work part-time past retirement in order to ease into retirement status slowly. Plan for retirement — this is a good idea financially, but also making plans to incorporate other kinds of work or hobbies into post-employment life makes sense. Retire with someone — if the retiree is still married, it is a good idea to retire at the same time as a spouse, so that people can continue to work part-time and follow a retirement plan together. Have a happy marriage — people with marital problems tend to find retirement more stressful because they do not have a positive home life to return to and can no longer seek refuge in long working hours. Couples that work on their marriages can make their retirements a lot easier. Take care of physical and financial health — a sound financial plan and good physical health can ensure a healthy, peaceful retirement. Retire early from a stressful job — people who stay in stressful jobs for fear that they will lose their pensions or won’t be able to find work somewhere else feel trapped. Toxic environments can take a severe emotional toll on an employee. Leaving an unsatisfying job early may make retirement a relief. Retire “on time” — retiring too early or too late can cause people to feel “out of sync” or to feel they have not achieved their goals. Whereas these seven tips are helpful for a smooth transition to retirement, Wang also notes that people tend to be adaptable, and that no matter how they do it, retirees will eventually adjust to their new lifestyles. Death, Dying, and Bereavement Living includes dealing with our own and our loved ones’ mortality. In her book On Death and Dying (1997), Elisabeth Kübler-Ross describes five phases of grief through which people pass in grappling with the knowledge that they or someone close to them is dying: Denial: “I feel fine.” “This can’t be happening; not to me.” Anger: “Why me? It’s not fair!” “How can this happen to me?” “Who is to blame?” Bargaining: “Just let me live to see my children graduate.” “I’d do anything for a few more years.” “I’d give my life savings if…” Depression: “I’m so sad, why bother with anything?” “I’m going to die. What’s the point?” “I miss my loved ones — why go on?” Acceptance: “I know my time has come; it’s almost my time.” Despite Kübler-Ross’s popularity, there are a growing number of critics of her theory who argue that her five-stage sequence is too constraining because attitudes toward death and dying have been found to vary greatly across cultures and religions, and these variations make the process of dying different according to culture (Bonanno, 2009). As an example, Japanese Americans restrain their grief (Corr, Nabe, &amp; Corr, 2009) so as not to burden other people with their pain. By contrast, Jews observe a seven-day, publicly announced mourning period. In some cultures the elderly are more likely to be living and coping alone, or perhaps only with their spouse, whereas in other cultures, such as the Hispanic culture, the elderly are more likely to be living with their sons and daughters and other relatives, and this social support may create a better quality of life for them (Diaz-Cabello, 2004). Margaret Stroebe and her colleagues (2008) found that although most people adjusted to the loss of a loved one without seeking professional treatment, many had an increased risk of mortality, particularly within the early weeks and months after the loss. These researchers also found that people going through the grieving process suffered more physical and psychological symptoms and illnesses and used more medical services. The health of survivors during the end of life is influenced by factors such as circumstances surrounding the loved one’s death, individual personalities, and ways of coping. People serving as caretakers to partners or other family members who are ill frequently experience a great deal of stress themselves, making the dying process even more stressful. Despite the trauma of the loss of a loved one, people do recover and are able to continue with effective lives. Grief intervention programs can go a long way in helping people cope during the bereavement period (Neimeyer, Holland, Currier, &amp; Mehta, 2008). Key Takeaways Most older adults maintain an active lifestyle, remain as happy as they were when younger, or happier, and increasingly value their social connections with family and friends. Although older adults have slower cognitive processing overall (fluid intelligence), their experience in the form of crystallized intelligence — or existing knowledge about the world and the ability to use it — is maintained and even strengthened during old age. Expectancies about change in aging vary across cultures and may influence how people respond to getting older. A portion of the elderly suffer from age-related brain diseases, such as dementia, a progressive neurological disease that includes significant loss of cognitive abilities, and Alzheimer’s disease, a fatal form of dementia that is related to changes in the cerebral cortex. Two significant social stages in late adulthood are retirement and dealing with grief and bereavement. Studies show that a well-planned retirement can be a pleasant experience. A significant number of people going through the grieving process are at increased risk of mortality and physical and mental illness, but grief counselling can be effective in helping these people cope with their loss. How do the people in your culture view aging? What stereotypes are there about the elderly? Are there other ways that people in your society might learn to think about aging that would be more beneficial? Based on the information you have read in this chapter, what would you tell your parents about how they can best maintain healthy physical and cognitive function into late adulthood? References Angner, E., Ray, M. N., Saag, K. G., &amp; Allison, J. J. (2009). Health and happiness among older adults: A community-based study. Journal of Health Psychology, 14 , 503–512. Baltes, P. B., Staudinger, U. M., &amp; Lindenberger, U. (1999). Life-span psychology: Theory and application to intellectual functioning. Annual Review of Psychology, 50 , 471–506. Blanchard-Fields, F., Mienaltowski, A., &amp; Seay, R. B. (2007). Age differences in everyday problem-solving effectiveness: Older adults select more effective strategies for interpersonal problems. The Journals of Gerontology: Series B: Psychological Sciences and Social Sciences, 62B (1), P61–P64. Boduroglu, A., Yoon, C., Luo, T., &amp; Park, C.D. (2006). Stereotypes about young and old adults: A comparison of Chinese and American Cultures. Gerontology, 52, 324–333. Bonanno, G. (2009). The other side of sadness: What the new science of bereavement tells us about life after a loss . New York, NY: Basic Books. Burke, D. M., Shafto, M. A., Craik, F. I. M., &amp; Salthouse, T. A. (2008). Language and aging. In The handbook of aging and cognition (3rd ed., pp. 373–443). New York, NY: Psychology Press. Cherkas, L. F., Hunkin, J. L., Kato, B. S., Richards, J. B., Gardner, J. P., Surdulescu, G. L.,…Aviv, A. (2008). The association between physical activity in leisure time and leukocyte telomere length. Archives of Internal Medicine, 168 , 154–158. Corr, C. A., Nabe, C. M., &amp; Corr, D. M. (2009). Death and dying: Life and living (6th ed.). Belmont, CA: Wadsworth. Davis D. (1983). Long lives: Chinese elderly and the Communist revolution . Cambridge, MA: Harvard University Press. Diaz-Cabello, N. (2004). The Hispanic way of dying: Three families, three perspectives, three cultures. Illness, Crisis, &amp; Loss, 12 (3), 239–255. Ertel, K. A., Glymour, M. M., &amp; Berkman, L. F. (2008). Effects of social integration on preserving memory function in a nationally representative U.S. elderly population. American Journal of Public Health, 98 , 1215–1220. Giles, H., Noels, K., Ota, H., Ng, S.H., Gallois, C., Ryan, E.B., et al. (2000). Age vitality across eleven nations. Journal of Multilingual and Multicultural Development, 21, 308–323. Harwood, J., Giles, H., McCann, R.M., Cai, D., Somera, L.P., Ng, S.H., et al. (2001). Older adults’ trait ratings of three age-groups around the Pacific rim. Journal of Cross-Cultural Gerontology,16, 157–171. Hebert, L. E., Scherr, P. A., Beckett, L. A., Albert, M. S., Pilgrim, D. M., Chown, M. J.,…Evans, D. A. (1995). Age-specific incidence of Alzheimer’s disease in a community population. Journal of the American Medical Association, 273 (17), 1354–1359. Ho, D.Y. (1994). Filial Piety, authoritarian moralism, and cognitive conservatism in Chinese societies. Genetic, Social, and General Psychology Monographs, 120 , 347–365. Kennedy, Q., Mather, M., &amp; Carstensen, L. L. (2004). The role of motivation in the age-related positivity effect in autobiographical memory. Psychological Science, 15 , 208–214. Kübler-Ross, E. (1997). On death and dying . New York, NY: Scribner. Levy, B., &amp; Langer, E. (1994). Aging free from negative stereotypes: Successful memory in China among the American deaf. Journal of Personality and Social Psychology, 66 (6), 989–997. Levy, B. R., Slade, M. D., Kunkel, S. R., &amp; Kasl, S. V. (2002). Longevity increased by positive self-perceptions of aging. Journal of Personality and Social Psychology, 83 , 261–270. Myers, D. G., &amp; Diener, E. (1996). The pursuit of happiness. Scientific American, 274 (5), 70–72. Neimeyer, R. A., Holland, J. M., Currier, J. M., &amp; Mehta, T. (2008). Meaning reconstruction in later life: Toward a cognitive-constructivist approach to grief therapy. In D. Gallagher-Thompson, A. Steffen, &amp; L. Thompson (Eds.), Handbook of behavioral and cognitive therapies with older adults (pp. 264–277). New York, NY: Springer Verlag. Nemmers, T. M. (2005). The influence of ageism and ageist stereotypes on the elderly. Physical &amp; Occupational Therapy in Geriatrics, 22 (4), 11–20. Palmore, E. (1975). What can the USA learn from Japan about aging? Gerontologist, 15, 64–67. Persad, C. C., Abeles, N., Zacks, R. T., &amp; Denburg, N. L. (2002). Inhibitory changes after age 60 and the relationship to measures of attention and memory. The Journals of Gerontology: Series B: Psychological Sciences and Social Sciences, 57B (3), P223–P232. Pushkar, D., Basevitz, P., Arbuckle, T., Nohara-LeClair, M., Lapidus, S., &amp; Peled, M. (2000). Social behavior and off-target verbosity in elderly people. Psychology and Aging, 15 (2), 361–374. Pushkar, D., Bukowski, W. M., Schwartzman, A. E., Stack, D. M., &amp; White, D. R. (2007). Responding to the challenges of late life: Strategies for maintaining and enhancing competence . New York, NY: Springer Publishing. Rubin, L. (2007). 60 on up: The truth about aging in America . Boston, MA: Beacon Press. Ryan, E.B., Jin, Y.S., Anas, A.P., &amp; Luh, J. (2004). Communication beliefs about youth and old age in Asia and Canada. Journal of Cross-Cultural Gerontology, 19 , 343–360. Salthouse, T. A. (2004). What and when of cognitive aging. Current Directions in Psychological Science, 13 (4), 140–144. Scheibe, S., Kunzmann, U., &amp; Baltes, P. B. (2009). New territories of positive life-span development: Wisdom and life longings. In S. J. E. Lopez &amp; C. R. E. Snyder (Eds.), Oxford handbook of positive psychology (2nd ed., pp. 171–183). New York, NY: Oxford University Press. Sharps, M.J., Price-Sharps, J.L., &amp; Hanson, J. (1998). Attitudes of young adults toward older adults: Evidence from the United States and Thailand. Educational Gerontology, 24, 655–660. Sher A. (1984). Aging in post-Mao China: The politics of veneration . Boulder, CO: Westview Press. Sroufe, L. A., Collins, W. A., Egeland, B., &amp; Carlson, E. A. (2009). The development of the person: The Minnesota study of risk and adaptation from birth to adulthood . New York, NY: Guilford Press. Stroebe, M. S., Hansson, R. O., Schut, H., &amp; Stroebe, W. (2008). Bereavement research: Contemporary perspectives. In M. S. Stroebe, R. O. Hansson, H. Schut, &amp; W. Stroebe (Eds.), Handbook of bereavement research and practice: Advances in theory and intervention (pp. 3–25). Washington, DC: American Psychological Association. Tan, P.P., Zhang, N., &amp; Fan, L. (2004). Students’ attitude toward the elderly in the people’s Republic of China. Educational Gerontology, 30, 305–314. Verghese, J., Lipton, R., Katz, M. J., Hall, C. B., Derby, C. A.,…Buschke, M.D. (2003). Leisure activities and the risk of dementia in the elderly. New England Journal of Medicine, 348 , 2508–2516. Wang, M. (2007). Profiling retirees in the retirement transition and adjustment process: Examining the longitudinal change patterns of retirees’ psychological well-being. Journal of Applied Psychology, 92 (2), 455–474. Zhou, L. (2007). What college students know about older adults: A cross-cultural qualitative study. Educational Gerontology, 33, 811–831. 40 7.6 Chapter Summary Development begins at conception when a sperm from the father fertilizes an egg from the mother, creating a new life. The resulting zygote grows into an embryo and then a fetus. Babies are born prepared with reflexes and cognitive skills that contribute to their survival and growth. Piaget’s stage model of cognitive development proposes that children learn through assimilation and accommodation and that cognitive development follows specific sequential stages: sensorimotor, preoperational, concrete operational, and formal operational. An important part of development is the attainment of social skills, including the formation of the self-concept and attachment. Adolescence involves rapid physical changes, including puberty, as well as continued cognitive changes. Moral development continues in adolescence. In Western cultures, adolescence blends into emerging adulthood, the period from age 18 until the mid-20s. Muscle strength, reaction time, cardiac output, and sensory abilities begin to slowly decline in early and middle adulthood. Fertility, particularly for women, also decreases, and women eventually experience menopause. Most older adults maintain an active lifestyle — remaining as happy as they were when they were younger, or happier — and increasingly value their social connections with family and friends. Although older adults have slower cognitive processing overall (fluid intelligence), their experience in the form of crystallized intelligence, or existing knowledge about the world and the ability to use it, is maintained and even strengthened during aging. A portion of the elderly suffer from age-related brain diseases, such as dementia and Alzheimer’s disease. VIII Chapter 8. Learning 41 8. Learning My Story of Post-traumatic Stress Disorder It is a continuous challenge living with post-traumatic stress disorder (PTSD), and I’ve suffered from it for most of my life. I can look back now and gently laugh at all the people who thought I had the perfect life. I was young, beautiful, and talented, but unbeknownst to them, I was terrorized by an undiagnosed debilitating mental illness. Having been properly diagnosed with PTSD at age 35, I know that there is not one aspect of my life that has gone untouched by this mental illness. My PTSD was triggered by several traumas, most importantly a sexual attack at knifepoint that left me thinking I would die. I would never be the same after that attack. For me there was no safe place in the world, not even my home. I went to the police and filed a report. Rape counselors came to see me while I was in the hospital, but I declined their help, convinced that I didn’t need it. This would be the most damaging decision of my life. For months after the attack, I couldn’t close my eyes without envisioning the face of my attacker. I suffered horrific flashbacks and nightmares. For four years after the attack I was unable to sleep alone in my house. I obsessively checked windows, doors, and locks. By age 17, I’d suffered my first panic attack. Soon I became unable to leave my apartment for weeks at a time, ending my modeling career abruptly. This just became a way of life. Years passed when I had few or no symptoms at all, and I led what I thought was a fairly normal life, just thinking I had a “panic problem.” Then another traumatic event retriggered the PTSD. It was as if the past had evaporated, and I was back in the place of my attack, only now I had uncontrollable thoughts of someone entering my house and harming my daughter. I saw violent images every time I closed my eyes. I lost all ability to concentrate or even complete simple tasks. Normally social, I stopped trying to make friends or get involved in my community. I often felt disoriented, forgetting where, or who, I was. I would panic on the freeway and became unable to drive, again ending a career. I felt as if I had completely lost my mind. For a time, I managed to keep it together on the outside, but then I became unable to leave my house again. Around this time I was diagnosed with PTSD. I cannot express to you the enormous relief I felt when I discovered my condition was real and treatable. I felt safe for the first time in 32 years. Taking medication and undergoing behavioural therapy marked the turning point in my regaining control of my life. I’m rebuilding a satisfying career as an artist, and I am enjoying my life. The world is new to me and not limited by the restrictive vision of anxiety. It amazes me to think back to what my life was like only a year ago, and just how far I’ve come. For me there is no cure, no final healing. But there are things I can do to ensure that I never have to suffer as I did before being diagnosed with PTSD. I’m no longer at the mercy of my disorder, and I would not be here today had I not had the proper diagnosis and treatment. The most important thing to know is that it’s never too late to seek help. (Philips, 2010) The topic of this chapter is learning — the relatively permanent change in knowledge or behaviour that is the result of experience . Although you might think of learning in terms of what you need to do before an upcoming exam, the knowledge that you take away from your classes, or new skills that you acquire through practice, these changes represent only one component of learning. In fact, learning is a broad topic that is used to explain not only how we acquire new knowledge and behaviour but also how we acquire a wide variety of other psychological processes, including the development of both appropriate and inappropriate social behaviours, and even how a person may acquire a debilitating psychological disorder such as PTSD. Figure 8.1 Skinner and Watson. B. F. Skinner (left) and John B. Watson (right) were champions of the behaviourist school of learning. Learning is perhaps the most important human capacity. Learning allows us to create effective lives by being able to respond to changes. We learn to avoid touching hot stoves, to find our way home from school, and to remember which people have helped us in the past and which people have been unkind. Without the ability to learn from our experiences, our lives would be remarkably dangerous and inefficient. The principles of learning can also be used to explain a wide variety of social interactions, including social dilemmas in which people make important, and often selfish, decisions about how to behave by calculating the costs and benefits of different outcomes. The study of learning is closely associated with the behaviourist school of psychology, in which it was seen as an alternative scientific perspective to the failure of introspection. The behaviourists, including John B. Watson and B. F. Skinner (Figure 8.1), focused their research entirely on behaviour, to the exclusion of any kinds of mental processes. For behaviourists, the fundamental aspect of learning is the process of conditioning — the ability to connect stimuli (the changes that occur in the environment) with responses (behaviours or other actions) . But conditioning is just one type of learning. We will also consider other types, including learning through insight, as well as observational learning (also known as modelling ). In each case we will see not only what psychologists have learned about the topics but also the important influence that learning has on many aspects of our everyday lives. And we will see that in some cases learning can be maladaptive — for instance, when a person like P. K. Philips continually experiences disruptive memories and emotional responses to a negative event. References Philips, P. K. (2010). My story of survival: Battling PTSD . Anxiety Disorders Association of America. Retrieved from  Figure 8.1: “ B.F. Skinner ” ( is licensed under the CC BY 3.0 license ( “ John Broadus Watson ” ( is in the public domain . 42 8.1 Learning by Association: Classical Conditioning \n",
      "-----------\n",
      "Review the physical, cognitive, and social changes that accompany late adulthood.\n",
      "Describe the psychological and physical outcomes of bereavement.\n",
      "--------------------------\n",
      "The Purpose of Illustration in Writing To illustrate means to show or demonstrate something clearly. An effective illustration essay clearly demonstrates and supports a point through the use of evidence. As you learned in Chapter 3: Putting Ideas into Your Own Words and Paragraphs , the controlling idea of an essay is called a thesis . A writer can use different types of evidence to support his or her thesis. Using scientific studies, experts in a particular field, statistics, historical events, current events, analogies, and personal anecdotes are all ways in which a writer can illustrate a thesis. Ultimately, you want the evidence to help the reader “see” your point, as one would see a good illustration in a magazine or on a website. The stronger your evidence is, the more clearly the reader will consider your point. Using evidence effectively can be challenging, though. The evidence you choose will usually depend on your subject and who your reader is (your audience). When writing an illustration essay, keep in mind the following: Use evidence that is appropriate to your topic as well as to your audience. Assess how much evidence you need to adequately explain your point depending on the complexity of the subject and the knowledge your audience has of the subject. For example, if you were writing about a new kind of communication software and your audience was a group of English major undergrads, you might want to use an analogy or a personal story to illustrate how the software worked. You might also choose to add a few more pieces of evidence to make sure the audience understands your point. However, if you were writing about the same subject and your audience was information technology (IT) specialists, you would likely use more technical evidence because they would be familiar with the subject. Keeping in mind your subject in relation to your audience will increase your chances of effectively illustrating your point. Tip: You never want to insult your readers’ intelligence by over explaining concepts they may already be familiar with, but it may be necessary to clearly articulate your point. When in doubt, add an extra example to illustrate your idea. The Structure of an Illustration Essay The controlling idea, or thesis, belongs at the beginning of the essay . Evidence is then presented in the essay’s body sections/paragraphs to support the thesis. You can start supporting your main point with your strongest evidence first, or you can start with evidence of lesser importance and have the essay build to increasingly stronger evidence. You will learn about this type of organization— order of importance —in Chapter 5 : Putting the Pieces Together with a Thesis . The time transition words listed in Section 4.2 Narration, Transition Words and Phrases for Expressing Time are also helpful in ordering the presentation of evidence. Words like first, second, third, currently, next , and finally all help orient the reader and sequence evidence clearly. Because an illustration essay uses so many examples, it is also helpful to have a list of words and phrases to present each piece of evidence; see the list below. Phrases of Illustration case in point for example for instance in particular in this case one example another example specifically to illustrate Tip: Vary the phrases of illustration you use. Do not rely on just one. Variety in choice of words and phrasing is critical when trying to keep readers engaged in your writing and your ideas. Writing at Work In the workplace, it is often helpful to keep the phrases of illustration in mind and incorporate them whenever you can. Whether you are writing directives that colleagues will have to follow or requesting a new product or service from another company, making a conscious effort to incorporate a phrase of illustration will force you to provide examples of what you mean. Writing an Illustration Essay First, choose a topic you are interested in. Then create an interesting introduction to engage the reader. The main point, or thesis, should be stated at the end of the introduction. Gather evidence that is appropriate to both your subject and your audience. You can order the evidence in terms of importance, either from least important to most important or from most important to least important. Be sure to fully explain all your examples using strong, clear supporting details. See Appendix 1: Readings: Examples of Essays to read a sample illustration essay. Key Takeaways An illustration essay clearly explains a main point using evidence. When choosing evidence, always gauge whether the evidence is appropriate for the subject as well as the audience. Organize the evidence in terms of importance, either from least important to most important or from most important to least important. Use time transitions to order evidence. Use phrases of illustration to call out examples. 16 4.4 Description \n",
      "-----------\n",
      "Determine the purpose and structure of the illustration essay\n",
      "Understand how to write an illustration essay\n",
      "--------------------------\n",
      "Phenomena A phenomenon (plural, phenomena ) is a general result that has been observed reliably in systematic empirical research. In essence, it is an established answer to a research question. Some phenomena we have encountered in this book are that expressive writing improves health, women do not talk more than men, and cell phone usage impairs driving ability. Some others are that dissociative identity disorder (formerly called multiple personality disorder) increased greatly in prevalence during the late 20th century, people perform better on easy tasks when they are being watched by others (and worse on difficult tasks), and people recall items presented at the beginning and end of a list better than items presented in the middle. Some Famous Psychological Phenomena Phenomena are often given names by their discoverers or other researchers, and these names can catch on and become widely known. The following list is a small sample of famous phenomena in psychology. Blindsight . People with damage to their visual cortex are often able to respond to visual stimuli that they do not consciously see. Bystander effect . The more people who are present at an emergency situation, the less likely it is that any one of them will help. Fundamental attribution error . People tend to explain others’ behaviour in terms of their personal characteristics as opposed to the situation they are in. McGurk effect . When audio of a basic speech sound is combined with video of a person making mouth movements for a different speech sound, people often perceive a sound that is intermediate between the two. See a demonstration here: The McGurk Effect O ther -race effect . People recognize faces of people of their own race more accurately than faces of people of other races. Placebo effect . Placebos (fake psychological or medical treatments) often lead to improvements in people’s symptoms and functioning. Mere exposure effect . The more often people have been exposed to a stimulus, the more they like it—even when the stimulus is presented subliminally. Serial position effect . Stimuli presented near the beginning and end of a list are remembered better than stimuli presented in the middle. See a demonstration here: Serial Position Effect Spontaneous recovery . A conditioned response that has been extinguished often returns with no further training after the passage of time. Although an empirical result might be referred to as a phenomenon after being observed only once, this term is more likely to be used for results that have been replicated. Replication means conducting a study again—either exactly as it was originally conducted or with modifications—to be sure that it produces the same results. Individual researchers usually replicate their own studies before publishing them. Many empirical research reports include an initial study and then one or more follow-up studies that replicate the initial study with minor modifications. Particularly interesting results come to the attention of other researchers who conduct their own replications. The positive effect of expressive writing on health and the negative effect of cell phone usage on driving ability are examples of phenomena that have been replicated many times by many different researchers. Sometimes a replication of a study produces results that differ from the results of the initial study. This difference could mean that the results of the initial study or the results of the replication were a fluke—they occurred by chance and do not reflect something that is generally true. In either case, additional replications would be likely to resolve this discrepancy. A failure to produce the same results could also mean that the replication differed in some important way from the initial study. For example, early studies showed that people performed a variety of tasks better and faster when they were watched by others than when they were alone. Some later replications, however, showed that people performed worse when they were watched by others. Eventually researcher Robert Zajonc identified a key difference between the two types of studies. People seemed to perform better when being watched on highly practiced tasks but worse when being watched on relatively unpracticed tasks (Zajonc, 1965) .These two phenomena have now come to be called social facilitation and social inhibition. Physics has the laws of motions and chemistry has the law of conservation of mass. Unlike in other sciences, psychology does not have laws but rather effects. Laws imply that the phenomenon is universally true and rarely in psychology can you not find an exception. Even the effects that have been established are often culturally dependent. For example, the fundamental attribution error is committed more frequently in North America than in East Asia (Miyamoto &amp; Kitayama, 2002) . Theories What Is a Theory? A theory is a coherent explanation or interpretation of one or more phenomena. Although theories can take a variety of forms, one thing they have in common is that they go beyond the phenomena they explain by including variables, structures, processes, functions, or organizing principles that have not been observed directly. Consider, for example, Zajonc’s theory of social facilitation and social inhibition. He proposed that being watched by others while performing a task creates a general state of physiological arousal, which increases the likelihood of the dominant (most likely) response. So for highly practiced tasks, being watched increases the tendency to make correct responses, but for relatively unpracticed tasks, being watched increases the tendency to make incorrect responses. Notice that this theory—which has come to be called drive theory—provides an explanation of both social facilitation and social inhibition that goes beyond the phenomena themselves by including concepts such as “arousal” and “dominant response,” along with processes such as the effect of arousal on the dominant response. Outside of science, referring to an idea as a theory often implies that it is untested—perhaps no more than a wild guess. In science, however, the term theory has no such implication. A theory is simply an explanation or interpretation of a set of phenomena. It can be untested, but it can also be extensively tested, well supported, and accepted as an accurate description of the world by the scientific community. The theory of evolution by natural selection, for example, is a theory because it is an explanation of the diversity of life on earth—not because it is untested or unsupported by scientific research. On the contrary, the evidence for this theory is overwhelmingly positive and nearly all scientists accept its basic assumptions as accurate. Similarly, the “germ theory” of disease is a theory because it is an explanation of the origin of various diseases, not because there is any doubt that many diseases are caused by microorganisms that infect the body. In addition to theory , researchers in psychology use several related terms to refer to their explanations and interpretations of phenomena. A perspective is a broad approach—more general than a theory—to explaining and interpreting phenomena. For example, researchers who take a biological perspective tend to explain phenomena in terms of genetics or nervous and endocrine system structures and processes, while researchers who take a behavioural perspective tend to explain phenomena in terms of reinforcement, punishment, and other external events. A model is a precise explanation or interpretation of a specific phenomenon—often expressed in terms of equations, computer programs, or biological structures and processes. A hypothesis can be an explanation that relies on just a few key concepts—although this term more commonly refers to a prediction about a new phenomenon based on a theory (see Section 4.3 “Using Theories in Psychological Research” ).  A theoretical framework can be as broad as a perspective or a specific as a model, but it is the context applied to understanding a phenomenon. Adding to the confusion is the fact that researchers often use these terms interchangeably. It would not be considered wrong to refer to the drive theory as the drive model or even the drive hypothesis. And the biopsychosocial model of health psychology—the general idea that health is determined by an interaction of biological, psychological, and social factors—is really more like a perspective as defined here. Keep in mind, however, that the most important distinction remains that between observations and interpretations. What Are Theories For? Of course, scientific theories are meant to provide accurate explanations or interpretations of phenomena. But there must be more to it than this explanation. Consider that a theory can be accurate without being very useful. To say that expressive writing helps people “deal with their emotions” might be accurate as far as it goes, but it seems too vague to be of much use. Consider also that a theory can be useful without being entirely accurate. Figure 4.1 is a representation of the classic multistore model of human memory, which is still cited by researchers and discussed in textbooks despite the fact that it is now known to be inaccurate in a number of ways (Izawa, 1999). These two examples suggest that theories have purposes other than simply providing accurate explanations or interpretations. Here we look at three additional purposes of theories: the organization of known phenomena, the prediction of outcomes in new situations, and the generation of new research. Figure 4.1 Representation of the Multistore Model of Human Memory. In the multistore model of human memory, information from the environment passes through a sensory store on its way to a short-term store, where it can be rehearsed, and then to a long-term store, where it can be stored and retrieved much later. This theory has been extremely successful at organizing old phenomena and predicting new ones. Organization One important purpose of scientific theories is to organize phenomena in ways that help people think about them clearly and efficiently. The drive theory of social facilitation and social inhibition, for example, helps to organize and make sense of a large number of seemingly contradictory results. The multistore model of human memory efficiently summarizes many important phenomena: the limited capacity and short retention time of information that is attended to but not rehearsed, the importance of rehearsing information for long-term retention, the serial-position effect, and so on. Or consider a classic theory of intelligence represented by Figure 4.2. According to this theory, intelligence consists of a general mental ability, g, plus a small number of more specific abilities that are influenced by g (Neisset et al., 1996) . Although there are other theories of intelligence, this one does a good job of summarizing a large number of statistical relationships between tests of various mental abilities. This theory includes the fact that tests of all basic mental abilities tend to be somewhat positively correlated and the fact that certain subsets of mental abilities (e.g., reading comprehension and analogy completion) are more positively correlated than others (e.g., reading comprehension and arithmetic). Figure 4.2 Representation of One Theory of Intelligence. In this theory of intelligence, a general mental ability (g) influences each of three more specific mental abilities: numerical ability, spatial ability, and verbal ability. Theories of this type help to organize a large number of statistical relationships among tests of various mental abilities. Thus theories are good or useful to the extent that they organize more phenomena with greater clarity and efficiency. Scientists generally follow the principle of parsimony , also known as Occam's razor , which holds that a theory should include only as many concepts as are necessary to explain or interpret the phenomena of interest. Simpler, more parsimonious theories organize phenomena more efficiently than more complex, less parsimonious theories. Prediction A second purpose of theories is to allow researchers and others to make predictions about what will happen in new situations. For example, a gymnastics coach might wonder whether a student’s performance is likely to be better or worse during a competition than when practicing alone. Even if this particular question has never been studied empirically, Zajonc’s drive theory suggests an answer. If the student generally performs with no mistakes, she is likely to perform better during competition. If she generally performs with many mistakes, she is likely to perform worse. In clinical psychology, treatment decisions are often guided by theories. Consider, for example, dissociative identity disorder (formerly called multiple personality disorder). The prevailing scientific theory of dissociative identity disorder is that people develop multiple personalities (also called alters) because they are familiar with this idea from popular portrayals (e.g., the movie Sybil) and because they are unintentionally encouraged to do so by their clinicians (e.g., by asking to “meet” an alter). This theory implies that rather than encouraging patients to act out multiple personalities, treatment should involve discouraging them from doing this role playing (Lilienfeld &amp; Lynn, 2003) . Generation of New Research A third purpose of theories is to generate new research by raising new questions. Consider, for example, the theory that people engage in self-injurious behaviour such as cutting because it reduces negative emotions such as sadness, anxiety, and anger. This theory immediately suggests several new and interesting questions. Is there, in fact, a statistical relationship between cutting and the amount of negative emotions experienced? Is it causal? If so, what is it about cutting that has this effect? Is it the pain, the sight of the injury, or something else? Does cutting affect all negative emotions equally? Notice that a theory does not have to be accurate to serve this purpose. Even an inaccurate theory can generate new and interesting research questions. Of course, if the theory is inaccurate, the answers to the new questions will tend to be inconsistent with the theory. This new direction will lead researchers to reevaluate the theory and either revise it or abandon it for a new one. And this cycle of revising is how scientific theories become more detailed and accurate over time. Multiple Theories At any point in time, researchers are usually considering multiple theories for any set of phenomena. One reason is that because human behaviour is extremely complex, it is always possible to look at it from different perspectives. For example, a biological theory of sexual orientation might focus on the role of sex hormones during critical periods of brain development, while a sociocultural theory might focus on cultural factors that influence how underlying biological tendencies are expressed. A second reason is that—even from the same perspective—there are usually different ways to “go beyond” the phenomena of interest. For example, in addition to the drive theory of social facilitation and social inhibition, there is another theory that explains them in terms of a construct called “evaluation apprehension”—anxiety about being evaluated by the audience. Both theories go beyond the phenomena to be interpreted, but they do so by proposing somewhat different underlying processes. Different theories of the same set of phenomena can be complementary—with each one supplying one piece of a larger puzzle. A biological theory of sexual orientation and a sociocultural theory of sexual orientation might accurately describe different aspects of the same complex phenomenon. Similarly, social facilitation could be the result of both general physiological arousal and evaluation apprehension. But different theories of the same phenomena can also be competing in the sense that if one is accurate, the other is probably not. For example, an alternative theory of dissociative identity disorder—the posttraumatic theory—holds that alters are created unconsciously by the patient as a means of coping with sexual abuse or some other traumatic experience. Because the sociocognitive theory and the posttraumatic theories attribute dissociative identity disorder to fundamentally different processes, it seems unlikely that both can be accurate. See Note 4.10 “Where Do Multiple Personalities Come From?” for more on these competing theories. The fact that there are multiple theories for any set of phenomena does not mean that any theory is as good as any other or that it is impossible to know whether a theory provides an accurate explanation or interpretation. On the contrary, scientists are continually comparing theories in terms of their ability to organize phenomena, predict outcomes in new situations, and generate research. Those that fare poorly are assumed to be less accurate and are abandoned, while those that fare well are assumed to be more accurate and are retained and compared with newer—and hopefully better—theories. Although scientists generally do not believe that their theories ever provide perfectly accurate descriptions of the world, they do assume that this process produces theories that come closer and closer to that ideal. Where Do Multiple Personalities Come From? The literature on dissociative identity disorder (DID) features two competing theories. The sociocognitive theory is that DID comes about because patients are aware of the disorder, know its characteristic features, and are encouraged to take on multiple personalities by their therapists. The post-traumatic theory is that multiple personalities develop as a way of coping with sexual abuse or some other trauma. There are now several lines of evidence that support the sociocognitive model over the post-traumatic model (Lilienfeld &amp; Lynn, 2003 ). Diagnosis of DID greatly increased after the release of the book and film Sybil —about a woman with DID—in the 1970s. DID is extremely rare outside of North America. A very small percentage of therapists are responsible for diagnosing the vast majority of cases of DID. The literature on treating DID includes many practices that encourage patients to act out multiple personalities (e.g., having a bulletin board on which personalities can leave messages for each other). Normal people can easily re-create the symptoms of DID with minimal suggestion in simulated clinical interviews. Key Takeaways Scientists distinguish between phenomena, which are their systematic observations, and theories, which are their explanations or interpretations of phenomena. In addition to providing accurate explanations or interpretations, scientific theories have three basic purposes. They organize phenomena, allow people to predict what will happen in new situations, and help generate new research. Researchers generally consider multiple theories for any set of phenomena. Different theories of the same set of phenomena can be complementary or competing. Zajonc, R. B. (1965). Social facilitation. Science, 149 , 269–274. Miyamoto, Y. &amp; Kitayama, S. (2002). Cultural variation in correspondence bias: The critical role of attitude diagnosticity of socially constrained behavior. Journal of Personality and Social Psychology, 83 (5), 1239-1348. Izawa, C. (Ed.) (1999). On human memory: Evolution, progress, and reflections on the 30th anniversary of the Atkinson-Shiffrin model . Mahwah, NJ: Erlbaum. Neisser, U., Boodoo, G., Bouchard, T. J., Boykin, A. W., Brody, N., Ceci,…Urbina, S. (1996). Intelligence: Knowns and unknowns. American Psychologist, 51 , 77–101. Lilienfeld, S. O., &amp; Lynn, S. J. (2003). Dissociative identity disorder: Multiple personalities, multiple controversies. In S. O. Lilienfeld, S. J. Lynn, &amp; J. M. Lohr (Eds.), Science and pseudoscience in clinical psychology (pp. 109–142). New York, NY: Guilford Press. Lilienfeld, S. O., &amp; Lynn, S. J. (2003). Dissociative identity disorder: Multiple personalities, multiple controversies. In S. O. Lilienfeld, S. J. Lynn, &amp; J. M. Lohr (Eds.), Science and pseudoscience in clinical psychology (pp. 109–142). New York, NY: Guilford Press. 12 The Variety of Theories in Psychology \n",
      "-----------\n",
      "Define the terms phenomenon and theory and distinguish clearly between them.\n",
      "Explain the purposes of scientific theories.\n",
      "Explain why there are usually many plausible theories for any set of phenomena.\n",
      "--------------------------\n",
      "Just as the literary genre of poetry contains many forms — such as sonnets, haiku, epics, limericks, etc., — each with its own set of rules and conventions, technical writing also contains many forms, and each form has some conventions that must be observed.  This chapter discusses several of the most common document forms, and reviews the general requirements for content, formatting, and style. 7.1 Correspondence: Text Messages, Emails, Memos, and Letters Netiquette Text messaging, emailing, and posting on social media in a professional context requires that you be familiar with “netiquette,” or proper etiquette for using the internet. We have all heard the news stories about people who have been fired and companies that have been boycotted for making offensive or inappropriate social media posts . People have even gone to prison for illegal use of private messaging .  The digital world may seem like a free-for-all, “wild wild west” with no clear rules or regulations; however, this is clearly a dangerous perspective for a professional to take, as the consequences for breaking tacit rules, expectations, and guidelines for professional communications can be very costly. The way that you represent yourself in writing carries significant weight. Writing in an online environment requires tact, skill, and an awareness that what you write may be there for a very long time and may be seen by people you never considered as your intended audience. From text messages to memos to letters, from business proposals to press releases, your written business communication represents you and your company:  your goal is to make it clear, concise, constructive, and professional. We create personal pages, post messages, and interact via online technologies as a normal part of our careers, but how we conduct ourselves can leave a lasting image, literally. The photograph you posted on your Instagram page or Twitter feed may have been seen by your potential employer, or that insensitive remark in a Facebook post may come back to haunt you later. Guidelines for Communicating Online Following several guidelines for online postings, as detailed below, can help you avoid embarrassment later: Know your context Introduce yourself Avoid assumptions about your readers; remember that culture influences communication style and practices Familiarize yourself with policies on Acceptable Use of IT Resources at your organization. Remember the human Remember there is a person behind the words; ask for clarification before making judgment Check your tone before you publish; avoid jokes, sarcasm, and irony as these can often be misinterpreted and get “lost in translation” in the online environment Respond to people using their names Remember that culture, age, and gender can play a part in how people communicate Remain authentic and expect the same of others Remember that people may not reply immediately. People participate in different ways, some just by reading the communication rather than jumping into it. Recognize that text is permanent Be judicious and diplomatic; what you say online may be difficult or even impossible to retract later. Consider your responsibility to the group and to the working environment Agree on ground rules for text communication (formal or informal; seek clarification whenever needed) if you are working collaboratively Avoid flaming:  research before you react Accept and forgive mistakes Consider your responsibility to the group and to the working environment Seek clarification before reacting; what you heard is not always what was said Ask your supervisor for guidance.* Respect privacy and original ideas Quote the original author if you are responding with a specific point made by someone else Ask the author of an email for permission before forwarding the communication. * Sometimes, online behaviour can appear so disrespectful and even hostile that it requires attention and follow up. In this case, let your supervisor know right away so that the right resources can be called upon to help. For further information on netiquette, check out the following links: Business Insider: Email etiquette rules every professional needs to know LinkedIn: Why do you need email etiquette Texting Whatever digital device you use, written communication in the form of brief messages, or texting, has become a common way to connect. It is useful for short exchanges, and is a convenient way to stay connected with others when talking on the phone would be cumbersome. Texting is not useful for long or complicated messages, and careful consideration should be given to the audience. When texting, always consider your audience and your company, and choose words, terms, or abbreviations that will deliver your message appropriately and effectively. Guidelines for Effective Business Texting If your work situation allows or requires you to communicate via text messages, keep the following tips in mind: Know your recipient: “? % dsct” may be an understandable way to ask a close associate what the proper discount is to offer a certain customer, but if you are writing a text to your boss, it might be wiser to write, “what % discount does Murray get on $1K order?” Anticipate unintentional misinterpretation: texting often uses symbols and codes to represent thoughts, ideas, and emotions. Given the complexity of communication, and the useful but limited tool of texting, be aware of its limitation and prevent misinterpretation with brief messages. Use appropriately: contacting someone too frequently can border on harassment. Texting is a tool. Use it when appropriate but don’t abuse it. Don’t text and drive: research shows that the likelihood of an accident increases dramatically if the driver is texting behind the wheel. Being in an accident while conducting company business would reflect poorly on your judgment as well as on your employer. Email Email is familiar to most students and workers. In business, it has largely replaced print hard copy letters for external (outside the company) correspondence, and in many cases, it has taken the place of memos for internal (within the company) communication. Email can be very useful for messages that have slightly more content than a text message, but it is still best used for fairly brief messages. Many businesses use automated emails to acknowledge communications from the public, or to remind associates that periodic reports or payments are due. You may also be assigned to “populate” a form email in which standard paragraphs are used but you choose from a menu of sentences to make the wording suitable for a particular transaction. Emails may be informal in personal contexts, but business communication requires attention to detail, awareness that your email reflects you and your company, and a professional tone so that it may be forwarded to any third party if needed. Email often serves to exchange information within organizations. Although email may have an informal feel, remember that when used for business, it needs to convey professionalism and respect. Never write or send anything that you wouldn’t want read in public or in front of your company president. As with all writing, professional communications require attention to the specific writing context, and it may surprise you that even elements of form can indicate a writer’s strong understanding of audience and purpose. The principles explained here apply to the educational context as well; use them when communicating with your instructors and classroom peers. Guidelines for Effective Business Emails Open with a proper salutation: proper salutations demonstrate respect and avoid mix-ups in case a message is accidentally sent to the wrong recipient. For example, use a salutation like “Dear Ms. X” (external) or “Hi Barry” (internal). Include a clear, brief, and specific subject line: this helps the recipient understand the essence of the message. For example, “Proposal attached” or “Electrical specs for project Y.” Close with a signature: identify yourself by creating a signature block that automatically contains your name and business contact information. Avoid abbreviations: an email is not a text message, and the audience may not find your wit cause to ROTFLOL (roll on the floor laughing out loud). Be brief: omit unnecessary words. Use a good format: divide your message into brief paragraphs for ease of reading. A good email should get to the point and conclude in three small paragraphs or less. Reread, revise, and review: catch and correct spelling and grammar mistakes before you press “send.” It will take more time and effort to undo the problems caused by a hasty, poorly written email than to take the time to get it right the first time. Reply promptly: watch out for an emotional response—never reply in anger—but make a habit of replying to all emails within twenty-four hours, even if only to say that you will provide the requested information in forty-eight or seventy-two hours. Use “Reply All” sparingly: do not send your reply to everyone who received the initial email unless your message absolutely needs to be read by the entire group. Avoid using all caps: capital letters are used on the Internet to communicate emphatic emotion or yelling and are considered rude. Test links: if you include a link, test it to make sure it is working. Email ahead of time if you are going to attach large files: audio and visual files are often quite large; be careful to avoid exceeding the recipient’s mailbox limit or triggering the spam filter. Give feedback or follow up: if you don’t get a response in twenty-four hours, email or call. Spam filters may have intercepted your message, so your recipient may never have received it. Tip :  add the address of the recipient last to avoid sending prematurely.  This will give you time to do a last review of what you’ve written, make sure links work, make sure you’ve added the attachment, etc ., before adding the sender’s address and hitting send. The sample email below demonstrates the principles listed above. From: Steve Jobs &lt;sjobs@apple.com&gt; To: Human Resources Division &lt;hr@apple.com&gt; Date: September 12, 2015 Subject: Safe Zone Training Dear Colleagues: Please consider signing up for the next available Safe Zone workshop offered by the College. As you know, our department is working toward increasing the number of Safe Zone volunteers in our area, and I hope several of you may be available for the next workshop scheduled for Friday, October 9. For more information on the Safe Zone program, please visit Please let me know if you will attend. Steve Jobs CEO Apple Computing sjobs@apple.com Memos Memoranda, or memos , are one of the most versatile document forms used in professional settings.  Memos are “in house” documents (sent within an organization) to pass along or request information, outline policies, present short reports, and propose ideas.  While they are often used to inform, they can also be persuasive documents.  A company or institution typically has its own “in house” style or template that is used for documents such as letters and memos. Memo Format Figure 7.1.1 shows a sample of our “in house” memo style (the style we will use for memo assignments written for this class), with annotations pointing out various relevant features. The main formatted portions of a memo are the Logo or Letterhead (optional), the Header Block, and the Message. The attached Memos PowerPoint [PPTX] reviews some of these features in detail. Figure 7.1.1 Sample Memo, annotated. [Image description] Memo Header Block The Header Block appears at the top left side of your memo, directly underneath the word MEMO or MEMORANDUM in large, bold, capitalized letters.  This section contains detailed information on the recipient, sender, and purpose.  It includes the following lines: TO: give the recipient’s full name, and position or title within the organization FROM : include the sender’s (your) full name and position or title DATE : include the full date on which you sent the memo SUBJECT or RE : write a brief phrase that concisely describes the main content of your memo. Place a horizontal line under your header block, and place your message below. Memo Message The length of a memo can range from a few short sentences to a multi-page report that includes figures, tables, and appendices.  Whatever the length, there is a straightforward organizational principal you should follow.  Organize the content of your memo so that it answers the following questions for the reader: Opening: Do I have to read this?  Why do I have to read this? Details: What do I need to know? Closing: What am I expected to do now? Memos are generally very direct and concise.  There is no need to start with general introductions before getting to your point. Your readers are colleagues within the same organization, and are likely familiar with the context in which you are writing.  The opening sentences of the memo’s message should make it clear to the reader whether they have to read this entire memo and why (if the memo is informing me about an elevator that’s out of service in a building I never enter, then I don’t really have to read any further). The middle section of the message should give all of the information needed to adequately inform the readers and fulfill the purpose of the memo. Start with the most general information, and then add the more specific facts and details. Make sure there is enough detail to support your purpose, but don’t overwhelm your readers with unnecessary details or information that is already well known to them. The final part of the message indicates what, if any, action is required or requested of the readers.  If you are asking your readers to do something, be as courteous as possible, and try to indicate how this action will also benefit them. For more information on writing memos, check out the memo page on the the Online Writing Lab at Purdue University: Parts of a Memo . Letters Letters are brief messages sent to recipients that are often outside the organization. They are often printed on letterhead paper that represents the business or organization, and are generally limited to one or two pages. While email and text messages may be used more frequently today, the business letter remains a common form of written communication. It can serve to introduce you to a potential employer, announce a product or service, or even serve to communicate feelings and emotions (compliant letters, for example). There are many types of letters, and many adaptations in terms of form and content, but this chapter presents the fifteen elements of a traditional block-style letter. Letters may serve to introduce your skills and qualifications to prospective employers (cover letter), deliver important or specific information, provide documentation of an event or decision, or introduce an attached report or long document (letter of transmittal). Figure 7.1.2 shows a letter of transmittal meant to introduce a technical report to its recipient. Figure 7.1.2 Sample letter of transmittal (click image for an accessible PDF). Strategies for Effective Letters A typical letter has 7 main parts: Letterhead/logo :  Sender’s name and return address The heading: names the recipient, often including address and date Salutation :  “Dear ” use the recipient’s name, if known. The introduction :  establishes the overall purpose of the letter The body :  articulates the details of the message The conclusion: restates the main point and may include a call to action The signature line: sometimes includes the contact information Keep in mind that letters represent you and your company in your absence. In order to communicate effectively and project a positive image, remember that your language should be clear, concise, specific, and respectful each word should contribute to your purpose each paragraph should focus on one idea the parts of the letter should form a complete message the letter should be free of errors. Letters with Specific Purposes There are many possible reasons you might write a letter in a professional context.  Here is a list of the most common kinds of letters: Transmittal Letters:  w hen you send a report or some other document, such as a resumé, to an external audience, send it with a cover letter that briefly explains the purpose of the enclosed document and a brief summary.  Click the link to download a Letter of Transmittal Template [Word doc] . Letters of Inquiry: you may want to request information about a company or organization such as whether they anticipate job openings in the near future or whether they fund grant proposals from non-profit groups. In this case, you would send a letter of inquiry, asking for additional information. As with most business letters, keep your request brief, introducing yourself in the opening paragraph and then clearly stating your purpose and/or request in the second paragraph. If you need very specific information, consider placing your requests in list form for clarity. Conclude in a friendly way that shows appreciation for the help you will receive. Follow-up Letters: any time you have made a request of someone, write a follow-up letter expressing your appreciation for the time your letter-recipient has taken to respond to your needs or consider your job application. If you have had a job interview, the follow-up letter thanking the interviewer for his/her time is especially important for demonstrating your professionalism and attention to detail. Letters within the professional context may take on many other purposes, such as communicating with suppliers, contractors, partner organizations, clients, government agencies, and so on. For additional examples of professional letters, take a look at the sample letters provided by David McMurrey in his online textbook on technical writing: Online Technical Writing: Examples, Cases &amp; Models . Image Descriptions Figure 7.1.1 image description: Design features of a 1-page memorandum. The logo or letterhead is at the top of the page and centred or right-aligned (in this case, it is the University of Victoria letterhead). “Memorandum” appears at the top of the page left-aligned in large, bold font. The header block (which appears under the “Memorandum” heading) includes a “to,” “from,” “date,” and “subject” in a vertical list. Those values are aligned vertically for readability. A dividing line separates the header block from the message. The message begins by answering, “Why am I reading this?” The body of the message gives the details: (“What do I need to know?”) There is a table that is nicely formatted. (The table has a caption above the table in bold and italics, column headers are bold and centred, and text is left aligned.) A closing paragraph summarizes and indicates what (if any) action is expected of the reader (Answering, “What would you like me to do now?”) The text of this document uses an appropriate serif body font (Times New Roman) There is also a signature (optional) [Return to Figure 7.1.1] Text Attribution “ Professional Communications ” chapter in Technical Writing by Annemarie Hamlin, Chris Rubio, Michele DeSilva. This source is licensed under a CC BY-SA 4.0 International licence. Texting Blackberry by alexyangphotography is licensed under CC BY-NC 2.0 licence. Email icon by Alexiuz AS is free for commercial use . Figure 7.1.1 Sample Memo, annotated. Figure 7.1.2 Sample letter of transmittal by Annemarie Hamlin, Chris Rubio, Michele DeSilva is licensed under CC-BY-NC-SA 4.0 licence. \"Deadly distraction: Texting while driving, twice as risky as drunk driving, should be banned,\" Houston Chronicle, Sept 23, 2009 [Online]. Available:  M. Guffey, Essentials of Business Communication (7th ed.). Mason, OH: Thomson/Wadsworth, 2008. 7.2 Proposals Proposals and progress reports are some of the most common types of reports you will likely find yourself writing in the workplace. These reports are persuasive in nature:  proposals attempt to persuade the reader to accept the writer’s proposed idea; progress reports assure the reader that the project is on time and on budget, or explain rationally why things might not be going according to the initial plan. A proposal, in the technical sense, is a document that tries to persuade the reader to implement a proposed plan or approve a proposed project. Most businesses rely on effective proposal writing to ensure successful continuation of their business and to get new contracts. The writer tries to convince the reader that the proposed plan or project is worth doing (worth the time, energy, and expense necessary to implement or see through), that the author represents the best candidate for implementing the idea, and that it will result in tangible benefits. Not that kind of proposal. Proposals are often written in response to a Request For Proposals (RFP) by a government agency, organization, or company. The requesting body receives multiple proposals responding to their request, reviews the submitted proposals, and chooses the best one(s) to go forward. Thus, your proposal must persuade the reader that your idea is the one most worth pursuing. Proposals are persuasive documents intended to initiate a project and get the reader to authorize a course of action proposed in the document. These might include proposals to Perform a task (such as a feasibility study, a research project, etc. ) Provide a product Provide a service Proposals can have various purposes and thus take many forms. It may include sections such as the following: Introduction and/or background Problem statement Purpose/motivation/goal/objectives Definition of scope and approach Review of the state of the art Technical background Project description Schedule of work/timeline Budget Qualifications Conclusion Four Kinds of Proposals Solicited Proposals: an organization identifies a situation or problem that it wants to improve or solve and issues an RFP (Request for Proposals) asking for proposals on how to address it. The requesting organization will vet proposals and choose the most convincing one, often using a detailed scoring rubric or weighted objectives chart to determine which proposal best responds to the request. Unsolicited Proposals: a writer perceives a problem or an opportunity and takes the initiative to propose a way to solve the problem or take advantage of the opportunity (without being requested to do so). This can often be the most difficult kind of proposal to get approved. Internal Proposals: these are written by and for someone within the same organization. Since both the writer and reader share the same workplace context, these proposals are generally shorter than external proposals, and usually address some way to improve a work-related situation (productivity, efficiency, profit, etc .). As internal documents, they are often sent as memos, or introduced with a memo if the proposal is lengthy. External Proposals :  these are sent outside of the writer’s organization to a separate entity (usually to solicit business). Since these are external documents, they are usually sent as a formal report (if long), introduced by a cover letter (letter of transmittal). External proposals are usually sent in response to a Request for Proposals, but not always. Proposals written as an assignment in a Technical Writing classes generally do the following: Identify and define the problem that needs to be solved or the opportunity that can be taken advantage of. You must show that you clearly understand the problem/situation if you are to convince the reader that you can solve it.  Rubrics that assess proposals generally place significant weight (~20%) on clarity and accuracy of the problem definition. Describe your proposed project, clearly defining the scope of what you propose to do. Often, it is best to give a general overview of your idea, and then break it down into more detailed sub-sections. Indicate how your proposed solution will solve the problem and provide tangible benefits. Specifically, indicate how it will meet the objectives and abide by the constrains outlined in the problem definition. Give specific examples. Show the specific differences between “how things are now” and “how they could be.” Be as empirical as possible, but appeal to all appropriate persuasive strategies. Emphasize results, benefits, and feasibility of your proposed idea. Include the practical details: propose a budget and a timeline for completing your project. Represent these graphically (budget table, and Gantt chart) . Your timeline should include the major milestones or deliverables of the project, as well as dates or time frames for completion of each step. Conclude with a final pitch that summarizes and emphasizes the benefits of implementing your proposed idea – but without sounding like an advertisement. Additional Proposal Elements to Consider Describe your qualifications to take on and/or lead this project; persuade the reader that you have the required skills, experience, and expertise to complete this job. Decide what graphics to use to illustrate your ideas, present data, and enhance your pitch. Include secondary research to enhance your credibility and the strength of your proposal. Choose format; is this a memo to an internal audience or a formal report to an external audience? Does it require a letter of transmittal? All proposals must be convincing, logical, and credible, and to do this, they must consider audience, purpose and tone. Irish and Weiss urge readers to keep the following in mind: An engineering proposal is not an advertisement. It must show, with objective language, clarity, and thoroughness, that the writers know what they are doing and will successfully complete the project. Sample Proposal Organization Each proposal will be unique in that it must address a particular audience, in a particular context, for a specific purpose. However, the following offers a fairly standard organization for many types of proposals: Introduction/Background Clearly and fully defines the problem or opportunity addressed by the proposal, and briefly presents the solution idea; convinces the reader that there is a clear need, and a clear benefit to the proposed idea. Project Description Detailed description of solution idea and detailed explanation of how the proposed idea will improve the situation: Confirm feasibility (is it do-able?) How will you find out? Explain the specific benefits of implementing the idea and the consequences of not doing it Give a detailed description or explanation of your proposed idea or methodology, and the resources needed to achieve goals Address potential obstacles or objections; concede where appropriate Credentials Establish writer’s qualifications and experience to lead this project. Timeline and Budget Provide a detailed timeline for completion of project (use a Gantt chart to indicate when each stage of the project will be complete). Provide an itemized budget for completing the proposed project. Conclusion This is your last chance to convince the reader; be persuasive! References List your research sources. Language Considerations Proposals are fundamentally persuasive documents, so paying attention to the rhetorical situation—position of the reader (upward, lateral, downward or outward communication), the purpose of the proposal, the form, and the tone—is paramount. Clearly define your purpose and audience before you begin to write Be sure you have done research so you know what you are talking about Remain positive and constructive: you are seeking to improve a situation Be solution oriented; don’t blame or dwell on the negative Make your introduction very logical, objective, and empirical; don’t start off sounding like an advertisement or sounding biased; avoid logical fallacies Use primarily logical and ethical appeals; use emotional appeals sparingly As always, adhere to the 7 Cs by making sure that your writing is Clear and Coherent : don’t confuse your reader with unclear ideas or an illogically organized structure. Concise and Courteous :  don’t annoy your reader with clutter, unnecessary padding, inappropriate tone, or hard-to-read formatting. Concrete and Complete :  avoid vague generalities; give specifics. Don’t leave out necessary information. Correct :  don’t undermine your professional credibility by neglecting grammar and spelling, or by including inaccurate information. The Life Cycle of a Project Idea A great idea does not usually go straight from proposal to implementation. You may think it would be a great idea to construct a green roof on top of the Clearihue building, but before anyone gives you the go ahead for such an expensive and time-consuming project, they will need to know that you have done research to ensure the idea is cost effective and will actually work. Figure 7.2.1 breaks down the various stages a project might go through, and identifies some of the typical communications tasks that might be required at each stage. Most ideas start out as a proposal to determine if the idea is really feasible, or to find out which of several options will be most advantageous. So before you propose the actual green roof, you propose to study whether or not it is a feasible idea. Before you recommend a data storage system, you propose to study 3 different systems to find out which is the best one for this particular situation . Your proposal assumes the idea is worth looking into, convinces the reader that it is worth spending the time and resources to look into, and gives detailed information on how you propose to do the “finding out.” Figure 7.2.1 Phases of a project and some accompanying communications tasks. [Image description] Once a project is in the implementation phase, the people who are responsible for the project will likely want regular status updates and/or progress reports to make sure that the project is proceeding on time and on budget, or to get a clear, rational explanation for why it is not. To learn more about Progress Reports, go to 7.3 Progress Reports . Image Descriptions Figure 7.2.1 image description: Once there is an idea, a project goes through a design process made up of four stages. Pre-project planning. Problem Definition – identifying needs, goals, objectives, and constraints. Define context and do research. Identify potential projects. Public engagement projects; Stakeholder consultation. Project Development. Propose a project (budget, timeline, etc.). Create or respond to a request for proposals, evaluate proposals. Develop or design solution concepts. Project management plan. Feasibility Studies, Recommendation Reports). Project Implementation. Write contracts and apply for permits for construction and building sites. Progress reports, status updates. Documentation of project. Continued research and design improvements. Project completion. Final reports and documentation. Close contracts. Ongoing Support: User Guides, Troubleshooting, FAQs. [Return to Figure 7.2.1] Couple Love Marriage by Clker-Free-Vector-Images is licensed under a Pixabay License . Figure 7.2.1 Phases of a project and some accompanying communications tasks by Suzan Last is licensed under a CC BY 4.0 licence . Brilliance, idea, think icon by The Pictographers is free for commercial use . R. Irish and P. Weiss, Engineering Communication: From Principle to Practice , 2nd Ed., Don Mill, ONT:  Oxford UP, 2013. 7.3 Progress Reports You write a progress report to inform a supervisor, associate, or client about progress you have made on a project over a specific period of time. Periodic progress reports are common on projects that go on for several months (or more). Whoever is paying for this project wants to know whether tasks are being completed on schedule and on budget.  If the project is not on schedule or on budget, they want to know why and what additional costs and time will be needed. Progress reports answer the following questions for the reader: How much of the work is complete? What part of the work is currently in progress? What work remains to be done? When and how will the remaining work be completed? What changes, problems or unexpected issues, if any, have arisen? How is the project going in general? Purpose of a Progress Report The main function of a progress report is persuasive:  to reassure clients and supervisors that you are making progress, that the project is going smoothly, and that it will be completed by the expected date — or to give reasons why any of those might not be the case. They also offer the opportunity to do the following: Provide a brief look at preliminary findings or in-progress work on the project Give your clients or supervisors a chance to evaluate your work on the project and to suggest or request changes Give you a chance to discuss problems in the project and thus to forewarn the recipients Force you to establish a work schedule, so that you will complete the project on time. Format of a Progress Report Depending on the size of the progress report, the length and importance of the project, and the recipient, a progress report can take forms ranging from a short informal conversation to a detailed, multi-paged report. Most commonly, progress reports are delivered in following forms: Memo :  a short, semi-formal report to someone within your organization (can range in length from 1-4 pages) Letter :  a short, semi-formal report sent to someone outside your organization Formal report: a long, formal report sent to someone within or outside of your organization Presentation :  an oral presentation given directly to the target audience. Organizational Patterns for Progress Reports The recipient of a progress report wants to see what you’ve accomplished on the project, what you are working on now, what you plan to work on next, and how the project is going in general. The information is usually arranged with a focus either on time or on task, or a combination of the two: Focus on time: shows time period (previous, current, and future) and tasks completed or scheduled to be completed in each period Focus on specific tasks: shows order of tasks (defined milestones) and progress made in each time period Focus on larger goals :  focus on the overall effect of what has been accomplished. Information can also be arranged by report topic. You should refer to established milestones or deliverables outlined in your original proposal or job specifications. Whichever organizational strategy you choose, your report will likely contain the elements described below. Progress Reports – Structural Overview 1. Introduction Review the details of your project’s purpose, scope, and activities. The introduction may also contain the following: date the project began; date the project is scheduled to be completed people or organization working on the project people or organization for whom the project is being done overview of the contents of the progress report. 2. Project status This section (which could have sub-sections) should give the reader a clear idea of the current status of your project.  It should review the work completed, work in progress, and work remaining to be done on the project, organized into sub-sections by time, task, or topic. These sections might include Direct reference to milestones or deliverables established in previous documents related to the project Timeline for when remaining work will be completed Any problems encountered or issues that have arisen that might affect completion, direction, requirements, or scope. 3.  Conclusion The final section provides an overall assessment of the current state of the project and its expected completion, usually reassuring the reader that all is going well and on schedule. It can also alert recipients to unexpected changes in direction or scope, or problems in the project that may require intervention. 4.  References section if required. 7.4 Technical Descriptions and Definitions Descriptive technical writing uses a combination of visuals and text to both “show” and “tell” the reader about the information being conveyed. Like more creative descriptions, technical descriptions sometimes draw on the “five senses” and metaphorical comparisons (analogies) to allow the reader to fully conceptualize what is being described. More often, however, they rely on concrete, measurable descriptors. Technical descriptions can take many forms, depending on purpose and audience. Descriptions can range from a brief sentence, to a paragraph, a whole section of a report, or an entire manual.  Poorly written technical descriptions can cause confusion, waste time, and even result in catastrophe!  Technical product descriptions are often legally required to ensure safety and compliance.  Attention to detail is critical. Product specifications require detailed descriptions of design features; instructions often require specific descriptive detail to “show” the reader what to do. Some general categories of technical descriptions include the following: Mechanism Descriptions: provide a detailed overview the physical aspects of a tool, machine or other mechanical device that has moving parts and is designed to perform a specific function. These could be product descriptions for sales or manufacturing, documentation of design specifications, info-graphics, etc .  This chapter focuses in detail on this kind of description. Process Descriptions: detail a series of events ( natural/biological/ecological, mechanical, social, or psychological phenomenon ) that happen in particular sequence in order to achieve a specific outcome. These can be categorized into non-instructional processes (such as a process analyses of how an internal combustion engine works, or natural processes like photosynthesis) and instructional process (such as recommended/required procedures and explicit step-by-step instructions to be followed). (See Section 7.7 for detailed information on Writing Instructions ). Definitions: clarify the specific meaning, often related to a specific context, or express the essential nature of the terms being defined. These can range in length from a simple clarifying phrase to an extended document of several pages. Definitions will often include detailed descriptions and visuals to illustrate ideas. Click on the link below to view a student PowerPoint presentation on how to write effective definitions for technical purposes. This presentation is included with express permission of the student. Definitions in Technical Writing – Sample student presentation [PDF] Technical Description of a Mechanism Mechanism descriptions should provide a clear understanding of the object being described, including General appearance and physical properties Overall function/purpose Component parts How the parts interact to create a functioning whole. The reader should be able to clearly picture, and therefore understand, the nature of the object being described, what it does, and how it works. In order to achieve this clarity for the reader, the writer must choose significant details and organize information logically. Select details that can be described precisely and measurably, such as: color materials texture, smell, taste shape component parts finish size properties patterns, designs dimensions principles at work interactions Depending on the reader’s need, the description may range from a general overview requiring only a few sentences to a multi-chapter manual detailing every aspect of the mechanism’s parts and functions in order to troubleshoot technical problems and complete repairs. For a fun example of the latter, see the Star Trek: The Next Generation: Technical Manual (cover depicted in Figure 7.4.1 ), which provides detailed descriptions of all equipment and technology used aboard the fictional U.S.S. Enterprise-D. Figure 7.4.1 Cover Page of “Star Trek: The Next Generation: Technical Manual”. Before you begin to draft your description, you must consider your purpose and audience : Why does your audience need this description? What will they use it for? Are you describing different types of solar panels for the average consumers to help them choose the one that best fits their needs? Are you giving schematics to technicians and installers? Once you have your purpose and audience clearly in focus, draft a description that includes the following elements: Definition : What is it, and what is its main purpose? Overview : Describe the mechanism’s overall appearance (“big picture”). Components : Describe the main component parts in labeled sections; consider the order of information carefully here. Create a logical connection between each component described. Explanation: how do the parts work together to fulfill its function? What key principles govern its functioning? Consider how much detail is necessary here for your intended audience. Visuals: include graphics that clearly illustrate the mechanism and/or its parts. Show the device as a whole; consider showing specific details in expanded views, cut-aways, or labeled diagrams. You may even embed or link to videos showing the device in action. Conclusion : depending on the purpose, you might review product’s history, availability, manufacturing, costs, warnings, etc .) References : Sources you have used in your description, or additional sources of information available (if relevant). You might consider using a template, like the Technical Description Template below, keeping in mind that while templates can be helpful guides, they do not provide much flexibility and may not work for all situations. Technical Description Template Audience and Purpose Who will read this description and why? Definition and Function What is it? What does it do? What is its purpose? Overview Describe its overall appearance (shape, size, color, etc) Components and Explanations Describe the component parts (chose most relevant features) and explain how they work together Visuals What kind of illustrative graphics will you use? Where? Diagrams Photographs Cut-away views Exploded views Conclusion Do you need to offer any further information? History? Warnings? Context? Costs? etc . References Any sources used, or supplemental sources to suggest Sample Descriptions Examine the description of the “Up Goer Five” in Figure 7.4.2 (click on image for larger version). Who might the intended audience be? Figure 7.4.2 A description of the blueprints for NASA’s Saturn Five rocket using only the 1000 most commonly-used English words Compare the description in Figure 7.4.2 to the information given on the NASA website about the Mars Curiosity Rover . Note the differences in the level of detail, vocabulary, and overall purpose of the descriptions.  If you used the information on the NASA site to fill in the Technical Description Template , you might end up with something like the following chart. Template for Description of Mars Curiosity Rover Definition Curiosity Rover – a NASA robot designed to explore Mars Function Travels around the Gale Crater on Mars, collecting data to send back to Earth. Its mission is to see if Mars could ever have supported life, and if humans could survive there someday Overview Car-sized, 6 wheel robot, about 7’ tall, with a roughly square chassis that has several appendages connected to it that house sensors of various types Components Main body protects the computer, electronics and instrument systems “Neck and head” like a mast coming out of the centre of the chassis, this houses many of the rover’s cameras Six legs – “rocker bogie” design – wide apart, allows all wheels to remain on uneven terrain Arm – roughly 7 ’ long, (with “shoulder, elbow and wrist” joints), with a “hand” at the end, extends out of the front of the chassis. This contains many tools for drilling, collecting samples, etc. “Tail” – contains radio-isotopic power source that powers the rover Visuals Overall view (front and side? Top view?) View of arm with labeled components View of head and neck with labeled components Conclusion/Supplemental Information about lifespan? Travel speed? Energy use? References NASA website – Mars Curiosity Rover page You may find that some of these elements are not necessary; again, consider what your target audience already knows. Strike a balance between unnecessarily stating the obvious and incorrectly assuming your readers have knowledge that they lack. In refining the details of your description and its component parts, consider the following: Organization : Use a logical principle to organize your description Top to bottom (or foundation upward) Left to right (or right to left) Inside to outside (or outside to inside) Most important to least important features Central component to peripherals Material properties, etc . Language: Use specific, precise, concrete terms – avoid vague or overly-general terms Use correct terminology – define terms as necessary for your audience Use analogy to describe an unfamiliar thing in terms of a familiar thing Use objective language – no “ad speak” or subjective terms Use present tense, active verbs to describe how the device appears and what it does Use words that create vivid and specific pictures in the reader’s mind. Fig. 7.4.1. Thumbnail cover of R. Sturnback and M. Okuna, Star Trek: The Next Generation: Technical Manual. New York: Pocket Books, 1991. For noncommercial, educational use only. Figure 7.4.2 A description of the blueprints for NASA’s Saturn Five rocket using only the 1000 most commonly-used English words by Randall Munroe is licensed under CC BY-NC 2.5 licence. Figure 7.4.3 Corkscrew by Simon Brass is licensed under CC BY 2.0 licence. Figure 7.4.3 Bike is licensed under CC BY 2.0 licence. 7.5 Long Reports – Recommendation Reports and Feasibility Studies Long reports, such as Feasibility and Recommendation Reports, are most often the final step in a series of documents, often beginning with a Proposal and perhaps a series of Progress Reports . The reports in this rather loosely defined category are variously called feasibility reports, recommendation reports, evaluation reports, assessment reports, etc . They all do roughly the same thing—provide a careful study of a situation or problem, and often recommend what should be done to improve the situation. There are some subtle differences among these types, and names for them can vary. Feasibility Reports A feasibility report studies a situation (for example, a problem or opportunity) and a plan for doing something about it, and then determines whether that plan is “feasible”—whether it is practical in terms of current technology, economics, time frame, social needs and preferences, and so on. The feasibility report answers the question “Should we implement Plan X?” by stating “yes,” “no,” or sometimes a “maybe” or “under certain conditions.” Not only does it indicate whether the idea is feasible, it also provides the data and the reasoning behind that determination; conversely, it might outline the reasons why the idea cannot or should not be implemented, or what obstacles must be overcome before the idea can become feasible. Typical questions addressed in these reports include Is it possible? Can this be done within the allotted budget, time frame, legal and regulatory conditions, and technical capabilities? Is it financially viable? Even if it falls within our budget, should we do it?  Will it have long term benefits that outweigh costs? Is there a less expensive or financially risky way to achieving the same result? How does it compare to the cost of doing nothing about this situation? Will it be accepted by the community? Will people be in favor of this idea? Will anyone be opposed to it?  How much public support is necessary to make this successful? (What kind of stakeholder consultation might be necessary to determine this?) Recommendation Reports A recommendation reports starts from a stated need; it offers a selection of solution options, presents a detailed comparative analysis of the options, and then recommends one, some, or none. For example, a company might be looking at grammar-checking software and want a recommendation on which product is the best fit for them. As the report writer on this project, you could study the market for this type of application and recommend one particular product, 2-3 possible products (differing perhaps in their strengths and their weaknesses), or none (maybe none of them are appropriate for the client’s specific needs). The recommendation report answers the question “Which option should we choose?” (or in some cases “Which are the best options?) by recommending Product B, or maybe both Products B and C, or none of the products. These recommendations might arise from questions such as What should we do about Problem X? What is the best way to provide Function or Service A? Should we use Technology X or Technology Y to perform Function Z? Evaluation Reports An evaluation report provides a judgment or assessment rather than a yes-no-maybe answer or a recommendation. It provides a studied opinion on the value or worth of something. For example, for over a year the city of Austin had free bus transportation in an attempt to increase ridership and reduce automobile traffic. Did it work? Was it worthwhile?—These are questions an evaluation report would attempt to answer. This type of report compares a thing to a set of requirements (or criteria) and determines how well it meets those requirements. (And of course, this may result in a recommendation: to continue the project, scrap it, change it, or other possibilities.) As you can see, these distinctions are rather fine, and they overlap somewhat. In real-world writing, these types often combine; you might see elements of the recommendation report combine with the feasibility report, for example. Test your knowledge. Typical Contents of Recommendation and Feasibility Reports Whatever variety of feasibility or recommendation report you write, whatever name people call it—most of the sections and the organization of those sections are roughly the same. The structural principle fundamental to this type of report is this:  you provide not only your recommendation, choice, or judgment, but also the data, analysis, discussion, and the conclusions leading to it. That way, readers can check your findings, your logic, and your conclusions to make sure your methodology was sound and that they can agree with your recommendation. Your goal is to convince the reader to agree with you by using your careful research, detailed analysis, rhetorical style, and documentation. The general problem-solving approach for a Recommendation Report entails the steps shown in the example below. Typical Recommendation Report Elements 1. Identify the need What is the “unsatisfactory situation” that needs to be improved? 2. Identify the criteria for responding to the need What is the overall goal? What are the specific, measurable objectives any solution should achieve? What constraints must any solution adhere to? 3. Determine the solution options you will examine Define the scope of your approach to the problem. Identify the possible courses of action that you will examine in your report. You might include the consequences of simply doing nothing. 4. Study how well each option meets the criteria Systematically study each option, and compare how well they meet each of the objectives you have set. Provide a systematic and quantifiable way to compare how well to solution options meet the objectives (weighted objectives chart). 5. Draw conclusions based on your analysis Based on the research presented in your discussion section, sum up your findings and give a comparative evaluation of how well each of the options meets the criteria and addresses the need. 6. Formulate recommendations based on your conclusion Indicate which course of action the reader should take to address the problem, based on your analysis of the data presented in the report. These steps generally coincide with how you will organize your information.  Your report will be divided into several sections that will likely include most or all of the following elements: INTRODUCTION: t he introduction should clearly indicate the document’s purpose. Your introduction will discuss the “unsatisfactory situation” that has given rise to this report, and the requirements that must be met (the Problem Definition ). Your reader may also need some background. Finally, provide an overview of the contents of the report. TECHNICAL BACKGROUND: s ome recommendation or feasibility reports may require technical discussion in order to make the rest of the report meaningful. The dilemma with this kind of information is whether to put it in a section of its own or to fit it into the comparison sections where it is relevant. For example, a discussion of power and speed of tablet computers is going to necessitate some discussion of RAM, megahertz, and processors. Should you put that in a section that compares the tablets according to power and speed? Should you keep the comparison neat and clean, limited strictly to the comparison and the conclusion? Maybe all the technical background can be pitched in its own section—either toward the front of the report or in an appendix. REQUIREMENTS AND CRITERIA : a critical part of feasibility and recommendation reports is the discussion of the requirements (objectives and constraints) you’ll use to reach the final decision or recommendation. Here are some examples: If you’re trying to recommend a tablet computer for use by employees, your requirements are likely to involve size, cost, hard-disk storage, display quality, durability, and battery function. If you’re looking into the feasibility of providing every student at Austin Community College with an ID on the ACC computer network, you’d need define the basic requirements of such a program—what it would be expected to accomplish, problems that it would have to avoid, and so on. If you’re evaluating the recent program of free bus transportation in Austin, you’d need to know what was expected of the program and then compare its actual results to those requirements. Requirements can be defined in several ways: Numerical Values : many requirements are stated as maximum or minimum numerical values. For example, there may be a cost requirement—the tablet should cost no more than $900. Yes/no Values : some requirements are simply a yes-no question. Does the tablet come equipped with Bluetooth? Is the car equipped with voice recognition? Ratings Values : in some cases, key considerations cannot be handled either with numerical values or yes/no values. For example, your organization might want a tablet that has an ease-of-use rating of at least “good” by some nationally accepted ratings group. Or you may have to assign ratings yourself. The requirements section should also discuss how important the individual requirements are in relation to each other. Picture the typical situation where no one option is best in all categories of comparison. One option is cheaper; another has more functions; one has better ease-of-use ratings; another is known to be more durable. Set up your requirements so that they dictate a “winner” from situation where there is no obvious winner. A “weighted objectives chart” or “Decision Matrix” is often used in these cases. 4. DISCUSSION OF SOLUTION OPTIONS: In certain kinds of feasibility or recommendation reports, you’ll need to explain how you narrowed the field of choices down to the ones your report focuses on. Often, this follows right after the discussion of the requirements. Your basic requirements may well narrow the field down for you. But there may be other considerations that disqualify other options—explain these as well. Additionally, you may need to provide brief technical descriptions of the options themselves. Don’t get this mixed up with the comparison that comes up in the next section. In this description section, you provide a general discussion of the options so that readers will know something about them. The discussion at this stage is not comparative. It’s just a general orientation to the options. In the tablets example, you might want to give some brief, general specifications on each model about to be compared. 5. COMPARATIVE ANALYSIS: one of the most important parts of a feasibility or recommendation report is the comparison of the options. Remember that you include this section so that readers can follow the logic of your analysis and come up with different conclusions if they desire. This comparison can be structured using a “block” (whole-to-whole) approach, or an “alternating” (point-by-point) approach. Block Approach Alternating (Point-by-Point) Approach All the information about Option 1 Compare all Options according to Criteria A (cost) All the information about Option 2 Compare all Options according to Criteria B (functionality) All the information about Option 3 Compare all options according to Criteria C (ease of use) Direct Comparative Analysis of all three options and Summary of Results Summary of Results You might compare 3 options (1, 2, and 3) using three criteria for comparison (A, B, and C).  If you were comparing tablets, you’d likely use the point-by-point approach, having a section that compared all three options based on cost (criteria A), another section that compared them on battery function, and so on. You wouldn’t have a section that discussed everything about option 1, another that discussed everything about option 2, and so on. That would not be effective or efficient, because you still have to make direct comparisons somewhere near the end of your discussion (such as in a weighted objectives chart). Each of these comparative sections should end with a conclusion that sums up the relative strengths and weaknesses of each option and indicates which option is the best choice in that particular category of comparison. Of course, it won’t always be easy to state a clear winner—you may have to qualify the conclusions in various ways, providing multiple conclusions for different conditions. If you were writing an evaluation report, you wouldn’t be comparing options. Instead, you’d be comparing the thing being evaluated against the requirements placed upon it, the expectations people had of it. For example, Capital Metro had a program of more than a year of free bus transportation.  What was expected of that program? Did the program meet those expectations? 6. SUMMARY TABLE: a fter the individual comparisons, include a summary table (such as a Weighted Objectives Chart ) that summarizes the conclusions from the comparative analysis section. Some readers are more likely to pay attention to details in a table than in paragraphs; however, you still have to write up a clear summary paragraph of your findings. 7. CONCLUSIONS: the conclusions section of a feasibility or recommendation report amalgamates all of the conclusions you have already reached in each of the comparison sections. In this section, you restate the individual conclusions, for example, which model had the best price, which had the best battery function, and so on. You could give a summary of the relative strengths and weakness of each option based on how well they meet the criteria. This section has to go further. It must untangle all the conflicting conclusions and somehow reach the final conclusion, which is the one that states which is the best choice. Thus, the conclusion section first lists the primary conclusions —the simple, single-category ones. Then it must state secondary conclusions —the ones that balance conflicting primary conclusions. For example, if one tablet is the least inexpensive but has poor battery function, but another is the most expensive but has good battery function, which do you choose and why? The secondary conclusion would state the answer to this dilemma. 8. RECOMMENDATIONS: the final section of feasibility and recommendation reports states the recommendations which flow directly from your conclusions and directly address the problem outlined in the introduction. These may sometimes be repetitive, but remember that some readers may skip right to the recommendation section. Also, there will be some cases where there may be a best choice but you wouldn’t want to recommend it. Early in their history, laptop computers were heavy and unreliable—there may have been one model that was better than the rest, but even it was not worth having. You may want to recommend further research, a pilot project, or a re-design of one of the options discussed. The recommendation section should outline what further work needs to be done, based solidly on the information presented previously in the report and responding directly to the needs outlined in the beginning. In some cases, you may need to recommend several ranked options based on different possibilities. Revision Checklist for Feasibility and Recommendation Reports As you reread and revise your feasibility or recommendation report, ensure that you have included all of the sections and elements described below. Ensure you open each section and read the key content elements for each document section. Introductory Sections Indicate the situation and the audience. Discuss the background of the problem or opportunity – what brought about the need for the report? Give technical background if necessary. State requirements – those factors that influence the decision on the choice of options (objectives and constraints) Indicate how the field of options was narrowed to the ones being compared (if relevant). Provide an overview of the contents. Discussion Sections Organize the comparative analysis/discussion of the options using the point-by-point or whole-to-whole approach. Choose the structure that best matches your content and purpose. At the end of each comparative section, state the best choice in terms that point of comparison. Include a summary table, if possible, in which you summarize all the key data in table form. Conclusion Restate all the key conclusions from the Discussions section. State secondary conclusions, and based them on requirements established at the beginning. State a final conclusion (about the overall feasibility of the idea or about the overall strengths and weaknesses of each option compared). Recommendations Make recommendations for future actions; reiterate how these actions will provide the sought-after benefits outlined in the introduction. References Fully document any sources used in the report. Appendices Add any additional information that has been referred to, but not included in the body of the report. This chapter was adapted from David Murrey’s “Recommendation and Feasibility Reports”  in Online Technical Writing , which is under a CC BY 4.0 International License . 5 7.6 Lab Reports Whether your research takes place in a university lab or on some remote work site, you will often have to write up the results of your work in a Lab Report. Most basically, this report will describe the original hypothesis your work attempts to test, the methodology you used to test it, your observations and results of your testing, your analysis and discussion of what this data means, and your conclusions. In an academic context, especially in early courses, you are often asked to replicate the results of others rather than conduct your own original research. This is usually meant to instill an understanding of the scientific method into students, and teach students the proper use of instruments, techniques, processes, data analysis, and documentation. Once you demonstrate your ability to understand and apply the scientific method in these contexts, you will be able to go on to design your own research studies and develop new knowledge. Your reports then become the way you pass on this new knowledge to the field and to society at large. For scientists and engineers to make valuable contributions to the sum of human knowledge, they must be able to convince readers that their findings are valid (can be replicated) and valuable. Thus, the way that you write these reports can impact the credibility and authority of your work; people will judge your work partly on how you present it. Yes, even lab reports have a persuasive edge and must make careful use of rhetorical strategies. Careless writing, poor organization, ineffective document design, and lack of attention to convention may cast doubt on your authority and expertise, and thus on the value of your work. Science and Rhetoric Some aspects of your report that might require you to think rhetorically are exemplified in how you approach the following questions: Why is this research important? How does it solve a problem or contribute in some way to expanding human knowledge? What have other researchers already discovered about this? How are you contributing to this conversation? What gaps are there in our knowledge about this topic? Why have you chosen this methodology to test your hypothesis? What limitations might it have? How and why do you derive these inferences from the data you have collected? What further research should be done? Why? Writing a Lab Report Your report will be based on the work you have done in the lab. Therefore, you must have a plan for keeping careful notes on what you have done, how you have done it, and what you observed. Researchers often keep a notebook with them in the lab, sometimes with pre-designed tables or charts for recording the data they know they will be observing (you might be given a lab manual to use while completing a particular experiment to record your observations and data in a pre-organized format). Try to plan ahead so that you can capture as much information as possible during your research; don’t try to rely only on memory to record these important details. How you choose the content and format for your report will depend on your audience and purpose. Students must make sure to read lab manuals and instructions carefully to determine what is required; if writing for publication, make sure to follow the submission guidelines of the publication you are sending it to. Lab reports typically contain the elements outlined below. Typical Elements of a Lab Report Title : craft a descriptive and informative title that will enable readers to decide if this interests them, and will allow key words to be abstracted in indexing services. Ask your instructor about specific formatting requirements regarding title pages, etc. Abstract : write a summary of your report that mirrors your report structure (Hypothesis, Methods, Results, Discussion, Conclusion) in condensed form—roughly one sentence per section. Ideally, sum up your important findings. Introduction : establish the context and significance of your work, its relevance in the field, and the hypothesis or question your study addresses. Give a brief overview of your methodology for testing your hypothesis and why it is appropriate. If necessary for your readers, provide a specialized theoretical framework, background or technical knowledge to help them understand your focus and how it contributes to the field. Your instructor may describe a target audience for you; pay attention to that and write for that audience. More detailed reports may require a Literature Review section. Materials and Methods : this section has two key purposes. First, it must allow any reader to perfectly replicate your method; therefore, you must provide a thorough description of what you used and how you conducted your experiment. Second, you must persuade your reader that your chosen methodology and the materials are appropriate and valid for testing your hypothesis, and will lead to credible and valid results. This section will generally include 1) a list of all materials needed (which may include sub-lists, diagrams, and other graphics), and 2) a detailed description of your procedure, presented chronologically. Traditionally, the Sciences have required writers to describe what they did using the Passive Voice, as passive mode emphasizes the materials and actions taken and de-emphasizes the role of the scientist in the process. This is slowly changing, as the use of Active Voice is more concise; however, you should consult your instructor about which is preferred in your context. Results : this section presents the raw date that you generated in your experiment, and provides the evidence you will need to form conclusions about your hypothesis. Present only the data that is relevant to your results (but if you omit data, you may have to explain why it is not relevant). You can organize this section based on chronology (following your methodology) or on the importance of data in proving (or negating) the hypothesis (most important to least important). Present data visually whenever possible (in tables, graphs, flowcharts, etc .), and help readers understand the context of your data. Make sure you present the data honestly and ethically; do not distort or obscure data to make it better fit your hypothesis. If data is inconclusive or contradictory, be honest about that. In the Results section, you should avoid interpreting or explaining your data, as this belongs in your Discussion section. Discussion : this section includes your analysis and interpretation of the data you presented in the Results section in terms of how well it supports your original hypothesis. Start with the most important findings. It is perfectly fine to acknowledge that the data you have generated is problematic or fails to support the hypothesis. This points the way for further research. If your findings are inconsistent, try to suggest possible reasons for this. Conclusion : in 1-2 short paragraphs, review the overall purpose of your study and the hypothesis you tested; then summarize your key findings and the important implications. This is your opportunity to persuade the audience of the significance of your work. Acknowledgements : formally express appreciation for any assistance you have received while preparing the report (financial/funding support, help from colleagues or your institution, etc .). References : list all references you have cited in your report (such as those you may have included in a “literature review” in your introduction, or sources that help justify your methodology). Check with your instructor or publication guidelines for which citation style to use. Appendices : any information that does not fit within the body sections, but still adds valuable information to your report, can be placed in an appendix. Where your Results section may present summarized data, the full data tables may appear in an appendix. You may also include logs, calculations, or notes on analytical methods. Be sure to refer to your appendices in the body of your report to signal where readers can find additional information. How you write up the results of a scientific experiment will generally follow the formulaic pattern described above, but may vary depending on audience and purpose. As a student, you are often writing to demonstrate to your instructor that you have mastered the knowledge and skills required in a particular course. But remember that science writing generally focuses on the observable results, not on your “learning experience.” Your report should include what anyone doing this experiment might observe and conclude; these do not typically include personal reflections. In the professional academic world, your report may have to pass through a rigorous peer review process before being published in a scholarly journal. As a professional, your work may result in the development of products and services that will be used by the public, so documenting your process and findings has financial, safety, and legal implications. It is therefore critical that your writing is accurate and ethical. A Note on Scientific Writing Style Lab reports are often written using past tense, 3rd person, and passive verb constructions when describing what was done and what was observed. Why do you suppose that is? Strict adherence to this style has in recent years been relaxed somewhat, and you might find more science writing that use first person and active rather than passive verb constructions. Can you think of reasons why this is changing? Additional Resources For a fun example of Process Report that is similar in many ways to a lab report, see the attached Drafting Behind Big Rigs – Mythbusters Report [PDF] When evaluating scientific literature that you read, you might find the the following TED-Ed video by David H. Schwartz helpful: Not all Scientific Studies are Created Equal . 6 7.7 Writing Instructions One of the most common and important uses of technical writing is to provide instructions, those step-by-step explanations of how to assemble, operate, repair, or do routine maintenance on something. Although they may seems intuitive and simple to write, instructions are some of the worst-written documents you can find. Most of us have probably had many infuriating experiences with badly written instructions. This chapter will show you what professionals consider the best techniques in providing instructions. An effective set of instruction requires the following: Clear, precise, and simple writing A thorough understanding of the procedure in all its technical detail The ability to put yourself in the place of the reader, the person trying to use your instructions The ability to visualize the procedure in detail and to capture that awareness on paper Willingness to test your instructions on the kind of person you wrote them for. Preliminary Steps At the beginning of a project to write a set of instructions, it is important to determine the structure or characteristics of the particular procedure you are going to write about. Here are some steps to follow: 1. Do a careful audience and task analysis Early in the process, define the audience and situation of your instructions. Remember that defining an audience means defining the level of familiarity your readers have with the topic. 2. Determine the number of tasks How many tasks are there in the procedure you are writing about? Let’s use the term procedure to refer to the whole set of activities your instructions are intended to discuss. A task is a semi-independent group of actions within the procedure: for example, setting the clock on a microwave oven is one task in the big overall procedure of operating a microwave oven. A simple procedure like changing the oil in a car contains only one task; there are no semi-independent groupings of activities. A more complex procedure like using a microwave oven contains several semi-independent tasks:  setting the clock; setting the power level; using the timer; cleaning and maintaining the microwave, among others. Some instructions have only a single task, but have many steps within that single task. For example, imagine a set of instructions for assembling a kids’ swing set. In my own experience, there were more than a 130 steps! That can be a bit daunting. A good approach is to group similar and related steps into phases, and start renumbering the steps at each new phase. A phase then is a group of similar steps within a single-task procedure. In the swing-set example, setting up the frame would be a phase; anchoring the thing in the ground would be another; assembling the box swing would be still another. 3.  Determine the best approach to the step-by-step discussion For most instructions, you can focus on tasks, or you can focus on tools (or features of tools).  In a task approach (also known as task orientation) to instructions on using a phone-answering service, you’d have these sections: Recording your greeting Playing back your messages Saving your messages Forwarding your messages Deleting your messages, and so on These are tasks—the typical things we’d want to do with the machine. On the other hand, in a tools approach to instructions on using a photocopier, there likely would be sections on how to use specific features: Copy button Cancel button Enlarge/reduce button Collate/staple button Copy-size button, and so on If you designed a set of instructions on this plan, you’d write steps for using each button or feature of the photocopier. Instructions using this tools approach are hard to make work. Sometimes, the name of the button doesn’t quite match the task it is associated with; sometimes you have to use more than just the one button to accomplish the task. Still, there can be times when the tools/feature approach may be preferable. 4.  Design groupings of tasks Listing tasks may not be all that you need to do. There may be so many tasks that you must group them so that readers can find individual ones more easily. For example, the following are common task groupings in instructions: Unpacking and setup tasks Installing and customizing tasks Basic operating tasks Routine maintenance tasks Troubleshooting tasks. Common Sections in Instructions The following is a review of the sections you’ll commonly find in instructions. Don’t assume that each one of them must be in the actual instructions you write, nor that they have to be in the order presented here, nor that these are the only sections possible in a set of instructions. For alternative formats, check out the example instructions . A Set of Instructions Often Includes the Following Introduction: plan the introduction to your instructions carefully. It might include any of the following (but not necessarily in this order): Indicate the specific tasks or procedure to be explained as well as the scope (what will and will not be covered) Indicate what the audience needs in terms of knowledge and background to understand the instructions Give a general idea of the procedure and what it accomplishes Indicate the conditions when these instructions should (or should not) be used Give an overview of the contents of the instructions. General warning, caution, danger notices : instructions often must alert readers to the possibility of ruining their equipment, screwing up the procedure, and hurting themselves. Also, instructions must often emphasize key points or exceptions. For these situations, you use special notices —note, warning, caution, and danger notices. Notice how these special notices are used in the example instructions listed above. Technical background or theory: at the beginning of certain kinds of instructions (after the introduction), you may need a discussion of background related to the procedure. For certain instructions, this background is critical—otherwise, the steps in the procedure make no sense. For example, you may have had some experience with those software applets in which you define your own colors by nudging red, green, and blue slider bars around. To really understand what you’re doing, you need to have some background on color. Similarly, you can imagine that, for certain instructions using cameras, some theory might be needed as well. Equipment and supplies: notice that most instructions include a list of the things you need to gather before you start the procedure. This includes equipment , the tools you use in the procedure (such as mixing bowls, spoons, bread pans, hammers, drills, and saws) and supplies , the things that are consumed in the procedure (such as wood, paint, oil, flour, and nails). In instructions, these typically are listed either in a simple vertical list or in a two-column list. Use the two-column list if you need to add some specifications to some or all of the items—for example, brand names, sizes, amounts, types, model numbers, and so on. Discussion of the steps: when you get to the actual writing of the steps, there are several things to keep in mind: (1) the structure and format of those steps, (2) supplementary information that might be needed, and (3) the point of view and general writing style. Structure and format: normally, we imagine a set of instructions as being formatted as vertical numbered lists. And most are in fact. Normally, you format your actual step-by-step instructions this way. There are some variations, however, as well as some other considerations: Fixed-order steps are steps that must be performed in the order presented. For example, if you are changing the oil in a car, draining the oil is a step that must come before putting the new oil. These are numbered lists (usually, vertical numbered lists). Variable-order steps are steps that can be performed in practically any order. Good examples are those troubleshooting guides that tell you to check this, check that where you are trying to fix something. You can do these kinds of steps in practically any order. With this type, the bulleted list is the appropriate format. Alternate steps are those in which two or more ways to accomplish the same thing are presented. Alternate steps are also used when various conditions might exist. Use bulleted lists with this type, with OR inserted between the alternatives, or the lead-in indicating that alternatives are about to be presented. Nested steps may be used in  cases when individual steps within a procedure are rather complex in their own right and need to be broken down into sub-steps. In this case, you indent further and sequence the sub-steps as a, b, c, and so on. “Step-less” instructions . can be used when you really cannot use numbered vertical list or provide straightforward instructional-style directing of the reader. Some situations must be so generalized or so variable that steps cannot be stated. Supplementary discussion: often, it is not enough simply to tell readers to do this or to do that. They need additional explanatory information such as how the thing should look before and after the step; why they should care about doing this step; what mechanical principle is behind what they are doing; even more micro-level explanation of the step—discussion of the specific actions that make up the step. The problem with supplementary discussion, however, is that it can hide the actual step. You want the actual step—the specific actions the reader is to take—to stand out. You don’t want it all buried in a heap of words. There are at least two techniques to avoid this problem: you can split the instruction from the supplement into separate paragraphs; or you can bold the instruction. Writing Style Placing the key user steps in bold can a very helpful way to signal clearly what the reader needs to do.  Often the command verb is bolded; sometimes bold font highlights the key component being discussed. Use of the passive voice in instructions can be problematic. For some strange reason, some instructions sound like this: “The Pause button should be depressed in order to stop the display temporarily.” Not only are we worried about the pause button’s mental health, but we wonder who’s supposed to depress the thing ( ninjas ?). It would be more helpful to indicate when the reader must “ press the Pause button.”   Consider this example: “The Timer button is then set to 3:00.” Again, one might ask, “is set by whom? Ninjas ?” The person following these instructions might think it is simply a reference to some existing state, or she might wonder, “Are they talking to me?” Using the third person can also lead to awkwardness: “The user should then press the Pause button.” Instructions should typically be written using command verb forms and using “you” to make it perfectly clear what the reader should do. Illustrating Your Instructions Perhaps more than in any other form of technical writing, graphics are crucial to instructions. Sometimes, words simply cannot explain the step. Illustrations are often critical to the readers’ ability to visualize what they are supposed to do.  Be sure that the graphics represent the image from the reader’s perspective. Formatting Your Instructions Since people rarely want to read instructions, but often have to, format your instructions for reluctant readability. Try to make your reader want to read them, or at least not resistant to the idea of consulting them.  Highly readable format will allow readers who have figured out some of the instructions on their own to skip to the section where they are stuck.  Use what you have learned about headings , lists , visuals , and passive space to create effective and readable instructions: Headings : normally, you’d want headings for any background section you might have, the equipment and supplies section, a general heading for the actual instructions section, and subheadings for the individual tasks or phases within that section. Lists : similarly, instructions typically make extensive use of lists, particularly numbered vertical lists for the actual step-by-step explanations. Simple vertical lists or two-column lists are usually good for the equipment and supplies section. In-sentence lists are good whenever you give an overview of things to come. Special Notices :  you may have to alert readers to possibilities in which they may damage their equipment, waste supplies, cause the entire procedure to fail, injure themselves or others—even seriously or fatally. Companies have been sued for lack of these special notices, for poorly written special notices, or for special notices that were out of place. See special notices for a complete discussion of the proper use of these special notices as well as their format and placement within instructions. Revision Checklist for Written Instructions As you reread and revise your instructions, check that they do the following: Clearly describe the exact procedure to be explained Provide an overview of content Indicate audience requirements Use various types of lists wherever appropriate; in particular, use numbered lists for sequential steps Use headings and subheadings to divide the main sections and subsections in a logical, coherent order Use special notices as appropriate Use graphics to illustrate key actions and objects Provide additional supplementary explanation of the steps as necessary Create a section listing equipment and supplies if necessary. Text Attribution This chapter was adapted from Online Technical Writing by David McMurrey, which is under a CC BY 4.0 International License . VIII 8. Oral and Visual Presentation Chapter 8 \n",
      "-----------\n",
      "7.1 Correspondence: Text Messages, E-mails, Letters, and Memos\n",
      "7.2 Proposals\n",
      "7.3 Progress Reports\n",
      "7.4 Technical Descriptions and Definitions\n",
      "7.5 Long Reports: Feasibility and Recommendation Reports\n",
      "7.6 Lab Reports\n",
      "7.7 Instructions\n",
      "--------------------------\n",
      "Figure 7.1 Rat Portage Salvation Army Band by Cekli829 is in the public domain . 73 7.2 Social Reform Victorian-era industrialization created conditions that called out for reform. Child-labour, sexual abuse, poverty-level pay, filthy workplaces, and slum neighbourhoods were made visible by two things: urbanization from the 1860s through to the 1920s (which brought more observers and commentators within reach of factory life) and the new investigative role of the state (in the form of Royal Commissions of Enquiry, for example). Certainly there was poverty and abuse in rural Canada, but fewer observers there to catch it and comment on it, let alone act against it. Factory-life problems became public problems. The combination of science and urbanization — elements that were at the heart of industrialization — was key to the identification and relief of social and political liabilities. The rise of Darwinian thought and the relatively new concept of  evolution transformed the public’s understanding of biology and the engines of change. The germ theory of infection was just gaining ground as the Dominion of Canada took its first steps, so the possibility of employing strategies to avoid epidemics was increasingly well-understood. The cities were, in this context, laboratories in which social and health experiments were going to occur. What is more, the idea of “society” was undergoing profound change. The mid- and late-19th century witnessed the rise of the scientific study of society. Sociology, political theory, and psychology are young and dynamic fields in this era, led by powerhouse thinkers like Auguste Comte (1798-1857), Karl Marx (1818-1893), Frederick Engels (1820-1895), Émile Durkheim (1858-1917), and Herbert Spencer (1820-1903). This phenomenon — increased curiosity about how society works and how it might be changed systematically — was itself made possible by the rise of the secular state. That is, by the arrival of forms of government in which the Church stood well to one side, while government (Christian, but not subservient to the clergy) was both appropriating and being handed responsibility for more and more of the social environment. Into this mix stepped the new middle-classes. Professionals and merchants, they were — almost by definition — urban. Their ranks included the well-educated, the literate, and the people who would be tasked with dealing with outbreaks of illness (physicians), ignorance (teachers), political scandal (journalists), infrastructural disaster (engineers), and moral turpitude (the clergy). As a new spokes-class, the bourgeoisie — men and women alike — were increasingly connected to international movements and ideas. They were able to exploit their own rising importance in Canadian cities to launch programs aimed at eradicating, or at least mitigating, the worst effects of modernity. What distinguishes this generation of reformers from the religious reformers of earlier generations is their shared concentration on social change. The social reformers of the post-Confederation era were less concerned with individual improvement and redemption than they were with achieving urgent, collective, society-wide change. Meeting this goal would, they believed, create an environment in which individual betterment was more likely to occur. Save society and then save the individual; ignore society and watch it crumble and take the individual with it. Among the most vulnerable populations in the 19th and early 20th century were the elderly. Historian of institutionalization Megan Davies (York University) describes eldercare in the far west. An interactive or media element has been excluded from this version of the text. You can view it online here: Key Points The social reform movement was a product of urbanization and industrialization. It was built on a bedrock of evolutionary science that taught that change was possible and desirable, and with advances in medical science that created an awareness of public health. It was informed by a growing body of social sciences thinking about the nature of society. It was led by a growing middle class — an industrial-era bourgeoisie — with the cultural capital and position to develop a common understanding of the need for social change, and the ability to attempt it. 74 7.3 Poverty, 1867–1945 Eric W. Sager, Department of History, University of Victoria When the Dominion of Canada was created in 1867, governments did not assume direct responsibility for the poor. Before 1867, only the Maritime colonies had adopted English Poor Laws; there were no workhouses, in which the poor were given accommodation and food in return for work. Responsibility for the poor usually fell to churches and charities, and very poor people often ended up in houses of refuge, mental institutions, or prisons. Official and elite attitudes toward the poor were often negative or condescending. It was assumed that poverty resulted from a moral failing on the part of the poor. Idealistic visions contributed to such attitudes: Canada was a place with abundant land and resources where anybody willing to work was bound to prosper. This utopian vision of Canada ignored the reality that farms were very difficult to establish, that resources were highly seasonal, and that winter was a time of shortage and hardship for a large number of people. In the last half of the 19th century, urbanization and early industrialization increased the number of urban poor. A new type of poverty appeared: poverty that resulted from unemployment — not merely seasonal job shortages, but the shortage of wage-paid jobs due to economic cycles, the closing of businesses, short-term layoffs, and trade depressions. Historians have shown that in major Canadian cities in 1901, one of every seven families could not survive on the pooled wage earnings of family members. If the poor survived at all, they did so by participating in an informal economy — scrounging, bartering, growing vegetables, or keeping animals, or taking in lodgers, if they had space. Many did not survive. Montreal, for instance, was one of the most dangerous cities in the Western World for newborn babies. At the end of the 1890s, 26% of babies died before they reached their first birthday of illnesses associated with poverty and malnutrition. Studies of average wages in Montreal, Toronto, and Vancouver show that there was modest growth in real wages (which means wages after adjusting for price inflation) in the early 1900s. During World War I, rapid inflation halted the rise in real wages, and gains did not appear again until the 1920s. Then the Depression of the 1930s caused an increase in poverty due to unemployment. It has been estimated that in the winter of 1933, at the depths of the Depression, over 32% of all wage-paid workers were unemployed. In these circumstances, government began, although very slowly and at first without success, to develop policies that would help to alleviate the problem of poverty. The first universal social welfare program in Canada was the Family Allowance program, introduced by the federal government in 1944. The small unemployment insurance program, introduced during World War II, was expanded after the war. These were the foundations of Canada’s social security system or welfare state. The problem of poverty was not solved, however, and relative poverty (meaning wide gaps between low-income earners and others) persisted. Nevertheless, the social security system succeeded in reducing the impact of poverty for many families. Figure 7.2 A poor family in The Ward, Toronto, 1913. Additional Readings Copp, Terry. The Anatomy of Poverty: The Condition of the Working Class in Montreal 1897-1929. Toronto: McClelland and Stewart, 1974. Piva, Michael J. The Condition of the Working Class in Toronto – 1900-1921. Ottawa: University of Ottawa Press, 1979. Bartlett, Eleanor A. “Real Wages and the Standard of Living in Vancouver, 1901 – 1929.” BC Studies , no. 51 (Autumn 1981): 3-62. Baskerville, Peter and Eric W. Sager. Unwilling Idlers: The Urban Unemployed and their Families in Late Victorian Canada. Toronto: University of Toronto Press, 1998. Struthers, James. No Fault of their Own: Unemployment and the Canadian Welfare State, 1914-1941. Toronto: University of Toronto Press, 1983. Key Points Industrial and wage-labour changed the character and incidence of poverty in the post-Confederation era. Poverty has been linked in the pre-World War II era with inflation rates that outstripped wage increases. Seasonal, sectoral, and catastrophic unemployment levels contributed to different understandings of poverty. A state response was, consequently, slow in coming. Figure 7.2 Health Department photographs by City of Toronto Archives is in the public domain . 75 7.4 Families and Property Rights in Canada Chris Clarkson, Department of History, Okanagan College In the summer of 1872, Maria Cheffrey, a Spanish resident of Lytton, British Columbia, arrived in Judge Matthew Baillie Begbie’s courtroom. Cheffrey and her husband had separated six years earlier. After their separation, she worked in Lytton and maintained herself. But that July, he returned. Maria Cheffrey applied to Judge Begbie for a protection order because she feared that her husband might seize her earnings and property. She had good reason to be worried. Chris Clarkson, Domestic Reforms: Political Visions and Family Regulation in British Columbia, 1862-1940 (Vancouver: University of British Columbia Press, 2007), 47-8. Until the middle of the 19th century, married men held what amounted to a monopoly over property rights within Canadian families. Under the common law inherited by the English-speaking colonies, a married woman could not enter into contracts, sue, or be sued. Upon marriage, her wages and personal property passed into her husband’s possession. He also gained the right to manage her real estate, and to control any rents or profits it might produce. Minor children likewise lacked the right to contract, sue, or control property. In matters of inheritance, a widow held the right to dower in most colonies, a provision that entitled her to the lifetime use of one-third of her husband’s real estate after his death. A husband could distribute all of his property by will (including his widow’s life estate after her death) as he deemed fit. If he did not write a will, his property ultimately passed to his eldest son. These laws were the cornerstones of a patriarchal social order, facilitating male headship of households and the concentration of property among a small number of men. The law was structured so that married women and minor children would be financially dependent. There were very few exceptions and those could be found in the Court of Chancery , where married women with wealthy families or benevolent husbands could have property set aside for their independent use through special settlements. The Court of Chancery was also charged with protecting minors from irresponsible parents. Yet for various reasons, including the high costs involved, very few individuals were able to avail themselves of the protections offered by this court. Ibid., 1-3, 38. Figure 7.3 A widow (like this one in Ethelbert, MB, ca. 1924) would have control over the estate of her deceased husband only until the eldest son reached adulthood. This situation changed slowly in the late 19th and early 20th centuries as colonial, and then provincial, legislatures passed statutes changing the laws respecting family property in English Canada. The changes varied by province, but the general trend over time was toward granting married women and children greater legal rights. The first wave of legislation, passed during the 1850s and 1860s, granted limited property rights to wives in emergency situations, at the discretion of the courts. Constance Backhouse, “Married Women’s Property Law in Nineteenth-Century Canada,” Law and History Review 6, no. 2 (Fall 1988): 217-219. Maria Cheffrey was fortunate enough to be the beneficiary of one of these new laws, and Judge Begbie granted her a court order to protect her property from her husband. Over the latter part of the 19th century, politicians in the English-speaking provinces granted married women substantial new rights over earnings and property, as well as the capacity to contract, sue, and be sued — all without the need for a protection order. Ibid.: 221-4, 230-1. Then, in the early 20th century, some provinces imposed new obligations upon married men. These new maintenance laws required men to support their legal families and children born out of wedlock. In matters of inheritance, provincial legislators wrote new laws in the 19th century providing for a more equitable distribution of property among spouses and children, in cases where husbands and wives failed to write wills. Peter Baskerville, A Silent Revolution? Gender and Wealth in English Canada , 1860-1930 (Montreal &amp; Kingston: McGill-Queen’s University Press, 2008), 7. In the early 20th century, legislators in every province took an even more activist approach to inheritance law reform, adopting dependants’ relief statutes, which permitted family members to apply for a larger share of an estate under certain circumstances. See Manitoba. Law Reform Commission, “Report on ‘The Testators Family Maintenance Act’,” Report #63 (December 16, 1985): 3-4. Why were the laws changed? Lawmakers’ motives varied from province to province and from one decade to the next. Frequently they were responding to the urging of feminist activists and legislators, but this was not always the case. In passing the various laws, some proponents and legislators hoped to protect wives and children from financial hardship and foster gender equality. Others intended to stimulate commercial activity and limit government expenditures on emerging social welfare programs by holding family members legally responsible for maintenance. For discussions of political motives, see Backhouse, \"Married Women’s Property Law\"; Lori Chambers, Married Women and Property Law in Victorian Ontario (Toronto: University of Toronto Press, 1997); Clarkson, Domestic Reforms. The results of the laws were not easy to predict. For example, in several provinces, conservative judges attempted to limit the impact of married women’s new property rights. Even so, historian Peter Baskerville’s research on British Columbia and Ontario shows increased property ownership, borrowing activity, and entrepreneurship among married women. Peter Baskerville, “Women and Investment in Late-Nineteenth-Century Urban Canada: Victoria and Hamilton, 1880-1901,” Canadian Historical Review , vol. 80, no. 2 (June 1999): 191-218; and “‘She Has Already Hinted at “Board”’: Enterprising Urban Women in British Columbia, 1863-1896,” Histoire S ociale – Social History 26, no. 52 (November 1993): 205-27. Other evidence indicates that new rights produced new expectations among women, in both their personal and political lives. The rights of family members under Quebec’s civil law were different. As Bettina Bradbury et al., have written, “Marriage automatically created a community of property, legally shared equally by both spouses, but administered by the husband.” Bettina Bradbury, Peter Gossage, Evelyn Kolish, and Alan Stewart, “Property and Marriage: the Law and Practice in Early Nineteenth-Century Montreal,” Histoire S ociale – Social History, 26, no. 51 (May 1993): 16. On the continuities between the pre-Conquest Custom of Paris/ Coutume de Paris, and the Civil Code of 1866 regarding women’s legal status, see Micheline Dumont, Michèle Jean, Marie Lavigne, and Jennifer Stoddart [The Clio Collective], Quebec Women: A History , trans. Roger Gannon and Rosalind Gill (Toronto: The Women’s Press, 1987), 124. Those final words are important. While the phrase “community property” sounds egalitarian, the husband’s administrative rights meant that, in practice, he could generally dispose of the couple’s property as he wished. Property inherited by either spouse was an exception to this arrangement: each retained separate ownership of inherited property, yet neither had the right to dispose of that inherited property without their spouse’s consent. In addition, a small number of wealthy couples signed marriage contracts specifying a “separation of goods,” which permitted each spouse to maintain separate property. Bradbury et al, “Property and Marriage”, 16-17, 22-3, 35. Even in these cases, however, the law stated that wives needed their husbands’ authorization to manage their separate property, and the courts interpreted this requirement quite strictly. With respect to inheritance, Quebec, unlike English Canada, operated according to a system of a partible inheritance, in which the deceased’s property was divided amongst his or her heirs. A widow or widower was entitled to a half-share of any community property. If the deceased left no will, the remainder would be divided equally among descendants, or according to more complicated formulae among other heirs. The situation with respect to spouses’ separate property was less favourable. Legislation passed over the second half of the 19th century that gradually eliminated the widow’s customary right to dower in her husband’s separate lands, since traditional dower rights were a hindrance to land transfers. Bettina Bradbury, Wife to Widow : Lives, Laws, and Politics in Nineteenth-Century Montreal (Vancouver: University of British Columbia Press, 2011), 121, 137-8; Dumont et al., Quebec Women, 125. Children’s right to a fixed share of their parents’ separate estates was likewise abolished. H.R. Hahlo, “The Case for Family Maintenance in Quebec,” McGill Law Journal 16, no. 3 (1970): 536-537. After these changes, separate property could be distributed freely according to the terms of a will; in the absence of a will, it would be distributed to the children or other heirs, with the spouse ranking 13th in the hierarchy of potential claimants. The liberalization of family property rights came more slowly in Quebec than in the other provinces. This was not due to the absence of feminist agitation. Feminists in Quebec campaigned for a better claim to family property and greater legal independence throughout the early 20th century. While they gained improved inheritance rights respecting the spouse’s separate property in 1915, other markers of improved status under the law were slow to come. Women in Quebec gained the vote last, in 1940. Political and clerical opposition hindered their efforts to achieve the franchise and to more radical changes to married women’s property rights, and to gain them the legal capacity to act for and represent themselves. Such change would have to wait for a resurgence of feminist activity in the 1960s, accompanied by the social, religious, and governmental shifts engendered by the Quiet Revolution (see Section 9.9 ). Dumont et al., Quebec Women, 252-65, 314, 321-324, 336-339. Key Points Property rights historically favoured males over females, including sons over wives. Women’s rights regarding marital property increased slowly and unevenly in the post-Confederation era. Inheritance laws in Quebec were distinct from those in the rest of Canada and were the focus of feminist reform efforts in the early 20th century. Figure 7.3 Widow &amp; children on farm in Ethelbert, Manitoba by George E. Dragan / Library and Archives Canada is in the public domain . 76 7.5 Women’s Organizations and Reform Melanie Buddle, Department of History, Trent University Figure 7.4 At 26 years of age in 1889, Bertha Wright (later Mrs. Carr-Harris) was founder and first president of the Canadian YWCA. Beginning in the 1870s, a number of women’s organizations and clubs formed locally, nationally, and internationally. Some, such as the Young Women’s Christian Association (YWCA), which opened a Canadian branch in 1870, the Women’s Christian Temperance Union (WCTU), which opened its first Canadian branch in 1874, and the National Council of Women of Canada (NCWC), which formed in 1893, were Canadian affiliates of international women’s organizations. These and other women’s groups formed during a period of huge social upheaval. At the end of the 19th century, industrialization, urbanization, and increased immigration led some women to take public action against social ills that seemed to threaten traditional family life. They felt that the way to protect women and children was to protest the evils of alcohol and attendant evils, such as prostitution, poverty, and poor working conditions amongst the lower classes. The WCTU campaigned first and foremost for temperance (limiting the use of alcohol and encouraging sobriety) and prohibition (laws to ban alcohol entirely) because they blamed alcohol for social problems, such as poverty, immorality, and prostitution. Other groups had different mandates (education, working conditions for women, and philanthropy), but addressed the same social ills. Inside meetings of literary clubs, temperance societies, and Christian associations, women critiqued the political and educational limitations of womanhood but were careful to maintain the conventions of their time. Many maintained a mandate to support families, children, and womanly arts, and praised the conventional roles of women. This was an effective strategy, as it was not particularly threatening to Canadian society at the time: men voted and worked, and women were responsible for children and domestic labour — although this was changing as more women were joining the paid labour force. The WCTU shared features with other women’s groups that formed during this period: a focus on Christian values and on protecting women, children, and the less fortunate. These ideals formed what historians call the “Social Gospel”: a Christian-influenced approach that brought an evangelical fervour to public reform (see Section 7.6 ). See Mariana Valverde, The Age of Light, Soap, and Water: Moral Reform in English Canada, 1885-1925 (Toronto: McClelland and Stewart, 1991). Emerging women’s clubs shared another feature: a growing commitment to a larger public and political role for women, including steps toward women’s voting rights. Some were more tentative than others in moving toward women’s rights to the vote ( suffr age ) but by the early 1900s many discussed it. These groups provided a discursive space for women to talk about issues ranging from education, temperance, domestic arts and social reform, to arts and crafts and literature — and sometimes, female suffrage. The NCWC, a national umbrella organization for women’s groups, formed 20 years after the WCTU arrived in Canada, and became an affiliate of the International Council of Women. Led by Lady Aberdeen (1857-1939), wife of the Governor General, its first member was the Women’s Art Association of Canada. Adelaide Hoodless (1857-1910), a prominent social reformer who would be influential in the Canadian YWCA, co-founded the NCWC. The NCWC had a mandate to improve the status of women, and social conditions for women and children, but initially stopped short of supporting female suffrage. Interestingly, the WCTU influenced its formation but refused to join because the NCWC was not religious enough. Yet in 1888, the WCTU was the first large women’s group to specifically support suffrage. The NCWC did not specifically endorse women’s rights to vote until 1910, and many of their member organizations, including some of the local Councils of Women across the country, did not endorse, and even opposed, women’s suffrage. Katja Thieme, “Language and Social Change: The Canadian Movement for Women’s Suffrage, 1880-1918” (PhD Thesis, University of British Columbia, 2007), 31. Thus we see a mix of radicalism and conservatism in many early women’s groups. Other women’s organizations appeared in this fertile period. On the surface, national and local women’s groups such as the Canadian Women’s Press Club (1904), the Women’s Art Association of Canada (1892), the YWCA (1870; Canada-wide in 1893), the Imperial Order Daughters of the Empire (IODE, 1900), and the Toronto Women’s Literary Club (1876) appeared devoted to artistic, educational, and professional or business pursuits. Many promoted service to girls and women, such as the YWCA, which emphasized the temporal, religious, and moral welfare of young women. Toronto YWCA, Constitution of the Toronto YWCA, 1873, Article II, cited in Mary Quayle Innis, Unfold the Years: A History of the YWCA in Canada (Toronto: McClelland and Stewart, 1949), 13. But even outwardly more conservative groups such as the IODE (which resisted suffrage and focused on patriotism, education and philanthropy) could become vehicles of social and political change. The Toronto Literary Club was the first to publicly move in this direction, changing its name to the Canadian Women’s Suffrage Association, and becoming the first Canadian group with suffrage as its main aim. Alison Prentice et. al., Canadian Women: A History, 2nd Edition (Scarborough: Thomson Nelson, 2004), 195-196. Clubs could be screens for political action, and supporters of female suffrage were inevitably involved in one or more of the other women’s organizations, even those that did not focus on suffrage. The Canadian Women’s Press Club included female novelists, newspaper editors, and reporters and its early members included Nellie McClung (1873-1951) and Emily Murphy (1868-1933), who were prominent social reformers and suffragists. And the very fact that women were organizing and reaching out in a public way, regardless of the professed mandate or cause, was in itself a radical move for women. While working-class women also organized and protested the inequity of society, the most prominent female reformers in the late 1800s and early 1900s were white middle- and upper-class women. Their approach to social issues seemed to blame the “fallen women” and less fortunate: reformers attempted to preserve a fading Victorian middle-class family life and their identification of the problem was sometimes the fallen themselves, rather than industrial, economic, and related societal upheavals. Some of the same women supporting female suffrage and social reform also supported eugenics (see Section 7.8 ), limiting immigration of non-whites, and extending the vote only to white women, due to a fear of “racial degeneration.” See Anne-Maria Kinahan, “Transcendent Citizenship: Suffrage, the National Council of Women of Canada, and the Politics of Organized Womanhood,” Journal of Canadian Studies 42, 3 (2008): 5-27. Others, like Hoodless, opposed female suffrage; she argued that women should exercise their influence through their sons and husbands. Terry Crowley, “HUNTER, ADELAIDE SOPHIA [HOODLESS],” in Dictionary of Canadian Biography , vol. 13, University of Toronto/Université Laval, 2003–, accessed 22 September 2015, . By association, by marriage, by family status, and by community prominence, these women had time and energy for art associations, moral reform campaigns, temperance groups, and art clubs. We can acknowledge their efforts to provide aid and to give women more power through public life, and we can acknowledge that compared to men, they were treated unequally and were subject to discrimination. But these same women had a degree of privilege not afforded to non-white and lower-class women in Canada. They were also divided in their support for a more political role. Some women, and some groups, opposed suffrage or focused only on moral or spiritual issues. Some focused on domestic science and handicrafts but moved toward suffrage, and others specifically supported suffrage as the key to relieving other social ills. Early supporters of female suffrage have been called maternal feminists because they argued that their role as mothers and homemakers, as “angels of the house,” was the reason they needed more influence in society — and not, as later feminists would argue, because they ought to be treated as equal to men. Thieme, “Language and Social Change”, 15-16. Women’s clubs were pivotal in that they were early opportunities for women to discuss the increasingly public roles they could play in society. We cannot dismiss them only as social gatherings for ladies of privilege, because they also led to important conversations about women’s rights in society and in the political and professional realms. These groups were more radical in their context than they might appear to us, looking backward. Despite the grounding of many clubs in a narrow ideology of white women’s rights, mother’s rights, and Social Gospel “purity” arguments, they paved the way for women like Agnes Macphail (1890-1954), Canada’s first female member of parliament. Macphail, in 1925 said: “I do not want to be the angel of any home, I want for myself what I want for other women, absolute equality. After that is secured then men and women can take turns at being angels.” Canada, House of Commons, Debates , 26 February 1925. Figure 7.5 A good example of the rhetoric used by maternal feminists: an appeal to motherly feeling in the fight against the “Liquor Traffic”. Key Points The 1870s witnessed the creation of important and influential women’s organizations; more followed before 1914. Many of these organizations shared a strong Christian orientation and concern regarding social ills, including the social and domestic consequences of alcohol abuse. These organizations provided a springboard for female activism, early feminism, and demand for greater female rights (including the right to vote). Opposition to the franchise remained an important force in women’s organizations. Overwhelmingly, these were middle- and upper-class organizations representing white women with extensive privilege and social and cultural capital. Many were, as well, highly radical in their context. Figure 7.4 Miss Bertha Wright (later Mrs. Carr-Harris, first President of the Canadian Young Women’s Christian Association) (Online MIKAN no.3229086) by William James Topley / Library and Archives Canada / PA-167608 is in the public domain . Figure 7.5 Have You Any Boys? : Remember September 29, Down with the Liquor Traffic! (Online MIKAN no. 2988523) by Library and Archives Canada, Acc. No. 1984-4-943 W.C.T.U Dominion is in the public domain . 77 7.6 Social Gospel Figure 7.6 Urban missions began appearing in the late 19th century. The Toronto Mission opened in 1896 and became a centre for Social Gospel activism. Of all the reform movements arising out of the 19th century, arguably none had as extensive a reach as the Social Gospel. Faced with the new realities of urban overcrowding, grueling factory work, and grinding poverty, Christians in North America questioned whether their focus should be on the salvation of the individual or of society as a whole. Conventional wisdom in the mainstream churches had always been that the issue of salvation was entirely a personal matter. Urbanization and industrialization challenged that perspective. Increasingly, clergymen and religious writers were of a mind that the physical environment in which the battle against sin took place was so changed by industrialism that new approaches were necessary. They found a receptive audience in the middle- and working-classes, and produced several generations of political, social, and cultural leaders as a result. The values of the Social Gospel became the fuel behind many political and socio-economic movements in the first century after Confederation, some of which were inevitably contradictory. From the Pulpit to the Public Two of the largest and most influential institutions in British North America at the start of the 19th century were the Anglican (or Church of England) and Catholic Churches. Wherever there were Scots, there were Presbyterian churches as well, although this was in fact a number of fractious denominations that only converged around the time of Confederation. Methodists constituted the next most populous sect, and there were significant numbers of Congregationalists in the colonies, particularly in New Brunswick. But the two principal Christian churches — Catholic and Anglican — were head and shoulders above the competition in terms of adherents and political influence. The authority of the Anglicans was part of the very fibre of the Family Compacts in the English-speaking colonies and in anglophone Montreal; Catholicism enjoyed a near monopoly in French-Canada. Both churches were broadly engaged with civil society, providing much of pre-Confederation Canada’s educational , welfare , and healthcare infrastructure. Bishops and Archbishops endeavoured to set much of the moral tone and brokered power between the colonial governors and the secular leadership. Their values were simultaneously very conservative (in the case of Quebec’s Catholic clergy, they were defensively so in the face of Anglo-Protestant hostility) and community-minded. Much of the history of political struggle in Canada overlaps with the history of sectarian conflict. The Presbyterian and Methodist elements objected to the authority exerted by the Anglicans in what became Ontario; the mid-19th century Reform Party was overwhelmingly drawn from the non-conformist churches , while the Tories were essentially the political wing of the Anglican Church. The situation was similar in most parts of pre-Confederation Canada, although clearly different in Quebec where Anglicans and Presbyterians were allied against Catholics. Sectarian turmoil was not uncommon, and it is important to recall the vigour with which Orange elements attacked the rights — and the bodies — of Catholics in Saint John, Toronto, Red River, and elsewhere in Victorian Canada. This background underlines the extent to which divisions between denominations mattered, emotionally and practically, to Confederation-era Canadians. As the Dominion of Canada project got underway these relationships evolved and became important in new ways. The Victorian years witnessed the rise of new Christian denominations while some older sects changed their course. It is impossible to imagine these new elements occurring outside of the context of industrialism and other socio-economic disruptions in the Victorian era. The Presbyterians, Methodists, and Congregationalists — along with “Low” Anglicans — were already critical of the liturgical and hierarchical qualities (sometimes called “Churchianity” as opposed to Christianity) of the “High” Anglican and Catholic Churches, and the instances where it seemed political leaders were following the Archbishop or even the Pope rather than the electorate. But the influence of evangelicalism was embodied in smaller denominations like the Lutherans and Baptists, in elements within Methodism and Congregationalism (both of which were growing in popularity), and in entirely new churches like the Salvation Army — posed a challenge to the established churches’ view of spiritual redemption and, implicitly, to social relations. The 19th century evangelicals include profoundly different and distinctive voices and theological viewpoints. Many — the Salvation Army in particular — were very urban in their outlook, and all took the perspective that personal and direct salvation was a possibility. This was a critique of the older churches’ mediation of the relationship between the individual and God. While this brought the individual into sharp focus, it had the almost perverse effect of making the social more obvious. The evangelicals’ view, however, was one of a society made up of individuals (a view that was consistent with the rising tide of democracy), as opposed to one made up of categories and castes. “Evangelical” itself derives etymologically from “good news” — and the good news was that everyone (and thus the whole of society) could be saved. The infrastructure of the Social Gospel included bricks and mortar as well as personnel. The centre for much of the movement’s development was Wesley College in Winnipeg, a Methodist post-secondary institution established in 1888. The intersection of late-Victorian Methodism — with its redemptive message, culture of outreach, and largely working-class constituency — and the city of Winnipeg — growing at an explosive rate into the capital city of the whole West — was critical to the development of the ideals of the Social Gospel at Wesley College. Salem Bland (1859-1950) moved from central Canada to a professorship at Wesley in 1903, where he nurtured a generation of Social Gospel leaders. These include two founders of the Cooperative Commonwealth Federation (CCF): James Shaver (J.S.) Woodsworth (1874-1942) and William “Bill” Irvine (1885-1962) (see Section 7.9 ). Wesley College students, faculty, and graduates played an increasingly vocal role in criticizing the conduct of the Great War, some of them (like Woodsworth) embracing pacificism , others attacking wartime profiteering. They were also active in the events around the Winnipeg General Strike ( Section 3.9 ) and together believed that if revolution was coming, it would be a revolution of religion and the establishment of a new order, with Social Gospel evangelism at its centre. Ramsay Cook, \"Ambiguous Heritage: Wesley College and the Social Gospel Re-considered,\" Manitoba History , 19 (Spring 1990). Figure 7.7 The elegant, gothic sandstone facade of Wesley Hall (opened in 1895). In 1938 it became United College, and in 1967 the University of Winnipeg. What this new — and extremely popular, entertaining, and challenging — religious movement discovered, of course, was that salvation was hard work particularly when the sinners in the crosshairs are living their lives in squalor, poverty, addiction, and ignorance. Saving souls was one thing; saving society was another. Building a Heaven on Earth The range of projects in which the Social Gospellers engaged was broad but they shared some core elements. Temperance was one, fighting the causes of poverty was another (although methods might differ drastically), and a representative cross-section took an interest in eugenics. In Central and Eastern Canada the focus was heavily on urban squalor and sin, while in the West there was a stronger emphasis on the project of building a new and ideal society from the ground up. Their approaches combined elements of faith and science, a feature that further distinguished them from the Anglicans and Catholics (although both of the big churches would change in this regard in the 20th century). Sometimes these combinations produced contradictions. The Social Gospel interest in eugenics, for example, arose from an awareness of advances in biological sciences. It might be argued that their commitment to the view that genes (nature) trumped environment (nurture) was inconsistent with their view that the physical world mired the individual in sin. They criticized, as well, the role of the non-evangelical faiths in matters of government, while simultaneously seeking to create a more activist and interventionist state. Regardless of these contradictions, the Social Gospellers constitute the first generation of Christian thinkers to understand sin and redemption through a science lens, and to attempt to resolve it through the further application of science and social innovation. Social Gospellers were prepared to make full use of the arsenal of modern technology, engineering, and planning. Clean water and well-lit streets were as critical to this project as any Sunday sermon. At the same time, they recast the issues of moral failings from the individual (e.g., drinking or ignorance) to the social (e.g., alcoholism or lack of educational opportunity). As the century closed and a new one began, some of the concerns of the Social Gospellers shifted to questions associated with immigrant communities. Many of the newcomers were neither Protestant nor Catholic and were regarded by some Social Gospellers as a threat in their own right. Education might play a role in assimilating immigrants, but reformers’ suspicion of the Eastern European or Asian Canadian proved hard to shake, and it would provide part of the context for the spread of eugenics across the Social Gospel movement. Targeting Reform The array of crusades launched by the various branches of the Social Gospel movement included high-level politics and street-level service. Missions and “settlement houses” were established among the urban poor and in Aboriginal communities. The Salvation Army became active in city centres, on reserves, and in the North. Wilfred Grenfell opened his own mission in Labrador, in 1893. Methodists in the 1880s joined with other denominations in establishing residential schools for Aboriginal students (see Sections 11.7 , 11.8 , 11.9 , 11.10 , and 11.11 ); support for these projects came from Social Gospellers who saw them as an instrument of assimilation into an advanced Christian- and Anglo-Canadian culture and also as “schools that met the practical and physical needs of Aboriginal peoples.” Eleanor J. Stebner, “More than Maternal Feminists and Good Samaritans: Women and the Social Gospel in Canada,” in Gender and the Social Gospel , eds. Wendy J. Deichmann Edwards and Carolyn De Swarte Gifford (Urbana and Chicago: University of Illinois Press, 2003), 57. The settlement houses were, similarly, located on the boundary between social change and social control : they offered daycare, some schooling, help finding employment, language classes for immigrants, and so on, but they were also centres for transferring and imposing the dominant societies’ moral values to newcomers. It was this combination of targeted Christian good deeds among the poor, the voiceless, and the colonized, the moral regulation of deviant (including alien) behaviour, and efforts to counter the ill effects of capitalism and urban life that characterized most Social Gospel activities. The Social Gospel Style Aimee Semple McPherson (1890-1944) was arguably the most famous Canadian of her time. Born Amie Elizabeth Kennedy in Salford, Ontario, she was influenced by the Salvation Army (still very much a new thing in late Victorian Canada), married at 18, widowed at 19 (while pregnant with her first child), remarried at 22, divorced at 29, married for a third time at 41 years, and divorced again three years later. Her travels across North America matched her tumultuous personal life: she relocated to the United States in her 20s and dedicated her life to evangelizing. Semple McPherson was a barnstorming preacher who was increasingly associated with the emergent Pentacostal faith. Moving to Los Angeles in 1918 put Semple McPherson at the centre of what was just emerging as America’s West Coast metropolis and film industry capital. Huge and elaborate stage sets were produced for her revivalist meetings, and the level of theatricality in Semple McPherson’s sermons was both astonishing and of the highest quality. Her meetings were attended by as many as 40,000 at their peak, and were often chaotic and fevered; their unpredictable and inventive features influenced other evangelicals and event producers for generations. The most elaborate of her performances were not entirely unlike 1970s and 1980s stadium-venue rock concerts, and the temple she built in Los Angeles owed more to music halls than to cathedrals. Moreover, Semple McPherson crossed media by combining live performances with film and radio broadcasts. She was a superstar before the term was invented. Figure 7.8 Small town Canadian girl makes good. Aimee Semple McPherson was already a force with which to reckon at 33 years of age when she raised the Angelus Temple on the strength of donations in cash and kind. There was room for only one Aimee Semple McPherson, but the Social Gospel and the evangelical trend both produced her, and was influenced by her. Some of the leading figures in the movement in Canada came from the pulpits, and many learned how to be political and rally speakers from watching and hearing the evangelicals in action. On the Left, J.S. Woodsworth was a Methodist minister and Tommy Douglas (1904-1986) was a Baptist preacher. Both men went on to lead the early CCF as champions for social change. Nellie McClung (1873-1951) was defined by her Social Gospel credo as much as her father’s Methodism; she sat in the Alberta legislature as a Liberal member. Further to the Right, William (“Bible Bill”) Aberhart (1878-1943) was an ardent Baptist who established his own evangelical organization — the Calgary Prophetic Bible Institute — and created the Social Credit Party as a means to achieve greater social equity through financial reforms (see Section 7.9 ). His successor at both the evangelical and secular level was Ernest Manning (1908-1996), who was raised in a generation that could identify its creed as simply “evangelical.” Manning went on to become one of the most successful politicians (in terms of longevity) in Canadian history, and he was the father of the late 20th century Reform Party leader, Preston Manning (b. 1942). Both Ernest Manning and Aberhart followed Semple McPherson’s pioneering work in radio as a means to reach into rural and urban households alike with social, economic, and political messages. All of these individuals shared in that evangelical, crusading, and urgent approach to modernity that demanded change based on the goal of a Christian moral civilization. Figure 7.9 Tommy Douglas. Watch this undated recording by Tommy Douglas on The Cream Separator . Tommy Douglas uses a familiar clergyman’s rhetorical technique, the parable, to deliver a moral lesson that crosses into the political. Many Canadian politicians still attempt to approximate this style, which is rooted in the Social Gospel experience of the late 19th and early 20th centuries. The Opposition Mainstream resistance to the Social Gospel message was powerful and persistent. The Anglican and Catholic Churches had their own agendas of social change, but these involved the preservation of social hierarchies, which, the left-wing of the Social Gospel would say, were at the foundation of social injustice. The further to the left some of the Social Gospellers moved, the more likely they were to be associated by their opponents with socialism and communism. In truth, while some of the Social Gospellers found their way toward social democracy, the Christian heart of the movement was a rampart against the secularism of communist movements. Right-wingers, too, fell afoul of the mainstream. When Aberhart attacked the banking system and attempted to dilute the national currency (with what was derided as “funny money”), he was twisting the tail of old money in Montreal and Toronto. (His conservative evangelicalism and suspicion of international money interests also drew a charge of anti-Semitism.) The very populism of the Social Gospel — its mass appeal and its folksy, inclusive style — was dismissed by Liberals and Conservatives as the work of “teachers and preachers.” Calls for fair treatment of labour organizations, relief to farmers caught by rising costs and falling farm produce prices at the end of the Great War, and money support for the unemployed in the 1930s were ignored by the old parties. Their intransigence across the first four decades of the 20th century cost them significant support and resulted in the creation of the United Farmers parties across English-speaking Canada, several of which formed governments at the provincial level. The Progressive Party followed, as did the CCF and Social Credit (see Section 7.9 ). These Social Gospel experiments in politics also drew fire from the Left. Socialist and communist organizations were suspicious and critical of the Christian agenda of the Social Gospel, regarding it as a fruitless and delusional attempt to manage the worst excesses of capitalism. Achieving “a society of justice, equality and freedom from economic oppression,” the socialists and communists argued, would require more than “good Samaritanism.” Eleanor J. Stebner “More than Maternal Feminists and Good Samaritans: Women and the Social Gospel in Canada,” Gender and the Social Gospel , eds. Wendy J. Deichmann Edwards and Carolyn De Swarte Gifford (Chicago: University of Illinois Press, 2003): 62. Many of the country’s early 20th century hard-leftists were drawn from the new immigrant community; the Social Gospel’s record of xenophobia (perhaps articulated best by Woodsworth in his 1909 book, Strangers Within Our Gates ) further alienated Eastern Europeans and Scandinavians who were comfortable with the politics of communism. For Social Gospel women, the track record of the old political parties as regards temperance and suffrage spoke for itself. Women who wanted to achieve social reform through electoral politics were more likely to find a home in the newer, smaller parties than they were among the Grits and Tories. Agnes Macphail (Progressive), Dorise Nielsen (CCF), and Gladys Strum (CCF) were three of the first five women elected to Ottawa. In 1944, Strum became the first woman to head up a provincial or federal political party when she took the presidency of the Saskatchewan CCF. At the provincial level, Louise McKinney (Nonpartisan League and United Farmers of Alberta) and Roberta MacAdams (nonpartisan) were both elected in 1917. Although women would also enjoy electoral success in the Liberal and Conservative parties, the progressive agendas of early feminists both contributed to, and would be better received, in the third parties . Figure 7.10 Andrew Carnegie’s unparalleled campaign of personal philanthropy left a mark on Canadian cities from coast to coast. This image comes from the British Punch magazine in 1903. Measuring the intellectual consequence of a movement like the Social Gospel is difficult. It was so diffuse and appeared in so many guises that it inevitably overlapped with other engines of change. For example, the Scottish-American industrialist Andrew Carnegie (1835-1919) was considered by his contemporary critics as the embodiment of the rapacious industrialist, whose enormous wealth was won at the expense of terrible working and living conditions for his employees; he wrote, however, on The Gospel of Wealth in 1889, calling for applied philanthropy on the part of his peers. In the last two decades of his life, he belonged to a Social Gospel church in New York and contributed millions of dollars to the improvement of civic and social infrastructure, a good deal of it in Canada. Philanthropy and charity were among the evangelical values promoted by the Social Gospel, and they remain important qualities in Canadian society, but they do not necessarily speak to the goal of social redemption. Nor, on the face of it, does social legislation like the Ontario Workmen’s Compensation Act of 1914 , which was nonetheless the product of Social Gospel lobbying. What can be said with some confidence is that the influence of the social gospel outlasted its earliest spokeswomen and men, and can yet be seen in the fabric of social welfare laws and in the language of debates about urban conditions and inequality. Figure 7.11 Vancouver was one of many Canadian cities to receive a Carnegie Library, which opened in 1903 next door to the City Hall. Key Points The Social Gospel movement grew out of changes in Protestant denominations and the rise of new churches in the 19th century. It was informed by deteriorating social and economic conditions in cities, and approached reform in urban areas and in remote and Aboriginal communities with missionary tactics. Elements within the Social Gospel movement were centred on Wesleyan College in Winnipeg, where a strongly social democratic wing developed. Social Gospellers targeted urban and social reform and some adopted new media and performance opportunities to produce a highly theatrical style outside of the traditional pulpit. The influence of the Social Gospel on Canadian politics and urban landscapes remains significant. Figure 7.6 YongeStreetMission by Skeezix1000 is in the public domain . Figure 7.7 UofW by KrazyTea is under a CC BY SA 3.0 license. Figure 7.8 ASM-AngelusTemple Plaque 1923 02 by Foursquare Church Heritage Center is in the public domain . Figure 7.9 Tommycropped by Samuell is in the public domain . Figure 7.10 Carnegie-1903 by Louis Dalrymple is in the public domain . Figure 7.11 Postcard: Carnegie Library and City Hall, c.1905 by Rob is in the public domain . 78 7.7 Temperance and Prohibition Alcohol consumption in Canada was prodigious in the early 19th century, and it hardly changed over the rest of the century. Any economy so heavily dependent on the production of wheat, rye, and other grains is going to quickly find a vent for surplus that involves fermentation. Some of the earliest and largest fortunes in both Upper and Lower Canada (Ontario and Quebec) were made in the brewing and distilling industries. Home manufacture was, of course, unregulated and widespread. The 19th century saw the growth of a movement culture around managing liquor production, sale, and consumption. It had many facets, and it was to prove the core movement around which many others revolved, and from which almost all 19th and 20th century reform movements would recruit their campaigners. Drink Canada Dry Rural drinking did not go unnoticed, nor was it without its critics. But it was different from what came after Confederation. Early attempts to “temper” or manage the consumption of liquor in British North America appear in the Canadas and the Maritime colonies in the 1830s and 1840s. These were “collective acts of individualism; each drinker who renounced the bottle was affirming the triumph of his or her will and the intent to meet the social and economic challenges that lay ahead.” Cheryl Krasnick Warsh, “‘John Barleycorn Must Die’: An Introduction to the Social History of Alcohol,” Drink in Canada: Historical Essays , Cheryl Krasnick Warsh, ed. (Montreal &amp; Kingston: McGill-Queen’s University Press, 1993): 12. Viewed this way, pre-Confederation temperance was not a mass movement in that it was scaled down to the personal and the communal. The late Victorian boom in city populations, however, propelled concern about liquor consumption to the forefront of public debate, and called for a mass and collective, rather than individualistic, response. As the economy came to value armies of men who could work in the resource-extraction sector or construction, the popularity of drink only increased. It is no coincidence that British Columbia, in 1893, boasted a resource-extraction economy with a severely distorted male:female ratio, and the highest per capita consumption of alcohol. Warsh, “‘John Barleycorn Must Die’”: 13-15. Nor should it be surprising to find that women’s consumption of alcohol increased in the Victorian era in step with the demand for single women in wage-labour. Wage earning, generally, was a critical element in the construction of a “wet” Canada. So, too, was the environment. Urban reformers focused much of their energy on water quality issues for good reason. With horse manure carpeting town and city streets, pigs fouling the roads and streams, and human waste disposed of in haphazard ways, there was no way that urban water supplies would remain reliable for long. The situation in Nanaimo was probably not unusual. There, as early as 1864, locals were signing petitions about water quality issues. Household sewage was being dumped by the bucket-load on the streets. Two decades later, it was finding its way into a ravine or the harbour, where it was revealed on the shoreline with every low tide. Some went into an abandoned coal mine underneath the downtown. As was the case with most Victorian towns before the construction of sewers, a “night soil” scavenger collected human waste and removed it to a dump on the edge of town. And, of course, it wasn’t unusual for people to use human manure in their gardens. John Douglas Belshaw, Becoming British Columbia: A Population History (Vancouver: University of British Columbia Press, 2009), 162-3. In short, there were plenty of reasons to be concerned about the quality of drinking water; for many, the solution was tea or coffee (made of boiled water) or alcohol (germ free, available in a multitude of flavours, and often served in sociable surroundings). Class and the Glass The earliest and most constant critics of liquor consumption were the emergent Canadian bourgeoisie. Their liberal ideal of democratic progress and their dependence on effective employees made it inevitable that they would see liquor consumption and drunkenness as a threat to polity and productivity. One historian has argued that this economic and political agenda was complimented by the rise of evangelical Christianity across Canada in the mid-19th century. It wasn’t just that the Baptists and Methodists disapproved of liquor: their creed emphasized personal responsibility for redemption in a way that the established churches did not. It was, Craig Heron maintains, this constellation of forces that gave the Temperance Movement an appeal in Canada beyond what it enjoyed in Britain and the other Dominions; the movement was comparably strong in the United States as well, making this one of those cultural moments that has a continental complexion. Craig Heron, Booze: A Distilled History (Toronto: Between the Lines, 2003), 372-3. If temperance had remained the exclusive preserve of the Canadian bourgeoisie, it would have gathered little momentum. But working people themselves were among the most vocal enemies of liquor. As a part of the community that sought greater inclusion in the political life of Canada and a better deal in the unfolding industrial era, artisans and craft workers articulated a view of respectability that denied alcohol a place in working-class culture. What is more, drink and a disciplined labour movement were incompatible. This was the position taken up by the Knights of Labor across North America (see Sections 3.4 and 3.6 ) and it was one that would echo through Canadian labour organizations into the 1920s. The regulation of womanhood in the 19th century was also driving the emergent temperance movement. Maternal feminists based their claim for improved women’s rights and privileges on the strength of women’s reproductive power. In this context, women who drank to excess were jeopardizing themselves, their embryos, and the health of the nation. They were also undermining the claim made by the feminists of superior female morality. Historian Cheryl Krasnick Warsh has shown how the courts in late 19th century Ontario sentenced as many as 803 women in one year under drunk and disorderly charges; women’s share of convictions between 1881 and 1899 averaged 16% but ran as high 24% in 1895. Cheryl Krasnick Warsh, “’Oh, Lord, pour a cordial in her wounded heart’: The Drinking Woman in Victorian and Edwardian Canada,” Drink in Canada: Historical Essays , ed. Cheryl Krasnick Warsh (Montreal &amp; Kingston: McGill-Queen’s University Press, 1993): 76-7. Women’s relationship with liquor was thus complex: increasingly dangerous, but at the very heart of an emergent feminist movement. Another motivating factor at the turn of the century was the arrival of immigrants from eastern and southern Europe. Here we see the collision of different cultures of drinking and the (largely Anglo-Protestant) Canadian fear of degenerate foreigners. Xenophobia, and prairie evangelism in particular, responded to the “threat” of foreign newcomers and their use of liquor, which simultaneously “eliminated the possibility of support from immigrants.” Warsh,“’John Barleycorn Must Die’”: 16-17. Historian of the liquor economy, drinking, and the drys Craig Heron (York University) discusses temperance. An interactive or media element has been excluded from this version of the text. You can view it online here: An interactive or media element has been excluded from this version of the text. You can view it online here: Temperance Before the Great War, the focus of the temperance crusade was the local and not the federal level. The possibility of regulating the sale and consumption of liquor seemed reasonable to some, and in 1878, the federal government passed enabling legislation, the Canada Temperance Act, which enabled the local option of prohibition through referenda. Like all referenda, the local option effectively lifts from the shoulders of legislators the burden of making a choice on behalf of their constituents. It necessitates the involvement of the local electorate in direct decision-making around an ideal that has not been expressed in the form of a policy. (Members of Parliament debate actual bills that they can see and hold and on which they may offer editorial suggestions; referenda typically ask for general agreement on a broad principal without providing any of the details.) The likelihood of winning a national referendum on prohibition was slim but at the municipal level, it might succeed. New Brunswickers seized upon the possibility of prohibiting public consumption of alcohol in the 1880s. Ten counties out of fifteen voted in favour of prohibition, and yet the sale of alcohol continued unabated. One study observes that “Moncton was, paradoxically, a prohibitionist town in which the liquor trade continued to flourish” from 1881 through the 1890s. Jacques Paul Couturier, “Prohibition or Regulation? The Enforcement of the Canada Temperance Act in Moncton, 1881-1896,” Drink in Canada: Historical Essays , ed. Cheryl Krasnick Warsh (Montreal &amp; Kingston: McGill-Queen’s University Press, 1993): 146-7. Enforcement issues plagued this experiment (as it would in many others); local police knew who was selling alcohol but were divided in their loyalties. One historian captures the situation perfectly: “relations between members of the police force and the liquor community were fluid.” ibid.: 156. Figure 7.12 Fearing for their livelihood, Toronto barmen take to the street in 1916. No other province would advance the temperance campaign as far as New Brunswick until the 20th century. One reason for the failure of the “drys” to gain ground was the presence and power of the “wets.” Commercial distillers in Canada could be found among the wealthiest member-families of the elite. Seagram, Labatt, Molson, Keith, Wiser, Carling, O’Keefe, and — in the early 20th century — Bronfman are names associated even now with the alcohol industry, and with families who held powerful directorships in other industries (including banks and railroads) and had significant political influence as well. Derrek Eberts, \"To Brew or Not to Brew: A Brief History of Beer in Canada,\" Manitoba History , 54 (February 2007), accessed 26 July 2015, . They employed huge numbers of Canadians and, despite the reach of the CPR, local breweries and distilleries were also competitive and important economically until the 1920s. Of course, not everyone in the middle or working classes wanted to go dry. Working men, returning soldiers, and members of the non-evangelical churches were highly unlikely to favour diminished access to booze. Young middle class women who entered the workforce in large numbers in the Edwardian years, and during the war, were a catalyst in the development of relatively respectable drinking “lounges” and, thus, became another population opposed to temperance. But this was the face of public drinking; the consumption of alcohol in private spaces was also a target of temperance agitators, and that aligned the elites and many middle class households against temperance. Insofar as the ranks of prohibitionists overlapped with anti-Catholic forces, they drove the Catholic Church into the arms of the wets (although where they were unbothered by assimilationist Protestants, the Catholic leadership was as likely to be dry). Heron, Booze , 191-6. There were, too, voices raised against the state regulation of liquor as a worrying example of growing governmental power. Prohibition The efforts of the temperance movement peaked in 1914 and were stayed by the outbreak of war. Unwilling to fight on two fronts, the issue was put to one side until it became clear that the Great War was not going to be brief. Increasingly, the consumption of liquor at home seemed an offence to the sacrifice being made abroad. Concerns were raised about productivity as well (a familiar theme in temperance circles in the industrial age). Province-wide referenda were organized, and by 1917, prohibition had arrived or was on its way in every province but Quebec, where one could buy wine or light beers, but not hard alcohol (see Section 6.5 ). It didn’t last. Returned soldiers were upset that the country had gone “dry” in their absence and felt that they had earned the right to drink after months and years in the trenches of Belgium and France. Quebec and British Columbia were the first to abandon prohibition in favour of regulation and government-controlled liquor sales in 1921. Prohibition was lifted in three provinces and the Yukon Territory by 1921; it didn’t last much longer in Alberta and Saskatchewan, but it held on longest in the Maritimes. The Dominion of Newfoundland prohibited possession or drinking of liquor from 1917 to 1924. Thereafter, the legal and illegal production of liquor in both Dominions exploded in an attempt to meet demand for the banned substance south of the border. Mark C. Hunter, \"Changing the Flag: The Cloak of Newfoundland Registry for American Rum-Running, 1924-34,\" Newfoundland and Labrador Studies , 21/1 (2005). American prohibition continued until 1933, creating a smuggling industry in every West Coast, East Coast, and Great Lakes Canadian town within range of an American market. While the heaviest traffic passed between the vicinity of Windsor, Ontario and Detroit, Michigan there was also extensive illicit trade between the nominally-dry Maritimes and the whole American East Coast. Figure 7.13 Liquor stills captured during prohibition in Vancouver, 1917. Rum-running was a feature of Vancouver’s black economy as well. The chain of Gulf and San Juan Islands provided some cover, as did the multitude of tiny bays and inlets around Puget Sound. Fortunes were made on the strength of boats that could outrun Coast Guard patrols and the RCMP. Daniel Francis, Closing Time: Prohibition, Rum-Runners, and Border Wars (Vancouver: Douglas &amp; McIntyre, 2014), 128. East Coast smugglers eluded local officials by claiming they were shipping out consignments to the Caribbean islands when, in fact, they were headed to Boston or New York. There were accusations that the Newfoundland government, under Premier Sir Richard Squires (1880-1940), “had turned the Board of Liquor Control into a covert bootlegging operation, the profits from ‘private’ sales going into his political account.” Margaret R. Conrad and James K. Hiller, Atlantic Canada: A Concise History (Don Mills: Oxford University Press, 2006), 170. Inland smugglers thrived as well, including those in Madawaska County (aka: the New Brunswick Panhandle) and the Kootenays in southern BC; both were remote and lightly-policed areas with porous borders. On the West Coast, this was what one study calls “the respectable crime” and the ranks of rum-runners in BC included members of very well-placed families. Stephen J. Moore, Bootleggers and Borders: The Paradox of Prohibition on a Canada-U.S. Borderland (Lincoln: University of Nebraska Press, 2014), 56. Figure 7.14 The sail/steam combination ship, the Malahat (described as a “Mabel Brown class” vessel) was known as the “Queen of Rum Row” on the West Coast. It served as a floating liquor warehouse to smaller, faster craft and was the source of much of the wealth earned by Vancouver’s Reifel family. Historical studies of rum-running mention women too often to suggest that their involvement was exceptional. The production of small quantities of home-brew liquor was almost certainly work that women did, but they also played frontline roles in the sale and delivery of banned cargo. One study explains that high unemployment rates in the Maritimes in the 1920s were more crippling for women than for men, a fact that propelled many single mothers — some of them, of course, war widows — into smuggling. A Mrs. Donnie Hart of Saint John stands as a good example: arrested no less than once every year between 1916 and 1924, she worked as a bootlegger in order to provide for her family. Ernest R. Forbes, “The East-Coast Rum-Running Economy,” Drink in Canada: Historical Essays , ed. Cheryl Krasnick Warsh (Montreal &amp; Kingston: McGill-Queen’s University Press, 1993): 168. Figure 7.15 A liquor raid at Elk Lake, Ontario, 1925. Illegal production of liquor wasn’t a problem before regulation. Prohibition combined several contradictory forces. It was a manifestation of democratic will, a case of state intervention in the economy, and it was instrumental in building up urban police forces as well. Simultaneously, it diminished the rights of the individual, curtailed urban enterprise, and made public policy of private morality. It was both a modern and anti-modern force (see Chapter 10). Both sides in this debate advanced the use and sophistication of modern advertising as they campaigned for, on the one side, hearts and minds, and on the other, dry throats and vulnerable livers. The campaign against liquor, then, introduces a panoply of historical themes. It also introduces many of the key players in other crusades. The Language of Liquor Given the central place of liquor in the social lives of Canadians (past and present), it is no surprise to find that the vocabulary around drinking is both extensive and potentially confusing. What follows is not an exhaustive list of terms. It is weighted towards west coast usages and, worse still, none of these words are used in the past or present with razor-sharp precision, but nonetheless it may be helpful. Where: Saloon – Generally a drinking establishment not attached to a hotel or restaurant, usually urban. There are few restrictions on standing or moving about, and probably not much in the way of food. Pub or Public House – These were often attached to roadside inns and “milehouses” in the mid- to late-19th century. They provided drink by the glass, and in larger take-away quantities, and often served food as well. A few survivors from that era kept the term in use and then it was revived in the 1970s with the spread of faux pubs (essentially saloons with somewhat better food and design that mimics an ideal of English or Irish drinking establishments). Beer parlours/taverns – 20th century; a regulated and licensed private establishment in which the public can drink beer by the glass; standing at the bar is prohibited in most provinces; there is usually not much in the way of food to soak up that beer. In British Columbia, there were for many years restrictions on women’s entry (they had to use the “Ladies &amp; Escorts” door) to restrict heterosexual mingling and, ostensibly, the sex trade. In beer parlours until the late-20th century, moreover, patrons were not allowed to carry their drinks from one table to another. Attempts to do so promoted the command to “sit down and drink your beer.” Robert A. Campbell, Sit Down and Drink Your Beer: Regulating Vancouver's Beer Parlours, 1925-1954 (Toronto: University of Toronto Press, 2001). Boozecan, Blind pig, Speakeasy – Colloquial terms for illegal drinking establishments. These were called into existence by the increasing regulation of drink from the late Victorian-era, and especially so during Prohibition. Even after Prohibition ended in Canada, there were illegal establishments that sought to evade repressive regulation. Who: Drys – Advocates for the limitation, if not outright prohibition, of alcohol production, sale, and consumption. Wets – Opponents to the above. This camp includes people who wanted to drink and also the powerful brewers, distillers, and other representatives of the liquor interests. Women’s Christian Temperance Union (WCTU) – One of the largest and most effective anti-drink lobbies in Canada. Established in 1874, months after its first branch was announced in the United States, the WCTU emerged as a vehicle for contiguous reforms in public behaviour, the political environment, and social conditions. Rum-runners – Vendors of alcohol (not just rum) who ship it illegally across provincial or national boundaries into territories where there are sanctions — like Prohibition — against the sale of liquor. Bootleggers – Anyone who sells liquor illegally. This term is used in the past to cover the rum-runners but its domestic face, historically, was the couple who sold cheap homebrew off their back porch, and the taxi driver who augmented his income with deliveries of bottles to homes and hotel rooms. Liquor Control Boards – Provincial agencies created in the 1920s to regulate post-prohibition drinking and alcohol sales. These all became a major source of revenue for provincial governments. When: Sundays – Highly unlikely. During the era of the six-day work-week, Sunday was the only opportunity working people had to enjoy rest and leisure. That meant, too, that drinking was most likely to be heaviest on Sundays. But this was a red rag to the Temperance Movement bull — doubly bad because it combined sin with the Sabbath. Sunday closing rules were subsequently introduced in the early 20th century, and survived in most parts of Canada until the 1970s and 1980s. When it’s quiet – Music and performances of all kinds used to go nicely with a drink in the 19th century. Joe Beef’s Tavern in Montreal — like many others in the Victorian era — brought together music, dancing bears, gambling, boisterous debate, and drink; low-brow entertainments became so closely associated with public drinking that reformers targeted both simultaneously. Peter DeLottinville, \"Joe Beef of Montreal: Working-Class Culture and Tavern, 1869-1889,\" Labour/Le Travailleur , 8/9 (Autumn/Spring 1981/82): 9-40. As Craig Heron puts it, “In English Canada, both before and after prohibition, the isolation of public drinking from music and other forms of entertainment undoubtedly stifled the growth of popular music and popular theatre in Canada, compared to what was seen in Britain and Ireland. Montreal’s nightclubs were a special case, where drink and music were allowed to co-exist and, coincidentally, where Canada’s most vigorous jazz scene developed. Canada’s booze legislation, then, contributed to the country’s international reputation as a coldly austere, culturally repressed country whose public cultural life matched its often forbidding climate.” Heron, Booze , 378-9. What to Do: Abstinence – The anti-drink advocates began their crusade with a call to abstain from drinking. It threw the responsibility onto the individual and, in the rhetoric of reform-minded Christianity, there were moral and eternal consequences for not abstaining. The parallel moment in the anti-drug movement of the last 30 years would be the “This is your brain on drugs” campaign, launched in 1987. Temperance – If you can’t completely give up the booze then at least drink in moderation. This approach was adopted by many drinkers but by the 1870s, by fewer and fewer within the temperance movement itself. By that time, the movement had become more intolerant of drink and organizations like the WCTU called for all-out prohibition. Mid- to late-19th century temperance agitators moved the discourse around drink from a personal and individual level to a social level, and from moral consequences to social consequences; they argued that the impact of liquor extended far beyond the drinker. Prohibition – Taking the social agenda a step further, the prohibition movement called for state intervention and the total eradication of liquor. Implicitly, this meant that the question of individual choice was resolved in favour of state and police authority. Prohibition meant that individual effort was insufficient and that moral consequences weren’t driving change fast enough: legal and financial consequences had to be brought to bear, and these could (and did) include jail time. Teetotalism – Often misunderstood as “tea”-totalism, the teetotal movement was an expression of the abstinence movement in that it promoted personal resolve and self-restraint on the liquor issue rather than legal sanctions. Seek the help of a professional – Fortunes were made during prohibition by the producers and vendors of so-called “medicinal” alcohol. Products containing small quantities of alcohol were marketed as bitters, cocktails, and energy drinks. Jason Vanderhill, \"The Daniel Joseph Kennedy Story,\" Vancouver Confidential , ed. John Belshaw (Vancouver: Anvil, 2014): 39-58 A cooperative physician or pharmacist might be able to supply what you need. Key Points Alcohol consumption in Canada increased and became more obvious with late 19th century urbanization. The temperance movement gained extra force in Canada because of the parallel rise of the evangelical denominations, the support of working class organizations, the role of maternal feminists, and fears associated with immigrants from non-traditional sources. Temperance was initially implemented on a municipality-by-municipality basis. Provincial referenda followed in the Great War, at which time both Canada and Newfoundland mostly went dry. The end of Prohibition in Canada and its continuance in the United States created opportunities for rum-runners on every shoreline. Figure 7.E1 The Great Deceiver by Dominion Scientific Temperance Committee, Provincial Archives of Alberta, PR1974.0001.0400a.0011 is in the public domain . Figure 7.E2 Smokers and Sport by Dominion Scientific Temperance Committee, Provincial Archives of Alberta, PR1974.0001.0400a.0011 is in the public domain . Figure 7.12 One half mile of barmen along Yonge Street during the Prohibition parade (Online MIKAN no.3193202) by John Boyd / Library and Archives Canada / PA-072524 is in the public domain . Figure 7.13 CVA 480-215 – View of liquor stills captured during Prohibition by Vancouver Police Department / City of Vancouver Archives is in the public domain . Figure 7.14 StateLibQld 1 147135 Malahat (ship) by John Oxley Library is in the public domain . Figure 7.15 Raid at elk lake by C.H.J Snider fonds is in the public domain . 79 7.8 Eugenics Figure 7.16 Sir Francis Galton (1822-1911) was a largely self-trained British social scientist, a half-cousin of Charles Darwin, and the figure most readily associated with Eugenics. It is Galton who is credited with coining the dichotomy: nurture vs. nature. One of the earliest and longest lasting of the reform movements was associated with the ideals of eugenics . Formulated in its modern context in 1883 by the English intellectual, Sir Francis Galton, eugenics took its lead from evolutionary and genetic theory, and was at the heart of what came to be known as scientific racism. Gene Theory The core idea of the eugenic theory is that genetic inheritance is a factor in the success or failure of a society. Along with Galton, the proponents of eugenics “believed that criminality, alcoholism, and feeble-mindedness were…inherited.” Angus McLaren, Our Own Master Race: Eugenics in Canada, 1885-1945 (Toronto: McClelland &amp; Stewart, 1990), 16. Individuals who are mentally or physically (and, sometimes, morally) challenged are doomed, the eugenicists argue, to pass along those traits to their heirs (which, it is now widely understood, was never the case). A person with a severe mental challenge like Down syndrome, for example, was reckoned incapable of conceiving a child without Down syndrome. Poverty and laziness (often paired as personal qualities) were sometimes viewed as heritable as well. According to eugenic theory, poverty (a condition of life that can be instantly changed with money) was not caused by changes in the economy or social circumstances: it was the consequence of bad genes. Moral weakness was also aligned with “feeble-mindedness.” This was especially true as regards eugenicists’ views of sexually active women (who were responsible, it was argued, for a rising tide of illegitimate births) and sex trade workers. The eugenicist strategy has been described as “selective breeding,” but that term does not do it justice. R. Douglas Francis, Richard Jones, and Donald Smith, Destinies: Canadian History Since Confederation , 6th edition (Toronto: Thomson Nelson, 2008), 173. “Selective breeding” invariably involves selecting in : that is, encouraging fit people (however defined) to have a significant number of children. But the eugenics message in Canada was more about selecting out : to find ways to deter the reproduction of what they regarded as fated populations who were doomed by their genes to imperil themselves, successive generations, and the nation as a whole. In this campaign, they were not alone. Part of the late 19th century context of eugenics in English-Canada was the falling fertility rate, particularly when measured against that of French-Canada and immigrant communities (see Section 1.2 ). Eugenicists internationally claimed that healthy societies were at risk from this fertility transition . Most of these cultures were hostile to the idea of birth control because it would limit the reproduction of their own people, but the idea of sterilizing the least healthy and least valued citizens had considerable appeal. Nazi Germany, of course, ran headlong down this path and became notorious for the forced sterilization of roughly 360,000 individuals who failed to meet one test or another of “normalcy.” The fascists did not have a monopoly on eugenics: it is reckoned that, in the United States from 1910 to the 1970s, no fewer than 60,000 “feebleminded” citizens were forcibly sterilized. Canada sterilized proportionately fewer — the total number is believed to be slightly in excess of 3,000 – but record keeping was inconsistent and there is little doubt that a true total is unknowable. Randall Hansen and Desmond King, Sterilized by the State: Eugenics, Race, and the Population Scare in Twentieth-Century North America (Cambridge: Cambridge University Press, 2013), 3. What is distinctive about this particular branch of social reform in Canada is that its advocates sought to change the human raw materials rather than the laws or conditions under which those humans lived. To quote the authority on this subject, historian Angus McLaren, “The eugenicists differed from most of their contemporaries not so much in envisaging a radically different future, but in supporting the intrusive social policies they felt were needed to bring it into being.” McLaren, Our Own Master Race, 165. While other social reformers were encouraging redemption through personal choice and institutional supports, the eugenicists were advocating change at the sharp end of a scalpel. A Nation of Thoroughbreds Eugenics in Canada had two principal roots. These were the deteriorating health of urban working people and a visible increase in the numbers (though not necessarily the incidence) of mental health cases. There was no shortage of evidence that urban work made people less well and the eugenicists feared that those weaknesses would be transmitted to successive generations. As for the mentally ill, their institutionalization and observation got underway in the mid-19th century with the construction of redoubtable asylums in the major cities. It was not until the early 20th century, however, that eugenic thinking produced eugenic action. This took place at the provincial level because of the allocation of powers under the BNA Act , but it was only Alberta and British Columbia that moved forward with forced sterilization policies and campaigns. Figure 7.17 The Provincial Training School for Mental Defectives, Red Deer, AB, n.d. Originally the Albertan legislation of 1928 did not permit involuntary sterilization but it was nevertheless coercive. Patients were more likely to be discharged from an asylum or hospital if they elected to be sterilized; there was an incentive, then, to go under the knife. This was evidently insufficient as far as Edmonton was concerned, and under the Social Credit government of William Aberhart, the Board of Eugenics was given the power in 1938 to make sterilization compulsory. The Board’s record of recommendations is astonishing: only 1% of cases considered were not recommended for immediate sterilization, and that tiny fraction was, in actuality, postponements. As one study of the Alberta Board of Eugenics states succinctly, “not once did it vote “no”.” Hansen and King, Sterilized by the State , 97. Scholars working in this field think that British Columbia’s experiment with eugenic policies was less dramatic in its numbers. The problem is that record keeping on this score was remarkably incomplete, and what records were kept were subsequently destroyed or lost. We do know, however, that sterilizations were performed on inmates in mental health and prison facilities beginning in 1933; perhaps a few hundred were affected. The eugenics movement in Western Canada and the application of sterilization is discussed by historian of institutionalization, Megan Davies (York University). An interactive or media element has been excluded from this version of the text. You can view it online here: Fear of the Other What these initiatives and the appeal of eugenics generally had in common was a fear of immigrants. One study points to the “convergence” of the study and management of public health, reform of educational systems, and concerns for immigrant selection in the 19-teens as a flashpoint in the development of eugenic sentiment. According to one historian of immigration, this was made … evident in a 1920 editorial of the Canadian Journal of Mental Hygiene, which observed that the feeble-minded, insane, and psychopathic found in the province of Manitoba came out of all reasonable proportions from the immigrant class, and it was found that these individuals were playing a major role in such conditions as crime, juvenile delinquency, prostitution, pauperism, certain phases of industrial unrest, and primary school inefficiency. Donald H. Avery, Reluctant Host: Canada’s Response to Immigrant Workers, 1896-1994 (Toronto: McClelland &amp; Stewart, 1995), 84-5. If the project of nation building had as its goal a law-abiding, physically and mentally healthy population, these weren’t just indicators of individual deviance: they were milestones of social decay and a call to action. In British Columbia, where Asian immigration was part of the landscape in a way that it wasn’t east of the Rockies, the eugenics movement took on a particularly racist tone. J.S. Woodsworth — an influential figure in the Social Gospel movement — described the Chinese as a “nonassimilable element” and advocated exclusion while one asylum director in the Vancouver area, Charles Doherty, conspired to illegally deport “feeble-minded” Chinese to Shanghai. His actions were consistent with the white majority’s fear that the Chinese constituted “a virulent racial plague that had invaded the unsuspecting western colonies and threatened to decimate the good works and dilute the blood of its British forebears.” Robert Menzies, “Race, Reason, and Regulation: British Columbia’s Mass Exile of Chinese ’Lunatics’ aboard the Empress of Russia, 9 February 1935,” in Regulating Lives: Historical Essays on the State, Society, the Individual, and the Law ,  John McLaren, Robert Menzies, and Dorothy E. Chunn, eds.(Vancouver: University of British Columbia Press, 2002): 199-203. With fewer rights to be stripped away than just about any other group, the Chinese-Canadians who found themselves in BC’s psychiatric and mental health facilities were exiled rather than sterilized. There was a kind of inexorable logic to it all. If the first principle of racism was correct and there was, in fact, a hierarchy of races in which northwestern Europeans stood at the top, and if genetics was a predictable business, then the intermingling of races might strengthen weaker peoples but it could only harm stronger nations. And if strong nations had their share of “feebleminded” individuals, then weak races would have far more. It was also widely believed that the poor, the racially inferior, and the mentally inferior had higher fertility rates than Anglo-Canadians. By encouraging the immigration of lower-tiered races, Canada had thus invited into its midst people whose mental, moral, and physical fabric posed a risk to the whole of this striving, ambitious Canadian project. Doing so was described by the eugenicists as race suicide . A couple of things are striking about this reform movement. First, it was championed principally by nominally progressive elements. In Alberta, the United Farmers (UFA) party brought in sterilization legislation and it was, in particular, the United Farm Women of Alberta who led the way in 1924, achieving legislation in 1928. J.S. Woodsworth espoused eugenicist ideas in his anti-immigrant book Strangers At Our Gates (1909). Tommy Douglas, the CCF leader and Premier of Saskatchewan, wrote his 1933 Master’s thesis on “The problem of the subnormal family” and advocated sterilization of the mentally subnormal. As the Social Gospel moved further from theological to sociological grounds and as that sociology became more allegedly scientific, the responses to mental health became less redemptive and more clinical. We also find maternal feminists in the frontlines of the eugenics movement. Having elevated motherhood to “woman’s highest calling,” the quality of motherhood would inevitably come into question, especially if the fertility of the “defective” population was left unchecked. Angus McLaren and Arlene Tigar McLaren, The Bedroom and the State: The Changing Practices and Politics of Contraception and Abortion in Canada, 1880-1997 , 2nd edition (Toronto: Oxford University Press, 1997), 68. Both Mary Ellen Smith (ca.1861-1933) and Emily Murphy (1868-1933) were outspoken advocates of sterilization in BC and Alberta. Smith — the first woman elected to the BC legislature in 1918 (with the slogan, “Women and children first!”) and the first woman in the British Empire to hold a Cabinet seat in government — brought the issue to the provincial Assembly in 1925. Murphy — one of the “Famous Five” who were key to the 1929 “Persons Case” — was brutally frank in her opinions on the subject. In 1932, she wrote that if the state could protect the public “against diseased and distempered cattle,” then it should also “protect [the public] against the offal of humanity.” She called on the government of BC to do whatever it could to produce “human thoroughbreds.” Hansen and King, Sterilized by the State , 99. Murphy’s position on Chinese immigration was made clear in her attacks on the “yellow peril” in the pages of The Black Candle (1922) under the pseudonym of “Janey Canuck”: she took the view that inferior peoples begat more inferior peoples and they were all inclined toward criminality. Figure 7.18 The Asylum for Idiots and Feeble-Minded at Orillia, ON, ca.1910. There were parallel movements in central and eastern Canada, though they failed to achieve legislation in support of sterilization. The Eugenics Society of Canada was established in 1925 but really only began meeting in earnest in the 1930s. More influential was the work of individuals in newly created professional fields. Dr. Helen MacMurchy held the position of Inspector of the Feeble-Minded for Ontario, from 1906 to 1919, and was another advocate of both institutionalization of the mentally “sub-normal” and sterilization. McLaren, Our Own Master Race , 30-6. Like many conservative first-wave feminists she was opposed to birth control. She felt the use of birth control by the dominant Anglo-Celtic society would only cause the fertility rates of what she regarded as the better sort of Canadians to fall against the unbridled fertility of inferior peoples (whose fecundity she sought to control through sterilization). Erin L. Moss, Henderikus J. Stam, and Diane Kattevilder, “From Suffrage to Sterilization: Eugenics and the Women’s Movement in 20th Century Alberta,” Canadian Psychology , vol. 54, no.2 (2013): 105-107. Immigrants and members of ethnic minorities were heavily targeted by the eugenicists, as were Aboriginal peoples. “Half-breed” — a term that carried with it a certain amount of pride and distinction in the previous century — was used by the eugenicists in the 20th century in rhetoric designed to show the debilitating effects of intermarriage between races. With that in mind, it is not surprising to find that Aboriginal and Métis individuals were vastly over-represented in the Albertan sterilization cases. Children, who enjoyed fewer legal protections than adults in institutional settings, were also over-represented. So, too, were women. Overwhelmingly, eugenics in practice was about sterilizing girls and women whose sexuality, morality, poverty, ethnicity, and intelligence combined to constitute a perceived threat to the health and safety of the larger community. Figure 7.19 The Provincial Lunatic Asylum in New Westminster, shortly after it was opened in 1878. It would subsequently become known as the Provincial Hospital for the Insane and, from 1950, as Woodlands School. Hard Language In the 21st century, we are accustomed to using vocabulary that is sensitive and respectful as regards physical and mental illnesses and challenges. The language used in the 19th century and through most of the 20th, however, was far more direct and judgmental. It is difficult to convey the level of conviction held by eugenicists if we use 21st century language. They didn’t consider mental illness a “disability”; instead, they made use of a rhetoric of “retardation,” “insanity,” “immorality,” and “idiocy.” Individuals with physical challenges were regarded as “handicapped” at best, but “crippled” most of the time. People, moreover, became their affliction: individuals with what is sometimes called “sub-normal intelligence” were both “retarded” and “retards,” perhaps “morons” or “imbeciles.” John Langdon Down (1828-1896), for whom “Down dyndrome” is named, came up with the term “mongoloids” — a disturbing reference to the physical appearance of his patients that, moreover, suggests a racist outlook as well. Individuals with physical disabilities were, of course, “cripples.” Women working in the sex trade were simply and inescapably “prostitutes.” These terms enabled 19th and 20th century reformers to objectify the individuals to whom they were referring. Understanding that (for us, discomfiting) relationship between language and reform is critical if we are to understand the attraction and authority of movements like eugenics. A mental disability wasn’t a challenge to be overcome: it was a permanent state that defined the individual in question and from which there was little likelihood of escape. Whatever happened to Eugenics? The eugenics movement survived in the post-war era to the 1970s. Involuntary sterilizations in Alberta and British Columbia actually increased between 1945 and the late 1960s. Across the country, however, the tide started to turn much earlier. A visit to Nazi Germany in 1936 was enough to flush eugenicism out of Tommy Douglas’ portfolio of social reforms. Physicians, theologians, and scientists in Quebec — those who did not share in the Anglo-Canadian terror of being over-run by Catholics and foreigners — focused their fire on the faulty science in hereditarian theory. By 1945 they had made much headway in discrediting the movement. It is worth noting that the Catholic Church came out as a consistent critic of eugenicist views, and it was particularly hostile to involuntary sterilization. This opposition derived from several concerns. One that especially mattered in Canada was the xenophobic and Protestant tone of eugenics: both the French and Irish Canadians were tarred with this hostile brush. In the years after 1945 increasing public awareness of the role played by eugenics in Hitler’s program of “racial purification” and genocide tempered Canadian attitudes. Nonetheless, BC and Alberta held on to their policies and practices for another generation. Facilities like the BC Provincial Hospital for the Mind (aka: Essondale, Riverview), Woodlands in New Westminster, and Red Deer’s Provincial Training School for Mental Defectives (after 1977 known as the Michener Centre), saw the majority of the provinces’ sterilizations in the 1950s. The westernmost provinces had something else in common: Social Credit governments, both of which fell in 1972. The Alberta sterilization laws were repealed almost immediately after the new Conservative administration led by Peter Lougheed came to office; the BC legislation was repealed without fanfare in 1973 under the New Democratic Party government of Dave Barrett (b. 1930). In both cases, the context of change was the rise of a stronger culture of individual and human rights. In the mid-1990s, the Alberta government began the process of apologizing and offering compensation to victims of involuntary sterilization. The British Columbia government did the same, but only when ordered to do so by the Supreme Court in 2006. This is not to say that the eugenicist perspective disappeared entirely. Even in the absence of sterilization legislation, it was revealed in 1978 that Ontarian physicians were performing parent-approved sterilization on children with developmental disabilities. McLaren, Our Own Master Race , 169. But the social panics about high rates of unemployment, the rise of an urban criminal class, a tidal wave of illegitimate births, and the “degenerate” qualities of the immigrant population — all of which contributed to the original calls for eugenicism described above — had passed. By the 1960s, modernity was entering into middle-age, and the social transformations that were being wrought by urbanization and industrial labour were no longer news. This normalizing of modernity affected movement cultures as a whole and gave way to newer, different tensions. Differently Abled Figure 7.20 Mary Macdonald, photographed in 1893 by William James Topley. The word “eugenics” means “well born.” Mary Macdonald (1869-1933), hydrocephalic and confined to a wheelchair, would have been fourteen years old when Sir Francis Galton coined the term. She was not well born. Her mother, Agnes Bernard, experienced “an excruciating labour,” and the infant Mary immediately displayed signs of the enlarged head that would guarantee, in the late 19th century, a lifetime of impairments. Her parents were at first devastated although, as the years passed, they would demonstrate a commitment to Mary’s welfare. Mary’s father was notoriously terrible with his finances and he struggled with alcohol, but somehow he and Agnes found the resources to hire a pair of caregivers and to pursue what proved to be fruitless medical treatments. They constructed a wheelchair-accessible gallery in their home that enabled Mary to meet her father’s visitors. Not all Victorians, it seems, were fearfully ashamed of their child’s mental and physical disabilities. Not Agnes and Sir John A. Macdonald at any rate. Ged Martin, John A. Macdonald: Canada’s First Prime Minister (Toronto: Dundurn, 2013), 116-17, 180. Key Points Eugenics was based on a scientific theory that posited the inheritability of intelligence and defects in intelligence, as well as morality, work ethic, and poverty. Eugenicists sought to reduce the impact of “inferior” peoples by means of institutionalization and sterilization, while fighting against campaigns for accessible birth control. No fewer than 3,000 Canadians were sterilized, principally in Alberta and British Columbia. Mostly, the subjects of sterilization were women, children, immigrants, Aboriginal people, and Métis. Support for the eugenicist cause came from within the Social Gospel movement and early feminist organizations. Official sterilization campaigns ended in the 1970s. Figure 7.16 Sir Francis Galton is in the public domain . Figure 7.17 The Provincial Training School in Red Deer, Alberta by Alberta Public Archives is in the public domain . Figure 7.18 The Asylum, Orillia by McCord Museum is used under a CC-BY-NC-ND 2.5 license. Figure 7.19 New Westminster Asylum 1878 by British Columbia Archives is in the public domain . Figure 7.20 Mary Macdonald by William James Topley / Library and Archives Canada is in the public domain . This image is available from Library and Archives Canada under the reference number FA-001 . 80 7.9 Reform Politics: 3rd Parties The American political system has been demonstrably inhospitable toward third parties for nearly two and a half centuries. The British parliamentary system, however, allows for third parties and more. Admittedly, the first-past-the-post arrangement eats into the likelihood of small party success. (While a party might secure 25% nationally, they might not win enough votes in any one constituency to elect even a single MP.) But the possibility of a breakthrough exists and this has encouraged the rise of several parties with limited prospects. Some of these parties have punched well above their weight in terms of their political importance and/or influence on the political forefront. Although some third parties never even achieve federal Official Opposition status, a few have exercised power and influence in minority governments. Some have held office provincially, and thus won a high profile there, even if nowhere else. All are expressions of Canadian political culture and values; none are unworthy of study. Since the early 19th century, political organizations that offer a critique of the constitution, the establishment, or government practices have seized the “reform” banner. Some made use of the name while others described their mission as one that had a reforming agenda. This distinguishes them from the mainstream parties (since 1867, the Liberals and the Conservatives) in that they sought more than a crack at power. Beginning in the late 19th century, social reform and financial reform movements generated political expressions. Perhaps because they had the sensibilities of a movement, some of these political parties were able to survive years of disappointment. First and Second Parties In order for the Grits and the Tories to become the Liberals and the Conservatives, respectively, they had to create the political machinery necessary to succeed at the polls across the country. This was no small task. In 1867, the Grits were heavily concentrated in southern Ontario and the Tories were part of an urban and landed elite in both Ontario and Quebec: neither showed much natural ability at expanding their reach. Within 30 years, however, the Liberals and the Conservatives held a duopoly on the federal and provincial stages alike. There were a few exceptions. In British Columbia, for example, party lines were not introduced until 1903. Otherwise, the 19th century closed with a political ecology in Canada that was all but identical to that of Britain, consisting almost exclusively of Liberals and Conservatives. What happened in the 20th century was, in some respects, a return to the politically fractious pre-Confederation days of Grits, Rouges, Tories, Patriotes, Reformers, and Bleus . And while Canada did not follow Britain’s (and Australia’s) lead in forming a Labour Party, neither did it conform to the rather limited vision of political options available to Britons, Antipodeans, and Americans. Canada experimented. Having said that, the multi-party system that emerged by the 1920s did not produce a rash of minority governments comparable to what happened in 20th century France and Italy. At the provincial level, the Maritimes would remain loyal to the binary options of Liberals and Conservatives in federal and provincial politics; the same could not be said of the rest of Canada, not even Ontario. Factionalists Within the established parties there have always been small break-away movements. Most instances see a disaffected elected representative or two leave their party caucus and sit as “Independents.” Sometimes Independent candidates will successfully seek election, although to do so they have to overcome the party machinery on which their opponents might call. More commonly in the 19th century, a hyphenated allegiance would be used in order to make the best of two partisan brands. Macdonald tried this himself when he promoted his party as the “Liberal-Conservatives” in the earliest days of Confederation. By 1873, the label had been dehyphenated and the “Liberal” part appropriated by the Grit-Rouge alliance. At about the same time, a “Conservative-Labour” candidate was elected to Parliament from Hamilton — the first working-class MP. Seeking to distance themselves from imperialists within their party, from 1878-1911, several Quebec Conservatives ran as “Nationalist-Conservatives.” By way of contrast, the hard-line, anti-Catholic, anti-French politician Dalton McCarthy (1836-98) eschewed any part of the established parties’ brand when he broke with the Conservatives and established his own slate of candidates in the 1896 election. They were known (modestly) as “McCarthyites.” Only McCarthy himself was ever elected and he died two years later in a traffic accident. The 20th century saw still more schisms in the main parties, but most remarkable was the ability of the Conservatives and Liberals to reel in their factional elements. The United Farmers It is perhaps ironic that farmers’ parties arrived on the scene when they did. After all, the 1921 census showed that Canada had crossed a threshold and was now more urban than rural. The first third party movement to win a majority of seats in any jurisdiction was the United Farmers of Ontario (UFO) in 1919. Despite its urban centres, Ontario south of the Canadian Shield was still heavily rural. Every constituency had enough farmers’ (and farmers’ allies’) votes to leave the old parties behind. Although the UFO administration was brief — it lasted only one term, from 1919 to 1923 — it was a breakthrough in that it showed the possibility of sectoral appeals across a whole province. The 1919 campaign involved a tactical alliance with the moderate Independent Labour Party of Ontario: the ILP didn’t run candidates in rural areas and the UFO stayed out of urban constituencies. The result was a coalition partnership that accomplished quite a lot in terms of early welfare legislation, prohibition, and the establishment of co-operatives, but failed to deliver one of its more innovative reforms: proportional representation . The UFO election was followed quickly by similar triumphs in the West. The United Farmers of Alberta (UFA) were elected to govern in 1921 and the United Farmers of Manitoba (UFM) won a significant number of seats in 1920. Ottawa’s wartime refusal to lift tariffs was an important source of UF popularity. Indeed, a common thread in the rise of the United Farmers was their anti-Ottawa posture. Criticism of the tariff component of the National Policy had failed to shift the Conservatives. The Liberals, for their part, blew hot and cold on free trade with the United States, despite farmers’ demands for reciprocity. What’s more, a succession of Liberal and Conservative provincial governments had failed to win concessions from federal governments. Local voters felt there was nothing to lose in voting United Farmer. The Progressives In 1919, the federal Union Government’s Minister of Agriculture, Thomas Crerar (1876-1975), split with the Borden administration over its apparent disregard for farmers’ issues. The United Farmers ran candidates successfully in a handful of federal by-elections in 1919 and 1920, which led Crerar to form a national pro-agriculturalist party. The result was the Progressive Party, which ran its first campaign in 1921, stealing 58 seats nationally and forming the second largest caucus in Ottawa. By rights, this should have made Crerar the head of the Official Opposition. The Progressives, however, were heavily influenced by populist and agrarian movements, particularly in the United States. They didn’t like caucus accountability and discipline and they preferred to vote their (individual) conscience. The Progressives turned down the opportunity to enter into a coalition with the Liberals under King and they passed the title of Official Opposition off to the third-place Conservatives under Arthur Meighen (see Section 6.7 ). While these decisions and tactics arose from the anti-party philosophy of the Progressives, they doomed the organization to insignificance in the House of Commons. It has been suggested by some analysts that the Progressives’ atomistic approach means that they weren’t a party at all, just an expression of the United Farmers movement. This may be true, but it is all too easy to understate their appeal in the Canadian heartland: half of their MPs came from Ontario, where the Progressives won a quarter of the province’s federal seats. (They were unable to make much headway in the Maritimes.) By 1926, the independently minded Progressives had unraveled. Crerar resigned and the House Leader was now Robert Forke (1860-1934), a veteran of the Liberal Party from Manitoba. When the Conservatives briefly formed a government in 1926, Forke took the Manitoban Progressives into the Liberal Party where they were quickly subsumed into the older organization. Ontarian support dissolved and the more hard-line Albertan members washed their hands of the Progressive label and sat as “UFA” representatives in Parliament. Although “Progressives” were still winning seats in the 1930 election, their numbers were down to single digits. Some of the Albertans were part of a more radical labour-farmer alliance with a strong social gospel pedigree. This group would go on to found the core parliamentary element of the CCF (see below). What remained of the Progressive Party disintegrated during the 1930s and Crerar was welcomed formally into the Liberal fold. He was rewarded with a cabinet post and a seat in the Senate. The “Progressive” name, however, was appropriated by the Conservative Party, thus the “Progressive Conservatives” from 1942 to 2003. The Reconstruction Party H.H. Stevens, a high ranking cabinet minister in the Tory governments of Meighen and Bennett, bailed on the latter on the eve of the 1935 election and formed the Reconstruction Party. Isolationist and inclined towards appeasement of the fascist powers in Europe, the Reconstruction Party finished third in the election with nearly 10% of the popular vote but won only one seat: Stevens’ own in the Kootenays. The party folded and Stevens rejoined the Conservatives, despite the fact that Reconstruction’s campaign split the vote in dozens of constituencies and ended up costing the Tories dearly. The Left Among the first political movements to achieve some measure of success were the Socialists. The Canadian Left took many forms, however, and there were more splinters and fragments on this side of the ideological spectrum than on the Right . The Socialist Party The Socialist Party of British Columbia (SPBC) was the first of several like-minded organizations to elect a candidate to a provincial legislature. They elected two in 1903: Parker Williams and James Hawthornthwaite. Late in 1904, the SPBC fused with socialist parties from across the Prairies and Ontario to create the Socialist Party of Canada (SPC). The whole array was, from the 1890s through the 1920s, deeply divided over the issue of reform versus revolution. An important and influential faction — dubbed impossibilists — argued against any gradualist or reformist approach to capitalism, maintaining that ameliorating the worst effects of the existing system would only enable it to last longer. This made the business of holding elected office exceedingly difficult for representatives of the SPBC and SPC: if they were able to secure better conditions for workers, they would lose the support of the impossibilist faction — if they didn’t, they would likely lose the support of the electorate. Even as the SPC’s membership and support level was growing during the first decade of the century — by 1910 it was the third largest party in Canada — moderate elements were leaving to form more reform-oriented social democratic parties. The SPC continued to enjoy success in British Columbia until the Great War. In the 1912 provincial election, the SPC won 11% of the vote, a high water mark for third parties in the furthest West before the end of the war. Nationally, however, the party entered into a difficult phase. Its anti-war stance , which grew out of an internationalist view of the working-class , brought it under the lens of national security monitors. Its members were harassed, its mail was tampered with and seized, and its newspaper ( The Western Clarion ) closed down. The revolution in Russia in 1917 led to the formation of a Canadian communist movement that was increasingly critical of the SPC. Attacked from the right and the left, the SPC staggered into the 1920s and collapsed in 1925, most of its members having left to join the communists. Communist Parties The Russian Revolution of 1917 inspired some Leftists to pursue a new organizational approach. The War Measures Act was still in effect in 1921 when the founding meetings took place and the ban on any “communist party” obliged the use of a different banner: the Workers’ Party of Canada. The ban was lifted in 1926 and the Communist Party of Canada (CPC) appeared. The Party struggled with the principal issue that divided communist parties internationally: whether to pursue a worldwide revolution or to support the goal of a successful revolution in Russia. Factions supporting international revolution (Trotskyites) were expelled from the party by the dominant Stalinist elements representing the will of the Communist International (aka the Third International, the Comintern ). When the 1930s began and the western world entered into a deep and (as it turned out) protracted crisis in capitalism, support for the CPC and similar movements grew. This resulted in an escalation of state surveillance and harassment. The 1931 arrest and imprisonment of Tim Buck (1891-1973), the leader of the CPC from 1929 to 1962, drove much of the CPC machinery underground. When Buck was released in 1934, he was met by a 17,000-person rally at Toronto’s Maple Leaf Gardens, a further sign that support for the CPC was growing while the economy was sinking. CPC efforts to organize the single transient unemployed were particularly effective and resulted in the establishment of the Relief Camp Workers’ Union and the Workers’ Unity League. The CPC was also able to forge anti-fascist partnerships with more moderate left-wing movements and it played a leading role in founding the 1500-member Mackenzie-Papineau Battalion that was sent to Spain to fight the fascists in the Civil War in 1837-38. Not that this initiative improved their relationship with an increasingly anti-fascist government in Ottawa: when war against Germany and Italy erupted in 1939, the “Mac-Pap” veterans were categorized by the federal government as “premature antifascists” and potential subversives. Figure 7.21 Tim Buck (left, seated) returns to Maple Leaf Gardens in 1942. At the provincial level the Communists were hounded particularly hard by the government of Quebec. The so-called “Padlock Law” of 1937 (officially, in English, an Act to Protect the Province Against Communistic Propaganda ) was used to close down communist presses and to imprison anyone involved in production or distribution of printed materials for up to three years. It would be another 20 years before the law was struck down as unconstitutional. Figure 7.22 Annie Buller (1895-1973) was a dynamic activist in the CPC, leading a general strike of dressmakers in Toronto and allegedly inciting a riot at Estevan, SK, during a coal miners’ strike, both in 1931. She ran for office on at least three occasions and was jailed repeatedly, mainly for belonging to the CPC. The Party itself walked a difficult tightrope on international issues. Anti-fascist in 1938, they adhered to the Comintern’s anti-war strictures until 1941. The Molotov-Ribbentrop Pact of 1939 — a mutual non-aggression agreement between Nazi Germany and Soviet Russia — was meant to produce a war between capitalist nations. In that context the CPC was viewed by Ottawa as an organization intent on subverting the war effort of the western Allies, not least of which because the Soviet Union was busily annexing the Baltic nations and badgering Finland. When Germany invaded the Soviet Union in June 1941 and the USSR joined in the battle against the Axis Powers, the status of the CPC and its members improved dramatically. The party reached a zenith of popularity in 1945, when Joseph Stalin’s Soviet Union was Canada’s indispensable ally. In the general election of that year, the CPC’s Labor-Progressive Party (LPP) pulled in over 2% of the national vote and won one seat. The LPP ran candidates until 1959 and the CPC after that. It failed to win a single seat after 1945. Support for the Communists was progressively gutted from the mid-1950s onward. Soviet President Nikita Khruschev’s damning 1956 speech on Stalin-era purges and atrocities caused some members to leave the party, as did the Soviet suppression of the Hungarian Revolution that same year. Disclosures of anti-Semitism at the highest levels of the Soviet Union further alienated members of the CPC, many of whom were Jewish. The Soviet assault on Czechoslovakia’s 1968 rising was cause for further desertions in the decade that followed. There was a surge in electoral support for the CPC in 1974 when it secured 12,100 votes in the federal election. But by any standard, this was an abject failure as a partisan endeavour. Things worsened for the party at the polls as the Cold War ground to a close. The collapse of the Soviet Union flushed out divisions within the CPC and its assets became, in 1991, the subject of an acrimonious and very public separation battle. The party re-established itself thereafter as an organization dedicated to Marxist-Leninist ideals and it continues to operate in provincial, civic, and federal elections. Social Democrats The branch of the political tree that produced the Cooperative Commonwealth Federation (CCF) and the New Democratic Party (NDP) had roots in the social reform movements of the 19th and early 20th century: the United Farmers movements, the Progressives (discussed below), labour organizations like the Knights of Labor, trade unionism, the cooperative movement, and a wide range of socialist philosophies. Established as a national political party in 1932, the CCF ran in its first election in 1933 in British Columbia, where it became the Official Opposition. Thereafter, the party enjoyed success principally at the provincial level, particularly in three of the four western provinces, but it also played a key role in federal politics both in its original form and, later, as the NDP. The core elements of the moderate socialist movement came together in 1924 in Ottawa. The Progressive Party was nursing closer relations with the Liberal Party and were, some of its members believed, abandoning several key values. Five United Farmers MPs from Alberta and one from Ontario formed a faction within the Progressive Party — a party within a party — and they were joined soon after by five other Progressives, along with four Labour MPs, and four Independent Labour Party MPs. Together this was the Ginger Group , a coalition of like-minded men and one woman. What they brought together was a shared belief in the need for greater equality of opportunity and living standards across the social classes, elimination of the worst effects of competitive capitalism, and political reform that included an extension of greater rights to women. In the midst of an economic boom, their voices were largely drowned out. Eight years later, in the midst of the Great Depression, what they had to say appealed to a far greater number of Canadians. This wasn’t the first attempt to forge a common front on the left of the Canadian political spectrum but it had certain qualities that gave it the possibility of greater longevity. For starters, it was a group made up mostly of men who were in their mid- to late-forties; that is, they were all (but one) born in the late 1870s or early/mid-1880s and were thus mostly too old to have served in the Great War. They constituted a peer group that was neither too young to be dismissed as immature radical cranks, nor so old that they seemed out of touch with any particular demographic. Farming backgrounds were a common denominator, as was Methodism, Presbyterianism, and a commitment to the goals of the cooperative movement . They had some occupational range: their number included a lawyer and an upholsterer. The two outliers in the group were to have, arguably, the greatest impact on the Ginger – CCF project. J.S. Woodsworth (1874-1942) was the oldest and came into the Group with a reputation as a writer, a Methodist minister and teacher, a pacifist, a labour activist, and a leading light in the social gospel movement. He was also an architect of Canada’s first old age pension legislation in 1926 and so demonstrated how the state could play a direct role in alleviating hardship. This was a significant reversal from the old “Poor Law” mentality of the 19th century and opened the door to social welfare legislation across Canada. Woodsworth would become the de facto leader of the Ginger Group and officially, in 1932, of the CCF. The other peerless member of the Group was Agnes Macphail (1890-1954), the youngest of the founders by three years, the only woman, and the only representative of the United Farmers of Ontario. Macphail was a “firster,” first woman elected to Parliament, one of the first women elected to the Ontario legislature, the first woman to represent Canada at the League of Nations (the precursor to the United Nations), and the first president of the Ontario CCF. A Methodist in her youth, she was swept up in the evangelical movement in the early 20th century. Macphail worked as a school teacher before pursuing a career in politics, and the very act of being a female “career politician” constituted another first. She wasn’t directly involved in the Persons Case of 1929 but was almost a beneficiary; she was about to be offered a seat in the Senate when she died in 1954. Macphail’s significant contribution was both symbolic and practical. She demonstrated by her presence that the social democratic movement was a welcoming place for women in politics and, as a pioneer woman in Canadian politics, she set the bar high for accomplishments. By the 1930s the Ginger Group itself had fractured; some of its members had retired from politics or had been voted out of office. The economic crisis, however, pulled others into the conversation about a political mechanism for achieving social change. These included the League for Social Reconstruction (LSR), a socialist think-tank (before the words “think” and “tank” were ever combined) led by two outstanding Canadian intellectuals. Frank Underhill, a historian at the University of Toronto, and F.R. Scott, a Law professor at McGill University, very informally founded the LSR with an eye to building a national network of intellectuals who could shift the conversation about the causes of and solutions to the Depression along a constructive, socialist path. Both Underhill and Scott were convinced that capitalism was at the root of the Depression, not moral or social issues; that only systemic changes that delivered socialist policies could change things for the better. The LSR lasted barely a decade and was responsible for building support for the idea of social, economic, and political planning across the party spectrum. It was joined early on by two figures who would play important roles in Canadian politics: Eugene Forsey (1904-91), a young political economist from Newfoundland via Oxford University and elite circles in Toronto, and David Lewis (1909-81), a brilliant Rhodes Scholar and political animal, freshly returned from England. Lewis, like A. A. Heaps (1885-1954) — one of the original Gingers — was a Jew and a consistent and strident opponent of the Communist movement. In 1932, Underhill and Scott met with the Ginger Group in Ottawa and began the process of founding what they initially called the “Commonwealth Party.” A convention was held in 1932 and, influenced by the agrarian socialism of the UFA, “Cooperative” was added to the party’s name, and its many threads recognized in the word “Federation.” For a while the party banner also carried the words “Farmer-Labour-Socialist”. In 1933, at the second convention, the main tenets of the Cooperative Commonwealth Federation were codified into the Regina Manifesto ; these included an ambitious program of social welfare legislation, national ownership of key industries, and a program of universal healthcare. The Manifesto also called for an end to capitalism, a resolution that would be a red rag to anti-communists for the next two decades. Almost immediately the CCF scored important victories that dwarfed the achievements of any other socialist party in Canadian history. Official Opposition status came first in BC, then in Ontario, but it was in Saskatchewan where the party first formed a government, in 1944. The first socialist government in North America, it would serve as an example of social democratic programming for the rest of the country, piloting the universal healthcare program that was embraced by Ottawa in the 1960s. Outside of Saskatchewan and British Columbia (where it continued as the Opposition), the post-War years were grim for the CCF. The CCF found itself undermined by the Communists and targeted by an increasingly paranoid Cold War media. To be sure, there were CCFers who came to the party via more ideologically Marxist organizations and some espoused a radical position regarding property and capitalism. David Lewis spent years trying to minimize their impact on the party’s policies and profile. In 1956 he finally succeeded, replacing the Regina Manifesto with the much milder Winnipeg Declaration . He was aided in this campaign by another CCF veteran of the 1930s, M. J. Coldwell (1888-1974), who undertook a purge of the party’s red elements and repositioned the CCF as an opponent of the Soviet Union. By the late 1950s, however, campaigns against the Left had reached such a pitch that the CCF was all but irrelevant in most jurisdictions. At that point, the newly restructured national labour centre — the Canadian Labour Congress (CLC) — negotiated a partnership with the CCF. This produced, in the course of nearly seven years, the “New Party,” a CCF-CLC collaboration that changed its name in 1963 to the New Democratic Party (NDP). Tommy Douglas, the former CCF premier of Saskatchewan, took over the leadership and the social democratic party’s fortunes began to improve instantly. There was steady growth through the 1960s and in 1972, the NDP secured enough seats to hold the balance of power in Pierre Trudeau’s minority government. This was an opportunity to push through social democratic legislation in exchange for propping up the Liberals. The next election, in 1974, cost the NDP dearly; its share of the popular vote hardly changed but it lost half its seats in Parliament nevertheless and was reduced to the third party once more. There were, however, some victories at the provincial level. The first Manitoban NDP government was elected in 1969 under Edward “Ed” Schreyer (b.1935); Allan Blakeney (1925-2011) revived the Saskatchewan NDP in 1971, forming a government that would last until 1982; in BC in 1972, David Barrett ended 20 years of Social Credit government under W.A.C. Bennett but his NDP government would endure a mere three years; the Yukon NDP formed its first government in 1985 under Tony Penikett (b.1945) and held on to power until 1992. In Ontario, the provincial NDP would go from a position of strength in the 1970s to even greater strength in the 1980s. Beginning with David Lewis’ son Stephen (b.1937), then Bob Rae (b.1948), the NDP headed up the Official Opposition in the legislature (Lewis, 1975-77) and held the balance of power (Rae, 1985-87), until forming the government (Rae, 1990-95). NDP claims of being a national party remained more wishful thinking than empirically verifiable through the late 20th century. The party continued to be marginal in Alberta, Quebec, and the Maritimes. In the rest of the country, however, and especially under the leadership of Edward “Ed” Broadbent (b.1936) from 1975 to 1989, the NDP’s central role in federal politics became increasingly confirmed. By the end of the 1980s, it was clear that Liberal and NDP candidates were fighting over Left-centrist votes, a fact that split their possible combined support and thus contributed to two Conservative governments under Brian Mulroney. The last decade of the century would see the NDP’s fortunes slide. Audrey McLaughlin (b.1936), the first woman (and first Yukoner) to lead a national party, took the NDP through the economic turmoil of the early 1990s and some of their weakest results nationally (and worst years provincially) before handing the mantle on to Alexa McDonough (b.1944). McDonough, a Nova Scotian, kept the party afloat to the end of the century when, in 2000, it narrowly avoided losing official party status . The CCF-NDP drew on several progressive threads in Canadian society and culture, some of which became severely entangled. The agrarian radicalism of the Progressives and United Farmers, the militant unionism and revolutionism of the Socialist Party of BC, the Fabian democratic socialism of the LSR, and the powerful and persistent influence of the Social Gospel gave it both a broad foundation to build on and the raw materials for continuous infighting. With the addition of the CLC it became a kind of Labour Party, but it did so in a way that would guarantee tensions between the CLC elements and those more associated with CCF values. When, in 1969-71, a faction within the NDP emerged that embraced left-wing nationalism, feminism, social activism and called for an independent socialist Canada, many of the fracture lines within the Party were laid bare. The Waffle , as the splinter group was known, failed to take over the leadership of the national party but the question remained as to whether the NDP was the party of organized labour or the party of social justice and socialism. These debates continue within the party and are unlikely to end anytime soon. Social Credit and the Ralliement Créditistes In 1924, a British engineer and former soldier, Major C.H. Douglas (1879-1952), published a densely argued treatise on a flaw within capitalism. The costs of goods produced across a spectrum of industries, he pointed out, were invariably greater than the wages paid out to the people producing them. This meant that there was not enough money in circulation to purchase what was being manufactured. Consumers, he argued, were invariably at a disadvantage and the whole of the economy continually headed toward bottlenecks. To solve this conundrum, he proposed a system of credits that would be applied across society and a radically changed democratic system that, together, would empower the populace as consumers and political actors. Douglas was one of a great many economic theorists in the Interwar years — offering up ways to overhaul or replace conventional capitalism and address the shortcomings of liberal democracy. His ideas and analyses were complex and roundly criticized by economists. His suggestions, however, found purchase in two places in particular: New Zealand and Canada. The concept of social credit landed in Alberta in the late 1920s and might have disappeared if not for the conjunction of several elements. Politics in Alberta had taken on a strong evangelical tone thanks, in part, to the social gospel themes and rhetoric employed by the ruling United Farmers party. The idea of preachers in politics was widely accepted and a certain amount of trust and even deference was enjoyed by evangelical clergymen. Not surprisingly, the high-energy, “tub-thumping,” “fire-and-brimstone” preachers were among the most compelling. The most widely recognized voice of religion in the early 1930s in Alberta was that of “Bible Bill” Aberhart (1878-1943). A school principal and Baptist minister, Aberhart established the Calgary Prophetic Bible Institute and took to the airwaves with a weekly radio evangelical program. He was a pioneer in this respect, what today we would call an “early adopter” of communications technologies. Moreover, Aberhart’s own deep rolling voice was joined behind the microphone by a team of actors who played out moral parables on live radio. His audience was huge, and radio at this time — played in the home on a wireless set that was often the beautifully designed centerpiece of the parlour or front room — was listened to in a manner that involved a kind of quiet engagement by everyone in the household. Aberhart would invite his listeners to consider what they heard and to discuss it, as though they were holding a seminar or a bible-reading group in their own home. Why does this matter? A member of the Prophetic Bible Institute introduced Aberhart to social credit theory and the latter quickly saw it as a solution to the crisis of the Depression. He became so convinced of its potential that he promoted his understanding of Douglas’ theories from the pulpit and, more importantly, through his radio program. (One particularly effective episode involved a recurring character, the “Man from Mars,” who commented on the inexplicably strange things Earthlings do, offering Martian solutions to crime, immorality, and unemployment and the use of social credits.) David R. Elliott and Iris Miller, Bible Bill: A Biography of William Aberhart (Edmonton: Reidmore Books, 1987), 151. The failure of the United Farmers to take up the social credit idea launched Aberhart into politics. In 1935, the Social Credit Party — helped by scandal in the UFA — won a landslide victory. Success at the polls was not matched by fiscal victories: issuing social credits meant, in essence, producing a currency, something that was exclusively reserved to the federal government. The coupons or “scrip” were fiscally, operationally, and constitutionally problematic, so much so that the lieutenant-governor of Alberta refused to pass into law Aberhart’s experiment, which became derided as “funny money.” This didn’t stop Social Credit from holding onto power in Alberta for the next 36 years, nor did it stop its spread across Canada. Two studies addressing the theoretical elements of Douglas' social credit and the practicality of some of his aims in Alberta are Alvin Finkel, The Social Credit Phenomenon in Alberta (Toronto: University of Toronto Press, 1989) and Bob Hesketh, Major Douglas and Alberta Social Credit (Toronto: University of Toronto Press, 1997). Outside of Alberta, the ideas behind social credit produced three different partisan typologies. Douglas’ beliefs regarding democracy were complex and in some ways idiosyncratic while simultaneously typical of the imaginative hothouse that was the 1920s. He advocated government by experts (he was, after all, an engineer) and believed politicians should act as middlemen between the voters and the planners. Aberhart echoed this perspective, especially if he was cornered on a difficult aspect of economic theory. In a statement that acquired some fame, he said: You don’t have to know all about Social Credit before you vote for it. You don’t have to understand electricity to make use of it, for you know that experts have put the system in and all you have to do about Social Credit is to cast your ballot for it, and we’ll get experts to put the system in. Aberhart to John Hargrave, and Albertans, during a 1935 election campaign. Originally from the Edmonton Journal, (14 August 1935), and cited in Harry Hiller, Religion, Populism, and Social Credit in Alberta , p. 375, (PhD Thesis, November 1972), accessed 13 May 2016, . But Aberhart was a partisan and Douglas didn’t like parties. This thread of his thought took shape in Quebec in the 1940s with the Union des électeurs and briefly in Ontario by the similarly named Union of Electors. The second typology was the more conventional party format, like that in Alberta and the Social Credit Party of Canada (SCPC). The national party struggled from 1953 to 1958 when they were wiped out by the Diefenbaker landslide in the West. But the party had a base of support in Quebec as well and it rebounded in 1962, winning 29 seats, all but four of them in Quebec. This gave Social Credit the balance of power in Parliament, which they used a year later to oust the Diefenbaker minority. Shortly thereafter, the national party split and the larger part of the caucus formed the Ralliement des créditistes under the leadership of Réal Caouette (1917-76), the remainder keeping the SCPC brand. As a “third” party they typically finished fourth in Parliamentary seats, behind the NDP. In 1972, Caouette’s Ralliement won 15 seats but began an unbroken slide into the 1980s, after which it was frozen out. Never at risk of forming a national government (nor a provincial one in Ontario or Quebec), the eastern and national parties continued to support the economic theories of Douglas, and to espouse anti-Semitic and occasionally pro-fascist sentiments. Caouette was, too, a Quebec nationalist but also a rabid enemy of radical separatists like the Front de libération du Québec (FLQ). The third type of Social Credit Party was that of W.A.C. Bennett (1900-79), the charismatic premier of British Columbia from 1952 to 1972. Bennett, a former Conservative Member of the Legislative Assembly, split with his old party and was able to take the reins of a slow-moving Social Credit Party that was largely populated by former Albertans. Once he formed government he never spoke again of “funny money” and the party, for all intents and purposes, pursued the (right-of-centre) politics of populism and pragmatism. After he won a majority in 1953, Bennett disposed of BC’s peculiar preferential-ballot system and restored the conventional first-past-the-post model. Informed by small-town piety, devotion to private (especially small) enterprise, and a Cold War-era loathing for unions and the Left, the party took a breather during the Barrett/NDP administration of 1972-75 and then governed for another 16 years before falling apart in the 1991 general election. Figure 7.23 Alberta’s “Prosperity Certificates” circulated briefly under Social Credit. The bearer had to purchase a penny stamp for the reverse side at the end of each week, which meant that there was a frenzy to get rid of them every seven days. The conservative Christian values of Social Credit’s various incarnations has meant that its support has mostly migrated to parties on the Right. Preston Manning’s Reform Party attracted some based in part on the leader’s long connection with Social Credit (Manning’s father succeeded Aberhart as Premier from 1943-68) as did the electorally insignificant Christian Heritage Party. The pragmatism of the leadership — exemplified by W.A.C. Bennett and his son and successor, William “Bill” Bennett, also enabled its constituency to find a home in the BC Liberal Party. The Ralliement articulated a conservative nationalism consistent with Duplessis’ Union Nationale along with some aspects of both the Parti Québecois and the Bloc Québecois (see Section 9.9 and Section 9.10 ) . Key Points The Canadian parliamentary system enables the establishment of alternative political parties. Historically, some reform movements have taken the form of political parties. These have included agrarian parties like the United Farmers and the Progressive Party, socialist parties like the Cooperative Commonwealth Federation/New Democratic Party and the Communist Party of Canada, and the various parties associated with social credit. Figure 7.21 Tim Buck at Maple Leaf Gardens by GRuban is in the public domain . Figure 7.22 Annie Buller addressing a crowd before the Estevan Riot by Esemono is in the public domain . Figure 7.23 1936 Alberta Prosperity Certificate by Awmcphee is in the public domain . 81 7.10 The Second Wave of Feminism Robert Rutherdale, Department of Philosophy &amp; History, Algoma University In 1963 feminist author and activist, Betty Friedan, captured extraordinary attention with her book, The Feminine Mystique . She struck a chord for many readers and a nerve among her critics. She wrote about “the problem that has no name,” the unhappiness and dissatisfaction experienced by many women in their roles as homemaker, mother, and feminine wife. At its source, she argued, was patriarchy . Notions of privileged males resonated with the daily experience of many women in Canada, especially in the middle-class. Inspired by The Feminine Mystique, and by Simone de Beauvoir’s The Second Sex (1948, translated into English in 1953), as well as by Germaine Greer’s The Female Eunuch (1970) a growing number of women across the western world, including women in Canada, launched a significant activist movement in the late 1960s and early 1970s. The Women’s Liberation Movement aimed to empower women in both their private and public lives. This second wave feminist challenge staged public protests, producing iconic images that were easily consumed on television screens and often sensationalized. They challenged assumptions about conventional roles for women and the “normalcy” of patriarchy, leading in Canada’s centennial year to the establishment of the Royal Commission on the Status of Women, which produced its report in 1970 and established the National Action Committee on the Status of Women . Progressive changes in gender roles, with respect to enhancing women’s power, were attempted by establishing a portfolio on the status of women in the federal cabinet and in creating an Office of Equal Opportunities in the Public Service Commission. A new Citizenship Act was passed in 1975 and legislation to amend the Labour Code was adopted in 1978. That same year, the Canadian Human Rights Act came into effect, ensuring that “equal pay for equal work” be reflected in the workforce. These shifts in public policy and public opinion provided space for a discussion of the brutal side of patriarchy. Women’s Liberation in the 1960s — which was sometimes exuberant and even fun — was followed in the 1970s by a grim and growing recognition of gendered violence in the form of wife abuse. Friedan’s critique of a patriarchal society made possible the revelation of life stories of battered women. She offered a challenge, taken up by many readers in Canada beginning in the early 1960s, which had been largely absent in the popular discourse. Even now, out-of-sight struggles from this generation (and others) are gradually being revealed by oral histories and life writing. With renewed local community support throughout the 1970s, the rising number of women’s and family shelters provided a necessary, if distressing, measure of the problem of spousal abuse. At this point, two generations of Canadian women — mothers who remembered the 1930s and beyond, and their daughters — could step past the so-called generation gap between parents and the young, to confront long histories of becoming a woman, altogether. In the 1970s Women’s Studies courses and, later, programs were appearing for the first time on Canadian university campuses; daughters enrolled in these newly instituted disciplines started bringing home copies of the much reprinted Our Bodies, Ourselves (a key, and evolving, textbook, launched by a Boston-based feminist movement established in 1969) for mom to have look at. Old assumptions about property rights, income-earning potential for women (who often earned less than two-thirds pay for work of equal value at this time), taxation laws, and child-care responsibilities spoke to the larger picture of patriarchy’s persistence during and beyond the so-called “good life” of the 1950s. That the Dominion Bureau of Statistics (replaced by Statistics “Stats” Canada in 1972) routinely recorded fathers and husbands in the conjugal family as household “heads,” even in the early 1970s, is understandable: adult males earned much more as paid workers and their gendered role conformed to Western cultural practice and expectations. Despite these feminist challenges, most barriers to gender equality held fast beyond the 1960s. The second wave had momentum, but it crashed again and again against opposition from both men and women, opposition that was as much conditioned by past assumptions, as it was just plain reactionary. The “trouble with normal,” as Mary Louise Adams put it, was that the great postwar experiment in restoring a heterosexual, gendered family regime — rooted in a mythical past — had failed to live up to its billing. Mary Louise Adams, The Trouble with Normal: Postwar Youth and the Making of Heterosexuality (Toronto: University of Toronto, 1997). Dismantling its structures through new laws and public policy in employment equity, day care provision, and family law reform continue to present day. Probing these broad patterns can take us to unexpected places, as historians move from an era when “mixed marriages” described a union across Christian denominations to one in which same-sex nuptials are protected by Canada’s Charter of Freedoms and Rights . In hindsight, from the end of the Second World War to the early 1980s, gender roles did not obliterate old boundaries, but they shifted considerably in pushing them toward more equality. Nonetheless, the ongoing task of translating legal gender equality into everyday realities in the continual making of gender roles leaves work yet to be done — throughout Canadian society, and by historians at work mapping their historical contexts in the years ahead. Present-day trends have deep historical roots. Gender roles remain defined more by patriarchy than equal partnership. It is also evident that they have been significantly challenged in histories of the struggle for women’s rights. Key Points The movement to improve the condition of women changed in the 1960s and 1970s, becoming variously known as the Women’s Liberation Movement and second wave feminism. A result of this activism and a stimulus to further action was the Royal Commission on the Status of Women in 1970. Legislation aimed at achieving gender equality was introduced incrementally, although barriers proved resistant and continue to be so. 82 7.11 Greenpeace The 1960s ended with the apparent disappearance of an array of social movements. Some were exhausted, others lost personnel, a few accomplished their limited goals and ceased to have a purpose. Mostly, however, they were redeployed into other projects. Greenpeace is an example of a movement organization that combined a critique of capitalism and Cold War politics with a strong environmentalist sensibility. Established in Vancouver in 1971, Greenpeace opened its first office in Kitsilano, a neighbourhood deeply associated with the hippy movement of the previous decade. Starting out as the “Don’t Make a Wave Committee,” the organization took the name of its first ship, the Greenpeace , for the organization as a whole. The catalyst was American nuclear weapon testing on a remote Aleutian island in Alaska. The Americans, British, and French had been testing atomic explosives in isolated island locations since the 1940s. With an arms race against the Soviet Union well underway, the Americans were eager to both maintain their apparent technological lead, and to do so as close to the Soviet hinterland of Siberia as possible. Environmentalists and anti-Cold War activists saw the proposal to detonate a warhead beneath Amchitka Island (the third test on the island in ten years) as offensive and dangerous. There were fears, too, that the test would cause a tsunami, and that radiation would inevitably seep into the sea. The organization cannily incorporated journalists and media figures into its numbers. Its leaders were principally middle-class professionals who presented Greenpeace as inclusive and open; the opposite of the corporate forces it was fighting. Within a couple of years, the focus of Greenpeace’s activity had shifted to the international whale hunt and, in the late 1970s, the Newfoundland-Labrador seal hunt. This latter campaign pitted the still-mostly British Columbian organization against Newfoundland workers, and was (at least temporarily) highly divisive. Thanks in part to the anti-sealing campaign launched in Europe, Greenpeace quickly became a global brand. Its flag and emblems could be found across the western world and in ports across Oceania. However, it retained a powerful presence in Canada. This would be seen again in British Columbia, from 1992-1996, in the War in the Woods — a mass protest and occupation of old growth forests that culminated in the arrest of 300 protesters in one day. Figure 7.24 The fur trade between Canada and Europe was fundamental to the growth of colonial commerce and population but by the 1980s it had become an economic and moral battleground internationally. Critics of Greenpeace have pointed to their record as enemies of working class people. Seal hunters and loggers — not to mention whalers as well as farmers working with genetically modified foods — have been impacted when the corporations for which they work have been targeted. Greenpeace also has a spotty record when it comes to consulting with First Nations, an accusation that was levelled against it by the seal hunting Inuit of Labrador and the Nuu-chah-nulth First Nation in whose ancestral territory the War in the Woods took place. John-Henry Harter, “Environmental Justice for Whom? Class, New Social Movements and the Environment: A Case Study of Greenpeace Canada, 1971-2000,” Labour /Le Travail , 54 (Fall 2004): 83-119. Internal divisions have wracked the organization since the 1970s, and it principally survives now as “Greenpeace International.” From the perspective of Canada, Greenpeace did many incontrovertibly important things in the first 30 years of its existence. It raised awareness of environmental issues as they pertained to the Cold War, global capitalism and consumerism, and the difficulties inherent in policing a mobile operation like the whale hunt. As a movement, it had greater international reach than any other has that originated in Canada. In mobilizing hundreds, if not thousands, of people to put themselves in the way of corporate foes — and at the risk of being arrested and jailed — Greenpeace created a generational cadre of environmental activists and shifted the political agenda (at least in some quarters). Finally, Greenpeace carried forward many of the traditions of the social reform movements we have been studying: largely middle-class, morally forthright, redemptive, and as inclined toward prohibition of offending behaviours as it was to tempering practices. Greenpeace may be contentious in some quarters but it is in many respects an illustration of Canadian historical traditions. Key Points Greenpeace originated in the anti-nuclear movement of the 1960s and 1970s, turning its attention to animal rights issues in the late 1970s. Increasingly associated with protests against whaling and sealing, Greenpeace became an international movement in the 1980s, at which time it refocused again on the logging of old growth forests. Founded in Vancouver, Greenpeace was an important late-20th century organization in Canada that drew on the traditions of older reform movements. Figure 7.24 Stop the Seal Hunt by Alejandro Hernandez. is used under a CC-BY-2.0 license. 83 7.12 Summary Figure 7.25 Temperance and prohibition were causes around which 19th and 20th century reformers could unite, and it attracted a crusading Christian ethos. (Published by Dominion Scientific Temperance Committee, ca. 1912.) Urban living and industrial working conditions, the prevalence of alcohol abuse, the vulnerability of families (more visible now in urban conditions), and a nativist response to immigration, all contributed to the growth of reform movements in the post-Confederation period. These were like crusades, their knights tilting at issues that were, one after the other, guaranteed to cause the moral, economic, and even genetic destruction of whatever constituted “Canadian” society. Some reform movements sought to accomplish, on a society-wide scale, what the emergent labour movement hoped to achieve at the factory level. Better conditions, more time for leisure and reflection, and supports for the most vulnerable member of society were common goals. The things that animated reform movements varied tremendously. Political reform movements in the West, for example, were united in their criticism of Central Canadian imperialism. After the Second World War, reform movements ceased to be a mass phenomenon. That is not to say they went away. Many of the strategies and goals of pre-WWII reform movements were carried forward by the social democratic parties and some, too, were transmitted to the populist right-wing parties. In Quebec the Catholic Church continued to play a role and there was, as well, the powerful secularization of the reform agenda in the Quiet Revolution. In some respects the environmentalism of the late 20th century — descended from conservationism — continues the reform movement tradition, as do prohibitionist movements like the “war on drugs.” These are, however, movements that are either limited in their membership or so generalized as not to constitute a coherent agenda of social change with clear objectives and outcomes. And, for the most part, they lack the cure-all quality to many of the earlier reform programs. The rise of mass education, the professionalization of teaching, and the development of a social work sector all became extensions of the reform movement tradition, but in ways that closed off access and engagement to everyone but the experts. Figure 7.26 Now known predominately as a source of inexpensive recycled clothes, used books, and well-used furniture, the Salvation Army today presents itself very differently from its Victorian incarnation. While it is still engaged in work among vulnerable populations, Sally Ann’s efforts to save society as a whole have effectively ended. Key Terms anti-party: The position that political parties constitute an unwelcome constraint on democratic politics. balance of power: In parliamentary politics, describes a minority government that is dependent on another party to provide enough votes to prohibit defeat through a vote of non-confidence. Comintern: Also the Communist International, the Third International; 1919-1943; called for world revolution and the establishment of communist regimes. cooperative movement : Also spelled co-operative. Established in growing numbers in Britain in the mid-19th century and is associated with the “Rochdale Pioneers”; several typologies; goals include making available goods and/or supplies to members at low costs by taking advantage of economies of scale as a group, also obtaining optimal prices for community products by pooling output for sale. Surpluses and profits are redistributed to members of the cooperative; some have an educational mandate as well. Examples include grocery stores, housing co-ops, and the dairy industry. See also wheat pools. Court of Chancery: In England, the Court dealt primarily with trusts; dissolved in 1875. established churches: Organized religion recognized by the state. In Canada there are no officially recognized sects but the Anglican Church is the “established church” of England and the Queen is its head. Similarly, the Catholic Church was historically the official church of French Canada and it retains in the post-Confederation period a de facto official status. eugenics: An early theory respecting genetic transmission of physical, social, intellectual, and moral qualities which sought to advantage “races” that it considered superior stock against those that it regarded as inferior. evangelicalism: In Christianity, a belief that salvation is achieved through faith in Jesus; individualistic in that redemption occurs at a personal, not a social level; evangelical denominations are often associated with fundamentalism as well. Fabian: A belief that reforms to capitalism can produce a social and economic order of fairness for working people; sometimes called “gradualism.” fertility transition: Demographic trend in which populations move from a level of high fertility to a much lower level; associated with urbanization and modernization. first-past-the-post: Electoral system in which the candidate receiving the greatest number (though not necessarily a majority) of ballots wins; considered problematic by some when a party wins a majority of seats while winning much less than a majority of votes. generation gap: Notable differences in values, tastes, interests, and practices between individuals and whole cohorts from different generations. In the 1960s, used extensively to describe the conflict in values between people born before WWII and the baby boom generation. genocide: The premeditated extermination of an identifiable group of humans, often defined by race or ethnicity. See also cultural genocide. germ theory: The identification of microorganisms as the cause of some illnesses, particularly infectious diseases. Ginger Group: An alliance of progressive MPs in Ottawa that led to the founding of the Cooperative Commonwealth Federation (CCF). gradualist: The idea that great change can occur incrementally, in slow, small, and subtle steps, rather than by large uprisings or revolutions. Among left-wing activists, a belief that reforms to capitalism can produce a social and economic order of fairness for working people; sometimes called “Fabianism;” derided by revolutionaries as delusional. In the context of Quebec’s independence movements the equivalent term is étapisme . See also reformist and impossibilist. Greenpeace: An environmental movement founded in Vancouver in the early 1970s as part of an international anti-nuclear arms movement; became more directly associated with environmental issues like sealing and whaling. impossibilists: Among left-wing activists, a belief that it is impossible to reform capitalism and that it must be overthrown rather than overhauled. See also gradualist and reformist. internationalist: In the history of organized labour, the belief that workers of all countries had more in common than they did with co-nationals who belong to other social classes. Views nationalist movements as antithetical to the interests of working people. League for Social Reconstruction (LSR): A socialist think-tank established by Frank Underhill and F.R. Scott in 1932. Left: Coined during the French Revolution to describe opponents of the monarchy; since then, used to describe a spectrum of reform and radical positions and political organizations that includes some Liberals, the Cooperative Commonwealth Federation, the New Democratic Party, the Socialist Party of Canada, and — at the far end of the Left — the Communist Party and, in some instances, anarchists. See also Right. Mackenzie-Papineau Battalion: A 1,500-strong contingent of Canadian volunteers in the war against the Fascists in Spain during the Civil War, 1937-38; took their name from the two leaders of the Rebellions of 1837-38, Louis-Joseph Papineau and William Lyon Mackenzie (the grandfather of Prime Minister William Lyon Mackenzie King). Marxist-Leninist: Building on the scientific socialism of Karl Marx, which argued that socialist, worker-led governments would supersede bourgeois capitalism, the Leninist thread — arising in revolutionary and post-revolutionary Russia — introduced the idea of a vanguard of the proletariat, single-party rule, internationalism, and a state-run economy. In Canadian communism, one of several variants on Marxist doctrine. maternal feminists: Adherents to the ideals of maternal feminism. Molotov-Ribbentrop Pact (1939): A mutual non-aggression treaty signed between Germany and the USSR; allowed Germany to move forward with its attacks on France and the Low Countries while the Soviet Union annexed territories in the Baltic region. National Action Committee on the Status of Women: Established in 1971 to agitate for implementation of the recommendations of the Bird Commission. See also Royal Commission on the Status of Women. New Democratic Party (NDP): Successor to the Cooperative Commonwealth Federation; created out of the union of the Canadian Labour Congress (CLC) and the CCF in 1961. non-conformist churches: A descriptive term attached to dissenting Protestant sects that broke with the Anglican Church as early as 1660; associated specifically with Methodism, Congregationalism, and the Baptist Church. Official Opposition: In parliamentary systems, the party with the second largest number of seats in the House of Commons. On occasion, the second largest caucus has refused the title of Official Opposition. official party status: The recognition of a political party’s representatives in an assembly as sufficient to merit certain parliamentary privileges, including the right to ask questions during question period. In Ottawa, the federal House of Commons requires that a party have no fewer than 12 MPs in order to qualify for official status. patriarchy: A socio-economic system in which males have legal, political, social, and economic primacy and privilege, sometimes to the complete exclusion of women. Under a patriarchy, control over children is also a male (fatherly) prerogative. Poor Laws: A series of laws enacted in Britain, including several amendments in the 19th century; aimed at providing support for the unemployed and impoverished; characterized by the use of “poor houses” and “workhouses” in which conditions were sufficiently appalling to keep all but the least able-bodied and most desperate off of the public dole. progressive: In politics and social policy, the belief in the improvability of human society. In partisan politics, associated with the Progressive Party (below) and the Progressive Conservative Party. In music, indicates a sub-genre of rock and roll which tends to be more symphonic and influenced by electronic jazz. proportional representation Distinct from the first-past-the-post system; can take several forms but common aspect is that political parties will be elect a number of seats that reflects in some measure the percentage of votes they receive. For example, a party might win 49% of the votes in every constituency but not elect a single candidate if the only other party running wins 51% of the votes; proportional representation (sometimes called “PR”) would ensure that the second-place party received something closer to 49% of the seats. race suicide: An idea common to the eugenics movement; the idea that “inferior races” will inevitably squeeze out “superior races” by dint of having higher reproductive rates; especially popular at times when fertility in the anxious community is falling. referenda: A public opinion poll for registered voters, the results of which may or may not be binding. Members of Parliament debate actual bills that they can see and hold, and on which they may offer suggestions and amendments; referenda typically ask for general agreement on a broad principal without providing any of the details. reformist: Among left-wing activists, a belief that incremental changes to capitalism can produce a social and economic order of fairness for working people; derided by revolutionaries as delusional. See also gradualist and impossibilist. Regina Manifesto: 1933; the original statement of purpose and beliefs of the Cooperative Commonwealth Federation. Right: Individuals, groups, and parties espousing a conservative perspective; a broad continuum that includes Red Tories, Blue Tories, neo-liberals/conservatives, the late 20th century Reform Party, and — far to the Right — fascists. Royal Commission on the Status of Women: Created in 1967 and reported out in 1970; chaired by Florence Bird; produced 167 recommendations that focussed on issues of equality of opportunity and identifying the many institutional, legal, and systemic barriers to the same. While most of the recommendations have been adopted, provision of day care remains an outstanding exception. The RCSW did not address issues associated with sexual identity or sexual orientation and its failure to discuss violence against women was a major oversight. The Office for the Status of Women was established as a consequence of the Commission’s report. Salvation Army: Founded in England in 1865; a Christian denomination identified with charitable works in urban industrial areas; adopted a military model with uniforms, marching bands, and ranks. Introduced to Canada in 1882, where it is also known as the “Sally Ann,” sometimes as the “Starvation Army.” Keenly interested in social justice issues, the Salvation Army was instrumental in the social gospel movement. scientific racism: The use of scientific technique or pseudo-scientific technique to provide a rational and empirically verifiable basis of racial discrimination. Utterly demolished as a theory in the postwar period, it nevertheless contributed not only to the spread of racism in Euro-Canadian communities but to its legitimation and respectability. second wave feminist: A renewal of movement feminism in the postwar era; focussed on rights in the workplace, equality of opportunity and pay, reproductive rights, and violence against women. See also Women’s Liberation social control: The regulation of social behaviour through direct (laws, policing) and indirect (social pressure, moral suasion) means. social credit: Primarily an economic theory and monetary policy, developed in the 1920s and touted as a solution to the Depression in Canada by Social Credit political parties. social democratic: A political movement that advocates reform that will achieve greater social equality, a degree of socialist governance, and the preservation of democratic institutions. Associated with the Cooperative Commonwealth Federation and New Democratic Party. social reformers: Advocates of change at the social — rather than individual — level; associated with 19th century social movements like the suffragettes, maternal feminism, and temperance agitation. suffrage: The right to vote in elections; associated strongly with women’s suffrage. third parties: Political parties other than the Liberals and Conservatives; distinguished from “fourth” or “fringe parties” by their more respectable showing at the polls. Principally, the CCF-NDP, Social Credit, and Reform Party of Canada. The Bloc Québécois occupies a special place in this respect because it has enjoyed a large following and has formed the official opposition in Ottawa, but is not a national party. Waffle: A faction within the NDP in 1969-1971 that embraced left-wing nationalism, feminism, and social activism, and called for an independent socialist Canada. War in the Woods: 1992-1996; a series of mass protests against logging in old growth forests in British Columbia. Winnipeg Declaration: Fully, the 1956 Winnipeg Declaration of Principles of the Co-operative Commonwealth Federation; replaced the Regina Manifesto; significant in that it moved the party away from socialism and closer to democratic socialism and a pro-union position; made possible the alignment of the CCF with the CLC very soon after. Women’s Liberation Movement: Both an informal and loose organization of various women’s advocacy and political groups, and an alternative term for second wave feminism; first appeared in 1968. Young Women’s Christian Association (YWCA): Originated in Britain in 1855 as a faith-based organization in support of the first generations of women in urban industrial settings; first Canadian chapter established in Saint John in 1870. Suggested Readings Baskerville, Peter. “‘She Has Already Hinted at “Board”’: Enterprising Urban Women in British Columbia, 1863-1896,” Histoire sociale/Social History, 26, no. 52 (November 1993): 205-27. Belisle, Donica. “Crazy for Bargains: Inventing the Irrational Female Shopper in Modernizing English Canada,” Canadian Historical Review , 92, Number 4 (December 2011): 581-606. Boschma, Geertje. “Deinstitutionalization Reconsidered: Geographic and Demographic Changes in Mental Health Care in British Columbia and Alberta, 1950-1980,” Histoire sociale/Social History, 44, Number 88 (Novembre-November 2011): 223-56. Clément, Dominique. “Generations and the Transformation of Social Movements in Postwar Canada,” Histoire sociale/Social history, 42, Number 84 (Novembre-November 2009): 361-87. Girard, Philip. “‘If two ride a horse, one must ride in front’: Married Women’s Nationality and the Law in Canada 1880–1950,” Canadian Historical Review , 94, Number 1 (March 2013): 28-54. Kelm, Mary-Ellen. “Manly Contests: Rodeo Masculinities at the Calgary Stampede,” Canadian Historical Review , 90, Number 4 (December 2009): 711-51. McDonald, Robert A.J. “‘Telford Time’ and the Populist Origins of the CCF in British Columbia,” Labour/Le Travail , 71 (Spring 2013): 87-100. Naylor, James. “The British Columbia CCF’s Working-Class Moment: Socialism Not Populism,” Labour/Le Travail , 71 (Spring 2013): 101-21. Figure 7.25 Temperance poster promoting the prohibition of alcohol (PR1974.0001.0400a.0012) by Provincial Archives of Alberta has no known restrictions . Figure 7.26 A flyer from a Toronto “Take Off Your Clothes” clothing swap by Neelan Rach is used under a CC BY SA 2.0 license. IX Chapter 8. The Economy since 1920 84 8.1 Introduction The political transformations that ushered in the Confederation era were both a product and a reflection of the economic changes that were underway. Chapter 3 considered the industrialization of the economy and how that led to the emergence of new social classes and political agendas. However, there were also important continuities in the Canadian economy. This chapter explores the outlines of the Dominion economy from the 19th through the 20th century. It examines the most commonly used theoretical model of the Canadian economy (the staples model) because of its implications for the economy in the past and the present. Some of the principal features of capitalism are reviewed as well, including capital markets and business cycles. The enormous impact crater that was the 1930s Depression is also considered, as is the emergence of what historians describe as the “new economy” in the 20th century. Three persistent sectors — shipping, fishing, and oil and gas — offer insights into the rhythms of the national economy. The post-war economic order is reviewed, as is the regional economy of the Maritimes. The chapter concludes with an essay on economic nationalism, an idea that informed Macdonald and that continues to influence economic policy-making. \n",
      "-----------\n",
      "Identify the major reform movements of the post-Confederation era.\n",
      "Describe the common features, tactics, goals, and beliefs of the reform movements.\n",
      "Account for the popularity and longevity of specific reform movements.\n",
      "Detail the influence of the social gospel, temperance, and maternal feminist movements.\n",
      "Explain the rise of third parties as aspects of the reform movement.\n",
      "Assess the apparent distinctions between the first and second waves of feminism.\n",
      "Evaluate the extent to which late 20th-century movements like Greenpeace are part of a longer reform tradition.\n",
      "--------------------------\n",
      "What Is the Environment? For any organization, the environment consists of the set of external conditions and forces that have the potential to influence the organization. In the case of Subway, for example, the environment contains its customers, its rivals such as McDonald’s and Kentucky Fried Chicken, social trends such as the shift in society toward healthier eating, political entities such as the U.S. Congress, and many additional conditions and forces. It is useful to break the concept of the environment down into two components. The general environment (or macroenvironment) includes overall trends and events in society such as social trends, technological trends, demographics, and economic conditions. The industry (or competitive environment) consists of multiple organizations that collectively compete with one another by providing similar goods, services, or both. Every action that an organization takes, such as raising its prices or launching an advertising campaign, creates some degree of changes in the world around it. Most organizations are limited to influencing their industry. Subway’s move to cut salt in its sandwiches, for example, may lead other fast-food firms to revisit the amount of salt contained in their products. A few organizations wield such power and influence that they can shape some elements of the general environment. While most organizations simply react to major technological trends, for example, the actions of firms such as Intel, Microsoft, and Apple help create these trends. Some aspects of the general environment, such as demographics, simply must be taken as a given by all organizations. Overall, the environment has a far greater influence on most organizations than most organizations have on the environment. Why Does the Environment Matter? Understanding the environment that surrounds an organization is important to the executives in charge of the organizations. There are several reasons for this. First, the environment provides resources that an organization needs in order to create goods and services. In the 17th century, British poet John Donne famously noted that “no man is an island.” Similarly, it is accurate to say that no organization is self-sufficient. As the human body must consume oxygen, food, and water, an organization needs to take in resources such as labor, money, and raw materials from outside its boundaries. Subway, for example, simply would cease to exist without the contributions of the franchisees that operate its stores, the suppliers that provide food and other necessary inputs, and the customers who provide Subway with money through purchasing its products. An organization cannot survive without the support of its environment. Second, the environment is a source of opportunities and threats for an organization. Opportunities are events and trends that create chances to improve an organization’s performance level. In the late 1990s, for example, Jared Fogle’s growing fame created an opportunity for Subway to position itself as a healthy alternative to traditional fast-food restaurants. Threats are events and trends that may undermine an organization’s performance. Subway faces a threat from some upstart restaurant chains. Saladworks, for example, offers a variety of salads that contain fewer than 500 calories. Noodles and Company offers a variety of sandwiches, pasta dishes, and salads that contain fewer than 400 calories. These two firms are much smaller than Subway, but they could grow to become substantial threats to Subway’s positioning as a healthy eatery. Executives must also realize that virtually any environmental trend or event is likely to create opportunities for some organizations and threats for others. This is true even in extreme cases. In addition to horrible human death and suffering, the March 2011 earthquake and tsunami in Japan devastated many organizations, ranging from small businesses that were simply wiped out to corporate giants such as Toyota whose manufacturing capabilities were undermined. As odd as it may seem, however, these tragic events also opened up significant opportunities for other organizations. The rebuilding of infrastructure and dwellings requires concrete, steel, and other materials. Japanese concrete manufacturers, steelmakers, and construction companies are likely to be very busy in the years ahead. Figure 3.2 Natural disasters devastate many organizations. Third, the environment shapes the various strategic decisions that executives make as they attempt to lead their organizations to success. The environment often places important constraints on an organization’s goals, for example. A firm that sets a goal of increasing annual sales by 50 percent might struggle to achieve this goal during an economic recession or if several new competitors enter its business. Environmental conditions also need to be taken into account when examining whether to start doing business in a new country, whether to acquire another company, and whether to launch an innovative product, to name just a few. Key Takeaway An organization’s environment is a major consideration. The environment is the source of resources that the organizations needs. It provides opportunities and threats, and it influences the various strategic decisions that executives must make. Tangshan_earthquake © The National Oceanic and Atmospheric Administration is licensed under a Public Domain license 12 Evaluating the General Environment \n",
      "-----------\n",
      "Define the environment in the context of business.\n",
      "Understand how an organization and its environment affect each other.\n",
      "Learn the difference between the general environment and the industry.\n",
      "--------------------------\n",
      "My Post-Secondary Education The first class I went to in my post-secondary education was philosophy, and it changed my life forever. Our first assignment was to write a short response paper to the Albert Camus essay “The Myth of Sisyphus.” I was extremely nervous about the assignment as well as college. However, through all the confusion in philosophy class, many of my questions about life were answered. I entered my post-secondary studies intending to earn a degree in engineering. I always liked the way mathematics had right and wrong answers. I understood the logic and was very good at it. When I received my first philosophy assignment that asked me to write my interpretation of the Camus essay, I was instantly confused. What is the right way to do this assignment, I wondered. I was nervous about writing an incorrect interpretation and did not want to get my first assignment wrong. Even more troubling was that the professor refused to give us any guidelines on what he was looking for; he gave us total freedom. He simply said, “I want to see what you come up with.” Full of anxiety, I first set out to read Camus’s essay several times to make sure I really knew what was it was about. I did my best to take careful notes, yet even after I took all these notes and knew the essay inside and out, I still did not know the right answer. What was my interpretation? I could think of a million different ways to interpret the essay, but which one was my professor looking for? In math class, I was used to examples and explanations of solutions. This assignment gave me nothing; I was completely on my own to come up with my individual interpretation. Next, when I sat down to write, the words just did not come to me. My notes and ideas were all present, but the words were lost. I decided to try every prewriting strategy I could find. I brainstormed, made idea maps, and even wrote an outline. Eventually, after a lot of stress, my ideas became more organized and the words fell on the page. I had my interpretation of “The Myth of Sisyphus,” and I had my main reasons for interpreting the essay. I remember being unsure of myself, wondering if what I was saying made sense, or if I was even on the right track. Through all the uncertainty, I continued writing the best I could. I finished the conclusion paragraph, had my spouse proofread it for errors, and turned it in the next day simply hoping for the best. Then, a week or two later, came judgment day. The professor gave our papers back to us with grades and comments. I remember feeling simultaneously afraid and eager to get the paper back in my hands. It turned out, however, that I had nothing to worry about. The professor gave me an A on the paper, and his notes suggested that I wrote an effective essay overall. He wrote that my reading of the essay was very original and that my thoughts were well organized. My relief and newfound confidence upon reading his comments could not be overstated. What I learned through this process extended well beyond how to write a post-secondary school paper. I learned to be open to new challenges. I never expected to enjoy a philosophy class and always expected to be a math and science person. This class and assignment, however, gave me the self-confidence, critical thinking skills, and courage to try a new career path. I left engineering and went on to study law and eventually became a lawyer. More importantly, that class and paper helped me understand education differently. Instead of seeing post-secondary studies as a direct stepping stone to a career, I learned to see those studies as a place to first learn and then seek a career or enhance an existing career. By giving me the space to express my own interpretation and to argue for my own values, my philosophy class taught me the importance of education for education’s sake. That realization continues to pay dividends every day. A.3 Illustration Essay \n",
      "-----------\n",
      "Read an example of the narrative rhetorical mode\n",
      "--------------------------\n",
      "This book has been enhanced with H5P content. What does that mean for you as a reader? Throughout the book, you will find embedded interactive activities that will help you practice your new learning and test your skills. These will provide you with immediate feedback and you can complete them as many times as you like. You are encouraged to check your answers as you proceed by clicking the Check button after each question to check your answer and receive feedback. Click the Retry or Show Solutions buttons for any questions that you cannot solve. Click Finish at the end of the questions to see your overall results. Note: If you see a speech bubble with an I in it, this will provide you with more information. This first one is simply a demonstration. When you hear the term “technical communication,” what comes to mind? Perhaps you think of scientific reports, specifications, instructions, software documentation, or technical manuals. And you would be correct. However, technical communication is so much more than that. Technical Writing is a genre of non-fiction writing that encompasses not only technical materials such as manuals, instructions, specifications, and software documentation, but it also includes writing produced in day-to-day business operations such as correspondence, proposals, internal communications, media releases, and many kinds of reports. It includes the communication of specialized technical information, whether relating to computers and scientific instruments, or the intricacies of meditation. And because oral and visual presentations are such an important part of professional life, technical communication also encompasses these as well. Why are Technical Communication Skills Important? In a recent presentation on the topic of Co-op Work Term Reports, the Engineering co-op coordinator for the University of Victoria presented the following statistics regarding the importance of communication skills in the professional world of engineering: The Reality: Technical Writing and Communication How graduate engineers spend their time: 25-50% Problem solving of some kind 50-75% Communicating (Writing and reading reports, letters, memos, proposals, presentations, discussions w/colleagues, managers, clients) Performance evaluations and job advancement usually depend more on communications skills than on technical skills He added that engineers who are more advanced in their careers spend only 5-10% of their time engaged in problem solving of some kind and 90-95% of their time engaging in related communications tasks:  researching, writing and reading reports, proposals, emails, letters, memos; giving or attending presentations; discussing and meeting with colleagues, team mates, managers, clients, and so forth. In a recent survey of over 1000 professionals from various professions, over 70% of engineers and almost 50% of programmers rated the quality of their writing as either “very important” or “extremely important” to the performance of their jobs. Clearly, as Barry Hyman asserts in Fundamentals of Engineering Design , “the stereotype that engineering is for inarticulate nerds is way off base.” Technical communication is “transactional” – it entails a purposeful transaction between sender and receiver that provides specific information for practical and specific purposes (informing, instructing, persuading) and is usually geared towards the needs of a specific audience. Technical communicators produce a wide variety of documents and other products, such as Proposals and requests for proposals (RFPs) Technical or research reports Documentation records and product specifications User guides (step-by-step instructions, procedures, manuals) Online help, technical support Reference information (encylopedia-style information) Consumer literature (information for the public about regulations, safety issues, etc .) Marketing literature (product specifications, brochures, promotional literature) Technical journalism (found in trade magazines, media releases, etc. ) Thus, it is a highly “designed” form of communication that requires practitioners to have a heightened awareness of the conventions (rules and expectations) and rhetorical situations (audience, purpose, context) in which they are communicating. This textbook aims to provide you with that heightened awareness – that is, to introduce you to the basic conventions of technical communications, and to train you to take a reader-centred or audience-centred approach to communications tasks, to find the tools and methods that will work best to communicate your ideas to your target audience, and to achieve the desired results. What Does Technical Writing Look Like? Technical communications can take many forms, depending on the purpose and intended audience.  Consider the following example of technical writing, which is an excerpt adapted from a book called Scientific Sailboat Racing by Ted Wells. From the excerpt in the box below, what can you tell about the intended audience? The most common question asked by skippers wanting to get to the windward mark faster than they have been doing is “ How can I make my boat point higher?” Getting to the windward mark first depends primarily on the skill and experience of the skipper; however, having a well-rigged boat will make a significant difference.  Look for the following, in order of importance: Sails: Have good quality sails, and use the appropriate sails for the wind conditions expected.  No one can win races with poor sails, so use the best you can afford.  Keep in mind that the leeches of all sails flutter a little, the jib will backwind the luff of the main on any full or medium sail, and in very light wind, even a perfectly cut sail will probably develop a wrinkle along the front of the battens.  If the sails are obviously no good, replace them. Mast and Centerboard: Ensure that the mast is far enough forward and the centerboard is far enough back so that there is little or no weather helm.  Make sure the stiffness of the mast suits the sails. Jib Fairleads : Ensure jib fairleads are properly located for the type of jib being used and the strength of wind expected. Cleats: Have cleats for both jib and mainsheet; place cleats so that crew can easily make small adjustments for varying wind velocities and hang on the to the jib sheet without having it pop out of the cleat. Traveler : Have a mainsheet traveler that allows the main to be pulled down without pulling the boom in too far; it should allow the sail to be pulled down tightly enough so that the leech does not fall off without pulling the boom in any further than it should be. Tiller: Have a flexible tiller extension that allows you to sit well forward, but can be adjusted so that it does not get in the way when coming about. Boat Weight: Keep the boat as close to minimum weight as possible.  Clearly, a lighter boat is easier to handle, but this is not as critical as other factors.  If choosing between a lighter crew member with less skill and experience, and a heavier crew member who has greater skill, the latter is usually preferable. Once the boat is properly set up, a skilled and experienced skipper can point significantly higher than expected by understanding and using wind deflection from other boats.  Immediately to leeward of any boat and extending for a distance of about three mast lengths, there is a wind shadow where the wind velocity is greatly decreased.  To leeward of the bow of the boat there is a very small region where the direction of the wind is deflected opposite to the normal deflection and where the velocity is accelerated slightly (see Figure 34).  Except in the direct wind shadow, the deflection of the wind is more important than the decrease in wind velocity, as the decrease in velocity is very slight except in the immediate shadow of the sails of the windward boat. Because of this wind deflection, a boat on the opposite tack cutting behind another boat will be able to point appreciably higher than it normally would.  Many skippers on port tacks who thought they could clear starboard tackers have been fooled by not realizing this fact.  The deflection of their wind in trying to cross in front of the starboard tacker will enable the starboard tacker to point higher without luffing than he normally would be able to do, and the port tacker who thought he could squeeze by suddenly finds that he cannot (See Figure 35). S.1. Excerpt from T. Wells, Scientific Sailboat Racing, New York: Dodd, Mead, and Co., 1950, pp. 94-96. This book is out of print, and every attempt has been made to locate the copyright owner. For noncommercial, educational use only. S. McConkey, “Writing a work term report,” ENGR 120 Plenary Lecture , University of Victoria, March 3, 2017. J. Swartz, S. Pigg, J. Larsen, J. Helo Gonzalez, R. De Haas, and E. Wagner, \"Communication in the workplace: What can NC State students expect?\" Professional Writing Program, North Carolina State University, 2018 [Online]. Available: B. Hyman, “Ch. 2: Problem formulation,” in Fundamentals of Engineering Design , Upper Saddle River, NJ: Prentice Hall, 2002, p. 42. T. Wells, Scientific Sailboat Racing , New York: Dodd, Mead, and Co., 1950, pp. 94-96. 1.1 KEY CONCEPT: Problem-Solving Approach to Communications Tasks In the workplace, many of the communications tasks you perform are designed to solve a problem or improve a situation. Whether you are doing work for a client, for your employer, with your team, or for someone else, you will typically use some sort of design process to tackle and solve the problem. A clearly-articulated design process provides you with a clear, step-by-step plan for finding the best solution for your situation. Take a moment to search the Internet for the term “design process” and look at “images.” You will find many variations. Have a look at several of them and see if you can find a common pattern. One commonality you will likely find in examining other people’s design process diagrams is this: the first step in designing any solution is to clearly define the problem . Figure 1.1.1 shows NASA’s basic design process. Think about the kind of communication that each step of this process might entail. Figure 1.1.1 NASA’s Design Process Diagram. You cannot begin to work on solutions until you have a clear definition of the problem and goals you want to achieve. This critical first stage of the design process requires that you effectively communicate with the “client” or whoever has the “problem” that needs solving. Poor communication at this stage can derail a project from the start. For our purposes, we will use Barry Hyman’s Problem Formulation model to clearly define a problem. Hyman’s Problem Formulation model consists of 4 elements: Need Statement: recognizes and describes the need for a solution or improvement to an “unsatisfactory situation.”  It answers the questions, “what is wrong with the way things are currently? What is unsatisfactory about it? What negative effects does this situation cause?” You may need to do research and supply data to quantify the negative effects. Goal Statement: describes what the improved situation would look like once a solution has been implemented. The goal statement defines the scope of your search for a solution. At this point, do not describe your solution, only the goal that any proposed solution should achieve. The broader you make your goal, the more numerous and varied the solution can be; a narrowly focused goal limits the number and variety of possible solutions. Objectives : define measurable, specific outcomes that any feasible solution should optimize (aspects you can use to “grade” the effectiveness of the solution). Objectives provide you with ways to quantifiably measure how well any solution will solve the problem; ideally, they will allow you to compare multiple solutions and figure out which one is most effective (which one gets the highest score on meeting the objectives?). Constraints : define the limits that any feasible solution must adhere to in order to be acceptable (pass/fail conditions, range limits, etc .). The key word here is must — constraints are the “go/no go” conditions that determine whether a solution is acceptable or not.  These often include budget and time limits, as well as legal, safety and other regulatory requirements. Communication as Solution This model can apply to a communications task as well as more physical design tasks. Imagine your communications task as something that will solve a problem or improve a situation. Before you begin drafting this document or presentation, define the problem you want to solve with this document: Understand the Need: consider what gave rise to the need to communicate. Does someone lack sufficient information to make a decision or take a position on an issue? Did someone request information? Is there some unsatisfactory situation that needs to be remedied by communicating with your audience? What specifically is unsatisfactory about it? Consider your audience.  For example A potential client lacks sufficient information on whether the solution I have proposed to solve the client’s problem will be feasible, affordable, and effective. My instructor lacks sufficient examples of my written work to assign a grade for how well I met the course learning objectives. Establish a Goal: consider your purpose in writing. What do you want your reader to do, think, or know? Do you want your reader to make a decision? Change their opinion or behaviour? Follow a course of action? What is your desired outcome? And what form and style of communication will best lead to that outcome?  For example Provide the client with enough information, in an effective and readable format, to make a decision (ideally, to hire you to build the solution for the problem). Provide my instructor with samples of my writing that demonstrate my achievement of the course learning objectives (provide relevant and complete  information in a professionally appropriate forma t, using evidence-based argument; earn an A+ grade on the assignment. ) Define Objectives: consider the specifics of your message and your audience to determine what criteria you should meet. What form should it take? What content elements will you need to include? What kind of research will be required? What information does your audience want/need? What do they already know? Review the client’s RFP to see what specific objectives it lists and how your proposal will be assessed. Review the Assignment Description and G rading Rubric for your assignment to determin e specific requirements and objectives that your instructor will use to evaluate your work. Identify Constraints: what are the pass/fail conditions of this document?  Consider your rhetorical situation. What conditions exist that present barriers or challenges to communication? How can you address them? For example, how much time is your audience willing to spend on this? How long can you make your document or presentation? (word length/time limit) What format and style do they require? Is there a Style Guide you must follow? A template you can use? How much time do you have to create it?  Do you have a deadline? (due date) Are there requirements for using sources? (academic integrity rules) Keep in mind that the document you produce is evaluated in terms of how well it responds to the “problem” — that is, how well it meets the overall goal and demonstrates achievement of specific objectives while abiding by constraints. Figure 1.1.1 NASA design process by NASA STEM Engagement . Used for educational and non-commercial purposes. B. Hyman, “Ch. 2: Problem formulation,” in Fundamentals of Engineering Design , Upper Saddle River, NJ: Prentice Hall, 2002, pp. 40-54. 1.2 Conventions and Characteristics Every genre of writing has unique characteristics and rules, called conventions , that help readers classify a document as belonging to a particular genre. This also applies to film and music. Think about the last movie you saw. What type of movie was it? What about that movie gave you that impression? Did the characters wear Stetson hats, ride horses, and carry guns? Did they fly in space ships, encounter alien beings, and use futuristic technology? Those elements are typical conventions of Western and Science Fiction genres. Non-fiction is a category that can be broken into various genres. The main genres that are relevant to us are journalism (newspaper writing), academic writing (written by scholars and published in peer reviewed academic journals or books), and technical writing. Before we get into the specific conventions that characterize technical writing, take a moment to think back to your academic writing course and list some conventions typical of journalism (popular press) and academic writing in Table 1.1.1 . TABLE 1.1.1 Identify the conventions for journalistic and academic writing Criteria Journalistic Academic Purpose Audience Writing Style Tone Structure Format/Formatting Other Features Like journalism and scholarly writing, technical writing also has distinct features that readers expect to see in documents that fall within this genre. These include (a) use of headings to organize information into coherent sections, (b) use of lists to present information concisely, (c) use of figures and tables to present data and information visually, and (d) use of visual design to enhance readability (all of these topics are covered in Chapter 3: Document Design ). These conventions are connected to the main purposes of technical writing, which include communicating the following: Technical or specialized information in an accessible and usable ways Clear instructions on how to do something in a clear manner Information that advances the goals of the company or organization. Technical documentation is intended to communicate information to the people who need it in a way that is clear and easy to read, at the right time to help make decisions and to support productivity. Designing technical communication is like designing any other product for an intended user:  the ultimate goal is to make it “user friendly.” Key words here are accessible , usable, clear, goal-oriented , effective , and reader-centred .  The characteristics of technical writing support these goals and concepts. If we filled in Table 1.1.1 with typical characteristics of technical writing, it might look something like Table 1.1.2 : TABLE 1.1.2 Conventions of technical writing Criteria Technical Writing Purpose To communicate technical and specialized information in a clear, accessible, usable manner to people who need to use it to make decisions, perform processes, or support company goals. Audience Varied, but can include fellow employees such as subordinates, colleagues, managers, and executives, as well as clients and other stakeholders, the general public, and even readers within the legal system. Writing Style Concise, clear, plain, and direct language; may include specialized terminology; typically uses short sentences and paragraphs; uses active voice; makes purpose immediately clear. Tone Business/professional in tone, which falls between formal and informal; may use first person or second person if appropriate; courteous and constructive. Structure Highly structured; short paragraphs; clear transitions and structural cues (headings and sub-headings) to move the reader through and direct the reader. Format/Formatting Can be in electronic, visual, or printed formats; may be long (reports) or short (emails, letters, memos); often uses style guides to describe required formatting features; uses headings, lists, figures and tables. Other Features Typically objective and neutral; ideas are evidence and data-driven; descriptors are precise and quantitative whenever possible. Use this practice activity to test your understanding. 1.3 Understanding the Rhetorical Situation Suzan Last and Candice Neveu 1.4 Case Study: The Cost of Poor Communication J. Bernoff, \"Bad writing costs business billions,\" Daily Beast , Oct. 16, 2016 [Online]. Available: G. Robertson, “Comma quirk irks Rogers,” Globe and Mail , Aug. 6, 2006 [Online]. Available: “The £8.8m typo: How one mistake killed a family business,” (28 Jan. 2015). The Guardian [online]. Available: E. Tufte, The Cognitive Style of PowerPoint , 2001 [Online]. Available: C. McFadden, \"Understanding the tragic Hyatt Regency walkway collapse,\" Interesting Engineering , July 4, 2017 [Online]: T.M. Goerges (1996), Analytical Writing for Science and Technology [Online], Available: C. Sagan, The Demon-Haunted World: Science as a Candle in the Dark, New York, NY: Random House, 1995. 1 1.5 Writing Processes Just as we use design processes to creatively solve complex problems, we use writing processes to create complex documents. In both cases, there are steps or stages, but we don’t always proceed directly from one step to next in a chronological manner. These processes are often iterative, meaning we might return to previous stages in the process from time to time. The more complex the task, the more iteration might be needed. Examine the Design Process ( Figure 1.5.1 ) and Writing Process ( Figure 1.5.2 ) diagrams below. What similarities and differences can you see in these two processes? Figure 1.5.1 Design Process. [Image description] Figure 1.5.2 Writing Process Diagram. [Image description] You may have come across a “writing process” before, and it may or may not have worked well for you. There is no single process that works for everyone in every situation. The key is to recognize the various steps in a typical writing process and figure out how to use or adapt them most effectively for your situation. For example, you may have come across the 40-20-40 writing process, which suggests that you should break up the amount of time you spend on the writing task into three distinct stages of planning, drafting and revising, and give each one a specific percentage of the time you have available. 40-20-40 Writing Process Stage 1 – Planning: spend 40% of your time planning your document (task analysis, thinking, discussing, free-writing, researching, brainstorming, concept mapping, focusing ideas, outlining, etc .) Stage 2 – Drafting: spend 20% of your time writing a rough draft (quickly getting all your ideas down in print, in more or less complete sentences and paragraphs, in more or less the right order, without agonizing over style or grammar choices) Stage 3 – Revising: spend 40% of your time revising, editing, and proofreading (polishing your draft, making sure the content is complete and well supported, ideas flow logically, formatting meets expectations, expression is grammatically correct and has the appropriate tone and vocabulary). These percentages are a helpful guideline, as they emphasize the need to allot significant time for revision, but don’t always work for all people in all situations (think of a final exam situation!). It also does not clearly account for the need to iterate; sometimes while revising your draft (stage 3), you may have to go back to the planning stage (stage 1) to do additional research, adjust your focus, or reorganize ideas to create a more logical flow. Writing, like any kind of design work, demands an organic and dynamic process. As with the design process, the writing process must begin with an understanding of the problem you are trying to solve. In an educational context, this means understanding the assignment you’ve been given, the specifications of that assignment, the objectives you are meant to achieve, and the constraints you must work within (due dates, word limits, research requirements, etc .). This is often referred to as “Task Analysis.” In professional contexts, you must also consider who your intended reader(s) will be, why they will be reading this document, and what their needs are, as well as deadlines and documentation requirements. Image Descriptions Figure 1.5.1 Design Process A design process flow chart that encourages you to revisit previous steps as needed. Define the problem. This involves a needs assessment, problem statement, designing criteria and goals and background research. Generate possible solutions. Brainstorming using the idea trigger method, thumbnail sketching, and creative thinking. At this point, you may need to revisit your problem definition. Once you have a number of possible solutions, move on to the next step. Evaluate possible solutions. Do ideas meet design criteria? List the advantages and disadvantages. Select the best design alternatives. Use a decision matrix to evaluation. At this point, you may need to revisit your problem definition or brainstorm some more. Once you have evaluated possible solutions, move on to the next step. Make and test a model. Create detailed technical drawings, prototype or scale model, mathematical and computer models, Conduct performance and user tests. At this point, you made need to go back to brainstorming solutions or evaluating possible solutions. Once you have a model you are happy with, move on to the next step. Modify and improve design. Fix problems, improve design, do more testing if needed. In the worse case, scrap the design. You may need to go back to evaluating possible solutions to making and testing the model. Once you have a design you are happy with, move on to the next step. Communicate final design. Create final technical drawings, and technical manuals for assembly, operation, and maintenance. [Return to Figure 1.5.1] Figure 1.5.2 Writing Process Diagram A writing process diagram that encourages constantly revisiting previous stages. Prewriting. This stage is for generating ideas, understanding the ideas of others, and collecting information (note taking, free-writing, brainstorming, looping). Planning. Here, you are organizing and focusing ideas. This may involve mind mapping, clustering, listing, and creating outlines. Drafting. In the drafting stage you are writing initial drafts of a text focusing mainly on the development, organization, and elaboration of ideas. Reflection. In the reflection stage, you can let the work sit and come back to it at a later point. You may cycle back between drafting a reflection a number of times before moving on. Peer/tutor review. Now you can get feedback from others. This may require you to return to the drafting and reflecting stages. Revision. Here you are further developing and clarifying ideas and the structure of the text. This may require you to return to the drafting and reflecting stages. If the work requires additional research or idea generation, return to the planning stage. Editing and proofreading. Here the focus is on surface-level features of the text. [Return to Figure 1.5.2] Figure 1.5.1 The Engineering design process by Tufts University. Every attempt has been made to locate the copyright owner. For noncommercial, educational use only. Figure 1.5.2 Writing Process Diagram is from M.J. Curry and A. Hewings “Approaches to teaching writing,” in Teaching Academic Writing: A Toolkit for Higher Education. New York: Routledge, 2003. Used with permission. II 2. Professional Style Chapter 2 \n",
      "-----------\n",
      "This chapter will help you Understand what technical writing is, why its important, and what it looks like\n",
      "Apply a “ problem-solving” approach to communications tasks, starting by learning how to fully define the problem before looking for solutions\n",
      "Recognize the main conventions and characteristics of technical writing, and how they differ from other forms, such as academic and journalistic writing\n",
      "Understand the importance of defining the “ rhetorical situation ” in which you are communicating\n",
      "Apply what you have learned so far by examining “ case studies ” that demonstrate the costs of poor communication\n",
      "Appreciate the complexity and iterative nature of a writing process in determining what writing process works best for you.\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "for thing in merged_df.sample(30).itertuples():\n",
    "    print(thing.lecture)\n",
    "    print(\"-----------\")\n",
    "    print(thing.question_group)\n",
    "    print(\"--------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
